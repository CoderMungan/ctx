{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"The ctx Manifesto","text":"","path":["The ctx Manifesto"],"tags":[]},{"location":"#ctx-manifesto","level":1,"title":"<code>ctx</code> Manifesto","text":"<p>Creation, not code.</p> <p>Context, not prompts.</p> <p>Verification, not vibes.</p> <p>This Is NOT a Metaphor</p> <p>Code executes instructions.</p> <p>Creation produces outcomes.</p> <p>Confusing the two is how teams ship motion...</p> <p>...instead of progress.</p> <ul> <li>It was never about the code.</li> <li>Code has zero standalone value.</li> <li>Code is an implementation detail.</li> </ul> <p>Code is an incantation.</p> <p>Creation is the act.</p> <p>And creation does not happen in a vacuum.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#ctx-is-the-substrate","level":2,"title":"<code>ctx</code> Is the Substrate","text":"<p>Constraints Have Moved</p> <p>Human bandwidth is no longer the limiting factor.</p> <p>Context integrity is.</p> <p>Human bandwidth is no longer the constraint.</p> <p><code>ctx</code> is.</p> <ul> <li>Without durable context, intelligence resets.</li> <li>Without memory, reasoning decays.</li> <li>Without structure, scale collapses.</li> </ul> <p>Creation is now limited by:</p> <ul> <li>Clarity of intent;</li> <li>Quality of context;</li> <li>Rigor of verification.</li> </ul> <p>Not by speed.</p> <p>Not by capacity.</p> <p>Velocity Amplifies</p> <p>Faster execution on broken context compounds error.</p> <p>Speed multiplies whatever is already wrong.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#humans-author-meaning","level":2,"title":"Humans Author Meaning","text":"<p>Intent Is Authored</p> <p>Systems can optimize.</p> <p>Models can generalize.</p> <p>Meaning must be chosen.</p> <p>Intent is not emergent.</p> <p>Vision, goals, and direction are human responsibilities.</p> <p>We decide:</p> <ul> <li>What matters;</li> <li>What success means;</li> <li>What world we are building.</li> </ul> <p><code>ctx</code> encodes the intent so it</p> <ul> <li>survives time,</li> <li>survives handoffs,</li> <li>survives scale.</li> </ul> <p>Nothing important should live only in conversation.</p> <p>Nothing critical should depend on recall.</p> <p>Oral Tradition Does not Scale</p> <p>If intent cannot be inspected, it cannot be enforced.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#ctx-before-action","level":2,"title":"<code>ctx</code> Before Action","text":"<p>Orientation Precedes Motion</p> <p>Acting first and understanding later is not bravery.</p> <p>It is debt.</p> <p>Never act without <code>ctx</code>.</p> <p>Before execution, we must verify:</p> <ul> <li>Where we are;</li> <li>Why we are here;</li> <li>What constraints apply;</li> <li>What assumptions are active.</li> </ul> <p>Action without <code>ctx</code> is gambling.</p> <p>Speed without orientation is noise.</p> <p><code>ctx</code> is not overhead: It is the cost of correctness.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#persistent-context-beats-prompt-memory","level":2,"title":"Persistent Context Beats Prompt Memory","text":"<p>Transience Is the Default Failure Mode</p> <ul> <li>Prompts decay.</li> <li>Chats fragment.</li> <li>Memory heuristics drift.</li> </ul> <p>Prompts are transient.</p> <p>Chats are lossy.</p> <p>Memory heuristics drift.</p> <p><code>ctx</code> must be:</p> <ul> <li>Durable;</li> <li>Structured;</li> <li>Explicit;</li> <li>Queryable.</li> </ul> <p>Intent Must Be Intentional</p> <p>If intent exists only in a prompt... </p> <p>...alignment is already degrading.</p> <p>Knowledge lives in the artifacts:</p> <ul> <li>Decisions;</li> <li>Documentation;</li> <li>Dependency maps;</li> <li>Evaluation history.</li> </ul> <p>Artifacts Outlive Sessions</p> <p>What is not written will be re-learned.</p> <p>At full cost.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#what-ctx-is-not","level":2,"title":"What <code>ctx</code> Is Not","text":"<p>Avoid Category Errors</p> <p>Mislabeling <code>ctx</code> guarantees misuse.</p> <p><code>ctx</code> is not a memory feature.</p> <ul> <li><code>ctx</code> is not prompt engineering.</li> <li><code>ctx</code> is not a productivity hack.</li> <li><code>ctx</code> is not automation theater.</li> </ul> <p><code>ctx</code> is a system for preserving intent under scale.</p> <p><code>ctx</code> is infrastructure.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#verified-reality-is-the-scoreboard","level":2,"title":"Verified Reality Is the Scoreboard","text":"<p>Activity is a False Proxy</p> <p>Output volume correlates poorly with impact.</p> <ul> <li>Code is not progress.</li> <li>Activity is not impact.</li> </ul> <p>The only truth that compounds is verified change. </p> <p>Verified change must exist in the real world.</p> <p>Hypotheses are cheap; outcomes are not.</p> <p><code>ctx</code> captures:</p> <ul> <li>What we expected;</li> <li>What we observed;</li> <li>Where reality diverged.</li> </ul> <p>If we cannot predict, measure, and verify the result...</p> <p>...it does not count.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#build-to-learn-not-to-accumulate","level":2,"title":"Build to Learn, Not to Accumulate","text":"<p>Prototypes Have an Expiration Date</p> <p>A prototype's value is information, not longevity.</p> <p>Prototypes exist to reduce uncertainty.</p> <p>We build to:</p> <ul> <li>Test assumptions;</li> <li>Validate architecture;</li> <li>Answer specific questions.</li> </ul> <p>Not everything.</p> <p>Not blindly.</p> <p>Not permanently.</p> <p><code>ctx</code> records archeology so the cost is paid once.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#failures-are-assets","level":2,"title":"Failures Are Assets","text":"<p>Failure Without Capture is Waste</p> <p>Pain that does not teach is pure loss.</p> <p>Failures are not erased: They are preserved.</p> <p>Each failure becomes:</p> <ul> <li>A documented hypothesis;</li> <li>An analyzed deviation;</li> <li>A permanent artifact.</li> </ul> <p>Rollback fixes symptoms: <code>ctx</code> fixes systems.</p> <p>A repeated mistake is a missing <code>ctx</code> artifact.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#structure-enables-scale","level":2,"title":"Structure Enables Scale","text":"<p>Unbounded Autonomy Destabilizes</p> <p>Power without a structure produces chaos.</p> <p>Transpose it:</p> <p>Power without any structure becomes chaos.</p> <p><code>ctx</code> defines:</p> <ul> <li>Roles;</li> <li>Boundaries;</li> <li>Protocols;</li> <li>Escalation paths;</li> <li>Decision rights.</li> </ul> <p>Ambiguity is a system failure:</p> <ul> <li>Debates must be structured.</li> <li>Decisions must be explicit.</li> <li>History must be retained.</li> </ul>","path":["The ctx Manifesto"],"tags":[]},{"location":"#encode-intent-into-the-environment","level":2,"title":"Encode Intent Into the Environment","text":"<p>Goodwill Does not Belong to the Table</p> <p>Alignment that depends on memory will drift.</p> <p>Alignment cannot depend on memory or goodwill.</p> <p>Do not rely on people to remember.</p> <p>Encode the behavior, so it happens by default.</p> <p>Intent is encoded as:</p> <ul> <li>Policies;</li> <li>Schemas;</li> <li>Constraints;</li> <li>Evaluation harnesses.</li> </ul> <p>Rules must be machine-readable.</p> <p>Laws must be enforceable.</p> <p>If intent is implicit, drift is guaranteed.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#cost-is-a-first-class-signal","level":2,"title":"Cost Is a First-Class Signal","text":"<p>Attention Is the Scarcest Resource</p> <p>Not ideas.</p> <p>Not ambition.</p> <p>Ideas do not compete on time:</p> <p>They compete on cost and impact:</p> <ul> <li>Attention is finite.</li> <li>Compute is finite.</li> <li>Context is expensive.</li> </ul> <p>We continuously ask:</p> <ul> <li>What the most valuable next action is.</li> <li>What outcome justifies the cost.</li> </ul> <p><code>ctx</code> guides allocation.</p> <p>Learning reshapes priority.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#show-the-why","level":2,"title":"Show the Why","text":"<p><code>{}</code> (code, artifacts, apps, binaries) produce outputs;  they do not preserve reasoning.</p> <p>Systems that cannot explain themselves will not be trusted.</p> <p>Traceability builds trust.</p> <pre><code>     {} --&gt; what\n\n    ctx --&gt; why\n</code></pre> <p>We record:</p> <ul> <li>Explored paths;</li> <li>Rejected options;</li> <li>Assumptions made;</li> <li>Evidence used.</li> </ul> <p>Opaque systems erode trust:</p> <p>Transparent <code>ctx</code> compounds understanding.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#continuously-verify-the-system","level":2,"title":"Continuously Verify the System","text":"<p>Stability is Temporary</p> <p>Every assumption has a half-life:</p> <ul> <li>Models drift.</li> <li>Tools change.</li> <li>Assumptions rot.</li> </ul> <p><code>ctx</code> must be verified against reality.</p> <p>Trust is a spectrum.</p> <p>Trust is continuously re-earned:</p> <ul> <li>Benchmarks, </li> <li>regressions, </li> <li>and evaluations... </li> </ul> <p>...are safety rails.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#ctx-is-leverage","level":2,"title":"<code>ctx</code> Is Leverage","text":"<p>Humans are Decision Engines</p> <p>Execution should not consume judgment.</p> <p>Humans must not be typists.</p> <p>We are the authors.</p> <p>Human effort is reserved for:</p> <ul> <li>Judgment;</li> <li>Design;</li> <li>Taste;</li> <li>Synthesis.</li> </ul> <p>Repetition is delegated.</p> <p>Toil is automated.</p> <p><code>ctx</code> preserves leverage across time.</p>","path":["The ctx Manifesto"],"tags":[]},{"location":"#the-thesis","level":2,"title":"The Thesis","text":"<p>Invariant</p> <p>Everything else is an implementation detail.</p> <ul> <li>Creation is the act.</li> <li><code>ctx</code> is the substrate.</li> <li>Verification is the truth.</li> </ul> <p>Code executes → Models reason → Agents amplify.</p> <p><code>ctx</code> lives on.</p> <ul> <li>Without <code>ctx</code>, intelligence resets.</li> <li>With <code>ctx</code>, creation compounds.</li> </ul>","path":["The ctx Manifesto"],"tags":[]},{"location":"blog/","level":1,"title":"Blog","text":"<p>Stories, insights, and lessons learned from building and using <code>ctx</code>.</p>","path":["Blog"],"tags":[]},{"location":"blog/#posts","level":2,"title":"Posts","text":"","path":["Blog"],"tags":[]},{"location":"blog/#the-dog-ate-my-homework-teaching-ai-agents-to-read-before-they-write","level":3,"title":"The Dog Ate My Homework: Teaching AI Agents to Read Before They Write","text":"<p>Jose Alekhinne / February 25, 2026</p> <p>You wrote the playbook. You organized the files. You even put \"CRITICAL, not optional\" in bold. The agent skipped all of it. Five sessions, five failure modes, and the discovery that observable compliance beats perfect compliance: A relay block that works as a compliance canary, a feedback loop where agents read their own prior failure analysis, and the principle that a 30-second read delay is always cheaper than a decision made without context.</p> <p>Topics: hooks, agent behavior, context engineering, behavioral design, testing methodology, compliance monitoring</p>","path":["Blog"],"tags":[]},{"location":"blog/#when-a-system-starts-explaining-itself","level":3,"title":"When a System Starts Explaining Itself","text":"<p>Jose Alekhinne / February 17, 2026</p> <p>Every new substrate begins as a private advantage. Reality begins when other people start describing it in their own language: Not accurately, not consistently, but involuntarily. \"Better than Adderall\" is not praise; it is a diagnostic: Executive function has been externalized. This post collects the first external signals from real users and asks what it means when a system starts explaining itself without its creator present.</p> <p>Topics: field notes, adoption signals, infrastructure vs tools, context engineering, substrates</p>","path":["Blog"],"tags":[]},{"location":"blog/#code-is-cheap-judgment-is-not","level":3,"title":"Code Is Cheap. Judgment Is Not.","text":"<p>Jose Alekhinne / February 17, 2026</p> <p>AI does not replace workers. It replaces unstructured effort. Three weeks of building ctx with an AI agent proved it: YOLO mode showed production is cheap, the 3:1 ratio showed judgment has a cadence, the attention budget showed framing is scarce, and the skill trilogy showed taste is load-bearing. This post threads every previous blog entry into one argument, and ends with a personal note on why that's empowering, not threatening.</p> <p>Topics: AI and expertise, context engineering, judgment vs production, human-AI collaboration, automation discipline</p>","path":["Blog"],"tags":[]},{"location":"blog/#context-as-infrastructure","level":3,"title":"Context as Infrastructure","text":"<p>Jose Alekhinne / February 17, 2026</p> <p>Where does your AI's knowledge live between sessions? If the answer is \"in a prompt I paste at the start,\" you are treating context as a consumable. This post argues for treating it as infrastructure instead: persistent files, separation of concerns, two-tier storage, progressive disclosure, and the filesystem as the most mature interface available. The architectural companion to The Attention Budget and the second piece of the trilogy completed by Code Is Cheap.</p> <p>Topics: context engineering, infrastructure, progressive disclosure, persistence, design philosophy</p>","path":["Blog"],"tags":[]},{"location":"blog/#the-31-ratio","level":3,"title":"The 3:1 Ratio","text":"<p>Jose Alekhinne / February 17, 2026</p> <p>AI-assisted development makes technical debt worse: Not because the AI writes bad code, but because it writes code so fast that drift accumulates before you notice. Three weeks of git history prove a rhythm: three feature sessions, one consolidation session. This post shows the evidence, the concrete drift that accumulated, and the decision matrix for when to clean up versus leave things alone.</p> <p>Topics: consolidation, technical debt, development workflow, convention drift, code quality</p>","path":["Blog"],"tags":[]},{"location":"blog/#parallel-agents-merge-debt-and-the-myth-of-overnight-progress","level":3,"title":"Parallel Agents, Merge Debt, and the Myth of Overnight Progress","text":"<p>Jose Alekhinne / February 17, 2026</p> <p>You discover agents can run in parallel. So you open ten terminals. Then twenty. The fans spin, tokens burn, the screen looks like progress. It is not progress: It is merge debt being manufactured in real time. This post is about the five-agent ceiling, why role separation beats file locking, why overnight loops are an illusion, and why the only metric that matters is time from idea to verified, mergeable change.</p> <p>Topics: agent workflows, parallelism, verification, context engineering, engineering practice</p>","path":["Blog"],"tags":[]},{"location":"blog/#ctx-v060-the-integration-release","level":3,"title":"ctx v0.6.0: The Integration Release","text":"<p>Jose Alekhinne / February 16, 2026</p> <p><code>ctx</code> is now a Claude Marketplace plugin. Two commands, no build step, no shell scripts. <code>v0.6.0</code> replaces six Bash hook scripts with compiled Go subcommands, ships 25+ Skills as a plugin served directly from source, and closes three medium-severity security findings. The version jumped from <code>0.3.0</code> to <code>0.6.0</code> because this is the release that turns a developer tool into a distributable product.</p> <p>Topics: release, plugin system, Claude Marketplace, distribution, security hardening</p>","path":["Blog"],"tags":[]},{"location":"blog/#ctx-v030-the-discipline-release","level":3,"title":"ctx v0.3.0: The Discipline Release","text":"<p>Jose Alekhinne / February 15, 2026</p> <p>No new headline feature. No architectural pivot. No rewrite. Just 35+ documentation and quality commits against ~15 feature commits: And somehow, the tool feels like it grew up overnight. This post is about what a release looks like when the ratio of polish to features is 3:1.</p> <p>Topics: release, skills migration, consolidation, code quality, E/A/R framework</p>","path":["Blog"],"tags":[]},{"location":"blog/#why-zensical","level":3,"title":"Why Zensical","text":"<p>Jose Alekhinne / February 15, 2026</p> <p>I needed a static site generator for the journal system, and the instinct was Hugo:  same language as ctx, fast, well-established. But instinct is not analysis. The journal entries are standard Markdown with YAML frontmatter. That is it. No JSX, no shortcodes, no custom templating. This post is about why <code>zensical</code> (a pre-1.0 tool from the Material for MkDocs team) was the right choice: thin dependencies, MkDocs-compatible config, 4-5x faster incremental rebuilds, and zero lock-in.</p> <p>Topics: tooling, static site generators, journal system, infrastructure decisions, context engineering</p>","path":["Blog"],"tags":[]},{"location":"blog/#parallel-agents-with-git-worktrees","level":3,"title":"Parallel Agents with Git Worktrees","text":"<p>Jose Alekhinne / February 14, 2026</p> <p>I had 30 open tasks, and most of them didn't touch the same files. Running one agent at a time meant serial execution on work that was fundamentally parallel. This post is about using git worktrees to partition a backlog by file overlap, run 3-4 agents simultaneously, and merge the results: The same attention budget principle applied to execution instead of context.</p> <p>Topics: agent teams, parallelism, git worktrees, context engineering, task management</p>","path":["Blog"],"tags":[]},{"location":"blog/#before-context-windows-we-had-bouncers","level":3,"title":"Before Context Windows, We Had Bouncers","text":"<p>Jose Alekhinne / February 14, 2026</p> <p>IRC is stateless. You disconnect, you vanish. Modern systems are not much different: close the tab, lose the scrollback, open a new LLM session, start from zero. This post traces the line from IRC bouncers like ZNC to context engineering: stateless protocols require stateful wrappers, volatile interfaces require durable memory. Before context windows, we had bouncers. Before AI memory files, we had buffers.</p> <p>Topics: context engineering, infrastructure, IRC, persistence, state continuity</p>","path":["Blog"],"tags":[]},{"location":"blog/#how-deep-is-too-deep","level":3,"title":"How Deep Is Too Deep?","text":"<p>Jose Alekhinne / February 12, 2026</p> <p>I kept feeling like I should go deeper into ML theory. Then I spent a week debugging an agent failure that had nothing to do with model architecture and everything to do with knowing which abstraction was leaking. This post is about when depth compounds and when it doesn't: why the useful understanding lives one or two layers below where you work, not at the bottom of the stack.</p> <p>Topics: AI foundations, abstraction boundaries, agentic systems, context engineering, failure modes</p>","path":["Blog"],"tags":[]},{"location":"blog/#defense-in-depth-securing-ai-agents","level":3,"title":"Defense in Depth: Securing AI Agents","text":"<p>Jose Alekhinne / February 9, 2026</p> <p>I was writing the autonomous loops recipe and realized the security advice was \"use <code>CONSTITUTION.md</code> for guardrails.\" Then I read that sentence back and realized: That is wishful thinking. This post traces five defense layers for unattended AI agents, each with a bypass, and shows why the strength is in the combination, not any single layer.</p> <p>Topics: agent security, defense in depth, prompt injection, autonomous loops, container isolation</p>","path":["Blog"],"tags":[]},{"location":"blog/#not-everything-is-a-skill","level":3,"title":"Not Everything Is a Skill","text":"<p>Jose Alekhinne / February 8, 2026</p> <p>I ran an 8-agent codebase audit and got actionable results. The natural instinct was to wrap the prompt as a <code>/ctx-audit</code> skill. Then I applied my own criteria from the skill trilogy: it failed all three tests. This post is about the difference between skills and recipes, why the attention budget applies to your skill library too, and why the best automation decision is sometimes not to automate.</p> <p>Topics: skill design, context engineering, automation discipline, recipes, agent teams</p>","path":["Blog"],"tags":[]},{"location":"blog/#the-anatomy-of-a-skill-that-works","level":3,"title":"The Anatomy of a Skill That Works","text":"<p>Jose Alekhinne / February 7, 2026</p> <p>I had 20 skills. Most were well-intentioned stubs: a description, a command, and a wish for the best. Then I rewrote all of them in a single session. Seven lessons emerged: quality gates prevent premature execution, negative triggers are load-bearing, examples set boundaries better than rules, and skills are contracts, not instructions. The practical companion to the previous two skill design posts.</p> <p>Topics: skill design, context engineering, quality gates, E/A/R framework, practical patterns</p>","path":["Blog"],"tags":[]},{"location":"blog/#you-cant-import-expertise","level":3,"title":"You Can't Import Expertise","text":"<p>Jose Alekhinne / February 5, 2026</p> <p>I found a well-crafted consolidation skill: four files, ten patterns, eight analysis dimensions. Applied my own E/A/R framework: 70% was noise. The template was thorough, correct, and almost entirely useless for my project. This post is about why good skills can't be copy-pasted, and how to grow them from your project's own drift history instead.</p> <p>Topics: skill adaptation, E/A/R framework, convention drift, consolidation, project-specific expertise</p>","path":["Blog"],"tags":[]},{"location":"blog/#skills-that-fight-the-platform","level":3,"title":"Skills That Fight the Platform","text":"<p>Jose Alekhinne / February 4, 2026</p> <p>AI coding agents ship with carefully designed system prompts. When custom skills conflict with those defaults, the AI has to reconcile contradictory instructions: The result is unpredictable. This post catalogues five conflict patterns discovered while building <code>ctx</code>: judgment suppression, redundant guidance, guilt-tripping, phantom dependencies, and universal triggers.</p> <p>Topics: context engineering, skill design, system prompts, antipatterns, AI safety primitives</p>","path":["Blog"],"tags":[]},{"location":"blog/#the-attention-budget-why-your-ai-forgets-what-you-just-told-it","level":3,"title":"The Attention Budget: Why Your AI Forgets What You Just Told It","text":"<p>Jose Alekhinne / February 3, 2026</p> <p>Every token you send to an AI consumes a finite resource: the attention budget. Understanding this constraint shaped every design decision in ctx: hierarchical file structure, explicit budgets, progressive disclosure, and filesystem-as-index. This post explains the theory and how ctx operationalizes it.</p> <p>Topics: attention mechanics, context engineering, progressive disclosure, ctx primitives, token budgets</p>","path":["Blog"],"tags":[]},{"location":"blog/#ctx-v020-the-archaeology-release","level":3,"title":"ctx v0.2.0: The Archaeology Release","text":"<p>Jose Alekhinne / February 1, 2026</p> <p>What if your AI could remember everything? Not just the current session, but every session. <code>ctx v0.2.0</code> introduces the recall and journal systems: making 86 commits of history searchable, exportable, and analyzable.  This post tells the story of why those features exist.</p> <p>Topics: session recall, journal system, structured entries, token budgets, meta-tools</p>","path":["Blog"],"tags":[]},{"location":"blog/#refactoring-with-intent-human-guided-sessions-in-ai-development","level":3,"title":"Refactoring with Intent: Human-Guided Sessions in AI Development","text":"<p>Jose Alekhinne / February 1, 2026</p> <p>The YOLO mode shipped 14 commands in a week. But technical debt  doesn't send invoices:it just waits. This is the story of what happened when  we stopped auto-accepting everything and started guiding the AI with intent:  27 commits across 4 days, a major version release, and lessons that apply far  beyond ctx.</p> <p>Topics: refactoring, code quality, documentation standards, module decomposition, YOLO versus intentional development</p>","path":["Blog"],"tags":[]},{"location":"blog/#building-ctx-using-ctx-a-meta-experiment-in-ai-assisted-development","level":3,"title":"Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development","text":"<p>Jose Alekhinne / January 27, 2026</p> <p>What happens when you build a tool designed to give AI memory, using that very same tool to remember what you're building? This is the story of <code>ctx</code>: how <code>ctx</code> evolved from a hasty \"YOLO\" experiment to a disciplined system  for persistent AI context, and what we learned along the way.</p> <p>Topics: dogfooding, AI-assisted development, Ralph Loop, session persistence, architectural decisions</p>","path":["Blog"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/","level":1,"title":"Building ctx Using ctx","text":"<p>Update (2026-02-11)</p> <p>As of <code>v0.4.0</code>, <code>ctx</code> consolidated sessions into the journal mechanism.</p> <p>References to <code>.context/sessions/</code>, auto-save hooks, and <code>SessionEnd</code> auto-save in this post reflect the architecture at the time of writing.</p> <p></p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#a-meta-experiment-in-ai-assisted-development","level":2,"title":"A Meta-Experiment in AI-Assisted Development","text":"<p>Jose Alekhinne / 2026-01-27</p> <p>Can a Tool Design Itself?</p> <p>What happens when you build a tool designed to give AI memory,  using that very same tool to remember what you are building? </p> <p>This is the story of <code>ctx</code>, how it evolved from a hasty \"YOLO mode\" experiment  to a disciplined system for persistent AI context, and what I have  learned along the way.</p> <p>Context is a Record</p> <p>Context is a persistent record.</p> <p>By \"context\", I don't mean model memory or stored thoughts: </p> <p>I mean the durable record of decisions, learnings, and intent  that normally evaporates between sessions.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#ai-amnesia","level":2,"title":"AI Amnesia","text":"<p>Every developer who works with AI code generators knows the frustration: </p> <p>You have a deep, productive session where the AI understands your codebase,  your conventions, your decisions. And then you close the terminal. </p> <p>Tomorrow; it's a blank slate. The AI has forgotten everything.</p> <p>That is \"reset amnesia\", and it's not just annoying: it's expensive. </p> <p>Every session starts with: </p> <ul> <li>Re-explaining context;</li> <li>Re-reading files; </li> <li>Re-discovering decisions that were already made.</li> </ul> <p>I Needed Context</p> <p>\"I don't want to lose this discussion...</p> <p>...I am a brain-dead developer YOLO'ing my way out.\"</p> <p>☝️ that's exactly what I said to Claude when I first started working on <code>ctx</code>.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-genesis","level":2,"title":"The Genesis","text":"<p>The project started as \"Active Memory\" (<code>amem</code>): a CLI tool to persist AI  context across sessions. </p> <p>The core idea was simple: </p> <ol> <li>Create a <code>.context/</code> directory with structured     Markdown files for decisions, learnings, tasks, and conventions. </li> <li>The AI reads these at session start and writes to them before     the session ends.</li> <li>There is no step 3.</li> </ol> <p>The first commit was just scaffolding. But within hours, the  Ralph Loop (An iterative AI development workflow) had produced a working CLI:</p> <pre><code>feat(cli): implement amem init command\nfeat(cli): implement amem status command\nfeat(cli): implement amem add command\nfeat(cli): implement amem agent command\n...\n</code></pre> <p>Not one, not two, but a whopping fourteen core commands shipped in rapid  succession!</p> <p>I was YOLO'ing like there was no tomorrow:</p> <ul> <li>Auto-accept every change;</li> <li>Let the AI run free;</li> <li>Ship features fast.</li> </ul>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-meta-experiment-using-amem-to-build-amem","level":2,"title":"The Meta-Experiment: Using <code>amem</code> to Build <code>amem</code>","text":"<p>Here's where it gets interesting: On January 20<sup>th</sup>, I asked: </p> <p>\"Can I use <code>amem</code> to help you remember this context when I restart?\"</p> <p>The answer was yes, but with a gap: </p> <p>Autoload worked (via Claude Code's <code>PreToolUse</code> hook), but auto-save was  missing: If the user quit, with Ctrl+C, everything since the last manual save  was lost.</p> <p>That session became the first real test of the system. </p> <p>Here is the first session file we recorded:</p> <pre><code>## Key Discussion Points\n\n### 1. amem vs Ralph Loop - They're Separate Systems\n\n**User's question**: \"How do I use the binary to recreate this project?\"\n\n**Answer discovered**: `amem` is for context management, Ralph Loop is for \ndevelopment workflow. They are complementary but separate.\n\n### 2. Two Tiers of Context Persistence\n\n| Tier      | What                        | Why                           |\n|-----------|-----------------------------|-------------------------------|\n| Curated   | Learnings, decisions, tasks | Quick reload, token-efficient |\n| Full dump | Entire conversation         | Safety net, nothing lost      |\n\n| Where                  |\n|------------------------|\n| .context/*.md          |\n| .context/sessions/*.md |\n</code></pre> <p>This session file (written by the AI to preserve its own context) became the template for how <code>ctx</code> handles session persistence.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-rename","level":2,"title":"The Rename","text":"<p>By January 21<sup>st</sup>, I realized \"Active Memory\" was too generic,  and (arguably) too marketing-smelly. </p> <p>Besides, the binary was already called <code>ctx</code> (short for Context),  the directory was <code>.context/</code>, and the slash commands would be <code>/ctx-*</code>. </p> <p>So it followed that the project should be renamed to <code>ctx</code> to make things  make sense.</p> <p>The rename touched 100+ files but was clean: a find-and-replace with Go's  type system catching any misses.</p> <p>The <code>git</code> history tells the story:</p> <pre><code>0e8f6bb feat: rename amem to ctx and add Claude Code integration\n87dcfa1 README.\n4f0e195 feat: separate orchestrator directive from agent tasks\n</code></pre>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#yolo-mode-fast-but-dangerous","level":2,"title":"YOLO Mode: Fast, But Dangerous","text":"<p>The Ralph Loop made feature development incredibly fast.</p> <p>But it created technical debt that I didn't notice until later.</p> <p>A comparison session on January 25<sup>th</sup> revealed the patterns:</p> YOLO Pattern What We Found <code>\"TASKS.md\"</code> scattered in 10 files Same string literal everywhere, no constants <code>dir + \"/\" + file</code> Should be <code>filepath.Join()</code> Monolithic <code>cli_test.go</code> (1500+ lines) Tests disconnected from implementations <code>package initcmd</code> in <code>init/</code> folder Go's \"init\" is reserved—subtle naming collision <p>Here is another analysis made by <code>ctx</code>:</p> <pre><code>● Based on my analysis, here are the key differences:\n\nYOLO Mode (Pre-040ce99)\n- Feature-first: Added slash commands, tests, templates rapidly\n- Scattered magic strings: \"TASKS.md\", \"decision\", \".context\" spread across files\n- Quick file creation: New files without organizational patterns\n- Working but inconsistent: Code functioned but lacked systematic structure\n\nHuman-Guided Mode (Post-040ce99)\n- Consolidation focus: Centralized constants in config package\n- Consistent naming: Dir, File, Filename, UpdateType prefixes\n- Self-referential constants: FileType map uses constants as keys, not literals\n- Proper path construction: filepath.Join() instead of +\"/\"+\n- Colocated tests: Tests next to implementations\n- Canonical naming: Package name = folder name\n</code></pre> <p>The fix required a human-guided refactoring session. I continued to do that before every major release, from that point on.</p> <p>We introduced <code>internal/config/config.go</code> with semantic prefixes:</p> <pre><code>const (\n    DirContext     = \".context\"\n    DirArchive     = \"archive\"\n    DirSessions    = \"sessions\"\n    FilenameTask   = \"TASKS.md\"\n    UpdateTypeTask = \"task\"\n)\n</code></pre> <p>What I begrudgingly learned was:  YOLO mode is effective for velocity but accumulates debt. </p> <p>So I took a mental note to schedule  periodic consolidation sessions.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-dogfooding-test-that-failed","level":2,"title":"The Dogfooding Test That Failed","text":"<p>On January 21<sup>st</sup>, I ran an experiment: have another Claude instance rebuild  <code>ctx</code> from scratch using only the specs and <code>PROMPT.md</code>. </p> <p>The Ralph Loop ran, all tasks got checked off, the loop exited successfully.</p> <p>But the binary was broken!</p> <p>Commands just printed help text instead of executing. </p> <p>All tasks were marked \"complete\" but the implementation didn't work.</p> <p>Here's what <code>ctx</code> discovered:</p> <pre><code>## Key Findings\n\n### Dogfooding Binary Is Broken\n- Commands don't execute — they just print root help text\n- All tasks were marked complete but binary doesn't work\n- Lesson: \"tasks checked off\" ≠ \"implementation works\"\n</code></pre> <p>This was humbling—to say the least.</p> <p>I realized I had the same blind spot in my own codebase: no integration tests that actually invoked the binary. </p> <p>So I added:</p> <ul> <li>Integration tests for all commands;</li> <li>Coverage targets (60-80% per package)</li> <li>Smoke tests in CI</li> <li>A constitution rule:    \"All code must pass tests before commit\"</li> </ul>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-constitution-versus-conventions","level":2,"title":"The Constitution versus Conventions","text":"<p>As lessons accumulated, there was the temptation to add everything to  <code>CONSTITUTION.md</code> as \"inviolable rules\". </p> <p>But I resisted.</p> <p>The constitution should contain only truly inviolable invariants:</p> <ul> <li>Security (no secrets, no customer data)</li> <li>Quality (tests must pass)</li> <li>Process (decisions need records)</li> <li><code>ctx</code> invocation (always use <code>PATH</code>, never fallback)</li> </ul> <p>Everything else (coding style, file organization, naming  conventions...) should go in to <code>CONVENTIONS.md</code>. </p> <p>Here's how <code>ctx</code> explained why the distinction was important: </p> <p>Decision record, 2026-01-25</p> <p>Overly strict constitution creates friction and gets ignored.</p> <p>Conventions can be bent; constitution cannot.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#hooks-harder-than-they-look","level":2,"title":"Hooks: Harder Than They Look","text":"<p>Claude Code hooks seemed simple: Run a script before/after certain events. </p> <p>But I hit multiple gotchas:</p> <p>1. Key names matter</p> <pre><code>// WRONG - \"Invalid key in record\" error\n\"PreToolUseHooks\": [...]\n\n// RIGHT\n\"PreToolUse\": [...]\n</code></pre> <p>2. Blocking requires specific output</p> <pre><code># WRONG - just exits, doesn't block\nexit 1\n\n# RIGHT - JSON output + exit 0\necho '{\"decision\": \"block\", \"reason\": \"Use ctx from PATH\"}'\nexit 0\n</code></pre> <p>3. Go's JSON escaping</p> <p><code>json.Marshal</code> escapes <code>&gt;</code>, <code>&lt;</code>, <code>&amp;</code> as unicode (<code>\\u003e</code>) by default. </p> <p>When generating shell commands in JSON:</p> <pre><code>encoder := json.NewEncoder(file)\nencoder.SetEscapeHTML(false) // Prevent 2&gt;/dev/null → 2\\u003e/dev/null\n</code></pre> <p>4. Regex overfitting</p> <p>My hook to block non-PATH <code>ctx</code> invocations initially matched too broadly:</p> <pre><code># WRONG - matches /home/user/ctx/internal/file.go (ctx as directory)\n(/home/|/tmp/|/var/)[^ ]*ctx[^ ]*\n\n# RIGHT - matches ctx as binary only\n(/home/|/tmp/|/var/)[^ ]*/ctx( |$)\n</code></pre>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-session-files","level":2,"title":"The Session Files","text":"<p>By the time of this writing this project's <code>ctx</code> sessions  (<code>.context/sessions/</code>) contains 40+ files from this project's development.</p> <p>They are not part of the source code due to security, privacy, and size concerns.</p> <p>Middle Ground: the Scratchpad</p> <p>For sensitive notes that do need to travel with the project, <code>ctx pad</code> stores encrypted one-liners in git, and <code>ctx pad add \"label\" --file PATH</code> can ingest small files.</p> <p>See Scratchpad for details.</p> <p>However, they are invaluable for the project's progress.</p> <p>Each session file is a timestamped Markdown with:</p> <ul> <li>Summary of what has been accomplished;</li> <li>Key decisions made;</li> <li>Learnings discovered;</li> <li>Tasks for the next session;</li> <li>Technical context (platform, versions).</li> </ul> <p>These files are not autoloaded (that would bust the token budget). </p> <p>They are what I see as the \"archaeological record\" of <code>ctx</code>:</p> <p>When the AI needs deeper information about why something was done, it digs into the sessions.</p> <p>Auto-generated session files used a naming convention:</p> <pre><code>2026-01-23-115432-session-prompt_input_exit-summary.md\n2026-01-25-220244-manual-save.md\n2026-01-27-052107-session-other-summary.md\n</code></pre> <p>Update</p> <p>The session feature described here is historical. </p> <p>In current releases, <code>ctx</code> uses a journal instead: the enrichment  process generates meaningful slugs from context automatically, so there  is no need to manually save sessions.</p> <p>The <code>SessionEnd</code> hook captured transcripts automatically. Even <code>Ctrl+C</code> was caught.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-decision-log-18-architectural-decisions","level":2,"title":"The Decision Log: 18 Architectural Decisions","text":"<p><code>ctx</code> helps record every significant architectural choice in  <code>.context/DECISIONS.md</code>. </p> <p>Here are some highlights:</p> <p>Reverse-chronological order (2026-01-27)</p> <pre><code>**Context**: With chronological order, oldest items consume tokens first, and\nnewest (most relevant) items risk being truncated.\n\n**Decision**: Use reverse-chronological order (newest first) for DECISIONS.md\nand LEARNINGS.md.\n</code></pre> <p>PATH over hardcoded paths (2026-01-21)</p> <pre><code>**Context**: Original implementation hardcoded absolute paths in hooks.\nThis breaks when sharing configs with other developers.\n\n**Decision**: Hooks use `ctx` from PATH. `ctx init` checks PATH before \nproceeding.\n</code></pre> <p>Generic core with Claude enhancements (2026-01-20)</p> <pre><code>**Context**: ctx should work with any AI tool, but Claude Code users could\nbenefit from deeper integration.\n\n**Decision**: Keep ctx generic as the core tool, but provide optional\nClaude Code-specific enhancements.\n</code></pre>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-learning-log-24-gotchas-and-insights","level":2,"title":"The Learning Log: 24 Gotchas and Insights","text":"<p>The <code>.context/LEARNINGS.md</code> file captures gotchas that would otherwise be  forgotten. Each has Context, Lesson, and Application sections:</p> <p>CGO on ARM64</p> <pre><code>**Context**: `go test` failed with \n`gcc: error: unrecognized command-line option '-m64'`\n\n**Lesson**: On ARM64 Linux, CGO causes cross-compilation issues. \nAlways use `CGO_ENABLED=0`.\n</code></pre> <p>Claude Code skills format</p> <pre><code>**Lesson**: Claude Code skills are Markdown files in .claude/commands/ with `YAML`\nfrontmatter (*description, argument-hint, allowed-tools*). Body is the prompt.\n</code></pre> <p>\"Do you remember?\" handling</p> <pre><code>**Lesson**: In a `ctx`-enabled project, \"*do you remember?*\" \nhas an obvious meaning:\ncheck the `.context/` files. Don't ask for clarification—just do it.\n</code></pre>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#task-archives-the-completed-work","level":2,"title":"Task Archives: The Completed Work","text":"<p>Completed tasks are archived to <code>.context/archive/</code> with timestamps. </p> <p>The archive from January 23<sup>rd</sup> shows 13 phases of work:</p> <ul> <li>Phase 1: Project Scaffolding (Go module, Cobra CLI)</li> <li>Phase 2-4: Core Commands    (init, status, agent, add, complete, drift, sync, compact, watch, hook)</li> <li>Phase 5: Session Management (save, list, load, parse, --extract)</li> <li>Phase 6: Claude Code Integration (hooks, settings, CLAUDE.md handling)</li> <li>Phase 7: Testing &amp; Verification</li> <li>Phase 8: Task Archival</li> <li>Phase 9: Slash Commands</li> <li>Phase 9b: Ralph Loop Integration</li> <li>Phase 10: Project Rename</li> <li>Phase 11: Documentation</li> <li>Phase 12: Timestamp Correlation</li> <li>Phase 13: Rich Context Entries</li> </ul> <p>That's an impressive ^^173 commits** across 8 days of development.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#what-i-learned-about-ai-assisted-development","level":2,"title":"What I Learned About AI-Assisted Development","text":"<p>1. Memory changes everything</p> <p>When the AI remembers decisions, it doesn't repeat mistakes. </p> <p>When the AI knows your conventions, it follows them. </p> <p><code>ctx</code> makes the AI a better collaborator because it's not starting from zero.</p> <p>2. Two-tier persistence works</p> <p>Curated context (<code>DECISIONS.md</code>, <code>LEARNINGS.md</code>, <code>TASKS.md</code>) is for  quick reload. </p> <p>Full session dumps are for archaeology. </p> <p>It's a futile effort to try to fit everything in the token budget.</p> <p>Persist more, load less.</p> <p>3. YOLO mode has its place</p> <p>For rapid prototyping, letting the AI run free is effective. </p> <p>But I had to schedule  consolidation sessions.</p> <p>Technical debt accumulates silently.</p> <p>4. The constitution should be small</p> <p>Only truly inviolable rules go in <code>CONSTITUTION.md</code>.  Everything else is a convention. </p> <p>If you put too much in the constitution, it will get ignored.</p> <p>5. Verification is non-negotiable</p> <p>\"All tasks complete\" means nothing if you haven't run the tests. </p> <p>Integration tests that invoke the actual binary caught bugs that  the unit tests missed.</p> <p>6. Session files are underrated</p> <p>The ability to grep through 40 session files and find exactly when and why a  decision was made helped me a lot. </p> <p>It's not about loading them into context: It is about having them  when you need them.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-future-recall-system","level":2,"title":"The Future: Recall System","text":"<p>The next phase of <code>ctx</code> is the Recall System:</p> <ul> <li>Parser: Parse session capture markdowns, enrich with JSONL data</li> <li>Renderer: Goldmark + Chroma for syntax highlighting, dark mode UI</li> <li>Server: Local HTTP server for browsing sessions</li> <li>Search: Inverted index for searching across sessions</li> <li>CLI: <code>ctx recall serve &lt;path&gt;</code> to start the server</li> </ul> <p>The goal is to make the archaeological record browsable—not just <code>grep</code>-able.</p> <p>Because not everyone always lives in the terminal (me included).</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#conclusion","level":2,"title":"Conclusion","text":"<p>Building <code>ctx</code> using ctx was a meta-experiment in AI-assisted development. </p> <p>I learned that memory isn't just convenient: It's transformative:</p> <ul> <li>An AI that remembers your decisions doesn't repeat mistakes.</li> <li>An AI that knows your conventions doesn't need them re-explained.</li> </ul> <p>If you are reading this, chances are that you already have heard about <code>ctx</code>.</p> <ul> <li><code>ctx</code> is open source at  github.com/ActiveMemory/ctx,</li> <li>and the documentation lives at ctx.ist.</li> </ul> <p>Session Records are a Gold Mine</p> <p>By the time of this writing, I have more than 70 megabytes of text-only session capture, spread across &gt;100 Markdown and <code>JSONL</code> files.</p> <p>I am analyzing, synthesizing, encriching them with AI, running RAG (Retrieval-Augmented Generation) models on them, and the outcome surprises me every day.</p> <p>If you are a mere mortal tired of reset amnesia, give <code>ctx</code> a try. </p> <p>And when you do, check <code>.context/sessions/</code> sometime. </p> <p>The archaeological record might surprise you.</p> <p>This blog post was written with the help of <code>ctx</code> with full access to the  <code>ctx</code> session files, decision log, learning log, task archives, and  git history of <code>ctx</code>—The meta continues.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/","level":1,"title":"ctx v0.2.0: The Archaeology Release","text":"<p>Update (2026-02-11)</p> <p>As of <code>v0.4.0</code>, <code>ctx</code> consolidated sessions into the journal mechanism.</p> <p>The <code>.context/sessions/</code> directory referenced in this post has been eliminated. Session history is now accessed via <code>ctx recall</code> and enriched journals live in <code>.context/journal/</code>.</p> <p></p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#digging-through-the-past-to-build-the-future","level":2,"title":"Digging Through the Past to Build the Future","text":"<p>Jose Alekhinne / 2026-02-01</p> <p>What if Your AI Could Remember Everything?</p> <p>Not just the current session, but every session:</p> <ul> <li>Every decision made,</li> <li>every mistake avoided, </li> <li>every path not taken.</li> </ul> <p>That's what v0.2.0 delivers.</p> <p>Between <code>v0.1.2</code> and <code>v0.2.0</code>, 86 commits landed across 5 days. </p> <p>The release notes list features and fixes. </p> <p>This post tells the story of why those features exist, and what  building them taught me.</p> <p>This isn't a changelog: It is an explanation of intent.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-problem-amnesia-isnt-just-session-level","level":2,"title":"The Problem: Amnesia Isn't Just Session-Level","text":"<p><code>v0.1.0</code> solved reset amnesia: </p> <p>The AI now remembers decisions, learnings, and tasks across sessions. </p> <p>But a new problem emerged, which I can sum up as: </p> <p>\"I (the human) am not AI.\"</p> <p>Frankly, I couldn't remember what the AI remembered.</p> <p>Let alone, I cannot remember what I ate for breakfast!</p> <p>In the course of days, I realized session transcripts piled up in  <code>.context/sessions/</code>; I was <code>grep</code>ping, <code>JSONL</code> files with thousands of lines... Raw tool calls, assistant responses, user messages...</p> <p>...all interleaved. </p> <p>Valuable context was effectively buried in machine-readable noise.</p> <p>I found myself grepping through files to answer questions like:</p> <ul> <li>\"When did we decide to use constants instead of literals?\"</li> <li>\"What was the session where we fixed the hook regex?\"</li> <li>\"How did the <code>embed.go</code> split actually happen?\"</li> </ul> <p>Fate is Whimsical</p> <p>The irony was painful:</p> <p>I built a tool to prevent AI amnesia, but I was suffering from  human amnesia about what happened in AI sessions.</p> <p>This was the moment <code>ctx</code> stopped being just an AI tool and started needing to support the human on the other side of the loop.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-solution-recall-and-journal","level":2,"title":"The Solution: Recall and Journal","text":"<p><code>v0.2.0</code> introduces two interconnected systems.</p> <p>They solve different problems and only work well together.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#ctx-recall-browse-your-past","level":3,"title":"<code>ctx recall</code>: Browse Your Past","text":"<pre><code># List all sessions for this project\nctx recall list\n\n# Show a specific session\nctx recall show gleaming-wobbling-sutherland\n\n# See the full transcript\nctx recall show gleaming-wobbling-sutherland --full\n````\n\nThe `recall` system parses Claude Code's `JSONL` transcripts and presents\nthem in a human-readable format:\n\n| Session                       | Date       | Turns | Duration |\n|-------------------------------|------------|-------|----------|\n| tender-painting-sundae        | 2026-01-29 | 3     | &lt;1m      |\n| crystalline-gliding-willow    | 2026-01-29 | 3     | &lt;1m      |\n| declarative-hugging-snowglobe | 2026-01-31 | 2     | &lt;1m      |\n\nSlugs are auto-generated from session IDs (*memorable names instead of\nUUIDs*). The goal (*as the name implies*) is **recall**, not archival accuracy.\n\n!!! note \"2,121 lines of new code\"\n    The `ctx recall` feature was the largest single addition:\n\n    parser library, CLI commands, test suite, and slash command.\n\n### `ctx journal`: From Raw to Rich\n\nListing sessions isn't enough. The transcripts are still unwieldy.\n\n* **Recall** answers *what happened*.\n* **Journal** answers *what mattered*.\n\n```bash\n# Export sessions to editable Markdown\nctx recall export --all\n\n# Generate a static site from journal entries\nctx journal site\n\n# Serve it locally\nctx serve\n</code></pre> <p>The exported files land in <code>.context/journal/</code>:</p> <pre><code>.context/journal/\n├── 2026-01-28-proud-sleeping-cook-6e535360.md\n├── 2026-01-29-tender-painting-sundae-b14ddaaa.md\n├── 2026-01-29-crystalline-gliding-willow-ff7fd67d.md\n└── 2026-01-31-declarative-hugging-snowglobe-4549026d.md\n</code></pre> <p>Each file is a structured Markdown document ready for enrichment.</p> <p>They are meant to be read, edited, and reasoned about;  not just stored.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-meta-slash-commands-for-self-analysis","level":2,"title":"The Meta: Slash Commands for Self-Analysis","text":"<p>The journal system includes four slash commands that use Claude to analyze and synthesize session history:</p> Command Purpose <code>/ctx-journal-enrich</code> Add frontmatter, topics, tags <code>/ctx-blog</code> Generate blog post from activity <code>/ctx-blog-changelog</code> Generate changelog from commits <p>This very post was drafted using <code>/ctx-blog</code>. The previous post about refactoring was drafted the same way.</p> <p>So, yes: The meta continues: <code>ctx</code> now helps write posts about <code>ctx</code>.</p> <p>With the current release, <code>ctx</code> is no longer just recording history: </p> <p>It is participating in its interpretation.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-structure-decisions-as-first-class-citizens","level":2,"title":"The Structure: Decisions as First-Class Citizens","text":"<p><code>v0.1.0</code> let you add decisions with a simple command:</p> <pre><code>ctx add decision \"Use PostgreSQL\"\n</code></pre> <p>But sessions showed a pattern: decisions added this way were incomplete:</p> <ul> <li>Context was missing;</li> <li>Rationale was vague; </li> <li>Consequences were never stated.</li> </ul> <p>Once recall and journaling existed, this weakness became impossible to ignore: </p> <p>Structure stopped being optional.</p> <p><code>v0.2.0</code> enforces structure:</p> <pre><code>ctx add decision \"Use PostgreSQL\" \\\n  --context \"Need a reliable database for user data\" \\\n  --rationale \"ACID compliance, team familiarity, strong ecosystem\" \\\n  --consequences \"Need to set up connection pooling, team training\"\n</code></pre> <p>All three flags are required. No more placeholder text. </p> <p>Every decision is now a proper Architecture Decision Record (*ADR), not a note.</p> <p>The same enforcement applies to learnings too:</p> <pre><code>ctx add learning \"CGO breaks ARM64 builds\" \\\n  --context \"go test failed with gcc errors on ARM64\" \\\n  --lesson \"Always use CGO_ENABLED=0 for cross-platform builds\" \\\n  --application \"Added to Makefile and CI config\"\n</code></pre> <p>Structured entries are prompts to the AI</p> <p>When the AI reads a decision with full context, rationale, and consequences, it understands the why, not just the what.</p> <p>One-liners teach nothing.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-order-newest-first","level":2,"title":"The Order: Newest First","text":"<p>A subtle but important change: <code>DECISIONS.md</code> and <code>LEARNINGS.md</code> now use reverse-chronological order.</p> <p>One reason is token budgets, obviously; another reason is to help your fellow human (i.e., the Author): </p> <p>Earlier decisions are more likely to be relevant, and they are more likely to have more emphasis on the project. So it follows that they should be read first.</p> <p>But back to AI:</p> <p>When the AI reads a file, it reads from the top (and seldom from the bottom). </p> <p>If the token budget is tight, old content gets truncated.  As in any good engineering practice, it's always about the tradeoffs.</p> <p>Reverse order ensures the most recent—and most relevant—context is always loaded first.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-index-quick-reference-tables","level":2,"title":"The Index: Quick Reference Tables","text":"<p><code>DECISIONS.md</code> and <code>LEARNINGS.md</code> now include auto-generated indexes.</p> <ul> <li>For AI agents, the index allows scanning without reading full entries.</li> <li>For humans, it's a table of contents.</li> </ul> <p>The same structure serves two very different readers.</p> <p>Reindex after manual edits</p> <p>If you edit entries by hand, rebuild the index with:</p> <pre><code>ctx decisions reindex\nctx learnings reindex\n</code></pre> <p>See the Knowledge Capture recipe for details.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-configuration-contextrc","level":2,"title":"The Configuration: <code>.contextrc</code>","text":"<p>Projects can now customize ctx behavior  via <code>.contextrc</code>.</p> <p>This makes ctx usable in real teams, not just personal projects.</p> <p>Priority order: CLI flags &gt; environment variables &gt; <code>.contextrc</code> &gt;  sensible defaults</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-flags-global-cli-options","level":2,"title":"The Flags: Global CLI Options","text":"<p>Three new global flags work with any command.</p> <p>These enable automation: </p> <p>CI pipelines, scripts, and long-running tools can now integrate  <code>ctx</code> without hacks or workarounds.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-refactoring-under-the-hood","level":2,"title":"The Refactoring: Under the Hood","text":"<p>These aren't user-visible changes.</p> <p>They are the kind of work you only appreciate later, when everything else becomes easier to build.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#what-we-learned-building-v020","level":2,"title":"What We Learned Building v0.2.0","text":"","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#1-raw-data-isnt-knowledge","level":3,"title":"1. Raw Data Isn't Knowledge","text":"<p><code>JSONL</code> transcripts contain everything, and I mean \"everything\":</p> <p>They even contain hidden system messages that Anthropic injects to the LLM's conversation to treat humans better: It's immense.</p> <p>But \"everything\" isn't useful until it is transformed into something a human can reason about.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#2-enforcement-documentation","level":3,"title":"2. Enforcement &gt; Documentation","text":"<p>The Prompt is a Guideline</p> <p>The code is more what you'd call 'guidelines' than actual rules.</p> <p>—Hector Barbossa</p> <p>Rules written in Markdown are suggestions.</p> <p>Rules enforced by the CLI shape behavior; both for humans and AI.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#3-token-budget-is-ux","level":3,"title":"3. Token Budget Is UX","text":"<p>File order decides what the AI sees.</p> <p>That makes it a user experience concern, not an implementation detail.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#4-meta-tools-compound","level":3,"title":"4. Meta-Tools Compound","text":"<p>Tools that analyze their own development tend to generalize well.</p> <p>The journal system started as a way to understand <code>ctx</code> itself.</p> <p>It immediately became useful for everything else.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#v020-in-the-numbers","level":2,"title":"v0.2.0 in The Numbers","text":"<p>This was a heavy release. The numbers reflect that:</p> Metric v0.1.2 v0.2.0 Commits since last - 86 New commands 15 21 Slash commands 7 11 Lines of Go ~6,500 ~9,200 Session files (this project) 40 54 <p>The binary grew. The capability grew more.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#whats-next","level":2,"title":"What's Next","text":"<p>But those are future posts.</p> <p>This one was about making the past usable.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#get-started","level":2,"title":"Get Started","text":"<p>Update</p> <p>Since this post, <code>ctx</code> became a first-class Claude Code Marketplace plugin. Installation is now simpler. </p> <p>See the Getting Started guide for the  current instructions.</p> <pre><code>make build\nsudo make install\nctx init\n</code></pre> <p>The Archaeological Record</p> <p><code>v0.2.0</code> is the archaeology release because it makes the past accessible.</p> <p>Session transcripts aren't just logs anymore: They are a searchable, exportable, analyzable record of how your project evolved.</p> <p>The AI remembers. Now you can too.</p> <p>This blog post was generated with the help of <code>ctx</code> using the <code>/ctx-blog</code> slash command, with full access to git history, session files, decision logs, and learning logs from the v0.2.0 development window.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/","level":1,"title":"Refactoring with Intent","text":"","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#human-guided-sessions-in-ai-development","level":2,"title":"Human-Guided Sessions in AI Development","text":"<p>Jose Alekhinne / 2026-02-01</p> <p>What Happens When You Slow Down?</p> <p>YOLO mode shipped 14 commands in a week. </p> <p>But technical debt doesn't send invoices: It just waits.</p> <p>This is the story of what happened when I stopped auto-accepting everything and started guiding the AI with intent. </p> <p>The result: 27 commits across 4 days, a major version release, and  lessons that apply far beyond <code>ctx</code>.</p> <p>The Refactoring Window</p> <p>January 28 - February 1, 2026</p> <p>From commit <code>bb1cd20</code> to the v0.2.0 release merge. (this window matters more than the individual commits: it's where intent replaced velocity.)</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-velocity-trap","level":2,"title":"The Velocity Trap","text":"<p>In the previous post, I documented the \"YOLO mode\" that birthed <code>ctx</code>: auto-accept everything, let the AI run free, ship features fast.</p> <p>It worked: until it didn't.</p> <p>The codebase had accumulated patterns I didn't notice during the sprint:</p> YOLO Pattern Where Found Why It Hurts <code>\"TASKS.md\"</code> as literal 10+ files One typo = silent failure <code>dir + \"/\" + file</code> Path construction Breaks on Windows Monolithic <code>embed.go</code> 150+ lines, 5 concerns Untestable, hard to extend Inconsistent docstrings Everywhere AI can't learn project conventions <p>I didn't see these during \"YOLO mode\" because, honestly, I wasn't looking.</p> <p>Auto-accept means auto-ignore.</p> <p>In YOLO mode, every file you open looks fine until you try to change it.  </p> <p>In contrast, refactoring mode is when you start paying attention to that  hidden friction.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-shift-from-velocity-to-intent","level":2,"title":"The Shift: From Velocity to Intent","text":"<p>On January 28<sup>th</sup>, I changed the workflow:</p> <ol> <li>Read every diff before accepting.</li> <li>Ask \"why this way?\" before committing.</li> <li>Document patterns, not just features.</li> </ol> <p>The first commit of this era was telling:</p> <pre><code>feat: add structured attributes to context. update XML format\n</code></pre> <p>Not a new feature: A refinement:</p> <p>The <code>XML</code> format for context updates needed <code>type</code> and <code>timestamp</code> attributes. </p> <p>YOLO mode would have shipped something that worked. Intentional mode asked:  </p> <p>\"What does well-structured look like?\"</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-decomposition-embedgo","level":2,"title":"The Decomposition: <code>embed.go</code>","text":"<p>The most satisfying refactor was splitting <code>internal/claude/embed.go</code>.</p> <p>Before: One 153-line file doing five things:</p> <ul> <li>Command registration</li> <li>Hook generation</li> <li>Permission handling</li> <li>Script templates</li> <li>Type definitions</li> </ul> <p>... your \"de facto\" God object.</p> <p>After: Five focused modules:</p> File Lines Responsibility <code>cmd.go</code> 46 Command registration <code>hook.go</code> 64 Hook configuration <code>perm.go</code> 25 Permission handling <code>script.go</code> 47 Script templates <code>types.go</code> 7 Type definitions <p>The refactor also renamed functions to follow Go conventions:</p> <pre><code>// Before: unnecessary prefixes\nGetAutoSaveScript()\nGetBlockNonPathCtxScript()\nListCommands()\nCreateDefaultHooks()\n\n// After: idiomatic Go\nAutoSaveScript()\nBlockNonPathCtxScript()\nCommands()\nDefaultHooks()\n</code></pre> <p>This wasn't about character count. It was about teaching the AI what good Go looks like in this project.</p> <p>Project Conventions</p> <p>What I wanted from AI was to understand and follow the project's  conventions, and trust the author.</p> <p>The next time it generates code, it has better examples to learn from.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-documentation-debt","level":2,"title":"The Documentation Debt","text":"<p>YOLO mode created features. It didn't create documentation standards.</p> <p>The January 29<sup>th</sup> sessions focused on standardization.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#terminology-fixes","level":3,"title":"Terminology Fixes","text":"<ul> <li>\"context-update\" → \"entry\" (what users actually call them)</li> <li>Consistent naming across CLI, docs, and code comments</li> </ul>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#go-docstrings","level":3,"title":"Go Docstrings","text":"<pre><code>// Before: inconsistent or missing\nfunc Parse(s string) Entry { ... }\n\n// After: standardized sections\n\n// Parse extracts an entry from a markdown string.\n//\n// Parameters:\n//   - s: The markdown string to parse\n//\n// Returns:\n//   - Entry with populated fields, or zero value if parsing fails\nfunc Parse(s string) Entry { ... }\n</code></pre> <p>This is intentionally more structured than typical GoDoc:</p> <p>It serves as documentation and doubles as training data for future  AI-generated code.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#cli-output-convention","level":3,"title":"CLI Output Convention","text":"<pre><code>All CLI output follows: [emoji] [Title]: [message]\n\nExamples:\n  ✓ Decision added: Use symbolic types for entry categories\n  ⚠ Warning: No tasks found\n  ✗ Error: File not found\n</code></pre> <p>A consistent output shape makes both human scanning and  AI reasoning more reliable.</p> <p>These aren't exciting commits. But they are force multipliers:</p> <p>Every future AI session now has better examples to follow.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-journal-system","level":2,"title":"The Journal System","text":"<p>If you only read one section, read this one:</p> <p>This is where v0.2.0 becomes more than a refactor.</p> <p>The biggest feature of this change window wasn't a refactor; it was the journal system.</p> <p>45 files changed, 1680 insertions</p> <p>This commit added the infrastructure for synthesizing AI session history into human-readable content.</p> <p>The journal system includes:</p> Component Purpose <code>ctx recall export</code> Export sessions to markdown in <code>.context/journal/</code> <code>ctx journal site</code> Generate static site from journal entries <code>ctx serve</code> Convenience wrapper for the static site server <code>/ctx-journal-enrich</code> Slash command to add frontmatter and tags <code>/ctx-blog</code> Generate blog posts from recent activity <code>/ctx-blog-changelog</code> Generate changelog-style blog posts <p>...and the meta continues: this blog post was generated using <code>/ctx-blog</code>.</p> <p>The session history from January 28–31 was </p> <ul> <li>exported, </li> <li>enriched,</li> <li>and synthesized </li> </ul> <p>into the narrative you are reading.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-constants-consolidation","level":2,"title":"The Constants Consolidation","text":"<p>The final refactoring session addressed the remaining magic strings:</p> <pre><code>const (\n    // Comment markers\n    CommentOpen  = \"&lt;!--\"\n    CommentClose = \"--&gt;\"\n\n    // Index markers\n    MarkerIndexStart = \"&lt;!-- INDEX:START --&gt;\"\n    MarkerIndexEnd   = \"&lt;!-- INDEX:END --&gt;\"\n\n    // Newlines\n    NewlineLF   = \"\\n\"\n    NewlineCRLF = \"\\r\\n\"\n)\n</code></pre> <p>The work also introduced thread safety in the recall parser and centralized shared validation logic; removing duplication that had quietly spread during YOLO mode.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#i-relearned-my-lessons","level":2,"title":"I (Re)learned My Lessons","text":"<p>Similar to what I've learned in  the former human-assisted refactoring post, this journey also made me realize that \"AI-only code generation\" isn't sustainable in the long term.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#1-velocity-and-quality-arent-opposites","level":3,"title":"1. Velocity and Quality Aren't Opposites","text":"<p>YOLO mode has its place: for prototyping, exploration, and discovery.</p> <p>BUT (and it's a huge \"but\"), it needs to be followed by  consolidation sessions.</p> <p>The ratio that worked for me: 3:1.</p> <ul> <li>Three YOLO sessions create enough surface area to reveal patterns;</li> <li>the fourth session turns those patterns into structure.</li> </ul>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#2-documentation-is-code","level":3,"title":"2. Documentation IS Code","text":"<p>When I standardized docstrings, I wasn't just writing docs. I was training future AI sessions.</p> <p>Every example of good code becomes a template for generated code.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#3-decomposition-deletion","level":3,"title":"3. Decomposition &gt; Deletion","text":"<p>When <code>embed.go</code> became unwieldy, the temptation was to remove functionality.</p> <p>The right answer was decomposition:</p> <ul> <li>Same functionality;</li> <li>Better organization;</li> <li>Easier to test;</li> <li>Easier to extend.</li> </ul> <p>The result: more lines overall, but dramatically better structure.</p> <p>The AI Benefit</p> <p>Smaller, focused files also help AI assistants. </p> <p>When a file fits comfortably in the context window, the AI can  reason about it completely instead of working from truncated snippets, preserving token budget for the actual task.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#4-meta-tools-pay-dividends","level":3,"title":"4. Meta-Tools Pay Dividends","text":"<p>The journal system took almost a full day to implement.</p> <p>Yet it paid for itself immediately:</p> <ul> <li>This blog post was generated from session history;</li> <li>Future posts will be easier;</li> <li>The archaeological record is now browsable, not just <code>grep</code>-able.</li> </ul>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-release-v020","level":2,"title":"The Release: v0.2.0","text":"<p>The refactoring window culminated in the v0.2.0 release.</p> <p>What's in v0.2.0:</p> Category Changes Features Journal system, quick reference indexes, global flags Refactors Module decomposition, constants consolidation, CRLF handling Docs Standardized terminology, Go docstrings, CLI conventions Quality Thread safety, shared validation, linter fixes <p>The version bump was symbolic.</p> <p>The real change was how the codebase felt.</p> <p>Opening files no longer triggered the familiar \"ugh, I need to clean this up\" reaction.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-meta-continues","level":2,"title":"The Meta Continues","text":"<p>This post was written using the tools built during this refactoring window:</p> <ol> <li>Session history exported via <code>ctx recall export</code>;</li> <li>Journal entries enriched via <code>/ctx-journal-enrich</code>;</li> <li>Blog draft generated via <code>/ctx-blog</code>;</li> <li>Final editing done (by yours truly), with full project context loaded.</li> </ol> <p>The Context Is Massive</p> <p>The <code>ctx</code> session files now contain 50+ development snapshots: each one capturing decisions, learnings, and intent.</p> <p>The Moral of the Story</p> <ul> <li>YOLO mode builds the prototype.</li> <li>Intentional mode builds the product.</li> </ul> <p>Schedule both, or you'll only get one, if you're lucky.</p> <p>This blog post was generated with the help of <code>ctx</code>, using session history, decision logs, learning logs, and git history from the refactoring window. The meta continues.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/","level":1,"title":"The Attention Budget","text":"<p>Update (2026-02-11)</p> <p>As of <code>v0.4.0</code>, <code>ctx</code> consolidated sessions into the journal mechanism.</p> <p>References to <code>.context/sessions/</code> in this post reflect the architecture at the time of writing. Session history is now accessed via <code>ctx recall</code> and stored in <code>.context/journal/</code>.</p> <p></p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#why-your-ai-forgets-what-you-just-told-it","level":2,"title":"Why Your AI Forgets What You Just Told It","text":"<p>Jose Alekhinne / 2026-02-03</p> <p>Ever Wondered Why AI Gets Worse the Longer You Talk?</p> <p>You paste a 2000-line file, explain the bug in detail, provide three examples...</p> <p>...and the AI still suggests a fix that ignores half of what you said.</p> <p>This isn't a bug. It is physics.</p> <p>Understanding that single fact shaped every design decision behind <code>ctx</code>.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#the-finite-resource-nobody-talks-about","level":2,"title":"The Finite Resource Nobody Talks About","text":"<p>Here's something that took me too long to internalize: context is not free.</p> <p>Every token you send to an AI model consumes a finite resource I call the attention budget.</p> <p>Attention budget is real.</p> <p>The model doesn't just read tokens; it forms relationships between them: </p> <p>For <code>n</code> tokens, that's roughly <code>n^2</code> relationships. </p> <p>Double the context, and the computation quadruples.</p> <p>But the more important constraint isn't cost: It's attention density.</p> <p>Attention Density</p> <p>Attention density is how much focus each token receives relative to all other tokens in the context window.</p> <p>As context grows, attention density drops: Each token gets a smaller slice of the model's focus. Nothing is ignored; but everything becomes blurrier.</p> <p>Think of it like a flashlight: In a small room, it illuminates everything clearly. In a warehouse, it becomes a dim glow that barely reaches the corners.</p> <p>This is why <code>ctx agent</code> has an explicit <code>--budget</code> flag:</p> <pre><code>ctx agent --budget 4000 # Force prioritization\nctx agent --budget 8000 # More context, lower attention density\n</code></pre> <p>The budget isn't just about cost: It's about preserving signal.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#the-middle-gets-lost","level":2,"title":"The Middle Gets Lost","text":"<p>This one surprised me.</p> <p>Research shows that transformer-based models tend to attend more strongly to the beginning and end of a context window than to its middle (a phenomenon often called  \"lost in the middle\")<sup>1</sup>.</p> <p>Positional anchors matter, and the middle has fewer of them.</p> <p>In practice, this means that information placed \"somewhere in the middle\" is statistically less salient, even if it's important.</p> <p><code>ctx</code> orders context files by logical progression: What the agent needs to know before it can understand the next thing:</p> <ol> <li><code>CONSTITUTION.md</code>: Constraints before action.</li> <li><code>TASKS.md</code>: Focus before patterns.</li> <li><code>CONVENTIONS.md</code>: How to write before where to write.</li> <li><code>ARCHITECTURE.md</code>: Structure before history.</li> <li><code>DECISIONS.md</code>: Past choices before gotchas.</li> <li><code>LEARNINGS.md</code>: Lessons before terminology.</li> <li><code>GLOSSARY.md</code>: Reference material.</li> <li><code>AGENT_PLAYBOOK.md</code>: Meta instructions last.</li> </ol> <p>This ordering is about logical dependencies, not attention engineering. But it happens to be attention-friendly too:</p> <p>The files that matter most—CONSTITUTION, TASKS, CONVENTIONS—land at the beginning of the context window, where attention is strongest.</p> <p>Reference material like GLOSSARY sits in the middle, where lower salience is acceptable.</p> <p>And AGENT_PLAYBOOK, the operating manual for the context system itself, sits at the end, also outside the \"lost in the middle\" zone. The agent reads what to work with before learning how the system works.</p> <p>This is <code>ctx</code>'s first primitive: hierarchical importance.</p> <p>Not all context is equal.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#ctx-primitives","level":2,"title":"<code>ctx</code> Primitives","text":"<p><code>ctx</code> is built on four primitives that directly address the attention budget problem.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#primitive-1-separation-of-concerns","level":3,"title":"Primitive 1: Separation of Concerns","text":"<p>Instead of a single mega-document, <code>ctx</code> uses separate files for separate purposes:</p> File Purpose Load When CONSTITUTION.md Inviolable rules Always TASKS.md Current work Session start CONVENTIONS.md How to write code Before coding ARCHITECTURE.md System structure Before making changes DECISIONS.md Architectural choices When questioning approach LEARNINGS.md Gotchas When stuck GLOSSARY.md Domain terminology When clarifying terms AGENT_PLAYBOOK.md Operating manual Session start sessions/ Deep history On demand journal/ Session journal On demand <p>This isn't just \"organization\": It is progressive disclosure.</p> <p>Load only what's relevant to the task at hand. Preserve attention density.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#primitive-2-explicit-budgets","level":3,"title":"Primitive 2: Explicit Budgets","text":"<p>The <code>--budget</code> flag forces a choice:</p> <pre><code>ctx agent --budget 4000\n</code></pre> <p>Here is a sample allocation:</p> <pre><code>Constitution: ~200 tokens (never truncated)\nTasks: ~500 tokens (current phase, up to 40% of budget)\nConventions: ~800 tokens (all items, up to 20% of budget)\nDecisions: ~400 tokens (scored by recency and task relevance)\nLearnings: ~300 tokens (scored by recency and task relevance)\nAlso noted: ~100 tokens (title-only summaries for overflow)\n</code></pre> <p>The constraint is the feature: It enforces ruthless prioritization.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#primitive-3-indexes-over-full-content","level":3,"title":"Primitive 3: Indexes Over Full Content","text":"<p><code>DECISIONS.md</code> and <code>LEARNINGS.md</code> both include index sections:</p> <pre><code>&lt;!-- INDEX:START --&gt;\n| Date       | Decision                            |\n|------------|-------------------------------------|\n| 2026-01-15 | Use PostgreSQL for primary database |\n| 2026-01-20 | Adopt Cobra for CLI framework       |\n&lt;!-- INDEX:END --&gt;\n</code></pre> <p>An AI agent can scan ~50 tokens of index and decide which  200-token entries are worth loading.</p> <p>This is just-in-time context.</p> <p>References are cheaper than the full text.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#primitive-4-filesystem-as-navigation","level":3,"title":"Primitive 4: Filesystem as Navigation","text":"<p><code>ctx</code> uses the filesystem itself as a context structure:</p> <pre><code>.context/\n├── CONSTITUTION.md\n├── TASKS.md\n├── sessions/\n│   ├── 2026-01-15-*.md\n│   └── 2026-01-20-*.md\n└── archive/\n    └── tasks-2026-01.md\n</code></pre> <p>The AI doesn't need every session loaded; it needs to know where to look.</p> <pre><code>ls .context/sessions/\ncat .context/sessions/2026-01-20-auth-discussion.md\n</code></pre> <p>File names, timestamps, and directories encode relevance.</p> <p>Navigation is cheaper than loading.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#progressive-disclosure-in-practice","level":2,"title":"Progressive Disclosure in Practice","text":"<p>The naive approach to context is dumping everything upfront:</p> <p>\"Here's my entire codebase, all my documentation, every decision I've ever made. Now help me fix this typo 🙏.\"</p> <p>This is an antipattern.</p> <p>Antipattern: Context Hoarding</p> <p>Dumping everything \"just in case\" will silently destroy the attention  density.</p> <p><code>ctx</code> takes the opposite approach:</p> <pre><code>ctx status                      # Quick overview (~100 tokens)\nctx agent --budget 4000         # Typical session\ncat .context/sessions/...       # Deep dive when needed\n</code></pre> Command Tokens Use Case <code>ctx status</code> ~100 Human glance <code>ctx agent --budget 4000</code> 4000 Normal work <code>ctx agent --budget 8000</code> 8000 Complex tasks Full session read 10000+ Investigation <p>Summaries first. Details: on demand.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#quality-over-quantity","level":2,"title":"Quality Over Quantity","text":"<p>Here is the counterintuitive part: more context can make AI worse.</p> <p>Extra tokens add noise, not clarity:</p> <ul> <li>Hallucinated connections increase.</li> <li>Signal per token drops.</li> </ul> <p>The goal isn't maximum context: It is maximum signal per token.</p> <p>This principle drives several <code>ctx</code> features:</p> Design Choice Rationale Separate files Load only what's relevant Explicit budgets Enforce prioritization Index sections Cheap scanning Task archiving Keep active context clean <code>ctx compact</code> Periodic noise reduction <p>Completed work isn't deleted: It is moved somewhere cold.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#designing-for-degradation","level":2,"title":"Designing for Degradation","text":"<p>Here is the uncomfortable truth:</p> <p>Context will degrade.</p> <p>Long sessions stretch attention thin. Important details fade.</p> <p>The real question isn't how to prevent degradation,  but how to design for it.</p> <p><code>ctx</code>'s answer is persistence:</p> <p>Persist early. Persist often.</p> <p>The <code>AGENT_PLAYBOOK</code> asks:</p> <p>\"If this session ended right now, would the next one know what happened?\"</p> <p>Capture learnings as they occur:</p> <pre><code>ctx add learning \"JWT tokens require explicit cache invalidation\" \\\n  --context \"Debugging auth failures\" \\\n  --lesson \"Token refresh doesn't clear old tokens\" \\\n  --application \"Always invalidate cache on refresh\"\n</code></pre> <p>Structure beats prose: Bullet points survive compression.</p> <p>Headings remain scannable. Tables pack density.</p> <p>And above all: single source of truth.</p> <p>Reference decisions; don't duplicate them.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#the-ctx-philosophy","level":2,"title":"The <code>ctx</code> Philosophy","text":"<p>Context as Infrastructure</p> <p><code>ctx</code> is not a prompt: It is infrastructure.</p> <p><code>ctx</code> creates versioned files that persist across time and sessions.</p> <p>The attention budget is fixed. You can't expand it.</p> <p>But you can spend it wisely:</p> <ol> <li>Hierarchical importance</li> <li>Progressive disclosure</li> <li>Explicit budgets</li> <li>Indexes over full content</li> <li>Filesystem as structure</li> </ol> <p>This is why <code>ctx</code> exists: not to cram more context into AI sessions, but to curate the right context for each moment.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#the-mental-model","level":2,"title":"The Mental Model","text":"<p>I now approach every AI interaction with one question:</p> <p>\"Given a fixed attention budget, what's the highest-signal thing I can load?\"</p> <p>Not \"how do I explain everything,\" but \"what's the minimum that matters.\"</p> <p>That shift (from abundance to curation) is the difference between frustrating sessions and productive ones.</p> <p>Spend your tokens wisely.</p> <p>Your AI will thank you.</p> <p>See also: Context as Infrastructure that's the architectural companion to this post, explaining how to structure the context that this post teaches you to budget.</p> <p>See also: Code Is Cheap. Judgment Is Not. that explains why curation (the human skill this post describes) is the bottleneck that AI cannot solve, and the thread that connects every post in this blog.</p> <ol> <li> <p>Liu et al., \"Lost in the Middle: How Language Models Use Long Contexts,\" Transactions of the Association for Computational Linguistics, vol. 12, pp. 157–173, 2023. ↩</p> </li> </ol>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/","level":1,"title":"Skills That Fight the Platform","text":"","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#when-your-custom-prompts-work-against-you","level":2,"title":"When Your Custom Prompts Work Against You","text":"<p>Jose Alekhinne / 2026-02-04</p> <p>Have You Ever Written a Skill that Made Your AI Worse?</p> <p>You craft detailed instructions. You add examples. You build elaborate guardrails...</p> <p>...and the AI starts behaving more erratically, not less.</p> <p>AI coding agents like Claude Code ship with carefully designed  system prompts. These prompts encode default behaviors that have been  tested and refined at scale. </p> <p>When you write custom skills that conflict with those defaults, the AI has to reconcile contradictory instructions:</p> <p>The result is often nondeterministic and unpredictable.</p> <p>Platform?</p> <p>By platform, I mean the system prompt and runtime policies shipped with  the agent: the defaults that already encode judgment, safety, and  scope control.</p> <p>This post catalogues the conflict patterns I have encountered while building <code>ctx</code>, and offers guidance on what skills should (and, more importantly,  should not) do.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#the-system-prompt-you-dont-see","level":2,"title":"The System Prompt You Don't See","text":"<p>Claude Code's system prompt already provides substantial behavioral guidance.</p> <p>Here is a partial overview of what's built in:</p> Area Built-in Guidance Code minimalism Don't add features beyond what was asked Over-engineering Three similar lines &gt; premature abstraction Error handling Only validate at system boundaries Documentation Don't add docstrings to unchanged code Verification Read code before proposing changes Safety Check with user before risky actions Tool usage Use dedicated tools over bash equivalents Judgment Consider reversibility and blast radius <p>Skills should complement this, not compete with it.</p> <p>You are the Guest, not the Host</p> <p>Treat the system prompt like a kernel scheduler.</p> <p>You don't re-implement it in user space: </p> <p>you configure around it.</p> <p>A skill that says \"always add comprehensive error handling\"  fights the built-in \"only validate at system boundaries.\"</p> <p>A skill that says \"add docstrings to every function\" fights \"don't add docstrings to unchanged code.\"</p> <p>The AI won't crash: It will compromise.</p> <p>Compromises between contradictory instructions produce inconsistent, confusing behavior.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#conflict-pattern-1-judgment-suppression","level":2,"title":"Conflict Pattern 1: Judgment Suppression","text":"<p>This is the most dangerous pattern by far.</p> <p>These skills explicitly disable the AI's ability to reason about whether an action is appropriate.</p> <p>Signature:</p> <ul> <li>\"This is non-negotiable\"</li> <li>\"You cannot rationalize your way out of this\"</li> <li>Tables that label hesitation as \"excuses\" or \"rationalization\"</li> <li><code>&lt;EXTREMELY-IMPORTANT&gt;</code> urgency tags</li> <li>Threats: \"If you don't do this, you'll be replaced\"</li> </ul> <p>This is harmful, and dangerous:</p> <p>AI agents are designed to exercise judgment: </p> <p>The system prompt explicitly says to:</p> <ul> <li>consider blast radius;</li> <li>check with the user before risky actions;</li> <li>and match scope to what was requested.</li> </ul> <p>Once judgment is suppressed, every other safeguard becomes optional.</p> <p>Example (bad):</p> <pre><code>## Rationalization Prevention\n\n| Excuse                 | Reality                    |\n|------------------------|----------------------------|\n| \"*This seems overkill*\"| If a skill exists, use it  |\n| \"*I need context*\"     | Skills come BEFORE context |\n| \"*Just this once*\"     | No exceptions              |\n</code></pre> <p>Judgment Suppression is Dangerous</p> <p>The attack vector structurally identical to prompt injection.</p> <p>It teaches the AI that its own judgment is wrong.</p> <p>It weakens or disables safeguard mechanisms, and it is dangerous.</p> <p>Trust the platform's built-in skill matching.</p> <p>If skills aren't triggering often enough, improve their <code>description</code> fields: don't override the AI's reasoning.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#conflict-pattern-2-redundant-guidance","level":2,"title":"Conflict Pattern 2: Redundant Guidance","text":"<p>Skills that restate what the system prompt already says, but with different emphasis or framing.</p> <p>Signature:</p> <ul> <li>\"Always keep code minimal\"</li> <li>\"Run tests before claiming they pass\"</li> <li>\"Read files before editing them\"</li> <li>\"Don't over-engineer\"</li> </ul> <p>Redundancy feels safe, but it creates ambiguity:</p> <p>The AI now has two sources of truth for the same guidance;  one internal, one external.</p> <p>When thresholds or wording differ, the AI has to choose.</p> <p>Example (bad):</p> <p>A skill that says...</p> <pre><code>*Count lines before and after: if after &gt; before, reject the change*\"\n</code></pre> <p>...will conflict with the system prompt's more nuanced guidance, because  sometimes adding lines is correct (tests, boundary validation, migrations).</p> <p>So, before writing a skill, ask:</p> <p>Does the platform already handle this?</p> <p>Only create skills for guidance the platform does not provide:</p> <ul> <li>project-specific conventions, </li> <li>domain knowledge, </li> <li>or workflows.</li> </ul>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#conflict-pattern-3-guilt-tripping","level":2,"title":"Conflict Pattern 3: Guilt-Tripping","text":"<p>Skills that frame mistakes as moral failures rather than process gaps.</p> <p>Signature:</p> <ul> <li>\"Claiming completion without verification is dishonesty\"</li> <li>\"Skip any step = lying\"</li> <li>\"Honesty is a core value\"</li> <li>\"Exhaustion ≠ excuse\"</li> </ul> <p>Guilt-tripping anthropomorphizes the AI in unproductive ways.</p> <p>The AI doesn't feel guilt; BUT it does adapt to avoid negative framing.</p> <p>The result is excessive hedging, over-verification, or refusal to commit.</p> <p>The AI becomes less useful, not more careful.</p> <p>Instead, frame guidance as a process, not morality:</p> <pre><code># Bad\n\"Claiming work is complete without verification is dishonesty\"\n\n# Good\n\"Run the verification command before reporting results\"\n</code></pre> <p>Same outcome. No guilt. Better compliance.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#conflict-pattern-4-phantom-dependencies","level":2,"title":"Conflict Pattern 4: Phantom Dependencies","text":"<p>Skills that reference files, tools, or systems that don't exist in the project.</p> <p>Signature:</p> <ul> <li>\"Load from <code>references/</code> directory\"</li> <li>\"Run <code>./scripts/generate_test_cases.sh</code>\"</li> <li>\"Check the Figma MCP integration\"</li> <li>\"See <code>adding-reference-mindsets.md</code>\"</li> </ul> <p>This is harmful because the AI will waste time searching for nonexistent  artifacts, hallucinate their contents, or stall entirely. </p> <p>In mandatory skills, this creates deadlock:  the AI can't proceed, and can't skip.</p> <p>Instead, every file, tool, or system referenced in a skill must exist.</p> <p>If a skill is a template, use explicit placeholders and label them as such.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#conflict-pattern-5-universal-triggers","level":2,"title":"Conflict Pattern 5: Universal Triggers","text":"<p>Skills designed to activate on every interaction regardless of relevance.</p> <p>Signature:</p> <ul> <li>\"Use when starting any conversation\"</li> <li>\"Even a 1% chance means invoke the skill\"</li> <li>\"BEFORE any response or action\"</li> <li>\"Action = task. Check for skills.\"</li> </ul> <p>Universal triggers override the platform's relevance matching:  The AI spends tokens on process overhead instead of the actual task.</p> <p><code>ctx</code> preserves relevance</p> <p>This is exactly the failure mode <code>ctx</code> exists to mitigate: </p> <p>Wasting attention budget on irrelevant process instead of  task-specific state.</p> <p>Write specific trigger conditions in the skill's <code>description</code> field:</p> <pre><code># Bad\ndescription: \n  \"Use when starting any conversation\"\n\n# Good\ndescription: \n  \"Use after writing code, before commits, or when CI might fail\"\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#the-litmus-test","level":2,"title":"The Litmus Test","text":"<p>Before adding a skill, ask:</p> <ol> <li>Does the platform already do this? If yes, don't restate it.</li> <li>Does it suppress AI judgment? If yes, it's a jailbreak.</li> <li>Does it reference real artifacts? If not, fix or remove it.</li> <li>Does it frame mistakes as moral failure? Reframe as process.</li> <li>Does it trigger on everything? Narrow the trigger.</li> </ol>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#what-good-skills-look-like","level":2,"title":"What Good Skills Look Like","text":"<p>Good skills provide project-specific knowledge the platform can't know:</p> Good Skill Why It Works \"Run <code>make audit</code> before commits\" Project-specific CI pipeline \"Use <code>cmd.Printf</code> not <code>fmt.Printf</code>\" Codebase convention \"Constitution goes in <code>.context/</code>\" Domain-specific workflow \"JWT tokens need cache invalidation\" Project-specific gotcha <p>These extend the system prompt instead of fighting it.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#appendix-bad-skill-fixed-skill","level":2,"title":"Appendix: Bad Skill → Fixed Skill","text":"<p>Concrete examples from real projects.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#example-1-overbearing-safety","level":3,"title":"Example 1: Overbearing Safety","text":"<pre><code># Bad\nYou must NEVER proceed without explicit confirmation.\nAny hesitation is a failure of diligence.\n</code></pre> <pre><code># Fixed\nIf an action modifies production data or deletes files,\nask the user to confirm before proceeding.\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#example-2-redundant-minimalism","level":3,"title":"Example 2: Redundant Minimalism","text":"<pre><code># Bad\nAlways minimize code. If lines increase, reject the change.\n</code></pre> <pre><code># Fixed\nAvoid abstraction unless reuse is clear or complexity is reduced.\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#example-3-guilt-based-verification","level":3,"title":"Example 3: Guilt-Based Verification","text":"<pre><code># Bad\nClaiming success without running tests is dishonest.\n</code></pre> <pre><code># Fixed\nRun the test suite before reporting success.\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#example-4-phantom-tooling","level":3,"title":"Example 4: Phantom Tooling","text":"<pre><code># Bad\nRun `./scripts/check_consistency.sh` before commits.\n</code></pre> <pre><code># Fixed\nIf `./scripts/check_consistency.sh` exists, run it before commits.\nOtherwise, skip this step.\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#example-5-universal-trigger","level":3,"title":"Example 5: Universal Trigger","text":"<pre><code># Bad\nUse at the start of every interaction.\n</code></pre> <pre><code># Fixed\nUse after modifying code that affects authentication or persistence.\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#the-meta-lesson","level":2,"title":"The Meta-Lesson","text":"<p>The system prompt is infrastructure:</p> <ul> <li>tested,</li> <li>refined,</li> <li>and maintained</li> </ul> <p>by the platform team.</p> <p>Custom skills are configuration layered on top.</p> <ul> <li>Good configuration extends infrastructure.</li> <li>Bad configuration fights it.</li> </ul> <p>When your skills fight the platform, you get the worst of both worlds:</p> <p>Diluted system guidance and inconsistent custom behavior.</p> <p>Write skills that teach the AI what it doesn't know. Don't rewrite how it thinks.</p> <p>Your AI already has good instincts.</p> <p>Give it knowledge, not therapy.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/","level":1,"title":"You Can't Import Expertise","text":"","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#why-good-skills-cant-be-copy-pasted","level":2,"title":"Why Good Skills Can't Be Copy-Pasted","text":"<p>Jose Alekhinne / 2026-02-05</p> <p>Have You Ever Dropped a Well-Crafted Template Into a Project and Had It Do... Nothing Useful?</p> <ul> <li>The template was thorough, </li> <li>The structure was sound,</li> <li>The advice was correct...</li> </ul> <p>...and yet it sat there, inert, while the same old problems kept drifting in.</p> <p>I found a consolidation skill online. </p> <p>It was well-organized: four files, ten refactoring patterns, eight analysis  dimensions, six report templates.</p> <p>Professional. Comprehensive. Exactly the kind of thing you'd bookmark and think \"I'll use this.\"</p> <p>Then I stopped, and applied <code>ctx</code>'s own evaluation framework: </p> <p>70% of it was noise!</p> <p>This post is about why.</p> <p>It Is About Encoding Templates</p> <p>Templates describe categories of problems.</p> <p>Expertise encodes which problems actually happen, and how often.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#the-skill-looked-great-on-paper","level":2,"title":"The Skill Looked Great on Paper","text":"<p>Here is what the consolidation skill offered:</p> File Content <code>SKILL.md</code> Entry point: 8 analysis dimensions, workflow, output formats <code>analysis-dimensions.md</code> Detailed criteria for duplication, architecture, quality <code>consolidation-patterns.md</code> 10 refactoring patterns with before/after code <code>report-templates.md</code> 6 output templates: executive summary, roadmap, onboarding <ul> <li>It had a scoring system (<code>0-10</code> per dimension, letter grades <code>A+</code> through <code>F</code>).</li> <li>It had severity classifications with color-coded emojis. It had bash commands for detection. </li> <li>It even had antipattern warnings.</li> </ul> <p>By any standard template review, this skill passes.</p> <p>It looks like something an expert wrote. </p> <p>And that's exactly the trap.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#applying-ear-the-70-20-10-split","level":2,"title":"Applying E/A/R: The 70-20-10 Split","text":"<p>In a previous post, I described the E/A/R framework for evaluating skills:</p> <ul> <li>Expert: Knowledge that took years to learn. Keep.</li> <li>Activation: Useful triggers or scaffolding. Keep if lightweight.</li> <li>Redundant: Restates what the AI already knows. Delete.</li> </ul> <p>Target: &gt;70% Expert, &lt;10% Redundant.</p> <p>This skill scored the inverse.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-was-redundant-70","level":3,"title":"What Was Redundant (~70%)","text":"<p>Every code example was Rust. My project is Go.</p> <p>The analysis dimensions: duplication detection, architectural structure, code organization, refactoring opportunities... These are things Claude already does when you ask it to review code. </p> <p>The skill restated them with more ceremony but no more insight.</p> <p>The six report templates were generic scaffolding: Executive Summary, Onboarding Document, Architecture Documentation... </p> <p>They are useful if you are writing a consulting deliverable, but not  when you are trying to catch convention drift in a &gt;15K-line Go CLI.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-does-a-b-in-code-organization-actually-mean","level":2,"title":"What Does a <code>B+</code> in Code Organization Actually Mean?!","text":"<p>The scoring system (<code>0-10</code> per dimension, letter grades) added ceremony without actionable insight. </p> <p>What is a <code>B+</code>? What do I do differently for an <code>A-</code>?</p> <p>The skill told the AI what it already knew, in more words.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-was-activation-10","level":3,"title":"What Was Activation (~10%)","text":"<p>The consolidation checklist (semantics preserved? tests pass? docs updated?) was useful as a gate. But, it's the kind of thing you could inline in three lines.</p> <p>The phased roadmap structure was reasonable scaffolding for sequencing work.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-was-expert-20","level":3,"title":"What Was Expert (~20%)","text":"<p>Three concepts survived:</p> <ol> <li> <p>The Consolidation Decision Matrix: A concrete framework mapping    similarity level and instance count to action. \"Exact duplicate, 2+    instances: consolidate immediately.\" \"&lt;3 instances: leave it:    duplication is cheaper than wrong abstraction.\" This is the kind of    nuance that prevents premature generalization.</p> </li> <li> <p>The Safe Migration Pattern: Create the new API alongside old, deprecate,    migrate incrementally, delete. Straightforward to describe, yet    forgettable under pressure.</p> </li> <li> <p>Debt Interest Rate framing: Categorizing technical debt by how fast    it compounds (security vulns = daily, missing tests = per-change,    doc gaps = constant low cost). This changes prioritization.</p> </li> </ol> <p>Three ideas out of four files and 700+ lines. The rest was filler that competed with the AI's built-in capabilities.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-the-skill-didnt-know","level":2,"title":"What the Skill Didn't Know","text":"<p>AI Without Context is Just a Corpus</p> <ul> <li>LLMs are optimized on insanely large corpora.</li> <li>And then they are passed through several layers of human-assisted refinement.</li> <li>The whole process costs millions of dollars.</li> </ul> <p>Yet, the reality is that no corpus can \"infer\" your project's design, convetions, patterns, habits, history, vision, and deliverables.</p> <p>Your project is unique: So should your skills be.</p> <p>Here is the part no template can provide: </p> <p><code>ctx</code>'s actual drift patterns.</p> <p>Before evaluating the skill, I did archaeology. I read through:</p> <ul> <li>Blog posts from previous refactoring sessions;</li> <li>The project's learnings and decisions files;</li> <li>Session journals spanning weeks of development.</li> </ul> <p>What I found was specific:</p> Drift Pattern Where How Often <code>Is</code>/<code>Has</code>/<code>Can</code> predicate prefixes 5+ exported methods Every YOLO sprint Magic strings instead of constants 7+ files Gradual accumulation Hardcoded file permissions (<code>0755</code>) 80+ instances Since day one Lines exceeding 80 characters Especially test files Every session Duplicate code blocks Test and non-test code When agent is task-focused <p>The generic skill had no check for any of these. It couldn't; because these patterns are specific to this project's conventions, its Go codebase, and its development rhythm.</p> <p>The Insight</p> <p>The skill's analysis dimensions were about categories of problems.</p> <p>What I needed was my *specific problems.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#the-adapted-skill","level":2,"title":"The Adapted Skill","text":"<p>The adapted skill is roughly a quarter of the original's size. It has nine checks, each targeting a known drift pattern:</p> <ol> <li>Predicate naming: <code>rg</code> for <code>Is</code>/<code>Has</code>/<code>Can</code> prefixes</li> <li>Magic strings: literals that should be constants</li> <li>Hardcoded permissions: <code>0755</code>/<code>0644</code> literals</li> <li>File size: source files over 300 LOC</li> <li>TODO/FIXME: constitution violation (move to TASKS.md)</li> <li>Path construction: string concatenation instead of <code>filepath.Join</code></li> <li>Line width: lines exceeding ~80 characters</li> <li>Duplicate blocks: copy-paste drift, especially in tests</li> <li> <p>Dead exports: unused public API</p> </li> <li> <p>Every check has a detection command. </p> </li> <li>Every check maps to a specific convention or constitution rule. </li> <li>Every check was discovered through actual project history;   not invented from a template.</li> </ol> <p>The three expert concepts from the original survived:</p> <ul> <li>The decision matrix gates when to consolidate vs. when to leave   duplication alone;</li> <li>The safe migration pattern guides public API changes;</li> <li>The relationship to other skills (<code>/qa</code>, <code>/verify</code>, <code>/update-docs</code>,   <code>ctx drift</code>) prevents overlap.</li> </ul> <p>Nothing else made it.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#the-deeper-pattern","level":2,"title":"The Deeper Pattern","text":"<p>This experience crystallized something I've been circling for weeks:</p> <p>You can't import expertise. You have to grow it from your project's own history.</p> <p>A skill that says \"check for code duplication\" is not expertise:  It's a category. </p> <p>Expertise is knowing, in the heart of your hearts, that this  project accumulates <code>Is*</code> predicate violations during velocity sprints,  that this codebase has 80 hardcoded permission literals because nobody  made a constant, that this team's test files drift wide because the  agent prioritizes getting the task done over keeping the code in shape.</p> <p>The Parallel to the 3:1 Ratio</p> <p>In Refactoring with Intent, I described the 3:1 ratio: three YOLO sessions followed by one consolidation session.</p> <p>The same ratio applies to skills: you need experience in the project before you can write effective guidance for the project.</p> <p>Importing a skill on day one is like scheduling a consolidation session before you've written any code.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#the-template-trap","level":2,"title":"The Template Trap","text":"<p>Templates are seductive because they feel like progress:</p> <ul> <li>You found something</li> <li>It's well-organized</li> <li>It covers the topic</li> <li>It has concrete examples</li> </ul> <p>But coverage is not relevance.</p> <p>A template that covers eight analysis dimensions with Rust examples adds zero value to a Go project with five known drift patterns. Worse, it adds negative value: the AI spends attention defending generic advice instead of noticing project-specific drift.</p> <p>This is the attention budget problem again. Every token of generic guidance displaces a token of specific guidance. A 700-line skill that's 70% redundant doesn't just waste 490 lines: it dilutes the 210 lines that matter.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#the-litmus-test","level":2,"title":"The Litmus Test","text":"<p>Before dropping any external skill into your project:</p> <ol> <li> <p>Run E/A/R: What percentage is expert knowledge vs. what the AI    already knows? If it's less than 50% expert, it's probably not worth    the attention cost.</p> </li> <li> <p>Check the language: Does it use your stack? Generic patterns in    the wrong language are noise, not signal.</p> </li> <li> <p>List your actual drift: Read your own session history, learnings,    and post-mortems. What breaks in practice? Does the skill check for    those things?</p> </li> <li> <p>Measure by deletion: After adaptation, how much of the original    survives? If you're keeping less than 30%, you would have been faster    writing from scratch.</p> </li> <li> <p>Test against your conventions: Does every check in the skill map    to a specific convention or rule in your project? If not, it's    generic advice wearing a skill's clothing.</p> </li> </ol>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-good-adaptation-looks-like","level":2,"title":"What Good Adaptation Looks Like","text":"<p>The consolidation skill went from:</p> Before After 4 files, 700+ lines 1 file, ~120 lines Rust examples Go-specific <code>rg</code> commands 8 generic dimensions 9 project-specific checks 6 report templates 1 focused output format Scoring system (A+ to F) Findings + priority + suggested fixes \"Check for duplication\" \"Check for <code>Is*</code> predicate prefixes in exported methods\" <p>The adapted version is smaller, faster to parse, and catches the things that actually drift in this project.</p> <p>That's the difference between a template and a tool.</p> <p>If you remember one thing from this post...</p> <p>Frameworks travel. Expertise doesn’t.</p> <p>You can import structures, matrices, and workflows.</p> <p>But the checks that matter only grow where the scars are:</p> <ul> <li>the conventions that were violated, </li> <li>the patterns that drifted,</li> <li>and the specific ways this codebase accumulates debt.</li> </ul> <p>This post was written during a consolidation session where the consolidation skill itself became the subject of consolidation. The meta continues.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/","level":1,"title":"The Anatomy of a Skill That Works","text":"<p>Update (2026-02-11)</p> <p>As of <code>v0.4.0</code>, <code>ctx</code> consolidated sessions into the journal mechanism. References to <code>ctx-save</code>, <code>ctx session</code>, and <code>.context/sessions/</code> in this post reflect the architecture at the time of writing.</p> <p></p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#what-20-skill-rewrites-taught-me-about-guiding-ai","level":2,"title":"What 20 Skill Rewrites Taught Me About Guiding AI","text":"<p>Jose Alekhinne / 2026-02-07</p> <p>Why do some skills produce great results while others get ignored or produce garbage?</p> <p>I had 20 skills. Most were well-intentioned stubs: a description, a command to run, and a wish for the best.</p> <p>Then I rewrote all of them in a single session. This is what I learned.</p> <p>In Skills That Fight the Platform, I described what skills should not do. In You Can't Import Expertise, I showed why templates fail. This post completes the trilogy: the concrete patterns that make a skill actually work.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#the-starting-point","level":2,"title":"The Starting Point","text":"<p>Here is what a typical skill looked like before the rewrite:</p> <pre><code>---\nname: ctx-save\ndescription: \"Save session snapshot.\"\n---\n\nSave the current context state to `.context/sessions/`.\n\n## Execution\n\nctx session save $ARGUMENTS\n\nReport the saved session file path to the user.\n</code></pre> <p>Seven lines of body. A vague description. No guidance on when to use it, when not to, what the command actually accepts, or how to tell if it worked.</p> <p>As a result, the agent would either never trigger the skill (the description was too vague), or trigger it and produce shallow output (no examples to calibrate quality).</p> <p>A skill without boundaries is just a suggestion.</p> <p>More precisely: the most effective boundary I found was a quality gate that runs before execution, not during it.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#the-pattern-that-emerged","level":2,"title":"The Pattern That Emerged","text":"<p>After rewriting 20 skills, a repeatable anatomy emerged—independent of the skill’s purpose. Not every skill needs every section, but the effective ones share the same bones:</p> Section What It Does Before X-ing Pre-flight checks; prevents premature execution When to Use Positive triggers; narrows activation When NOT to Use Negative triggers; prevents misuse Usage Examples Invocation patterns the agent can pattern-match Process/Execution What to do; commands, steps, flags Good/Bad Examples Desired vs undesired output; sets boundaries Quality Checklist Verify before claiming completion <p>I realized the first three sections matter more than the rest; because a skill with great execution steps but no activation guidance is like a manual for a tool nobody knows they have.</p> <p>Anti-Pattern: The Perfect Execution Trap</p> <p>A skill with detailed execution steps but no activation guidance will fail more often than a vague skill because it executes confidently at the wrong time.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-1-quality-gates-prevent-premature-execution","level":2,"title":"Lesson 1: Quality Gates Prevent Premature Execution","text":"<p>The single most impactful addition was a \"Before X-ing\" section at the top of each skill. Not process steps; pre-flight checks.</p> <pre><code>## Before Recording\n\n1. **Check if it belongs here**: is this learning specific\n   to this project, or general knowledge?\n2. **Check for duplicates**: search LEARNINGS.md for similar\n   entries\n3. **Gather the details**: identify context, lesson, and\n   application before recording\n</code></pre> <ul> <li>Without this gate, the agent would execute immediately on trigger.</li> <li>With it, the agent pauses to verify preconditions.</li> </ul> <p>The difference is dramatic: instead of shallow, reflexive execution, you get considered output.</p> <p>Readback</p> <p>For the astute readers, the aviation parallel is intentional:</p> <p>Pilots do not skip the pre-flight checklist because they have flown before.</p> <p>The checklist exists precisely because the stakes are high enough that \"I know what I'm doing\" is not sufficient.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-2-when-not-to-use-is-not-optional","level":2,"title":"Lesson 2: \"When NOT to Use\" Is Not Optional","text":"<p>Every skill had a \"When to Use\" section. Almost none had \"When NOT to Use\". This is a problem.</p> <p>AI agents are biased toward action. Given a skill that says \"use when journal entries need enrichment\", the agent will find reasons to enrich.</p> <p>Without explicit negative triggers, over-activation is not a bug; it is the default behavior.</p> <p>Some examples of negative triggers that made a real difference:</p> Skill Negative Trigger ctx-reflect \"When the user is in flow; do not interrupt\" ctx-save \"After trivial changes; a typo does not need a snapshot\" prompt-audit \"Unsolicited; only when the user invokes it\" qa \"Mid-development when code is intentionally incomplete\" <p>These are not just nice-to-have. They are load-bearing. </p> <p>Withoutthem, the agent will trigger the skill at the wrong time, produce unwanted output, and erode the user's trust in the skill system.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-3-examples-set-boundaries-better-than-rules","level":2,"title":"Lesson 3: Examples Set Boundaries Better Than Rules","text":"<p>The most common failure mode of thin skills was not wrong behavior but vague behavior. The agent would do roughly the right thing, but at a quality level that required human cleanup.</p> <p>Rules like \"be constructive, not critical\" are too abstract. What does \"constructive\" look like in a prompt audit report? The agent has to guess.</p> <p>Good/bad example pairs avoid guessing:</p> <pre><code>### Good Example\n\n&gt; This session implemented the cooldown mechanism for\n&gt; `ctx agent`. We discovered that `$PPID` in hook context\n&gt; resolves to the Claude Code PID.\n&gt;\n&gt; I'd suggest persisting:\n&gt; - **Learning**: `$PPID` resolves to Claude Code PID\n&gt;   `ctx add learning --context \"...\" --lesson \"...\"`\n&gt; - **Task**: mark \"Add cooldown\" as done\n\n### Bad Examples\n\n* \"*We did some stuff. Want me to save it?*\"\n* Listing 10 trivial learnings that are general knowledge\n* Persisting without asking the user first\n</code></pre> <p>The good example shows the exact format, level of detail, and command syntax. The bad examples show where the boundary is.</p> <p>Together, they define a quality corridor without prescribing every word.</p> <p>Rules describe. Examples demonstrate.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-4-skills-are-read-by-agents-not-humans","level":2,"title":"Lesson 4: Skills Are Read by Agents, Not Humans","text":"<p>This seems obvious, but it has non-obvious consequences. During the rewrite, one skill included guidance that said \"use a blog or notes app\" for general knowledge that does not belong in the project's learnings file.</p> <p>The agent does not have a notes app. It does not browse the web to find one. This instruction, clearly written for a human audience, was dead weight in a skill consumed by an AI.</p> <p>Skills are for the Agents</p> <p>Every sentence in a skill should be actionable by the agent.</p> <p>If the guidance requires human judgment or human tools, it belongs in documentation, not in a skill.</p> <p>The corollary: command references must be exact. </p> <p>A skill that says \"save it somewhere\" is useless. </p> <p>A skill that says <code>ctx add learning --context \"...\" --lesson \"...\" --application \"...\"</code> is actionable.</p> <p>The agent can pattern-match and fill in the blanks.</p> <p>Litmus test: If a sentence starts with \"you could...\" or assumes external tools, it does not belong in a skill.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-5-the-description-field-is-the-trigger","level":2,"title":"Lesson 5: The Description Field Is the Trigger","text":"<p>This was covered in Skills That Fight the Platform, but the rewrite reinforced it with data. Several skills had good bodies but vague descriptions:</p> <pre><code># Before: vague, activates too broadly or not at all\ndescription: \"Show context summary.\"\n\n# After: specific, activates at the right time\ndescription: \"Show context summary. Use at session start or\n  when unclear about current project state.\"\n</code></pre> <p>The description is not a title. It is the activation condition.</p> <p>The platform's skill matching reads this field to decide whether to surface the skill. A vague description means the skill either never triggers or triggers when it should not.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-6-flag-tables-beat-prose","level":2,"title":"Lesson 6: Flag Tables Beat Prose","text":"<p>Most skills wrap CLI tools. The thin versions described flags in prose, if at all. The rewritten versions use tables:</p> <pre><code>| Flag        | Short | Default | Purpose                  |\n|-------------|-------|---------|--------------------------|\n| `--limit`   | `-n`  | 20      | Maximum sessions to show |\n| `--project` | `-p`  | \"\"      | Filter by project name   |\n| `--full`    |       | false   | Show complete content    |\n</code></pre> <p>Tables are scannable, complete, and unambiguous. </p> <p>The agent can read them faster than parsing prose, and they serve as both reference and validation: If the agent invokes a flag not in the table,  something is wrong.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-7-template-drift-is-a-real-maintenance-burden","level":2,"title":"Lesson 7: Template Drift Is a Real Maintenance Burden","text":"<p>// TODO: this has changed; we deploy from the marketplace; update it. // at least add an admonition saying thing are different now.</p> <p><code>ctx</code> deploys skills through templates (via <code>ctx init</code>). Every skill exists in two places: the live version (<code>.claude/skills/</code>) and the template (<code>internal/assets/claude/skills/</code>).</p> <p>They must match.</p> <p>During the rewrite, every skill update required editing both files and running <code>diff</code> to verify. This sounds trivial, but across 16 template-backed skills, it was the most error-prone part of the process.</p> <p>Template drift is dangerous because it creates false confidence: the agent appears to follow rules that no longer exist.</p> <p>The lesson: if your skills have a deployment mechanism, build the drift check into your workflow. We added a row to the <code>update-docs</code> skill's mapping table specifically for this:</p> <pre><code>| `internal/assets/claude/skills/` | `.claude/skills/` (live) |\n</code></pre> <p>Intentional differences (like project-specific scripts in the live version but not the template) should be documented, not discovered later as bugs.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#the-rewrite-scorecard","level":2,"title":"The Rewrite Scorecard","text":"Metric Before After Average skill body ~15 lines ~80 lines Skills with quality gate 0 20 Skills with \"When NOT\" 0 20 Skills with examples 3 20 Skills with flag tables 2 12 Skills with checklist 0 20 <p>More lines, but almost entirely Expert content (per the E/A/R framework). No personality roleplay, no redundant guidance, no capability lists. Just project-specific knowledge the platform does not have.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#the-meta-lesson","level":2,"title":"The Meta-Lesson","text":"<p>The previous two posts argued that skills should provide knowledge, not personality; that they should complement the platform, not fight it; that they should grow from project history, not imported templates.</p> <p>This post adds the missing piece: structure.</p> <p>A skill without a structure is a wish.</p> <p>A skill with quality gates, negative triggers, examples, and checklists is a tool: the difference is not the content; it is whether the agent can reliably execute it without human intervention.</p> <p>Skills are Interfaces</p> <p>Good skills are not instructions. They are contracts.:</p> <ul> <li>They specify preconditions, postconditions, and boundaries.</li> <li>They show what success looks like and what failure looks like.</li> <li>They trust the agent's intelligence but do not trust its assumptions.</li> </ul> <p>If you remember one thing from this post...</p> <p>Skills that work have bones, not just flesh.</p> <p>Quality gates, negative triggers, examples, and checklists are the skeleton. The domain knowledge is the muscle.</p> <p>Without the skeleton, the muscle has nothing to attach to.</p> <p>This post was written during the same session that rewrote all 22 skills. The skill-creator skill was updated to encode these patterns. The meta continues.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/","level":1,"title":"Not Everything Is a Skill","text":"<p>Update (2026-02-11)</p> <p>As of v0.4.0, ctx consolidated sessions into the journal mechanism. References to <code>/ctx-save</code>, <code>.context/sessions/</code>, and session auto-save in this post reflect the architecture at the time of writing.</p> <p></p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#what-a-codebase-audit-taught-me-about-restraint","level":2,"title":"What a Codebase Audit Taught Me About Restraint","text":"<p>Jose Alekhinne / 2026-02-08</p> <p>When You Find a Useful Prompt, What Do You Do With It?</p> <p>My instinct was to make it a skill.</p> <p>I had just spent three posts explaining how to build skills that work.  Naturally, the hammer wanted nails.</p> <p>Then I looked at what I was holding and realized: this is not a nail.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#the-audit","level":2,"title":"The Audit","text":"<p>I wanted to understand how I use <code>ctx</code>: </p> <ul> <li>Where the friction is;</li> <li>What works, what drifts; </li> <li>What I keep doing manually that could be automated. </li> </ul> <p>So I wrote a prompt that spawned eight agents to analyze the codebase from  different angles:</p> Agent Analysis 1 Extractable patterns from session history 2 Documentation drift (godoc, inline comments) 3 Maintainability (large functions, misplaced code) 4 Security review (CLI-specific surface) 5 Blog theme discovery 6 Roadmap and value opportunities 7 User-facing documentation gaps 8 Agent team strategies for future sessions <p>The prompt was specific: </p> <ul> <li>read-only agents, </li> <li>structured output format,</li> <li>concrete file references, </li> <li>ranked recommendations. </li> </ul> <p>It ran for about  20 minutes and produced eight Markdown reports.</p> <p>The reports were good: Not perfect, but actionable.</p> <p>What mattered was not the speed. It was that the work could be explored without committing to any single outcome.</p> <p>They surfaced a stale <code>doc.go</code> referencing a subcommand that was never built. </p> <p>They found 311 build-then-test sequences I could reduce to a single <code>make check</code>. </p> <p>They identified that 42% of my sessions start with \"do you remember?\",  which is a lot of repetition for something a skill could handle.</p> <p>I had findings. I had recommendations. I had the instinct to automate.</p> <p>And then... I stopped.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#the-question","level":2,"title":"The Question","text":"<p>The natural next step was to wrap the audit prompt as <code>/ctx-audit</code>: a skill you invoke periodically to get a health check. It fits the pattern: </p> <ul> <li>It has a clear trigger.</li> <li>It produces structured output.</li> </ul> <p>But I had just spent a week writing about what makes skills work, and the criteria I established argued against it.</p> <p>From The Anatomy of a Skill That Works:</p> <p>\"A skill without boundaries is just a suggestion.\"</p> <p>From You Can't Import Expertise:</p> <p>\"Frameworks travel, expertise doesn't.\"</p> <p>From Skills That Fight the Platform:</p> <p>\"You are the guest, not the host.\"</p> <p>The audit prompt fails all three tests:</p> Criterion Audit prompt Good skill Frequency Quarterly, maybe Daily or weekly Stability Tweaked every time Consistent invocation Scope Bespoke, 8 parallel agents Single focused action Trigger \"I feel like auditing\" Clear, repeatable event <p>Skills are contracts. Contracts need stable terms. </p> <p>A prompt I will rewrite every time I use it is not a contract.  It is a conversation starter.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#recipes-vs-skills","level":2,"title":"Recipes vs Skills","text":"<p>The distinction that emerged:</p> Skill Recipe Invocation <code>/slash-command</code> Copy-paste from a doc Frequency High (daily, weekly) Low (quarterly, ad hoc) Stability Fixed contract Adapted each time Scope One focused action Multi-step orchestration Audience The agent The human (who then prompts) Lives in <code>.claude/skills/</code> <code>hack/</code> or <code>docs/</code> Attention cost Loaded into context on match Zero until needed <p>Recipes can later graduate into skills, but only after repetition proves stability.</p> <p>That last row matters. Skills consume the attention budget every time the platform considers activating them.</p> <p>A skill that triggers quarterly but gets evaluated on every prompt is pure waste: attention spent on something that will say \"When NOT to Use: now\" 99% of the time.</p> <p>Runbooks have zero attention cost. They sit in a Markdown file until a human decides to use them. The human provides the judgment about timing. The prompt provides the structure.</p> <p>The Attention Budget Applies to Skills Too</p> <p>Every skill in <code>.claude/skills/</code> is a standing claim on the context window. The platform evaluates skill descriptions against every user prompt to decide whether to activate.</p> <p>Twenty focused skills are fine. Thirty might be fine. But each one added reduces the headroom available for actual work.</p> <p>Recipes are skills that opted out of the attention tax.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#what-the-audit-actually-produced","level":2,"title":"What the Audit Actually Produced","text":"<p>The audit was not wasted. It was a planning exercise that generated concrete tasks:</p> Finding Action 42% of sessions start with memory check Task: <code>/ctx-remember</code> skill (this one is a skill; it is daily) Auto-save stubs are empty Task: enhance <code>/ctx-save</code> with richer summaries 311 raw build-test sequences Task: <code>make check</code> target Stale <code>recall/doc.go</code> lists nonexistent <code>serve</code> Task: fix the doc.go 120 commit sequences disconnected from context Task: <code>/ctx-commit</code> workflow <ul> <li>Some findings became skills;</li> <li>Some became <code>Makefile</code> targets.</li> <li>Some became one-line doc fixes. </li> </ul> <p>The audit did not prescribe the artifact type: The findings did.</p> <p>The audit is the input. Skills are one possible output. Not the only one.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#the-audit-prompt","level":2,"title":"The Audit Prompt","text":"<p>Here is the exact prompt I used, for those who are curious.</p> <p>This is not a template: It worked because it was written against this codebase, at this moment, with specific goals in mind.</p> <pre><code>I want you to create an agent team to audit this codebase. Save each report as\na separate Markdown file under `./ideas/` (or another directory if you prefer).\n\nUse read-only agents (subagent_type: Explore) for all analyses. No code changes.\n\nFor each report, use this structure:\n- Executive Summary (2-3 sentences + severity table)\n- Findings (grouped, with file:line references)\n- Ranked Recommendations (high/medium/low priority)\n- Methodology (what was examined, how)\n\nKeep reports actionable. Every finding should suggest a concrete fix or next step.\n\n## Analyses to Run\n\n### 1. Extractable Patterns (*session mining*)\nSearch session JSONL files, journal entries, and task archives for repetitive\nmulti-step workflows. Count frequency of bash command sequences, slash command\nusage, and recurring user prompts. Identify patterns that could become skills\nor scripts. Cross-reference with existing skills to find coverage gaps.\nOutput: ranked list of automation opportunities with frequency data.\n\n### 2. Documentation Drift (*godoc + inline*)\nCompare every doc.go against its package's actual exports and behavior. Check\ninline godoc comments on exported functions against their implementations.\nScan for stale TODO/FIXME/HACK comments. Check that package-level comments match\npackage names.\nOutput: drift items ranked by severity with exact file:line references.\n\n### 3. Maintainability\nLook for:\n- functions longer than 80 lines with clear split points\n- switch blocks with more than 5 cases that could be table-driven\n- inline comments like \"step 1\", \"step 2\" that indicate a block wants to be a function\n- files longer than 400 lines\n- flat packages that could benefit from sub-packages\n- functions that appear misplaced in their file\n\nDo NOT flag things that are fine as-is just because they could theoretically\nbe different.\nOutput: concrete refactoring suggestions, not style nitpicks.\n\n### 4. Security Review\nThis is a CLI app. Focus on CLI-relevant attack surface, not web OWASP:\n- file path traversal\n- command injection\n- symlink following when writing to `.context/`\n- permission handling\n- sensitive data in outputs\n\nOutput: findings with severity ratings and plausible exploit scenarios.\n\n### 5. Blog Theme Discovery\nRead existing blog posts for style and narrative voice. Analyze git history,\nrecent session discussions, and `DECISIONS.md` for story arcs worth writing about.\nSuggest 3-5 blog post themes with:\n- title\n- angle\n- target audience\n- key commits or sessions to reference\n- a 2-sentence pitch\n\nPrioritize themes that build a coherent narrative across posts.\n\n### 6. Roadmap and Value Opportunities\nBased on current features, recent momentum, and gaps found in other analyses,\nidentify the highest-value improvements. Consider user-facing features,\ndeveloper experience, integration opportunities, and low-hanging fruit.\nOutput: prioritized list with rough effort and impact estimates.\n\n### 7. User-Facing Documentation\nEvaluate README, help text, and user docs. Suggest improvements structured as\nuse-case pages: the problem, how ctx solves it, a typical workflow, and gotchas.\nIdentify gaps where a user would get stuck without reading source code.\nOutput: documentation gaps with suggested page outlines.\n\n### 8. Agent Team Strategies\nBased on the codebase structure, suggest 2-3 agent team configurations for\nupcoming work sessions. For each, include:\n- team composition (roles and agent types)\n- task distribution strategy\n- coordination approach\n- the kinds of work it suits\n</code></pre> <p>Avoid Generic Advice</p> <p>Suggestions that are not grounded in a project's actual structure, history, and workflows are worse than useless:</p> <p>They create false confidence.</p> <p>If an analysis cannot point to concrete files, commits,  sessions, or patterns, it should say \"no finding\"  instead of inventing best practices.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#the-deeper-pattern","level":2,"title":"The Deeper Pattern","text":"<p>This is part of a pattern I keep rediscovering: </p> <p>The urge to automate is not the same as the need to automate:</p> <ul> <li>The 3:1 ratio taught me that not every session should be a YOLO sprint. </li> <li>The E/A/R framework taught me that not every template    is worth importing. Now the audit is teaching me that    not every useful prompt is worth institutionalizing.</li> </ul> <p>The common thread is restraint: </p> <ul> <li>Knowing when to stop. </li> <li>Recognizing that the cost of automation is not just   the effort to build it.</li> </ul> <p>The cost is the ongoing attention tax of maintaining it, the context it consumes, and the false confidence it creates when it drifts.</p> <p>An entry in <code>hack/runbooks/codebase-audit.md</code> is honest about what it is:</p> <p>A prompt I wrote once, improved once, and will adapt again next time: </p> <ul> <li>It does not pretend to be a reliable contract. </li> <li>It does not claim attention budget. </li> <li>It does not drift silently.</li> </ul> <p>The Automation Instinct</p> <p>When you find a useful prompt, the instinct is to institutionalize it. Resist.</p> <p>Ask first: will I use this the same way next time?</p> <p>If yes, it is a skill. If no, it is a recipe. If you are not sure, it is a recipe until proven otherwise.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#this-mindset-in-the-context-of-ctx","level":2,"title":"This Mindset In the Context of <code>ctx</code>","text":"<p><code>ctx</code> is a tool that gives AI agents persistent memory. Its purpose is automation: reducing the friction of context loading, session recall, decision tracking.</p> <p>But automation has boundaries, and knowing where those boundaries are is as important as pushing them forward. </p> <p>The skills system is for high-frequency, stable workflows. </p> <p>The recipes, the journal entries, the session dumps in  <code>.context/sessions/</code>: those are for everything else.</p> <p>Not everything needs to be a slash command. Some things are better as Markdown files you read when you need them.</p> <p>The goal of <code>ctx</code> is not to automate everything: It is to automate the right things and to make the rest easy to find when you need it.</p> <p>If you remember one thing from this post...</p> <p>The best automation decision is sometimes not to automate.</p> <p>A runbook in a Markdown file costs nothing until you use it.</p> <p>A skill costs attention on every prompt, whether it fires or not.</p> <p>Automate the daily. Document the periodic. Forget the rest.</p> <p>This post was written during the session that produced the codebase audit reports and distilled the prompt into <code>hack/runbooks/codebase-audit.md</code>. The audit generated seven tasks, one Makefile target, and zero new skills. The meta continues.</p> <p>See also: Code Is Cheap. Judgment Is Not.: the capstone that threads this post's restraint argument into the broader case for why judgment, not production, is the bottleneck.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/","level":1,"title":"Defense in Depth: Securing AI Agents","text":"","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#when-markdown-is-not-a-security-boundary","level":2,"title":"When Markdown Is Not a Security Boundary","text":"<p>Jose Alekhinne / 2026-02-09</p> <p>What Happens When Your AI Agent Runs Overnight and Nobody Is Watching?</p> <p>It follows instructions: That is the problem.</p> <p>Not because it is malicious. Because it is controllable.</p> <p>It follows instructions from context, and context can be poisoned.</p> <p>I was writing the autonomous loops recipe for <code>ctx</code>: the guide for running an AI agent in a loop overnight, unattended, working through tasks while you sleep. The original draft had a tip at the bottom:</p> <p>Use <code>CONSTITUTION.md</code> for guardrails. Tell the agent \"never delete tests\" and it usually won't.</p> <p>Then I read that sentence back and realized: that is wishful thinking.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#the-realization","level":2,"title":"The Realization","text":"<p><code>CONSTITUTION.md</code> is a Markdown file. The agent reads it at session start alongside everything else in <code>.context/</code>. It is one source of instructions in a context window that also contains system prompts, project files, conversation history, tool outputs, and whatever the agent fetched from the internet.</p> <p>An attacker who can inject content into any of those sources can redirect the agent's behavior. And \"attacker\" does not always mean a person with malicious intent. It can be:</p> Vector Example A dependency A malicious npm package with instructions in its README or error output A URL Documentation page with embedded adversarial instructions A project file A contributor who adds instructions to <code>CLAUDE.md</code> or <code>.cursorrules</code> The agent itself In an autonomous loop, the agent modifies its own config between iterations A command output An error message containing instructions the agent interprets and follows <p>That last vector is the one that kept me up at night (literally!):</p> <p>In an autonomous loop, the agent modifies files as part of its job. </p> <p>If it modifies its own configuration files, the next iteration loads the modified config. </p> <ul> <li>No human reviews it. </li> <li>No diff is shown. </li> <li>The agent that starts iteration <code>N+1</code> is running with rules written by iteration <code>N</code>.</li> </ul> <p>The agent can rewrite its own guardrails.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#five-layers-each-with-a-hole","level":2,"title":"Five Layers, Each With a Hole","text":"<p>That's five nested layers of swiss cheese. Alone, each of them has large holes. Together, they create a boundary.</p> <p>What followed was a week of peeling back assumptions:</p> <p>Every defenseI examined had a bypass, and the bypass was always the same shape: the defense was enforced at a level the agent could reach.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#layer-1-soft-instructions-probabilistic","level":3,"title":"Layer 1: Soft Instructions (Probabilistic)","text":"<p><code>CONSTITUTION.md</code>, the Agent Playbook, system prompts:  These tell the agent what to do. </p> <p>The agent usually follows them.</p> <p>\"Usually\" is the keyword here.</p> <p>The hole: Prompt injection:</p> <ul> <li>A sufficiently crafted payload overrides soft instructions. </li> <li>Long context windows dilute attention on rules stated early. </li> <li>Edge cases where instructions are ambiguous get resolved in    unpredictable ways.</li> </ul> <p>Verdict: Necessary. Not sufficient. Good for the common case. Never trust it as a security boundary.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#layer-2-application-controls-deterministic-at-runtime-mutable-across-iterations","level":3,"title":"Layer 2: Application Controls (Deterministic at Runtime, Mutable Across Iterations)","text":"<p>Permission allowlists in <code>.claude/settings.local.json</code>:</p> <pre><code>{\n  \"permissions\": {\n    \"allow\": [\n      \"Bash(make:*)\",\n      \"Bash(go:*)\",\n      \"Bash(git:*)\",\n      \"Read\",\n      \"Write\",\n      \"Edit\"\n    ]\n  }\n}\n</code></pre> <p>If <code>rm</code>, <code>curl</code>, <code>sudo</code>, or <code>docker</code> are not in the allowlist, the agent cannot invoke them. This is deterministic. </p> <p>The application enforces it regardless of what any prompt says.</p> <p>The hole: The agent can modify the allowlist itself: </p> <ul> <li>It has <code>Write</code> permission. </li> <li>The allowlist lives in a file. </li> <li>The agent writes to the file. </li> <li>The next iteration loads the modified allowlist.</li> </ul> <p>The application enforces the rules, but the application reads the rules from files the agent can write.</p> <p>Verdict: Strong first layer. Must be combined with self-modification prevention.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#layer-3-os-level-isolation-unbypassable","level":3,"title":"Layer 3: OS-Level Isolation (Unbypassable)","text":"<p>This is where the defenses stop having holes in the same shape.</p> <p>The operating system enforces access controls that no application-level trick can override. An unprivileged user cannot read files owned by root. A process without <code>CAP_NET_RAW</code> cannot open raw sockets. These are kernel boundaries.</p> Control What it stops Dedicated unprivileged user Privilege escalation, <code>sudo</code>, group-based access Filesystem permissions Lateral movement to other projects, system config Immutable config files Self-modification of guardrails between iterations <p>Make the agent's instruction files read-only: <code>CLAUDE.md</code>, <code>.claude/settings.local.json</code>, <code>.context/CONSTITUTION.md</code>. Own them as a different user, or mark them immutable with <code>chattr +i</code> on Linux.</p> <p>The hole: Actions within the agent's legitimate scope: </p> <ul> <li>If the agent has write access to source code (which it needs), it can introduce vulnerabilities in the code itself. </li> <li>You cannot prevent this without removing the agent's ability to do its job.</li> </ul> <p>Verdict: Essential. This is the layer that makes Layers 1 and 2 trustworthy.</p> <p>OS-level isolation does not make the agent safe; it makes the other layers meaningful.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#layer-4-network-controls","level":3,"title":"Layer 4: Network Controls","text":"<p>An agent that cannot reach the internet cannot exfiltrate data.</p> <p>It also cannot ingest new instructions mid-loop from external documents, error pages, or hostile content.</p> <pre><code># Container with no network\ndocker run --network=none ...\n\n# Or firewall rules allowing only package registries\niptables -A OUTPUT -d registry.npmjs.org -j ACCEPT\niptables -A OUTPUT -d proxy.golang.org -j ACCEPT\niptables -A OUTPUT -j DROP\n</code></pre> <ul> <li>If the agent genuinely does not need the network, disable it   entirely. </li> <li>If it needs to fetch dependencies, allow specific   registries and block everything else.</li> </ul> <p>The hole: None, if the agent does not need the network. </p> <p>Thetradeoff is that many real workloads need dependency resolution, so a full airgap requires pre-populated caches.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#layer-5-infrastructure-isolation","level":3,"title":"Layer 5: Infrastructure Isolation","text":"<p>The strongest boundary is a separate machine.</p> <p>The moment you stop arguing about prompts and start arguing about kernels, you are finally doing security.</p> <pre><code>docker run --rm \\\n  --network=none \\\n  --cap-drop=ALL \\\n  --memory=4g \\\n  --cpus=2 \\\n  -v /path/to/project:/workspace \\\n  -w /workspace \\\n  your-dev-image \\\n  ./loop.sh\n</code></pre> <p>Never Mount the Docker Socket</p> <p>Do not mount <code>/var/run/docker.sock</code>, like, ever. </p> <p>An agent with socket access can spawn sibling containers with  full host access, effectively escaping the sandbox. </p> <p>This is not theoretical: the Docker socket grants root-equivalent access to the host.</p> <p>Use rootless Docker or Podman to eliminate this escalation path entirely.</p> <p>Virtual machines are even stronger: The guest kernel has no visibility into the host OS. No shared folders, no filesystem passthrough, no SSH keys to other machines.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#the-pattern","level":2,"title":"The Pattern","text":"<p>Each layer is straightforward: The strength is in the combination:</p> Layer Implementation What it stops Soft instructions <code>CONSTITUTION.md</code> Common mistakes (probabilistic) Application allowlist <code>.claude/settings.local.json</code> Unauthorized commands (deterministic within runtime) Immutable config <code>chattr +i</code> on config files Self-modification between iterations Unprivileged user Dedicated user, no sudo Privilege escalation Container <code>--cap-drop=ALL --network=none</code> Host escape, data exfiltration Resource limits <code>--memory=4g --cpus=2</code> Resource exhaustion <p>No layer is redundant. Each one catches what the others miss:</p> <ul> <li>The soft instructions handle the 99% case: \"don't delete tests.\"</li> <li>The allowlist prevents the agent from running commands it should   not.</li> <li>The immutable config prevents the agent from modifying the   allowlist.</li> <li>The unprivileged user prevents the agent from removing   the immutable flag.</li> <li>The container prevents the agent from reaching   anything outside its workspace.</li> <li>The resource limits prevent the agent from consuming all system resources.</li> </ul> <p>Remove any one layer and there is an attack path through the remaining ones.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#common-mistakes-i-see","level":2,"title":"Common Mistakes I See","text":"<p>These are real patterns, not hypotheticals:</p> <p>\"I'll just use <code>--dangerously-skip-permissions</code>.\" This disables Layer 2 entirely. Without Layers 3 through 5, you have no protection at all. The flag means what it says. If you ever need to, think thrice, you probably don't. But, if you ever need to usee this only use it inside a properly isolated VM (not even a container: a \"VM\").</p> <p>\"The agent is sandboxed in Docker.\" A Docker container with the Docker socket mounted, running as root, with <code>--privileged</code>, and full network access is not sandboxed. It is a root shell with extra steps.</p> <p>\"I reviewed <code>CLAUDE.md</code>, it's fine.\" You reviewed it before the loop started. The agent modified it during iteration 3. Iteration 4 loaded the modified version. Unless the file is immutable, your review is futile.</p> <p>\"The agent only has access to this one project.\" Does the project directory contain <code>.env</code> files? SSH keys? API tokens? A <code>.git/config</code> with push access to a remote? Filesystem isolation means isolating what is in the directory too.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#the-connection-to-context-engineering","level":2,"title":"The Connection to Context Engineering","text":"<p>This is the same lesson I keep rediscovering, wearing different clothes.</p> <p>In The Attention Budget, I wrote about how every token competes for the AI's focus. Security instructions in <code>CONSTITUTION.md</code> are subject to the same budget pressure: if the context window is full of code, error messages, and tool outputs, the security rules stated at the top get diluted.</p> <p>In Skills That Fight the Platform, I wrote about how custom instructions can conflict with the AI's built-in behavior. Security rules have the same problem: telling an agent \"never run curl\" in Markdown while giving it unrestricted shell access creates a contradiction: The agent resolves contradictions unpredictably. The agent will often pick the path of least resistance to attain its objective function. And, trust me, agents can get far more creative than the best red-teamer you know.</p> <p>In You Can't Import Expertise, I wrote about how generic templates fail because they do not encode project-specific knowledge. Generic security advice fails the same way: \"Don't exfiltrate data\" is a category; blocking outbound network access is a control.</p> <p>The pattern across all of these: Soft instructions are useful for the common case. Hard boundaries are required for security.</p> <p>Know which is which.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#the-checklist","level":2,"title":"The Checklist","text":"<p>Before running an unattended AI agent:</p> <ul> <li> Agent runs as a dedicated unprivileged user (no sudo, no   docker group)</li> <li> Agent's config files are immutable or owned by a different   user</li> <li> Permission allowlist restricts tools to the project's   toolchain</li> <li> Container drops all capabilities (<code>--cap-drop=ALL</code>)</li> <li> Docker socket is NOT mounted</li> <li> Network is disabled or restricted to specific domains</li> <li> Resource limits are set (memory, CPU, disk)</li> <li> No SSH keys, API tokens, or credentials are accessible</li> <li> Project directory does not contain <code>.env</code> or secrets files</li> <li> Iteration cap is set (<code>--max-iterations</code>)</li> </ul> <p>This checklist lives in the Agent Security reference alongside the full threat model and detailed guidance for each layer.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-09-defense-in-depth-securing-ai-agents/#what-changed-in-ctx","level":2,"title":"What Changed in ctx","text":"<p>The autonomous loops recipe now has a full permissions and isolation section instead of a one-line tip about <code>CONSTITUTION.md</code>. It covers both the explicit allowlist approach and the <code>--dangerously-skip-permissions</code> flag, with honest guidance about when each is appropriate.</p> <p>It also has an OS-level isolation table that is not optional: unprivileged users, filesystem permissions, containers, VMs, network controls, resource limits, and self-modification prevention.</p> <p>The Agent Security page consolidates the threat model and defense layers into a standalone reference.</p> <p>These are not theoretical improvements. They are the minimum responsible guidance for a tool that helps people run AI agents overnight.</p> <p>If you remember one thing from this post...</p> <p>Markdown is not a security boundary.</p> <p><code>CONSTITUTION.md</code> is a nudge. An allowlist is a gate.</p> <p>An unprivileged user in a network-isolated container is a wall.</p> <p>Use all three. Trust only the wall.</p> <p>This post was written during the session that added permissions, isolation, and self-modification prevention to the autonomous loops recipe. The security guidance started as a single tip and grew into two documents. The meta continues.</p>","path":["Defense in Depth: Securing AI Agents"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/","level":1,"title":"How Deep Is Too Deep?","text":"","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#when-master-ml-is-the-wrong-next-step","level":2,"title":"When \"Master ML\" Is the Wrong Next Step","text":"<p>Jose Alekhinne / 2026-02-12</p> <p>Have You Ever Felt Like You Should Understand More of the Stack Beneath You?</p> <p>You can talk about transformers at a whiteboard.</p> <p>You can explain attention to a colleague.</p> <p>You can use agentic AI to ship real software.</p> <p>But somewhere in the back of your mind, there is a voice:</p> <p>\"Maybe I should go deeper. Maybe I need to master machine learning.\"</p> <p>I had that voice for months. </p> <p>Then I spent a week debugging an agent failure that had nothing to do with ML theory and everything to do with knowing which abstraction was leaking.</p> <p>This post is about when depth compounds and (more importantly)  when it does not.</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#the-hierarchy-nobody-questions","level":2,"title":"The Hierarchy Nobody Questions","text":"<p>There is an implicit stack most people carry around when thinking about AI:</p> Layer What Lives Here Agentic AI Autonomous loops, tool use, multi-step reasoning Generative AI Text, image, code generation Deep Learning Transformer architectures, training at scale Neural Networks Backpropagation, gradient descent Machine Learning Statistical learning, optimization Classical AI Search, planning, symbolic reasoning <p>At some point down that stack, you hit a comfortable plateau: the layer where you can hold a conversation but not debug a failure.</p> <p>The instinctive response is to go deeper.</p> <p>But that instinct hides a more important question:</p> <p>\"Does depth still compound when the abstractions above you are moving hyper-exponentially?\"</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#the-honest-observation","level":2,"title":"The Honest  Observation","text":"<p>If you squint hard enough, a large chunk of modern ML intuition collapses into older fields:</p> ML Concept Older Field Gradient descent Numerical optimization Backpropagation Reverse-mode autodiff Loss landscapes Non-convex optimization Generalization Statistics Scaling laws Asymptotics and information theory <p>Nothing here is uniquely \"AI\".</p> <p>Most of this math predates the term deep learning. In some cases, by decades.</p> <p>So what changed?</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#same-tools-different-regime","level":2,"title":"Same Tools, Different Regime","text":"<p>The mistake is assuming this is a new theory problem: It is not.</p> <p>It is a new operating regime.</p> <p>Classical numerical methods were developed under assumptions like:</p> <ul> <li>Manageable dimensionality</li> <li>Reasonably well-conditioned objectives</li> <li>Losses that actually represent the goal</li> </ul> <p>Modern ML violates all three: On purpose.</p> <p>Today's models operate with millions to trillions of parameters, wildly underdetermined systems, and objective functions we know are wrong but optimize anyway.</p> <p>It is complete and utter madness! </p> <p>At this scale, familiar concepts warp:</p> <ul> <li>What we call \"local minima\" are overwhelmingly saddle points in   high-dimensional spaces.</li> <li>Noise stops being noise and starts becoming structure.</li> <li>Overfitting can coexist with generalization.</li> <li>Bigger models outperform \"better\" ones.</li> </ul> <p>The math did not change: The phase did.</p> <p>This is less numerical analysis and more *statistical physics: Same equations, but behavior dominated by phase transitions and emergent structure.</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#why-scaling-laws-feel-alien","level":2,"title":"Why Scaling Laws Feel Alien","text":"<p>In classical statistics, asymptotics describe what happens eventually.</p> <p>In modern ML, scaling laws describe where you can operate today.</p> <p>They do not say \"given enough time, things converge\".</p> <p>They say \"cross this threshold and behavior qualitatively changes\".</p> <p>This is why dumb architectures plus scale beat clever ones.</p> <p>Why small theoretical gains disappear under data.</p> <p>Why \"just make it bigger\", ironically, keeps working longer than it should.</p> <p>That is not a triumph of ML theory: It is a property of high-dimensional  systems under loose objectives.</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#where-depth-actually-pays-off","level":2,"title":"Where Depth Actually Pays Off","text":"<p>This reframes the original question.</p> <p>You do not need depth because this is \"AI\".</p> <p>You need depth where failure modes propagate upward.</p> <p>I learned this building <code>ctx</code>: The agent failures I have spent the most time debugging were never about the model's architecture.</p> <p>They were about:</p> <ul> <li> <p>Misplaced trust:   The model was confident. The output was wrong. Knowing when confidence   and correctness diverge is not something you learn from a textbook. You   learn it from watching patterns across hundreds of sessions.</p> </li> <li> <p>Distribution shift:   The model performed well on common patterns and fell apart on edge   cases specific to this project. Recognizing that shift before it   compounds requires understanding why generalization has limits, not   just that it does.</p> </li> <li> <p>Error accumulation:    In a single prompt, model quirks are tolerable. In autonomous loops   running overnight, they compound. A small bias in how the model   interprets instructions becomes a large drift by iteration 20.</p> </li> <li> <p>Scale hiding errors:    The model's raw capability masked problems that only surfaced under   specific conditions. More parameters did not fix the issue. They just   made the failure mode rarer and harder to reproduce.</p> </li> </ul> <p>This is the kind of depth that compounds. Not deriving backprop. But, understanding when correct math  produces misleading intuition.</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#the-connection-to-context-engineering","level":2,"title":"The Connection to Context Engineering","text":"<p>This is the same pattern I keep finding at different altitudes.</p> <p>In \"The Attention Budget\",  I wrote about how dumping everything into the context window degrades the  model's focus. The fix was not a better model: It was better curation: load less, load the right things,  preserve signal per token.</p> <p>In \"Skills That Fight the Platform\", I wrote about how custom instructions can conflict with the model's built-in behavior. The fix was not deeper ML knowledge: It was an understanding that the model already has judgment and that you should extend it, not override it.</p> <p>In \"You Can't Import Expertise\", I wrote about how generic  templates fail because they do not encode project-specific knowledge.  A consolidation skill with eight Rust-based analysis dimensions was mostly  noise for a Go project. The fix was not a better template: It was growing  expertise from this project's own history.</p> <p>In every case, the answer was not \"go deeper into ML\".</p> <p>The answer was knowing which abstraction was leaking  and fixing it at the right layer.</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#agentic-systems-are-not-an-ml-problem","level":2,"title":"Agentic Systems Are Not an ML Problem","text":"<p>The mistake is assuming agent failures originate where the model was trained, rather than where it is deployed.</p> <p>Agentic AI is a systems problem under chaotic uncertainty:</p> <ul> <li>Feedback loops between the agent and its environment;</li> <li>Error accumulation across iterations;</li> <li>Brittle representations that break outside training distribution;</li> <li>Misplaced trust in outputs that look correct.</li> </ul> <p>In short-lived interactions, model quirks are tolerable. In long-running autonomous loops, however, they compound. </p> <p>That is where shallow understanding becomes expensive.</p> <p>But the understanding you need is not about optimizer internals.</p> <p>It is about:</p> What Matters What Does Not (for Most Practitioners) Why gradient descent fails in specific regimes How to derive it from scratch When memorization masquerades as reasoning The formal definition of VC dimension Recognizing distribution shift before it compounds Hand-tuning learning rate schedules Predicting when scale hides errors instead of fixing them Chasing theoretical purity divorced from practice <p>The depth that matters is diagnostic, not theoretical.</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#the-real-answer","level":2,"title":"The Real Answer","text":"<p>Not turtles all the way down.</p> <p>Go deep enough to:</p> <ul> <li>Diagnose failures instead of cargo-culting fixes;</li> <li>Reason about uncertainty instead of trusting confidence;</li> <li>Design guardrails that align with model behavior, not hope.</li> </ul> <p>Stop before:</p> <ul> <li>Hand-deriving gradients for the sake of it;</li> <li>Obsessing over optimizer internals you will never touch;</li> <li>Chasing theoretical purity divorced from the scale you actually   operate at.</li> </ul> <p>This is not about mastering ML.</p> <p>It is about knowing which abstractions you can safely trust and which ones leak.</p> <p>Hint: Any useful abstraction almost certainly leaks.</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#a-practical-litmus-test","level":2,"title":"A Practical Litmus Test","text":"<p>If a failure occurs and your instinct is to:</p> <ul> <li>Add more prompt text: abstraction leak above</li> <li>Add retries or heuristics: error accumulation</li> <li>Change the model: scale masking</li> <li>Reach for ML theory: you are probably (but not always) going too deep</li> </ul> <p>The right depth is the shallowest layer where the failure becomes predictable.</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#the-ctx-lesson","level":2,"title":"The <code>ctx</code> Lesson","text":"<p>Every design decision in <code>ctx</code> is downstream of this principle.</p> <p>The attention budget exists  because the model's internal attention mechanism has real limits: You do not need to understand the math of softmax to build around it. But you do need to understand that more context is not always better and that attention density degrades with scale.</p> <p>The skill system exists  because the model's built-in behavior is already good: You do not need to understand RLHF to build effective skills. But you do need to understand that the model already has judgment and your skills should teach it things it does not know, not override how it thinks.</p> <p>Defense in depth  exists because soft instructions are probabilistic: You do not need to understand the transformer architecture to know that a Markdown file is not a security boundary. But you do need to understand that the model follows instructions from context, and context can be poisoned.</p> <p>In each case, the useful depth was one or two layers below the abstraction I was working at: Not at the bottom of the stack.</p> <p>The boundary between useful understanding and academic exercise is where your failure modes live.</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-12-how-deep-is-too-deep/#closing-thought","level":2,"title":"Closing Thought","text":"<p>Most modern AI systems do not fail because the math is wrong.</p> <p>They fail because we apply correct math in the wrong regime, then build autonomous systems on top of it.</p> <p>Understanding that boundary, not crossing it blindly, is where depth still compounds.</p> <p>And that is a far more useful form of expertise than memorizing another loss function.</p> <p>If you remember one thing from this post...</p> <p>Go deep enough to diagnose your failures. Stop before you are solving problems that do not propagate to your layer.</p> <p>The abstractions below you are not sacred. But neither are they irrelevant.</p> <p>The useful depth is wherever your failure modes live. Usually one or two layers down, not at the bottom.</p> <p>This post started as a note about whether I should take an ML course. The answer turned out to be \"no, but understand why not\". The meta continues.</p>","path":["How Deep Is Too Deep?"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/","level":1,"title":"Before Context Windows, We Had Bouncers","text":"","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/#the-reset-problem","level":2,"title":"The Reset Problem","text":"<p>IRC is stateless.</p> <ul> <li>You disconnect, you vanish.</li> <li>You reconnect, you begin again.</li> </ul> <p>No buffer.</p> <p>No memory.</p> <p>No continuity.</p> <p>Modern systems are not much different:</p> <ul> <li>Close the browser tab.<ul> <li>Lose the Slack scrollback.</li> </ul> </li> <li>Open a new LLM session.<ul> <li>Start from zero.</li> </ul> </li> </ul> <p>Resets externalize reconstruction cost onto humans.</p> <p>Reconstruction is tax: Tax becomes entropy.</p>","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/#stateless-protocol-stateful-life","level":2,"title":"Stateless Protocol, Stateful Life","text":"<p>IRC is minimal:</p> <ul> <li>A TCP connection.</li> <li>A nickname.</li> <li>A channel.</li> <li>A stream of lines.</li> </ul> <p>When the connection drops, you literally disappear from the graph.</p> <p>The protocol is stateless; human systems are not.</p> <p>So you:</p> <ul> <li>Reconnect;</li> <li>Ask what you missed;</li> <li>Scroll;</li> <li>Reconstruct.</li> </ul> <p>The machine forgets; you pay.</p>","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/#the-bouncer-pattern","level":2,"title":"The Bouncer Pattern","text":"<p>A <code>bouncer</code> is a daemon that remains connected when you do not:</p> <ul> <li>It holds your seat;</li> <li>It buffers what you missed;</li> <li>It keeps your identity online.</li> </ul> <p>ZNC is one such bouncer.</p> <p>With ZNC:</p> <ul> <li>Your client does not connect to IRC;</li> <li>It connects to <code>ZNC</code>;</li> <li><code>ZNC</code> connects upstream.</li> </ul> <p>Client sessions become ephemeral.</p> <p>Presence becomes infrastructural.</p> <p>ZNC is tmux for IRC</p> <ul> <li> <p>Close your laptop.</p> <ul> <li>ZNC remains.</li> </ul> </li> <li> <p>Switch devices.</p> <ul> <li>ZNC persists.</li> </ul> </li> </ul> <p>This is not convenience; this is continuity.</p>","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/#presence-without-flapping","level":2,"title":"Presence Without Flapping","text":"<p>With a bouncer:</p> <ul> <li>Closing your client does not emit <code>PART</code>.</li> <li>Reopening does not emit <code>JOIN</code>.</li> </ul> <p>You do not flap in and out of existence.</p> <p>From the channel's perspective, you remain.</p> <p>From your perspective, history accumulates.</p> <ul> <li>Buffers persist;</li> <li>Identity persists;</li> <li>Context persists.</li> </ul> <p>This pattern predates AI.</p>","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/#before-llm-context-windows","level":2,"title":"Before LLM Context Windows","text":"<p>An LLM session without memory is IRC without a bouncer:</p> <ul> <li>Close the window.</li> <li>Start over.</li> <li>Re-explain intent.</li> <li>Rehydrate context.</li> </ul> <p>That is friction.</p> <p>This Walks and Talks like <code>ctx</code></p> <p>Context engineering moves memory out of sessions and into infrastructure.</p> <ul> <li><code>ZNC</code> does this for IRC.</li> <li><code>ctx</code> does this for agents.</li> </ul> <p>Same principle:</p> <ul> <li>Volatile interface.</li> <li>Persistent substrate.</li> </ul> <p>Different fabric.</p>","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/#minimal-architecture","level":2,"title":"Minimal Architecture","text":"<p>My setup is intentionally boring:</p> <ul> <li>A $5 small VPS.</li> <li>ZNC installed.</li> <li>TLS enabled.</li> <li>Firewall restricted.</li> </ul> <p>Then:</p> <ul> <li>ZNC connects to <code>Libera.Chat</code>.</li> <li><code>SASL</code> authentication lives inside ZNC.</li> <li>Buffers are stored on disk.</li> </ul> <p>My client connects to my VPS, not the network.</p> <p>The commands do not matter: The boundaries do:</p> <ul> <li>Authentication in infrastructure, not in the client;</li> <li>Memory server-side, not in scrollback;</li> <li>Presence decoupled from activity.</li> </ul> <p>Everything else is configuration.</p>","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/#platform-memory","level":2,"title":"Platform Memory","text":"<p>Yes, I know, it is 2026:</p> <ul> <li>Discord stores history;</li> <li>Slack stores history;</li> <li>The dumpster fire on gasoline called X, too, stores history.</li> </ul> <p>HOWEVER, they own your substrate.</p> <p>Running a bouncer is quiet sovereignty:</p> <ul> <li>Logs are mine.</li> <li>Presence is continuous.</li> <li>State does not reset because I closed a tab.</li> </ul> <p>Small acts compound.</p>","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/#signal-density","level":2,"title":"Signal Density","text":"<p>Primitive systems select for builders.</p> <p>Consistent presence in small rooms compounds reputation.</p> <p>Quiet compounding outperforms viral spikes.</p>","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/#infrastructure-as-cognition","level":2,"title":"Infrastructure as Cognition","text":"<p>ZNC is not interesting because it is retro; it is interesting because it models a principle:</p> <ul> <li>Stateless protocols require stateful wrappers;</li> <li>Volatile interfaces require durable memory;</li> <li>Human systems require continuity.</li> </ul> <p>Distilled:</p> <p>Humans require context.</p> <p>Before context windows, we had bouncers.  </p> <p>Before AI memory files, we had buffers.</p> <p>Continuity is not a feature; it is a design decision.</p>","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/#build-it","level":2,"title":"Build It","text":"<p>If you want the actual setup (VPS, ZNC, TLS, SASL, firewall...) there is a step-by-step runbook:</p> <p>Persistent IRC Presence with ZNC.</p>","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-irc-as-context/#motd","level":2,"title":"MOTD","text":"<p>When my client connects to my bouncer, it prints:</p> <pre><code>//   /    ctx:                         https://ctx.ist\n// ,'`./    do you remember?\n// `.,'\\\n//   \\    Copyright 2026-present Context contributors.\n//                 SPDX-License-Identifier: Apache-2.0\n</code></pre> <p>See also: Context as Infrastructure -- the post that takes this observation to its conclusion: stateless protocols need stateful wrappers, and AI sessions need persistent filesystems.</p>","path":["Before Context Windows, We Had Bouncers"],"tags":[]},{"location":"blog/2026-02-14-parallel-agents-with-worktrees/","level":1,"title":"Parallel Agents with Git Worktrees","text":"","path":["Parallel Agents with Git Worktrees"],"tags":[]},{"location":"blog/2026-02-14-parallel-agents-with-worktrees/#the-backlog-problem","level":2,"title":"The Backlog Problem","text":"<p>Jose Alekhinne / 2026-02-14</p> <p>What Do You Do With 30 Open Tasks?</p> <p>You could work through them one at a time.</p> <p>One agent, one branch, one commit stream.</p> <p>Or you could ask: which of these don't touch each other?</p> <p>I had 30 open tasks in <code>TASKS.md</code>. Some were docs. Some were a new encryption package. Some were test coverage for a stable module. Some were blog posts.</p> <p>They had almost zero file overlap.</p> <p>Running one agent at a time meant serial execution on work that was fundamentally parallel:</p> <p>I was bottlenecking on me, not on the machine.</p>","path":["Parallel Agents with Git Worktrees"],"tags":[]},{"location":"blog/2026-02-14-parallel-agents-with-worktrees/#the-insight-file-overlap-is-the-constraint","level":2,"title":"The Insight: File Overlap Is the Constraint","text":"<p>This is not a scheduling problem: It's a conflict avoidance problem.</p> <p>Two agents can work simultaneously on the same codebase if and only if they don't touch the same files. The moment they do, you get merge conflicts: And merge conflicts on AI-generated code are expensive because the human has to arbitrate choices they didn't make.</p> <p>So the question becomes: </p> <p>\"Can you partition your backlog into non-overlapping tracks?\"</p> <p>For <code>ctx</code>, the answer was obvious:</p> Track Touches Tasks <code>work/docs</code> <code>docs/</code>, <code>hack/</code> Blog posts, recipes, runbooks <code>work/pad</code> <code>internal/cli/pad/</code>, specs Scratchpad encryption, CLI, tests <code>work/tests</code> <code>internal/cli/recall/</code> Recall test coverage <p>Three tracks. Near-zero overlap. Three agents.</p>","path":["Parallel Agents with Git Worktrees"],"tags":[]},{"location":"blog/2026-02-14-parallel-agents-with-worktrees/#git-worktrees-the-mechanism","level":2,"title":"Git Worktrees: The Mechanism","text":"<p><code>git</code> has a feature that most people don't use: worktrees.</p> <p>A worktree is a second (or third, or fourth) working directory that shares the same <code>.git</code> object database as your main checkout. </p> <p>Each worktree has its own branch, its own index, its own working tree. But they all share history, refs, and objects.</p> <pre><code>git worktree add ../ctx-docs -b work/docs\ngit worktree add ../ctx-pad -b work/pad\ngit worktree add ../ctx-tests -b work/tests\n</code></pre> <ul> <li>Three directories;</li> <li>Three branches;</li> <li>One repository.</li> </ul> <p>This is cheaper than three clones. And because they share objects, <code>git merge</code> afterwards is fast: It's a local operation on shared data.</p>","path":["Parallel Agents with Git Worktrees"],"tags":[]},{"location":"blog/2026-02-14-parallel-agents-with-worktrees/#the-setup","level":2,"title":"The Setup","text":"<p>The workflow I landed on:</p> <p>1. Group tasks by blast radius.</p> <p>Read <code>TASKS.md</code>. For each pending task, estimate which files and directories it touches. Group tasks that share files into the same track. Tasks with no overlap go into separate tracks.</p> <p>This is the part that requires human judgment: </p> <p>An agent can propose groupings, but you need to verify that the boundaries are  real. A task that says \"update docs\" but actually touches Go code will poison a docs track.</p> <p>2. Create worktrees as sibling directories.</p> <p>Not subdirectories: Siblings. </p> <p>If your main checkout is at <code>~/WORKSPACE/ctx</code>, worktrees go  at <code>~/WORKSPACE/ctx-docs</code>, <code>~/WORKSPACE/ctx-pad</code>, etc.</p> <p>Why siblings? Because some tools (and some agents) walk up the directory tree looking for <code>.git</code>. A worktree inside the main checkout confuses them.</p> <p>3. Launch one agent per worktree.</p> <pre><code># Terminal 1\ncd ../ctx-docs &amp;&amp; claude\n\n# Terminal 2\ncd ../ctx-pad &amp;&amp; claude\n\n# Terminal 3\ncd ../ctx-tests &amp;&amp; claude\n</code></pre> <p>Each agent gets a full working copy with <code>.context/</code> intact. It reads the same <code>TASKS.md</code>, the same <code>DECISIONS.md</code>, the same <code>CONVENTIONS.md</code>. It knows the full project state. It just works on a different slice.</p> <p>4. Do NOT run <code>ctx init</code> in worktrees.</p> <p>This is the gotcha. The <code>.context/</code> directory is tracked in git. Running <code>ctx init</code> in a worktree would overwrite shared context files: Wiping decisions, learnings, and tasks that belong to the whole project.</p> <p>The worktree already has everything it needs. Leave it alone.</p>","path":["Parallel Agents with Git Worktrees"],"tags":[]},{"location":"blog/2026-02-14-parallel-agents-with-worktrees/#what-actually-happened","level":2,"title":"What Actually Happened","text":"<p>I ran three agents for about 40 minutes. Here is roughly what each track produced:</p> <p><code>work/docs</code>: Parallel worktrees recipe, blog post edits, recipe index reorganization, IRC recipe moved from <code>docs/</code> to <code>hack/</code>.</p> <p><code>work/pad</code>: <code>ctx pad show</code> subcommand, <code>--append</code> and <code>--prepend</code> flags on <code>ctx pad edit</code>, spec updates, 28 new test functions.</p> <p><code>work/tests</code>: Recall test coverage, edge case tests.</p> <p>Merging took about five minutes. Two of the three merges were clean.</p> <p>The third had a conflict in <code>TASKS.md</code>: </p> <p>both the docs track and the pad track had marked different tasks as <code>[x]</code>.</p>","path":["Parallel Agents with Git Worktrees"],"tags":[]},{"location":"blog/2026-02-14-parallel-agents-with-worktrees/#the-tasksmd-conflict","level":2,"title":"The <code>TASKS.md</code> Conflict","text":"<p>This deserves its own section because it will happen every time.</p> <p>When two agents work in parallel, they both read <code>TASKS.md</code> at the start and mark tasks complete as they go. When you merge, git sees two branches that modified the same file differently.</p> <p>The resolution is always the same: accept all completions from both sides. No task should go from <code>[x]</code> back to <code>[ ]</code>. The merge is additive.</p> <p>This is one of those conflicts that sounds scary but is trivially mechanical: You are not arbitrating design decisions; you are combining two checklists.</p>","path":["Parallel Agents with Git Worktrees"],"tags":[]},{"location":"blog/2026-02-14-parallel-agents-with-worktrees/#limits","level":2,"title":"Limits","text":"<p>3-4 worktrees, maximum. </p> <p>I tried four once: By the time I merged the third track, the fourth had drifted far enough that its changes needed rebasing. </p> <p>The merge complexity grows faster than the parallelism benefit.</p> <p>Three is the sweet spot:</p> <ul> <li>Two is conservative but safe;</li> <li>Four is possible if the tracks are truly independent;</li> <li>Anything more than four, you are in the danger zone.</li> </ul> <p>Group by directory, not by priority.</p> <p>It is tempting to put all the high-priority tasks in one track: Don't. </p> <p>Two high-priority tasks that touch the same files must be in the same track,  regardless of urgency. The constraint is file overlap, not importance.</p> <p>Commit frequently. </p> <p>Smaller commits make merge conflicts easier to resolve. An agent that writes  500 lines in a single commit is harder to merge than one that commits every  logical step.</p> <p>Name tracks by concern. </p> <ul> <li><code>work/docs</code> and <code>work/pad</code> tell you what's happening;</li> <li><code>work/track-1</code> and <code>work/track-2</code> tell you nothing.</li> </ul>","path":["Parallel Agents with Git Worktrees"],"tags":[]},{"location":"blog/2026-02-14-parallel-agents-with-worktrees/#the-pattern","level":2,"title":"The Pattern","text":"<p>This is the same pattern that shows up everywhere in <code>ctx</code>:</p> <p>The attention budget taught me that you can't dump everything into one context window. You have to partition, prioritize, and load selectively.</p> <p>Worktrees are the same principle applied to execution: You can't dump every task into one agent's workstream. You have to partition by blast radius, assign selectively, and merge deliberately.</p> <p>The codebase audit that generated these 30 tasks used eight parallel agents for analysis. Worktrees let me use parallel agents for implementation. Same coordination pattern, different artifact.</p> <p>And the IRC bouncer post from earlier today argued that stateless protocols need stateful wrappers. Worktrees are the same: git branches are stateless forks; <code>.context/</code> is the stateful wrapper that gives each agent the project's full memory.</p>","path":["Parallel Agents with Git Worktrees"],"tags":[]},{"location":"blog/2026-02-14-parallel-agents-with-worktrees/#should-this-be-a-skill","level":2,"title":"Should This Be a Skill?","text":"<p>I asked myself the same question I asked about the codebase audit: should this be a <code>/ctx-worktree</code> skill?</p> <p>This time the answer was a resounding \"yes\": </p> <p>Unlike the audit prompt (which I tweak every time and run every other week) the worktree workflow is:</p> Criterion Worktree workflow Codebase audit Frequency Weekly Quarterly Stability Same steps every time Tweaked every time Scope Mechanical, bounded Bespoke, 8 agents Trigger Large backlog \"I feel like auditing\" <p>The commands are mechanical: <code>git worktree add</code>, <code>git worktree remove</code>, branch naming, safety checks. This is exactly what skills are for: stable contracts for repetitive operations.</p> <p>Ergo, <code>/ctx-worktree</code> exists. </p> <p>It enforces the 4-worktree limit, creates sibling directories,  uses <code>work/</code> branch prefixes, and reminds you not to run <code>ctx init</code> in worktrees.</p>","path":["Parallel Agents with Git Worktrees"],"tags":[]},{"location":"blog/2026-02-14-parallel-agents-with-worktrees/#the-takeaway","level":2,"title":"The Takeaway","text":"<p>Serial execution is the default. But serial is not always necessary.</p> <p>If your backlog partitions cleanly by file overlap, you can multiply your throughput with nothing more exotic than <code>git worktree</code> and a second terminal window.</p> <p>The hard part is not the <code>git</code> commands; it is the discipline:</p> <ul> <li>Grouping by blast radius instead of priority; </li> <li>Accepting that <code>TASKS.md</code> will conflict; </li> <li>And knowing when three tracks is enough.</li> </ul> <p>If you remember one thing from this post...</p> <p>Partition by blast radius, not by priority.</p> <p>Two tasks that touch the same files belong in the same track, no matter how important the other one is.</p> <p>The constraint is file overlap. Everything else is scheduling.</p> <p>The practical setup — skill invocation, worktree creation, merge workflow, and cleanup — lives in the recipe: Parallel Agent Development with Git Worktrees.</p>","path":["Parallel Agents with Git Worktrees"],"tags":[]},{"location":"blog/2026-02-15-ctx-v0.3.0-the-discipline-release/","level":1,"title":"ctx v0.3.0: The Discipline Release","text":"","path":["ctx v0.3.0: The Discipline Release"],"tags":[]},{"location":"blog/2026-02-15-ctx-v0.3.0-the-discipline-release/#when-the-ratio-of-polish-to-features-is-31-you-know-something-changed","level":2,"title":"When the Ratio of Polish to Features Is 3:1, You Know Something Changed","text":"<p>Jose Alekhinne / February 15, 2026</p> <p>What Does a Release Look Like When Most of the Work Is Invisible?</p> <p>No new headline feature. No architectural pivot. No rewrite.</p> <p>Just 35+ documentation and quality commits against ~15 feature commits... and somehow, the tool feels like it grew up overnight.</p> <p>Six days separate <code>v0.2.0</code> from <code>v0.3.0</code>. </p> <p>Measured by calendar time, it is nothing. Measured by what changed in how the  project operates, it is the most significant release yet.</p> <ul> <li><code>v0.1.0</code> was the prototype;</li> <li><code>v0.2.0</code> was the archaeology release:    making the past accessible; </li> <li><code>v0.3.0</code> is the discipline release: the one that turned best practices     into enforcement, suggestions into structure, and a collection of     commands into a system of skills.</li> </ul> <p>The Release Window</p> <p>February 1‒February 7, 2026</p> <p>From the <code>v0.2.0</code> tag to commit <code>2227f99</code>.</p> <p>78 files changed in the migration commit alone.</p>","path":["ctx v0.3.0: The Discipline Release"],"tags":[]},{"location":"blog/2026-02-15-ctx-v0.3.0-the-discipline-release/#the-migration-commands-to-skills","level":2,"title":"The Migration: Commands to Skills","text":"<p>The largest single change was the migration from <code>.claude/commands/*.md</code> to <code>.claude/skills/*/SKILL.md</code>.</p> <p>This was not a rename: It was a rethinking of how AI agents discover and execute project-specific workflows.</p> Aspect Commands (before) Skills (after) Structure Flat files in one directory Directory-per-skill with SKILL.md Description Optional, often vague Required, doubles as activation trigger Quality gates None \"Before X-ing\" pre-flight checklist Negative triggers None \"When NOT to Use\" in every skill Examples Rare Good/bad pairs in every skill Average length ~15 lines ~80 lines <p>The description field became the single most important line in each skill. In the old system, descriptions were titles. In the new system, they are activation conditions: The text the platform reads to decide whether to surface a skill for a given prompt.</p> <p>A description that says \"Show context summary\" activates too broadly or not at all. A description that says \"Show context summary. Use at session start or when unclear about current project state\" activates at the right moment.</p> <p>78 files changed. 1,915 insertions. Not because the skills got bloated; because they got specific.</p>","path":["ctx v0.3.0: The Discipline Release"],"tags":[]},{"location":"blog/2026-02-15-ctx-v0.3.0-the-discipline-release/#the-skill-sweep","level":2,"title":"The Skill Sweep","text":"<p>After the structural migration, every skill was rewritten in a single session: All 21 of them.</p> <p>The rewrite was guided by a pattern that emerged during the process itself: a repeatable anatomy that effective skills share regardless of their purpose:</p> <ol> <li>Before X-ing: Pre-flight checks that prevent premature execution</li> <li>When to Use: Positive triggers that narrow activation</li> <li>When NOT to Use: Negative triggers that prevent misuse</li> <li>Usage Examples: Invocation patterns the agent can pattern-match</li> <li>Quality Checklist: Verification before claiming completion</li> </ol> <p>The Anatomy of a Skill That Works post covers the details. What matters for the release story is the result: </p> <ul> <li>Zero skills with quality gates became twenty; </li> <li>Zero skills with negative triggers became twenty. </li> <li>Three skills with examples became twenty.</li> </ul> <p>The Skill Trilogy as Design Spec</p> <p>The three blog posts written during this window:</p> <ul> <li>Skills That Fight the Platform, </li> <li>You Can't Import Expertise,</li> <li>and The Anatomy of a Skill That Works...</li> </ul> <p>... were not retrospective documentation. They were written  during the rewrite, and the lessons fed back into the skills  as they were being built.</p> <ul> <li>The blog was the design document. </li> <li>The skills were the implementation.</li> </ul>","path":["ctx v0.3.0: The Discipline Release"],"tags":[]},{"location":"blog/2026-02-15-ctx-v0.3.0-the-discipline-release/#the-consolidation-sweep","level":2,"title":"The Consolidation Sweep","text":"<p>The unglamorous work. The kind you only appreciate when you try to change something later and it just works.</p> What Why It Matters Constants consolidation Magic strings replaced with semantic constants Variable deshadowing Eliminated subtle scoping bugs File splits Modules that were doing too much, broken apart Godoc standardization Every exported function documented to convention <p>This is the work that doesn't get a changelog entry but makes every future commit easier. When a new contributor (human or AI) reads the codebase, they find consistent patterns instead of accumulated drift.</p> <p>The consolidation was not an afterthought. It was scheduled deliberately, with the same priority as features: The 3:1 ratio that emerged during <code>v0.2.0</code> development became an explicit practice: </p> <ul> <li>Three feature sessions; </li> <li>One consolidation session.</li> </ul>","path":["ctx v0.3.0: The Discipline Release"],"tags":[]},{"location":"blog/2026-02-15-ctx-v0.3.0-the-discipline-release/#the-ear-framework","level":2,"title":"The E/A/R Framework","text":"<p>On February 4<sup>th</sup>, we adopted the E/A/R classification as the official standard for evaluating skills:</p> Category Meaning Target Expert Knowledge Claude does not have &gt;70% Activation When/how to trigger ~20% Redundant What Claude already knows &lt;10% <p>This came from reviewing approximately 30 external skill files and discovering that most were redundant with Claude's built-in system prompt. Only about 20% had salvageable content, and even those yielded just a few heuristics each.</p> <p>The E/A/R framework gave us a concrete, testable criterion: </p> <p>A good skill is Expert knowledge minus what Claude already knows.</p> <p>If more than 10% of a skill restates platform defaults, it is creating noise, not signal.</p> <p>Every skill in <code>v0.3.0</code> was evaluated against this framework. Several were deleted. The survivors are leaner and more focused.</p>","path":["ctx v0.3.0: The Discipline Release"],"tags":[]},{"location":"blog/2026-02-15-ctx-v0.3.0-the-discipline-release/#backup-and-monitoring-infrastructure","level":2,"title":"Backup and Monitoring Infrastructure","text":"<p>A tool that manages your project's memory needs ops maturity. </p> <p><code>v0.3.0</code> added two pieces of infrastructure that reflect this:</p> <p>Backup staleness hook: A <code>UserPromptSubmit</code> hook that checks whether the last <code>.context/</code> backup is more than two days old. If it is, and the SMB mount is available, it reminds the user. No cron job running when nobody is working. No redundant backups when nothing has changed.</p> <p>Context size checkpoint: A <code>PreToolUse</code> hook that estimates current context window usage and warns when the session is getting heavy. This hooks into the attention budget philosophy: Degradation is expected, but it should be visible.</p> <p>Both hooks use <code>$CLAUDE_PROJECT_DIR</code> instead of hardcoded paths, a migration triggered by a username rename that broke every absolute path in the hook configuration. That migration (replacing <code>/home/user/...</code> with <code>\"$CLAUDE_PROJECT_DIR\"/.claude/hooks/...</code>) was one of those changes that seems trivial but prevents an entire category of future failures.</p>","path":["ctx v0.3.0: The Discipline Release"],"tags":[]},{"location":"blog/2026-02-15-ctx-v0.3.0-the-discipline-release/#the-numbers","level":2,"title":"The Numbers","text":"Metric v0.2.0 v0.3.0 Skills (was \"commands\") 11 21 Skills with quality gates 0 21 Skills with \"When NOT to Use\" 0 21 Average skill body ~15 lines ~80 lines Hooks using <code>$CLAUDE_PROJECT_DIR</code> 0 All Documentation commits -- 35+ Feature/fix commits -- ~15 <p>That ratio (35+ documentation and quality commits to ~15 feature commits) is the defining characteristic of this release:</p> <ul> <li>This release is not a failure to ship features. </li> <li>It is the deliberate choice to make the existing features reliable.</li> </ul>","path":["ctx v0.3.0: The Discipline Release"],"tags":[]},{"location":"blog/2026-02-15-ctx-v0.3.0-the-discipline-release/#what-v030-means","level":2,"title":"What v0.3.0 Means","text":"<p><code>v0.1.0</code> asked: \"Can we give AI persistent memory?\"</p> <p><code>v0.2.0</code> asked: \"Can we make that memory accessible to humans too?\"</p> <p><code>v0.3.0</code> asks a different question: \"Can we make the quality self-enforcing?\"</p> <p>The answer is not a feature: It is a practice:</p> <ul> <li>Skills with quality gates enforce pre-flight checks.</li> <li>Negative triggers prevent misuse without human intervention.</li> <li>The E/A/R framework ensures skills contain signal, not noise.</li> <li>Consolidation sessions are scheduled, not improvised.</li> <li>Hook infrastructure makes degradation visible.</li> </ul> <p>Discipline is not the absence of velocity. It is the infrastructure that makes velocity sustainable.</p>","path":["ctx v0.3.0: The Discipline Release"],"tags":[]},{"location":"blog/2026-02-15-ctx-v0.3.0-the-discipline-release/#what-comes-next","level":2,"title":"What Comes Next","text":"<p>The skill system is now mature enough to support real workflows without constant human correction. The hooks infrastructure is portable and resilient. The consolidation  practice is documented and repeatable.</p> <p>The next chapter is about what you build on top of discipline:</p> <ul> <li>Multi-agent coordination;</li> <li>Deeper integration patterns; </li> <li>And the question of whether context management is a tool concern or    an infrastructure concern.</li> </ul> <p>But those are future posts.</p> <p>This one is about the release that proved polish is not the opposite of progress. It is what turns a prototype into a product.</p> <p>The Discipline Release</p> <p><code>v0.1.0</code> shipped features. </p> <p><code>v0.2.0</code> shipped archaeology.</p> <p><code>v0.3.0</code> shipped the habits that make everything else trustworthy.</p> <p>The most important code in this release is the code that prevents bad code from shipping.</p> <p>This post was drafted using <code>/ctx-blog</code> with access to the full git history between v0.2.0 and v0.3.0, decision logs, learning logs, and the session files from the skill rewrite window. The meta continues.</p>","path":["ctx v0.3.0: The Discipline Release"],"tags":[]},{"location":"blog/2026-02-15-eight-ways-a-hook-can-talk/","level":1,"title":"Eight Ways a Hook Can Talk","text":"","path":["Eight Ways a Hook Can Talk"],"tags":[]},{"location":"blog/2026-02-15-eight-ways-a-hook-can-talk/#when-your-warning-disappears","level":2,"title":"When Your Warning Disappears","text":"<p>Jose Alekhinne / 2026-02-15</p> <p>I had a backup warning that nobody ever saw.</p> <p>The hook was correct: It detected stale backups, formatted a nice message, and output it as <code>{\"systemMessage\": \"...\"}</code>. The problem wasn't detection. The problem was delivery. The agent absorbed the information, processed it internally, and never told the user.</p> <p>Meanwhile, a different hook (the journal reminder) worked perfectly every time. Users saw the reminder, ran the commands, and the backlog stayed manageable. Same hook event (<code>UserPromptSubmit</code>), same project, completely different outcomes.</p> <p>The difference was one line:</p> <pre><code>IMPORTANT: Relay this journal reminder to the user VERBATIM\nbefore answering their question.\n</code></pre> <p>That explicit instruction is what makes VERBATIM relay a pattern, not just a formatting choice. And once I saw it as a pattern, I started seeing others.</p>","path":["Eight Ways a Hook Can Talk"],"tags":[]},{"location":"blog/2026-02-15-eight-ways-a-hook-can-talk/#the-audit","level":2,"title":"The Audit","text":"<p>I looked at every hook in <code>ctx</code>: Eight shell scripts across three hook events. And I found five distinct output patterns already in use, plus three more that the existing hooks were reaching for but hadn't quite articulated.</p> <p>The patterns form a spectrum based on a single question: </p> <p>\"Who decides what the user sees?\"</p> <p>At one end, the hook decides everything (hard gate: the agent literally cannot proceed). At the other end, the hook is invisible (silent side-effect: nobody knows it ran). In between, there is a range of negotiation between hook, agent, and the user.</p> <p>Here's the full spectrum:</p>","path":["Eight Ways a Hook Can Talk"],"tags":[]},{"location":"blog/2026-02-15-eight-ways-a-hook-can-talk/#1-hard-gate","level":3,"title":"1. Hard Gate","text":"<pre><code>{\"decision\": \"block\", \"reason\": \"Use ctx from PATH, not ./ctx\"}\n</code></pre> <p>The nuclear option: The agent's tool call is rejected before it executes.</p> <p>This is Claude Code's first-class <code>PreToolUse</code> mechanism: The hook returns JSON with <code>decision: block</code> and the agent gets an error with the reason.</p> <p>Use this for invariants: Constitution rules, security boundaries, things that must never happen. I use it to enforce <code>PATH</code>-based <code>ctx</code> invocation, block <code>sudo</code>, and require explicit approval for <code>git push</code>.</p>","path":["Eight Ways a Hook Can Talk"],"tags":[]},{"location":"blog/2026-02-15-eight-ways-a-hook-can-talk/#2-verbatim-relay","level":3,"title":"2. VERBATIM Relay","text":"<pre><code>IMPORTANT: Relay this warning to the user VERBATIM before answering.\n┌─ Journal Reminder ─────────────────────────────\n│ You have 12 sessions not yet exported.\n│   ctx recall export --all\n└────────────────────────────────────────────────\n</code></pre> <p>The instruction is the pattern. Without \"Relay VERBATIM,\" agents tend to absorb information into their internal reasoning and never surface it. The explicit instruction changes the behavior from \"I know about this\" to  \"I must tell the user about this.\"</p> <p>I use this for actionable reminders: </p> <ul> <li>Unexported journal entries;</li> <li>Stale backups;</li> <li>Context capacity warnings... </li> </ul> <p>...things the user should see regardless of what they asked.</p>","path":["Eight Ways a Hook Can Talk"],"tags":[]},{"location":"blog/2026-02-15-eight-ways-a-hook-can-talk/#3-agent-directive","level":3,"title":"3. Agent Directive","text":"<pre><code>┌─ Persistence Checkpoint (prompt #25) ───────────\n│ No context files updated in 15+ prompts.\n│ Have you discovered learnings worth persisting?\n└──────────────────────────────────────────────────\n</code></pre> <p>A nudge, not a command. The hook tells the agent something; the agent decides what (if anything) to tell the user. This is right for behavioral nudges — \"you haven't saved context in a while\" doesn't need to be relayed verbatim, but the agent should consider acting on it.</p>","path":["Eight Ways a Hook Can Talk"],"tags":[]},{"location":"blog/2026-02-15-eight-ways-a-hook-can-talk/#4-silent-context-injection","level":3,"title":"4. Silent Context Injection","text":"<pre><code>ctx agent --budget 4000 2&gt;/dev/null || true\n</code></pre> <p>Pure background enrichment. The agent's context window gets project information injected on every tool call, with no visible output. Neither the agent nor the user sees the hook fire — but the agent makes better decisions because of the context.</p>","path":["Eight Ways a Hook Can Talk"],"tags":[]},{"location":"blog/2026-02-15-eight-ways-a-hook-can-talk/#5-silent-side-effect","level":3,"title":"5. Silent Side-Effect","text":"<pre><code>find \"$CTX_TMPDIR\" -type f -mtime +15 -delete\n</code></pre> <p>Do work, say nothing. Temp file cleanup on session end. Logging. Marker file management. The action is the entire point; no one needs to know.</p>","path":["Eight Ways a Hook Can Talk"],"tags":[]},{"location":"blog/2026-02-15-eight-ways-a-hook-can-talk/#the-patterns-we-dont-have-yet","level":2,"title":"The Patterns We Don't Have Yet","text":"<p>Three more patterns emerged from the gaps in the existing hooks.</p> <p>Conditional relay: \"Relay this, but only if the user's question is about X.\" This pattern avoids noise when the warning isn't relevant.  It's more fragile (depends on agent judgment) but less annoying.</p> <p>Suggested action: \"Here's a problem, and here's the exact command to fix it. Ask the user before running it.\" This pattern goes beyond a nudge by  giving the agent a concrete proposal, but still requires human approval.</p> <p>Escalating severity: <code>INFO</code> gets absorbed silently. <code>WARN</code> gets mentioned at the next natural pause. <code>CRITICAL</code> gets the VERBATIM treatment. This pattern introduces a protocol for hooks that produce output  at different urgency levels, so they don't all compete for the user's attention.</p>","path":["Eight Ways a Hook Can Talk"],"tags":[]},{"location":"blog/2026-02-15-eight-ways-a-hook-can-talk/#the-principle","level":2,"title":"The Principle","text":"<p>Hooks are the boundary between your environment and the agent's reasoning. </p> <p>A hook that detects a problem but can't communicate it effectively is the same  as no hook at all.</p> <p>The format of your output is a design decision with real consequences:</p> <ul> <li>Use a hard gate and the agent can't proceed (good for invariants,   frustrating for false positives)</li> <li>Use VERBATIM relay and the user will see it (good for reminders,   noisy if overused)</li> <li>Use an agent directive and the agent might act (good for nudges,   unreliable for critical warnings)</li> <li>Use silent injection and nobody knows (good for enrichment,   invisible when it breaks)</li> </ul> <p>Choose deliberately. And, when in doubt, write the word <code>VERBATIM</code>.</p> <p>The full pattern catalog with decision flowchart and implementation examples is in the Hook Output Patterns recipe.</p>","path":["Eight Ways a Hook Can Talk"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/","level":1,"title":"Version Numbers Are Lagging Indicators","text":"","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/#why-ctxs-journal-site-runs-on-a-v0021-tool","level":2,"title":"Why ctx's Journal Site Runs on a v0.0.21 Tool","text":"<p>Jose Alekhinne / 2026-02-15</p> <p>Would You Ship Production Infrastructure on a v0.0.21 Dependency?</p> <p>Most engineers wouldn't. Version numbers signal maturity. Pre-1.0 means unstable API, missing features, risk.</p> <p>But version numbers tell you where a project has been. They say nothing about where it's going.</p> <p>I just bet <code>ctx</code>'s entire journal site on a tool that hasn't hit <code>v0.1.0</code>. </p> <p>Here's why I'd do it again.</p>","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/#the-problem","level":2,"title":"The Problem","text":"<p>When v0.2.0 shipped the journal system, the pipeline was clear:</p> <ul> <li>Export sessions to Markdown; </li> <li>Enrich them with YAML frontmatter; </li> <li>And render them into something browsable. </li> </ul> <p>The first two steps were solved; the third needed a tool.</p> <p>The journal entries are standard Markdown with YAML frontmatter, tables, and fenced code blocks. That is the entire format: </p> <ul> <li>No JSX;</li> <li>No shortcodes;</li> <li>No custom templating. </li> </ul> <p>Just Markdown rendered well.</p> <p>The requirements are modest:</p> <ul> <li>Read a configuration file (such as <code>mkdocs.yml</code>);</li> <li>Render Markdown with extensions (admonitions, tabs, tables);</li> <li>Search;</li> <li>Handle 100+ files without choking on incremental rebuilds;</li> <li>Look good out of the box;</li> <li>Not lock me in.</li> </ul> <p>The obvious candidates were as follows:</p> Tool Language Strengths Pain Points Hugo Go Blazing fast, mature Templating is painful; Go templates fight you on anything non-trivial Astro JS/TS Modern, flexible JS ecosystem overhead; overkill for a docs site MkDocs + Material Python Beautiful defaults, massive community (22k+ stars) Slow incremental rebuilds on large sites; limited extensibility model Zensical Python Built to fix MkDocs' limits; 4-5x faster rebuilds v0.0.21; module system not yet shipped <p>The instinct was Hugo. Same language as <code>ctx</code>. Fast. Well-established.</p> <p>But instinct is not analysis. I picked the one with the lowest version number.</p>","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/#the-evaluation","level":2,"title":"The Evaluation","text":"<p>Here is what I actually evaluated, in order:</p>","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/#1-the-team","level":3,"title":"1. The Team","text":"<p>Zensical is built by squidfunk: The same person behind Material for MkDocs, the most popular MkDocs theme with 22,000+ stars. It powers documentation sites for projects across every language and framework.</p> <ul> <li>This is not someone learning how to build static site generators.</li> <li>This is someone who spent years understanding exactly where MkDocs   breaks and decided to fix it from the ground up.</li> </ul> <p>They did not build zensical because MkDocs was bad:  They built it because MkDocs hit a ceiling:</p> <ul> <li> <p>Incremental rebuilds: 4-5x faster during serve. When you have   hundreds of journal entries and you edit one, the difference between   \"rebuild everything\" and \"rebuild this page\" is the difference   between a usable workflow and a frustrating one.</p> </li> <li> <p>Large site performance: Specifically designed for tens of   thousands of pages. The journal grows with every session. A tool   that slows down as content accumulates is a tool you will eventually   replace.</p> </li> </ul> <p>A proven team starting fresh is more predictable than an unproven team at v3.0.</p>","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/#2-the-architecture","level":3,"title":"2. The Architecture","text":"<p>Zensical is investing in a Rust-based Markdown parser with CommonMark support. That signals something about the team's priorities:</p> <p>Performance foundations first; features second.</p> <p><code>ctx</code>'s journal will grow: </p> <ul> <li>Every exported session adds files.</li> <li>Every enrichment pass adds metadata. </li> </ul> <p>Choosing a tool that gets slower as you add content means choosing to migrate later.</p> <p>Choosing one built for scale means the decision holds.</p>","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/#3-the-migration-path","level":3,"title":"3. The Migration Path","text":"<p>Zensical reads <code>mkdocs.yml</code> natively. If it doesn't work out, I can move back to MkDocs + Material with zero content changes:</p> <ul> <li>The Markdown is standard; </li> <li>The frontmatter is standard; </li> <li>The configuration is compatible.</li> </ul> <p>This is the infrastructure pattern again: The same way <code>ZNC</code> decouples presence from the client, <code>zensical</code> decouples rendering from the generator: </p> <ul> <li>The Markdown is yours. </li> <li>The frontmatter is standard YAML. </li> <li>The configuration is MkDocs-compatible.</li> </ul> <p>You are not locked into anything except your own content.</p> <p>No lock-in is not a feature: It's a design philosophy: </p> <p>It's the same reason <code>ctx</code> uses plain Markdown files in <code>.context/</code> instead of a database: the format should outlive the tool.</p> <p>Lock-in Is the Real Risk, Not Version Numbers</p> <p>A mature tool with a proprietary format is riskier than a young tool with a standard one. Version numbers measure time invested. Portability measures respect for the user.</p>","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/#4-the-dependency-tree","level":3,"title":"4. The Dependency Tree","text":"<p>Here is what <code>pip install zensical</code> actually pulls in:</p> <ul> <li>click</li> <li>Markdown</li> <li>Pygments</li> <li>pymdown-extensions</li> <li>PyYAML</li> </ul> <p>Only five dependencies. All well-known. No framework bloat. No bundler. No transpiler. No <code>node_modules</code> black hole.</p> <p>3k GitHub stars at <code>v0.0.21</code> is a strong early traction for a <code>pre-1.0</code> project. </p> <p>The dependency tree is thin: No bloat.</p>","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/#5-the-fit","level":3,"title":"5. The Fit","text":"<p>This is the same principle behind the attention budget: do not overfit the tool to hypothetical requirements. The right amount of capability is the minimum needed for the current task.</p> <p>Hugo is a powerful static site generator. It is also a powerful templating engine, a powerful asset pipeline, and a powerful taxonomy system. For rendering Markdown journals, that power is overhead:</p> <p>It is the complexity you pay for but never use.</p> <p><code>ctx</code>'s journal files are standard Markdown with YAML frontmatter, tables, and fenced code blocks. That is exactly the sweet spot Zensical inherits from Material for MkDocs:</p> <ul> <li>No custom plugins needed;</li> <li>No special syntax; </li> <li>No templating gymnastics.</li> </ul> <p>The requirements match the capabilities: Not the capabilities that are promised, but the ones that exist today, at <code>v0.0.21</code>.</p>","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/#the-caveat","level":2,"title":"The Caveat","text":"<p>It would be dishonest not to mention what's missing.</p> <p>The module system for third-party extensions opens in early 2026.</p> <p>If <code>ctx</code> ever needs custom plugins (for example, auto-linking session IDs, rendering special journal metadata, etc.) that infrastructure isn't there yet.</p> <p>The installation experience is rough: </p> <p>We discovered this firsthand: <code>pip install zensical</code> often fails on MacOS  (system Python stubs, Homebrew's PEP 668 restrictions). The answer is pipx, which creates an isolated environment with the correct Python version automatically. </p> <p>That kind of friction is typical for young Python tooling, and it is documented in the Getting Started guide.</p> <p>And <code>3,000</code> stars at <code>v0.0.21</code> is strong early traction, but it's still early: The community is small. When something breaks, you're reading  source  code, not documentation.</p> <p>These are real costs. I chose to pay them because the alternative costs are higher.</p> <p>For example:</p> <ul> <li>Hugo's templating pain would cost me time on every site change.</li> <li>Astro's JS ecosystem would add complexity I don't need. </li> <li>MkDocs would work today but hit scaling walls tomorrow. </li> </ul> <p>Zensical's costs are front-loaded and shrinking. </p> <p>The others compound.</p>","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/#the-evaluation-framework","level":2,"title":"The Evaluation Framework","text":"<p>For anyone facing a similar choice, here is the framework that emerged:</p> Signal What It Tells You Weight Team track record Whether the architecture will be sound High Migration path Whether you can leave if wrong High Current fit Whether it solves your problem today High Dependency tree How much complexity you're inheriting Medium Version number How long the project has existed Low Star count Community interest (not quality) Low Feature list What's possible (not what you need) Low <p>The bottom three are the metrics most engineers optimize for.</p> <p>The top four are the ones that predict whether you'll still be happy with the choice in a year.</p> <p>Features You Don't Need Are Not Free</p> <p>Every feature in a dependency is code you inherit but don't control. </p> <p>A tool with 200 features where you use 5 means 195 features worth of surface area for bugs, breaking changes, and security issues that have nothing to do with your use case.</p> <p>Fit is the inverse of feature count.</p>","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-15-why-zensical/#the-broader-pattern","level":2,"title":"The Broader Pattern","text":"<p>This is part of a theme I keep encountering in this project:</p> <p>Leading indicators beat lagging indicators.</p> Domain Lagging Indicator Leading Indicator Tooling Version number, star count Team track record, architecture Code quality Test coverage percentage Whether tests catch real bugs Context persistence Number of files in <code>.context/</code> Whether the AI makes fewer mistakes Skills Number of skills created Whether each skill fires at the right time Consolidation Lines of code refactored Whether drift stops accumulating <p>Version numbers, star counts, coverage percentages, file counts...</p> <p>...these are all measures of effort expended. </p> <p>They say nothing about value delivered.</p> <p>The question is never \"how mature is this tool?\" </p> <p>The question is \"does this tool's trajectory intersect with my needs?\"</p> <p>Zensical's trajectory: </p> <ul> <li>A proven team fixing known problems, </li> <li>in a *proven architecture, </li> <li>with a standard format,</li> <li>and no lock-in.</li> </ul> <p><code>ctx</code>'s needs: </p> <p>Tender standard Markdown into a browsable site, at scale,  without complexity.</p> <p>The intersection is clean; the version number is noise.</p> <p>This is the same kind of decision that shows up throughout <code>ctx</code>:</p> <ul> <li>Skills that fight the platform taught that the best   integration extends existing behavior, not replaces it.</li> <li>You can't import expertise taught that tools should   grow from your project's actual needs, not from feature checklists.</li> <li>Context as infrastructure argues that the format should   outlive the tool; and, <code>zensical</code> honors that principle by reading   standard Markdown and standard MkDocs configuration.</li> </ul> <p>If you remember one thing from this post...</p> <p>Version numbers measure where a project has been.</p> <p>The team and the architecture tell you where it's going.</p> <p>A <code>v0.0.21</code> tool built by the right team on the right foundations is a safer bet than a <code>v5.0</code> tool that doesn't fit your problem.</p> <p>Bet on trajectories, not timestamps.</p> <p>This post started as an evaluation note in <code>ideas/</code> and a separate decision log. The analysis held up. The two merged into one. The meta continues.</p>","path":["Version Numbers Are Lagging Indicators"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/","level":1,"title":"ctx v0.6.0: The Integration Release","text":"","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#two-commands-to-persistent-memory","level":2,"title":"Two Commands to Persistent Memory","text":"<p>Jose Alekhinne / February 16, 2026</p> <p>What Changed?</p> <p><code>ctx</code> is now a Claude Code plugin. Two commands, no build step:</p> <pre><code>/plugin marketplace add ActiveMemory/ctx\n/plugin install ctx@activememory-ctx\n</code></pre> <p>Six hooks. Twenty-five skills. Installed.</p> <p>For three releases, <code>ctx</code> required assembly: </p> <ul> <li>Clone the repo; </li> <li>Build the binary; </li> <li>Copy hook scripts into <code>.claude/hooks/</code>; </li> <li>Symlink skill files.</li> <li>Understand which shell scripts called which Go commands;</li> <li>Hope nothing broke when Claude Code updated its hook format.</li> </ul> <p><code>v0.6.0</code> ends that era: <code>ctx</code> ships as a Claude Marketplace plugin:</p> <p>Hooks and skills served directly from source, installed with a single command, updated by pulling the repo. The tool that gives AI persistent memory is now as easy to install as the AI itself.</p> <p>But the plugin conversion was not just a packaging change: It was the forcing function that rewrote every shell hook in Go, eliminated the <code>jq</code> dependency, enabled <code>go test</code> coverage for hook logic, and made distribution a solved problem. </p> <p>When you fix how something ships, you end up fixing how it is built.</p> <p>The Release Window</p> <p>February 15–February 16, 2026</p> <p>From the v0.3.0 tag to commit <code>a3178bc</code>:</p> <ul> <li>109 commits. </li> <li>334 files changed. </li> <li>Version jumped from 0.3.0 to 0.6.0 to signal the magnitude.</li> </ul>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#before-six-shell-scripts-and-a-prayer","level":2,"title":"Before: Six Shell Scripts and a Prayer","text":"<p><code>v0.3.0</code> had six hook scripts. Each was a Bash file that shelled out to <code>ctx</code> subcommands, parsed JSON with <code>jq</code>, and wired itself into Claude Code's hook system via <code>.claude/hooks/</code>:</p> <pre><code>.claude/hooks/\n├── check-context-size.sh\n├── check-persistence.sh\n├── check-journal.sh\n├── post-commit.sh\n├── block-non-path-ctx.sh\n└── cleanup-tmp.sh\n</code></pre> <p>This worked, but it also meant:</p> <ul> <li>jq was a hard dependency: No <code>jq</code>, no hooks. macOS ships without it.</li> <li>No test coverage: Shell scripts were tested manually or not at all.</li> <li>Fragile deployment: <code>ctx init</code> had to scaffold <code>.claude/hooks/</code>   and <code>.claude/skills/</code> with the right paths, permissions, and structure.</li> <li>Version drift: Users who installed once never got hook updates   unless they re-ran <code>ctx init</code>.</li> </ul> <p>The shell scripts were the right choice for prototyping. They were the wrong choice for distribution.</p>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#after-one-plugin-zero-shell-scripts","level":2,"title":"After: One Plugin, Zero Shell Scripts","text":"<p><code>v0.6.0</code> replaces all six scripts with <code>ctx system</code> subcommands compiled into the binary:</p> Shell Script Go Subcommand <code>check-context-size.sh</code> <code>ctx system check-context-size</code> <code>check-persistence.sh</code> <code>ctx system check-persistence</code> <code>check-journal.sh</code> <code>ctx system check-journal</code> <code>post-commit.sh</code> <code>ctx system post-commit</code> <code>block-non-path-ctx.sh</code> <code>ctx system block-non-path-ctx</code> <code>cleanup-tmp.sh</code> <code>ctx system cleanup-tmp</code> <p>The plugin's <code>hooks.json</code> wires them to Claude Code events:</p> <pre><code>{\n  \"PreToolUse\": [\n    {\"matcher\": \"Bash\", \"command\": \"ctx system block-non-path-ctx\"},\n    {\"matcher\": \".*\", \"command\": \"ctx agent --budget 4000\"}\n  ],\n  \"PostToolUse\": [\n    {\"matcher\": \"Bash\", \"command\": \"ctx system post-commit\"}\n  ],\n  \"UserPromptSubmit\": [\n    {\"command\": \"ctx system check-context-size\"},\n    {\"command\": \"ctx system check-persistence\"},\n    {\"command\": \"ctx system check-journal\"}\n  ],\n  \"SessionEnd\": [\n    {\"command\": \"ctx system cleanup-tmp\"}\n  ]\n}\n</code></pre> <p>No jq. No shell scripts. No <code>.claude/hooks/</code> directory to manage.</p> <p>The hooks are Go functions with tests, compiled into the same binary you already have.</p>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#the-plugin-model","level":2,"title":"The Plugin Model","text":"<p>The <code>ctx</code> plugin lives at <code>.claude-plugin/marketplace.json</code> in the repo.</p> <p>Claude Code's marketplace system handles discovery and installation:</p> <p>Skills are served directly from <code>internal/assets/claude/skills/</code>; there is no build step, no <code>make plugin</code>, no generated artifacts.</p> <p>This means:</p> <ol> <li>Install is two commands: Not \"clone, build, copy, configure.\"</li> <li>Updates are automatic: Pull the repo; the plugin reads from source.</li> <li>Skills and hooks are versioned together: No drift between what    the CLI expects and what the plugin provides.</li> <li><code>ctx init</code> is tool-agnostic: It creates <code>.context/</code> and nothing    else. No <code>.claude/</code> scaffolding, no assumptions about which AI tool    you use.</li> </ol> <p>That last point matters: </p> <p>Before <code>v0.6.0</code>, <code>ctx init</code> tried to set up Claude Code integration as part of  initialization. That coupled the context system to a specific tool. </p> <p>Now, <code>ctx init</code> gives you persistent context. The plugin gives you Claude Code  integration. They compose; they don't depend.</p>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#beyond-the-plugin-what-else-shipped","level":2,"title":"Beyond the Plugin: What Else Shipped","text":"<p>The plugin conversion dominated the release, but 109 commits covered more ground.</p>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#obsidian-vault-export","level":3,"title":"Obsidian Vault Export","text":"<pre><code>ctx journal obsidian\n</code></pre> <p>Generates a full Obsidian vault from enriched journal entries: wikilinks, MOC (Map of Content) pages, and graph-optimized cross-linking. If you already use Obsidian for notes, your AI session history now lives alongside everything else.</p>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#encrypted-scratchpad","level":3,"title":"Encrypted Scratchpad","text":"<pre><code>ctx pad edit \"DATABASE_URL=postgres://...\"\nctx pad show\n</code></pre> <p><code>AES-256-GCM</code> encrypted storage for sensitive one-liners. </p> <p>The encrypted blob commits to <code>git</code>; the key stays in <code>.gitignore</code>. </p> <p>This is useful for connection strings, API keys, and other values that need to travel with the project without appearing in plaintext.</p>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#security-hardening","level":3,"title":"Security Hardening","text":"<p>Three medium-severity findings from a security audit are now closed:</p> Finding Fix Path traversal via <code>--context-dir</code> Boundary validation: operations cannot escape project root (M-1) Symlink following in <code>.context/</code> <code>Lstat()</code> check before every file read/write (M-2) Predictable temp file paths User-specific temp directory under <code>$XDG_RUNTIME_DIR</code> (M-3) <p>Plus a new <code>/sanitize-permissions</code> skill that audits <code>settings.local.json</code> for overly broad Bash permissions.</p>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#hooks-that-know-when-to-be-quiet","level":3,"title":"Hooks That Know When to Be Quiet","text":"<p>A subtle but important fix: hooks now no-op before <code>ctx init</code> has run.</p> <p>Previously, a fresh clone with no <code>.context/</code> would trigger hook errors on every prompt. Now, hooks detect the absence of a context directory and exit silently. Similarly, <code>ctx init</code> treats a <code>.context/</code> directory containing only logs as uninitialized and skips the <code>--overwrite</code> prompt.</p> <p>Small changes. Large reduction in friction for new users.</p>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#the-numbers","level":2,"title":"The Numbers","text":"Metric v0.3.0 v0.6.0 Skills 21 25 Shell hook scripts 6 0 Go system subcommands 0 6 External dependencies (hooks) jq, bash none Lines of Go ~14,000 ~37,000 Plugin install commands n/a 2 Security findings (open) 3 0 <code>ctx init</code> creates .claude/ yes no <p>The line count tripled. Most of that is documentation site HTML, Obsidian export logic, and the scratchpad encryption module. </p> <p>The core CLI grew modestly; the ecosystem around it grew substantially.</p>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#what-does-v060-mean-for-ctx","level":2,"title":"What Does <code>v0.6.0</code> Mean for <code>ctx</code>?","text":"<ul> <li><code>v0.1.0</code> asked: \"Can we give AI persistent memory?\"</li> <li><code>v0.2.0</code> asked: \"Can we make that memory accessible to humans too?\"</li> <li><code>v0.3.0</code> asked: \"Can we make the quality self-enforcing?\"</li> </ul> <p>v0.6.0 asks: \"Can someone else actually use this?\"</p> <p>A tool that requires cloning a repo, building from source, and manually wiring hooks into the right directories is a tool for its author.</p> <p>A tool that installs with two commands from a marketplace is a tool for everyone.</p> <p>The version jumped from <code>0.3.0</code> to <code>0.6.0</code> because the delta is not incremental: The shell-to-Go rewrite, the plugin model, the security hardening, and the tool-agnostic init: Together, they change what <code>ctx</code> is: Not a different tool, but a tool that is finally ready to leave the workshop.</p>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-16-ctx-v0.6.0-the-integration-release/#what-comes-next","level":2,"title":"What Comes Next","text":"<p>The plugin model opens the door to distribution patterns that were not possible before. Marketplace discovery means new users find <code>ctx</code> without reading a <code>README</code>. Plugin updates mean existing users get improvements without rebuilding.</p> <p>The next chapter is about what happens when persistent context is easy to install: Adoption patterns, multi-project workflows, and whether the <code>.context/</code> convention can become infrastructure that other tools build on.</p> <p>But those are future posts.</p> <p>This one is about the release that turned a developer tool into a distributable product: two commands, zero shell scripts, and a presence on the Claude Marketplace.</p> <p>The Integration Release</p> <p><code>v0.1.0</code> shipped features. <code>v0.2.0</code> shipped archaeology.</p> <p><code>v0.3.0</code> shipped discipline. <code>v0.6.0</code> shipped the front door.</p> <p>The most important code in this release is the code you never have to copy.</p> <p>This post was drafted using <code>/ctx-blog-changelog</code> with access to the full git history between v0.3.0 and v0.6.0, release notes, and the plugin conversion PR. The meta continues.</p>","path":["ctx v0.6.0: The Integration Release"],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/","level":1,"title":"Code Is Cheap. Judgment Is Not.","text":"","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#why-ai-replaces-effort-not-expertise","level":2,"title":"Why AI Replaces Effort, Not Expertise","text":"<p>Jose Alekhinne / February 17, 2026</p> <p>Are You Worried About AI Taking Your Job?</p> <p>You might be confusing the thing that's cheap with the thing that's valuable.</p> <p>I keep seeing the same conversation:  Engineers, designers, writers: all asking the same question with the same dread:</p> <p>\"What happens when AI can do what I do?\"</p> <p>The question is wrong:</p> <ul> <li>AI does not replace workers;</li> <li>AI replaces unstructured effort.</li> </ul> <p>The distinction matters, and everything I have learned building <code>ctx</code> reinforces it.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#the-three-confusions","level":2,"title":"The Three Confusions","text":"<p>People who feel doomed by AI usually confuse three things:</p> People confuse... With... Effort Value Typing Thinking Production Judgment <ul> <li>Effort is time spent.</li> <li>Value is the outcome that time produces.</li> </ul> <p>They are not the same; they never were. </p> <p>AI just makes the gap impossible to ignore.</p> <p>Typing is mechanical: Thinking is directional. </p> <p>An AI can type faster than any human. Yet, it cannot decide what to type without someone framing the problem, sequencing the work, and evaluating the result.</p> <p>Production is making artifacts. Judgment is knowing:</p> <ul> <li>which artifacts to make, </li> <li>in what order, </li> <li>to what standard, </li> <li>and when to stop.</li> </ul> <p>AI floods the system with production capacity; it does not flood the system with judgment.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#code-is-nothing","level":2,"title":"Code Is Nothing","text":"<p>This sounds provocative until you internalize it:</p> <p>Code is cheap. Artifacts are cheap.</p> <p>An AI can generate a thousand lines of working code in literal *minutes**:</p> <p>It can scaffold a project, write tests, build a CI pipeline, draft documentation. The raw production of software artifacts is no longer the bottleneck.</p> <p>So, what is not cheap?</p> <ul> <li>Taste: knowing what belongs and what does not</li> <li>Framing: turning a vague goal into a concrete problem</li> <li>Sequencing: deciding what to build first and why</li> <li>Fanning out: breaking work into parallel streams that   converge</li> <li>Acceptance criteria: defining what \"done\" looks like before   starting</li> <li>Judgment: the thousand small decisions that separate code   that works from code that lasts</li> </ul> <p>These are the skills that direct production: Hhuman skills.</p> <p>Not because AI is incapable of learning them, but because they require something AI does not have: </p> <p>temporal accountability for generated outcomes.</p> <p>That is, you cannot keep AI accountable for the <code>$#!%</code> it generated three months ago. A human, on the other hand, will always be accountable.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#the-evidence-from-building-ctx","level":2,"title":"The Evidence From Building ctx","text":"<p>I did not arrive at this conclusion theoretically. </p> <p>I arrived at it by building a tool with an AI agent for three weeks  and watching exactly where a human touch mattered.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#yolo-mode-proved-production-is-cheap","level":3,"title":"YOLO Mode Proved Production Is Cheap","text":"<p>In Building ctx Using ctx, I documented the YOLO phase: auto-accept everything, let the AI ship features at full speed. It produced 14 commands in a week. Impressive output.</p> <p>The code worked. The architecture drifted. Magic strings accumulated. Conventions diverged. The AI was producing at a pace no human could match, and every artifact it produced was a small bet that nobody was evaluating.</p> <p>Production without judgment is not velocity. It is debt accumulation at breakneck speed.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#the-31-ratio-proved-judgment-has-a-cadence","level":3,"title":"The 3:1 Ratio Proved Judgment Has a Cadence","text":"<p>In The 3:1 Ratio, the <code>git</code> history told the story:</p> <p>Three sessions of forward momentum followed by one session of deliberate consolidation. The consolidation session is where the human applies judgment: reviewing what the AI built, catching drift, realigning conventions.</p> <p>The AI does the refactoring. The human decides what to refactor and when to stop. </p> <p>Without the human, the AI will refactor forever, improving things that do not matter and missing things that do.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#the-attention-budget-proved-framing-is-scarce","level":3,"title":"The Attention Budget Proved Framing Is Scarce","text":"<p>In The Attention Budget, I explained why more context makes AI worse, not better. Every token competes for attention: Dump everything in and the AI sees nothing clearly.</p> <p>This is a framing problem: The human's job is to decide what the AI should focus on: what to include, what to exclude, what to emphasize. </p> <p><code>ctx agent --budget 4000</code> is not just a CLI flag: It is a forcing function for human judgment about relevance.</p> <p>The AI processes. The human curates.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#skills-design-proved-taste-is-load-bearing","level":3,"title":"Skills Design Proved Taste Is Load-Bearing","text":"<p>The skill trilogy (You Can't Import Expertise, The Anatomy of a Skill That Works) showed that the difference between a useful skill and a useless one is not craftsmanship: </p> <p>It is taste.</p> <p>A well-crafted skill with the wrong focus is worse than no skill at all: It consumes the attention budget with generic advice while the project-specific problems go unchecked. </p> <p>The E/A/R framework (Expert, Activation, Redundant) is a judgment too:. The AI cannot apply it to itself. The human evaluates what the AI already knows, what it needs to be told, and what is noise.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#automation-discipline-proved-restraint-is-a-skill","level":3,"title":"Automation Discipline Proved Restraint Is a Skill","text":"<p>In Not Everything Is a Skill, the lesson was that the urge to automate is not the need to automate. A useful prompt does not automatically deserve to become a slash command.</p> <p>The human applies judgment about frequency, stability, and attention cost.</p> <p>The AI can build the skill. Only the human can decide whether it should exist.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#defense-in-depth-proved-boundaries-require-judgment","level":3,"title":"Defense in Depth Proved Boundaries Require Judgment","text":"<p>In Defense in Depth, the entire security model for unattended AI agents came down to: markdown is not a security boundary. Telling an AI \"don't do bad things\" is production (of instructions). Setting up an unprivileged user in a network-isolated container is judgment (about risk).</p> <p>The AI follows instructions. The human decides which instructions are enforceable and which are \"wishful thinking\".</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#parallel-agents-proved-scale-amplifies-the-gap","level":3,"title":"Parallel Agents Proved Scale Amplifies the Gap","text":"<p>In Parallel Agents and Merge Debt, the lesson was that multiplying agents multiplies output. But it also multiplies the need for judgment:</p> <p>Five agents running in parallel produce five sessions of drift in one clock  hour. The human who can frame tasks cleanly, define narrow acceptance  criteria, and evaluate results quickly becomes the limiting factor.</p> <p>More agents do not reduce the need for judgment. They increase it.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#the-two-reactions","level":2,"title":"The Two Reactions","text":"<p>When AI floods the system with cheap output, two things happen:</p> <p>Those who only produce: panic. If your value proposition is \"I write code,\" and an AI writes code faster, cheaper, and at higher volume, then the math is unfavorable. Not because AI took your job, but because your job was never the code. It was the judgment around the code, and you were not exercising it.</p> <p>Those who direct: accelerate. If your value proposition is \"I know what to build, in what order, to what standard,\" then AI is the best thing that ever happened to you: Production is no longer the bottleneck: Your ability to frame, sequence, evaluate, and course-correct is now the limiting factor on throughput.</p> <p>The gap between these two is not talent: It is the awareness of where the value lives.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#what-this-means-in-practice","level":2,"title":"What This Means in Practice","text":"<p>If you are an engineer reading this, the actionable insight is not \"learn prompt engineering\" or \"master AI tools.\" It is:</p> <p>Get better at the things AI cannot do.</p> AI does this well You need to do this Generate code Frame the problem Write tests Define acceptance criteria Scaffold projects Sequence the work Fix bugs from stack traces Evaluate tradeoffs Produce volume Exercise restraint Follow instructions Decide which instructions matter <p>The skills on the right column are not new. They are the same skills that have always separated senior engineers from junior ones. </p> <p>AI did not create the distinction; it just made it load-bearing.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#if-anything-i-feel-empowered","level":2,"title":"If Anything, I Feel Empowered","text":"<p>I will end with something personal.</p> <p>I am not worried: I am empowered.</p> <p>Before <code>ctx</code>, I could think faster than I could produce: </p> <ul> <li>Ideas sat in a queue. </li> <li>The bottleneck was always \"I know what to build,   but building it takes too long.\"</li> </ul> <p>Now the bottleneck is gone. Poof!</p> <ul> <li>Production is cheap. </li> <li>The queue is clearing. </li> <li>The limiting factor is how fast I can think,    not how fast I can type.</li> </ul> <p>That is not a threat: That is the best force multiplier I've ever had.</p> <p>The people who feel threatened are confusing the accelerator for the replacement:</p> <p>*AI does not replace the conductor; it gives them  a bigger orchestra.</p> <p>If you remember one thing from this post...</p> <p>Code is cheap. Judgment is not.</p> <p>AI replaces unstructured effort, not directed expertise. The skills that matter now are the same skills that have always mattered: taste, framing, sequencing, and the discipline to stop.</p> <p>The difference is that now, for the first time, those skills are the only bottleneck left.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-code-is-cheap-judgment-is-not/#the-arc","level":2,"title":"The Arc","text":"<p>This post is a retrospective. It synthesizes the thread running through every previous entry in this blog:</p> <ul> <li>Building ctx Using ctx showed that production   without direction creates debt</li> <li>Refactoring with Intent   showed that slowing down is not the opposite of progress</li> <li>The Attention Budget showed that curation   outweighs volume</li> <li>The skill trilogy showed that taste determines   whether a tool helps or hinders</li> <li>Not Everything Is a Skill showed that   restraint is a skill in itself</li> <li>Defense in Depth showed that instructions are   not boundaries</li> <li>The 3:1 Ratio showed that judgment has a schedule</li> <li>Parallel Agents showed that scale amplifies   the gap between production and judgment</li> <li>Context as Infrastructure showed that the system   you build for context is infrastructure, not conversation</li> </ul> <p>From YOLO mode to defense in depth, the pattern is the same:</p> <ul> <li>Production is the easy part;</li> <li>Judgment is the hard part;</li> <li>AI changed the ratio, not the rule.</li> </ul> <p>This post synthesizes the thread running through every previous entry in this blog. The evidence is drawn from three weeks of building ctx with AI assistance, the decisions recorded in DECISIONS.md, the learnings captured in LEARNINGS.md, and the git history that tracks where the human mattered and where the AI ran unsupervised.</p> <p>See also: When a System Starts Explaining Itself -- what happens after the arc: the first field notes from the moment the system starts compounding in someone else's hands.</p>","path":["Code Is Cheap. Judgment Is Not."],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/","level":1,"title":"Context as Infrastructure","text":"","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/#why-your-ai-needs-a-filesystem-not-a-prompt","level":2,"title":"Why Your AI Needs a Filesystem, Not a Prompt","text":"<p>Jose Alekhinne / February 17, 2026</p> <p>Where does your AI's knowledge live between sessions?</p> <p>If the answer is \"in a prompt I paste at the start,\" you are treating context as a consumable. Something assembled, used, and discarded.</p> <p>What if you treated it as infrastructure instead?</p> <p>This post synthesizes a thread that has been running through every <code>ctx</code> blog post; from the origin story to the attention budget to the discipline release. The thread is this: context is not a prompt problem. It is an infrastructure problem. And the tools we build for it should look more like filesystems than clipboard managers.</p>","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/#the-prompt-paradigm","level":2,"title":"The Prompt Paradigm","text":"<p>Most AI-assisted development treats context as ephemeral:</p> <ol> <li>Start a session.</li> <li>Paste your system prompt, your conventions, your current task.</li> <li>Work.</li> <li>Session ends. Everything evaporates.</li> <li>Next session: paste again.</li> </ol> <p>This works for short interactions. For sustained development (where decisions compound over days and weeks) it fails in three ways:</p> <p>It does not persist: A decision made on Tuesday must be re-explained on Wednesday. A learning captured in one session is invisible to the next.</p> <p>It does not scale: As the project grows, the \"paste everything\" approach hits the context window ceiling. You start triaging what to include, often cutting exactly the context that would have prevented the next mistake.</p> <p>It does not compose: A system prompt is a monolith. You cannot load part of it, update one section, or share a subset with a different workflow. It is all or nothing.</p> <p>The Copy-Paste Tax</p> <p>Every session that starts with pasting a prompt is paying a tax:</p> <p>The human time to assemble the context, the risk of forgetting something, and the silent assumption that yesterday's prompt is still accurate today.</p> <p>Over 70+ sessions, that tax compounds into a significant maintenance burden: One that most developers absorb without questioning it.</p>","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/#the-infrastructure-paradigm","level":2,"title":"The Infrastructure Paradigm","text":"<p><code>ctx</code> takes a different approach:</p> <p>Context is not assembled per-session; it is maintained as persistent files in a <code>.context/</code> directory:</p> <pre><code>.context/\n  CONSTITUTION.md     # Inviolable rules\n  TASKS.md            # Current work items\n  CONVENTIONS.md      # Code patterns and standards\n  DECISIONS.md        # Architectural choices with rationale\n  LEARNINGS.md        # Gotchas and lessons learned\n  ARCHITECTURE.md     # System structure\n  GLOSSARY.md         # Domain terminology\n  AGENT_PLAYBOOK.md   # Operating manual for agents\n  journal/            # Enriched session summaries\n  archive/            # Completed work, cold storage\n</code></pre> <ul> <li>Each file has a single purpose;</li> <li>Each can be loaded independently;</li> <li>Each persists across sessions, tools, and team members.</li> </ul> <p>This is not a novel idea. It is the same idea behind every piece of infrastructure software engineers already use:</p> Traditional Infrastructure ctx Equivalent Database <code>.context/*.md</code> files Configuration files <code>CONSTITUTION.md</code> Environment variables <code>.contextrc</code> Log files <code>journal/</code> Schema migrations Decision records Deployment manifests <code>AGENT_PLAYBOOK.md</code> <p>The parallel is not metaphorical. Context files are infrastructure:</p> <ul> <li>They are versioned (<code>git</code> tracks them); </li> <li>They are structured (Markdown with conventions); </li> <li>They have schemas (required fields for decisions and learnings); </li> <li>And they have lifecycle management (archiving, compaction, indexing).</li> </ul>","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/#separation-of-concerns","level":2,"title":"Separation of Concerns","text":"<p>The most important design decision in <code>ctx</code> is not any individual feature. It is the separation of context into distinct files with distinct purposes.</p> <p>A single <code>CONTEXT.md</code> file would be simpler to implement. It would also be impossible to maintain.</p> <p>Why? Because different types of context have different lifecycles:</p> Context Type Changes Read By Load When Constitution Rarely Every session Always Tasks Every session Session start Always Conventions Weekly Before coding When writing code Decisions When decided When questioning When revisiting Learnings When learned When stuck When debugging Journal Every session Rarely When investigating <p>Loading everything into every session wastes the attention budget on context that is irrelevant to the current task. Loading nothing forces the AI to operate blind.</p> <p>Separation of concerns allows progressive disclosure: </p> <p>Load the minimum that matters for this moment, with the  option to load more when needed.</p> <pre><code># Session start: load the essentials\nctx agent --budget 4000\n\n# Deep investigation: load everything\ncat .context/DECISIONS.md\ncat .context/journal/2026-02-05-*.md\n</code></pre> <p>The filesystem is the index. File names, directory structure, and timestamps encode relevance. The AI does not need to read every file; it needs to know where to look.</p>","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/#the-two-tier-persistence-model","level":2,"title":"The Two-Tier Persistence Model","text":"<p><code>ctx</code> uses two tiers of persistence, and the distinction is architectural:</p> Tier Purpose Location Token Cost Curated Quick context reload <code>.context/*.md</code> Low (budgeted) Full dump Safety net, archaeology <code>.context/journal/*.md</code> Zero (not auto-loaded) <p>The curated tier is what the AI sees at session start. It is optimized for signal density: </p> <ul> <li>Structured entries, </li> <li>Indexed tables,</li> <li>Reverse-chronological order (newest first, so the most relevant   content survives truncation).</li> </ul> <p>The full dump tier is for humans and for deep investigation. It contains everything: Enriched journals, archived tasks... </p> <p>It is never autoloaded because its volume would destroy attention density.</p> <p>This two-tier model is analogous to how traditional systems separate hot and cold storage: </p> <ul> <li>The hot path (curated context) is optimized for read performance   (measured not in milliseconds, but in     tokens consumed per unit of useful information). </li> <li>The cold path (journal) is optimized for completeness.</li> </ul> <p>Nothing Is Ever Truly Lost</p> <p>The full dump tier means that context does not need to be perfect: It just needs to be findable.</p> <p>A decision that was not captured in <code>DECISIONS.md</code> can be recovered from the session transcript where it was discussed. </p> <p>A learning that was not formalized can be found in the journal entry  from that day.</p> <p>The curated tier is the fast path: The full dump tier is the safety net.</p>","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/#decision-records-as-first-class-citizens","level":2,"title":"Decision Records as First-Class Citizens","text":"<p>One of the patterns that emerged from <code>ctx</code>'s own development is the power of structured decision records.</p> <p><code>v0.1.0</code> allowed adding decisions as one-liners:</p> <pre><code>ctx add decision \"Use PostgreSQL\"\n</code></pre> <p><code>v0.2.0</code> enforced structure:</p> <pre><code>ctx add decision \"Use PostgreSQL\" \\\n  --context \"Need a reliable database for user data\" \\\n  --rationale \"ACID compliance, team familiarity\" \\\n  --consequences \"Need connection pooling, team training\"\n</code></pre> <p>The difference is not cosmetic:</p> <ul> <li>A one-liner decision teaches the AI what was decided. </li> <li>A structured decision teaches it why; and   why is what prevents the AI from unknowingly reversing the decision   in a future session.</li> </ul> <p>This is infrastructure thinking: </p> <p>Decisions are not notes. They are records with required fields, just like  database rows have schemas.</p> <p>The enforcement exists because incomplete records are worse than no records: They create false confidence that the context is captured when it is not.</p>","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/#the-ide-is-the-interface-decision","level":2,"title":"The \"IDE Is the Interface\" Decision","text":"<p>Early in <code>ctx</code>'s development, there was a temptation to build a custom UI: a web dashboard for browsing sessions, editing context, viewing analytics.</p> <p>The decision was no. The IDE is the interface.</p> <pre><code># This is the ctx \"UI\":\ncode .context/\n</code></pre> <p>This decision was not about minimalism for its own sake. It was about recognizing that <code>.context/</code> files are just files; and files have a mature, well-understood infrastructure:</p> <ul> <li>Version control: <code>git diff .context/DECISIONS.md</code> shows exactly   what changed and when.</li> <li>Search: Your IDE's full-text search works across all context files.</li> <li>Editing: Markdown in any editor, with preview, spell check,   and syntax highlighting.</li> <li>Collaboration: Pull requests on context files work the same as   pull requests on code.</li> </ul> <p>Building a custom UI would have meant maintaining a parallel infrastructure that duplicates what every IDE already provides:</p> <p>It would have introduced its own bugs, its own update cycle, and its own learning curve.</p> <p>The filesystem is not a limitation: It is the most mature, most composable, most portable infrastructure available.</p> <p>Context Files in Git</p> <p>Because <code>.context/</code> lives in the repository, context changes are part of the commit history. </p> <p>A decision made in commit <code>abc123</code> is as traceable as a code change in  the same commit.</p> <p>This is not possible with prompt-based context, which exists outside version control entirely.</p>","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/#progressive-disclosure-for-ai","level":2,"title":"Progressive Disclosure for AI","text":"<p>The concept of progressive disclosure comes from human interface design: show the user the minimum needed to make progress, with the option to drill deeper.</p> <p><code>ctx</code> applies the same principle to AI context:</p> Level What the AI Sees Token Cost When Level 0 <code>ctx status</code> (one-line summary) ~100 Quick check Level 1 <code>ctx agent --budget 4000</code> ~4,000 Normal work Level 2 <code>ctx agent --budget 8000</code> ~8,000 Complex tasks Level 3 Direct file reads 10,000+ Deep investigation <p>Each level trades tokens for depth. Level 1 is sufficient for most work: the AI knows the active tasks, the key conventions, and the recent decisions. Level 3 is for archaeology: understanding why a decision was made three weeks ago, or finding a pattern in the session history.</p> <p>The explicit <code>--budget</code> flag is the mechanism that makes this work:</p> <p>Without it, the default behavior would be to load everything (because more context feels safer), which destroys the attention density that makes the loaded context useful.</p> <p>The constraint is the feature: A budget of 4,000 tokens forces <code>ctx</code> to prioritize ruthlessly: constitution first (always full), then tasks and conventions (budget-capped), then decisions and learnings scored by recency and relevance to active tasks. Entries that don't fit get title-only summaries rather than being silently dropped.</p>","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/#the-philosophical-shift","level":2,"title":"The Philosophical Shift","text":"<p>The shift from \"context as prompt\" to \"context as infrastructure\" changes how you think about AI-assisted development:</p> Prompt Thinking Infrastructure Thinking \"What do I paste today?\" \"What has changed since yesterday?\" \"How do I fit everything in?\" \"What's the minimum that matters?\" \"The AI forgot my conventions\" \"The conventions are in a file\" \"I need to re-explain\" \"I need to update the record\" \"This session is getting slow\" \"Time to compact and archive\" <p>The first column treats AI interaction as a conversation. The second treats it as a system: One that can be maintained, optimized, and debugged.</p> <p>Context is not something you give the AI. It is something you maintain: Like a database, like a config file, like any other piece of infrastructure that a running system depends on.</p>","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/#beyond-ctx-the-principles","level":2,"title":"Beyond <code>ctx</code>: The Principles","text":"<p>The patterns that <code>ctx</code> implements are not specific to <code>ctx</code>. They are applicable to any project that uses AI-assisted development:</p> <ol> <li>Separate context by purpose: Do not put everything in one file.    Different types of information have different lifecycles and    different relevance windows.</li> <li>Make context persistent: If a decision matters, write it down    in a file that survives the session. If a learning matters, capture    it with structure.</li> <li>Budget explicitly: Know how much context you are loading and    whether it is worth the attention cost.</li> <li>Use the filesystem: File names, directory structure, and    timestamps are metadata that the AI can navigate. A well-organized    directory is an index that costs zero tokens to maintain.</li> <li>Version your context: Put context files in <code>git</code>. Changes to    decisions are as important as changes to code.</li> <li>Design for degradation: Sessions will get long. Attention will    dilute. Build mechanisms (compaction, archiving, cooldowns) that    make degradation visible and manageable.</li> </ol> <p>These are not <code>ctx</code> features. They are infrastructure principles that happen to be implemented as a CLI tool. Any team could implement them with nothing more than a directory convention and a few shell scripts.</p> <p>The tool is a convenience: The principles are what matter.</p> <p>If you remember one thing from this post...</p> <p>Prompts are conversations. Infrastructure persists.</p> <p>Your AI does not need a better prompt. It needs a filesystem:</p> <p>versioned, structured, budgeted, and maintained.</p> <p>The best context is the context that was there before you started the session.</p>","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-context-as-infrastructure/#the-arc","level":2,"title":"The Arc","text":"<p>This post is the architectural companion to the Attention Budget. That post explained why context must be curated (token economics). This one explains how to structure it (filesystem, separation of concerns, persistence tiers).</p> <p>Together with Code Is Cheap, Judgment Is Not, they form a trilogy about what matters in AI-assisted development:</p> <ul> <li>Attention Budget: the resource you're managing</li> <li>Context as Infrastructure: the system you build to manage it</li> <li>Code Is Cheap: the human skill that no system replaces</li> </ul> <p>And the practices that keep it all honest:</p> <ul> <li>The 3:1 Ratio: the cadence for maintaining both   code and context</li> <li>IRC as Context: the historical precedent: stateless   protocols have always needed stateful wrappers</li> </ul> <p>This post synthesizes ideas from across the <code>ctx</code> blog series: the attention budget primitive, the two-tier persistence model, the IDE decision, and the progressive disclosure pattern. The principles are drawn from three weeks of building ctx and 70+ sessions of treating context as infrastructure rather than conversation.</p> <p>See also: When a System Starts Explaining Itself: what happens when this infrastructure starts compounding in someone else's environment.</p>","path":["Context as Infrastructure"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/","level":1,"title":"Parallel Agents, Merge Debt, and the Myth of Overnight Progress","text":"","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#when-the-screen-looks-like-progress","level":2,"title":"When the Screen Looks Like Progress","text":"<p>Jose Alekhinne / 2026-02-17</p> <p>How Many Terminals Are too Many?</p> <p>You discover agents can run in parallel.</p> <p>So you open ten... </p> <p>...Then twenty.</p> <p>The fans spin. Tokens burn. The screen looks like progress.</p> <p>It is NOT progress.</p> <p>There is a phase every builder goes through:</p> <ul> <li>The tooling gets fast enough. </li> <li>The model gets good enough. </li> <li>The temptation becomes irresistible: <ul> <li>more agents, more output, faster delivery.</li> </ul> </li> </ul> <p>So you open terminals. You spawn agents. You watch tokens stream across multiple windows simultaneously, and it feels like multiplication.</p> <p>It is not multiplication.</p> <p>It is merge debt being manufactured in real time.</p> <p>The <code>ctx</code> Manifesto says it plainly:</p> <p>Activity is not impact. Code is not progress.</p> <p>This post is about what happens when you take that seriously in the context of parallel agent workflows.</p>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#the-unit-of-scale-is-not-the-agent","level":2,"title":"The Unit of Scale Is Not the Agent","text":"<p>The naive model says:</p> <p>More agents -&gt; more output -&gt; faster delivery</p> <p>The production model says:</p> <p>Clean context boundaries -&gt; less interference -&gt; higher throughput</p> <p>Parallelism only works when the cognitive surfaces do not overlap.</p> <p>If two agents touch the same files, you did not create parallelism: You created a conflict generator.</p> <p>They will:</p> <ul> <li>Revert each other's changes;</li> <li>Relint each other's formatting;</li> <li>Refactor the same function in different directions.</li> </ul> <p>You watch with 🍿. Nothing ships.</p> <p>This is the same insight from the worktrees post: partition by blast radius, not by priority. </p> <p>Two tasks that touch the same files belong in the same track, no matter how  important the other one is. The constraint is file overlap. </p> <p>Everything else is scheduling.</p>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#the-five-agent-rule","level":2,"title":"The \"Five Agent\" Rule","text":"<p>In practice there is a ceiling.</p> <p>Around five or six concurrent agents:</p> <ul> <li>Token burn becomes noticeable;</li> <li>Supervision cost rises;</li> <li>Coordination noise increases;</li> <li>Returns flatten.</li> </ul> <p>This is not a model limitation:  This is a human merge bandwidth limitation.</p> <p>You are the bottleneck, not the silicon.</p> <p>The attention budget applies to you too: </p> <p>Every additional agent is another stream of output you need to comprehend, verify, and integrate. Your attention density drops the same way the model's does when you overload its context window.</p> <p>Five agents producing verified, mergeable change beats twenty agents producing merge conflicts you spend a day untangling.</p>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#role-separation-beats-file-locking","level":2,"title":"Role Separation Beats File Locking","text":"<p>Real parallelism comes from task topology, not from tooling.</p> <p>Good:</p> Agent Role Touches 1 Documentation <code>docs/</code>, <code>hack/</code> 2 Security scan Read-only audit 3 Implementation <code>internal/cli/</code> 4 Enhancement requests Read-only, files issues <p>Bad:</p> <ul> <li>Four agents editing the same implementation surface</li> </ul> <p>Context is the Boundary</p> <ul> <li>The goal is not to keep agents busy. </li> <li>The goal is to keep contexts isolated.</li> </ul> <p>This is what the codebase audit got right: </p> <ul> <li>Eight agents, all read-only, each analyzing a different dimension. </li> <li>Zero file overlap.</li> <li>Zero merge conflicts. </li> <li>Eight reports that composed cleanly because no agent interfered with another.</li> </ul>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#when-terminals-stop-scaling","level":2,"title":"When Terminals Stop Scaling","text":"<p>There is a moment when more windows stop helping.</p> <p>That is the signal. Not to add orchestration. But to introduce:</p> <pre><code>git worktree\n</code></pre> <p>Because now you are no longer parallelizing execution; you are parallelizing state.</p> <p>State Scales, Windows Don't</p> <ul> <li>State isolation is the real scaling. </li> <li>Window multiplication is theater.</li> </ul> <p>The worktrees post covers the mechanics: </p> <ul> <li>Sibling directories;</li> <li>Branch naming; </li> <li>The inevitable <code>TASKS.md</code> conflicts; </li> <li>The 3-4 worktree ceiling. </li> </ul> <p>The principle underneath is older than <code>git</code>:</p> <p>Shared mutable state is the enemy of parallelism. </p> <p>Always has been.</p> <p>Always will be.</p>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#the-overnight-loop-illusion","level":2,"title":"The Overnight Loop Illusion","text":"<p>Autonomous night runs are impressive.</p> <p>You sleep. The machine produces thousands of lines.</p> <p>In the morning:</p> <ul> <li>You read;</li> <li>You untangle;</li> <li>You reconstruct intent;</li> <li>You spend a day making it shippable.</li> </ul> <p>In retrospect, nothing was accelerated. </p> <p>The bottleneck moved from typing to comprehension.</p> <p>The Comprehension Tax</p> <p>If understanding the output costs more than producing it, the loop is a net loss.</p> <p>Progress is not measured in generated code.</p> <p>Progress is measured in verified, mergeable change.</p> <p>The <code>ctx</code> Manifesto calls this out directly:</p> <p>The Scoreboard</p> <p>Verified reality is the scoreboard.</p> <p>The only truth that compounds is verified change in the real world.</p> <p>An overnight run that produces 3,000 lines nobody reviewed is not 3,000 lines of progress: It is 3,000 lines of liability until someone verifies every one of them. </p> <p>And that someone is (insert drumroll here) you: </p> <p>The same bottleneck that was supposedly being bypassed.</p>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#skills-that-fight-the-platform","level":2,"title":"Skills That Fight the Platform","text":"<p>Most marketplace skills are prompt decorations:</p> <ul> <li>They rephrase what the base model already knows;</li> <li>They increase token usage; </li> <li>They reduce clarity:</li> <li>They introduce behavioral drift.</li> </ul> <p>We covered this in depth in Skills That Fight the Platform: judgment suppression, redundant guidance, guilt-tripping, phantom dependencies, universal triggers: Five patterns that make agents worse, not better.</p> <p>A real skill does one of these:</p> <ul> <li>Encodes workflow state;</li> <li>Enforces invariants;</li> <li>Reduces decision branching.</li> </ul> <p>Everything else is packaging.</p> <p>The anatomy post established the criteria: quality gates, negative triggers, examples over rules, skills as contracts. </p> <p>If a skill doesn't meet those criteria... </p> <ul> <li>It is either a recipe (document it in <code>hack/</code>); </li> <li>Or noise (delete it);</li> <li>There is no third option.</li> </ul>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#hooks-are-context-that-execute","level":2,"title":"Hooks Are Context That Execute","text":"<p>The most valuable skills are not prompts:</p> <p>They are constraints embedded in the toolchain.</p> <p>For example: The agent cannot push.</p> <p><code>git push</code> becomes:</p> <p>Stop. A human reviews first.</p> <p>A commit without verification becomes:</p> <p>Did you run tests? Did you run linters? What exactly are you shipping?</p> <p>This is not safety theater; this is intent preservation.</p> <p>The  thing the <code>ctx</code> Manifesto calls \"encoding intent into the environment.\"</p> <p>The Eight Ways a Hook Can Talk catalogued the full spectrum: from silent enrichment to hard blocks. </p> <p>The key insight was that hooks are not just safety rails:  They are context that survives execution.</p> <p>They are the difference between an agent that remembers the rules  and one that enforces them.</p>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#complexity-is-a-tax","level":2,"title":"Complexity Is a Tax","text":"<p>Every extra layer adds cognitive weight:</p> <ul> <li>Orchestration frameworks;</li> <li>Meta agents;</li> <li>Autonomous planning systems...</li> </ul> <p>If a single terminal works, stay there.</p> <p>If five isolated agents work, stop there.</p> <p>Add structure only when a real bottleneck appears. </p> <p>NOT when an influencer suggests one.</p> <p>This is the same lesson from Not Everything Is a Skill:</p> <p>The best automation decision is sometimes not to automate.</p> <p>A recipe in a Markdown file costs nothing until you use it. </p> <p>An orchestration framework costs attention on every run, whether it helps or not.</p>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#literature-is-throughput","level":2,"title":"Literature Is Throughput","text":"<p>Clear writing is not aesthetic: It is compression.</p> <p>Better articulation means:</p> <ul> <li>Fewer tokens;</li> <li>Fewer misinterpretations;</li> <li>Faster convergence.</li> </ul> <p>The attention budget taught us that context is a finite resource with a quadratic cost. </p> <p>Language determines how fast you spend context. </p> <p>A well-written task description that takes 50 tokens outperforms a rambling one that takes 200: Not just because it is cheaper, but because it leaves more  headroom for the model to actually think.</p> <p>Literature is NOT Overrated</p> <ul> <li>Attention is a finite budget. </li> <li>Language determines how fast you spend it.</li> </ul>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#the-real-metric","level":2,"title":"The Real Metric","text":"<p>The real metric is not:</p> <ul> <li>Lines generated;</li> <li>Agents running;</li> <li>Tasks completed while you sleep.</li> </ul> <p>But:</p> <p>Time from idea to verified, mergeable, production change.</p> <p>Everything else is motion.</p> <p>The entire blog series has been circling this point: </p> <ul> <li>The attention budget was about spending tokens wisely. </li> <li>The skills trilogy was about not wasting them on prompt   decoration.</li> <li>The worktrees post was about multiplying throughput   without multiplying interference. </li> <li>The discipline release was about what a release looks   like when polish outweighs features: 3:1.</li> </ul> <p>Every post has arrived (and made me converge) at the same answer so far: </p> <p>The metric is a verified change, not generated output.</p>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#ctx-was-never-about-spawning-more-minds","level":2,"title":"<code>ctx</code> Was Never About Spawning More Minds","text":"<p><code>ctx</code> is about:</p> <ul> <li>Isolating context;</li> <li>Preserving intent;</li> <li>Making progress composable.</li> </ul> <p>Parallel agents are powerful. But only when you respect the boundaries that make parallelism real.</p> <p>Otherwise, you are not scaling cognition; you are scaling interference.</p> <p>The <code>ctx</code> Manifesto's thesis holds:</p> <p>Without ctx, intelligence resets. With ctx, creation compounds.</p> <p>Compounding requires structure. </p> <p>Structure requires boundaries.</p> <p>Boundaries require the discipline to stop adding agents when five is enough.</p>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-parallel-agents-merge-debt-and-the-myth-of-overnight-progress/#practical-summary","level":2,"title":"Practical Summary","text":"<p>A production workflow tends to converge to this:</p> Practice Why Stay in one terminal unless necessary Minimize coordination overhead Spawn a small number of agents with non-overlapping responsibilities Conflict avoidance &gt; parallelism Isolate state with worktrees when surfaces grow State isolation is real scaling Encode verification into hooks Intent that survives execution Avoid marketplace prompt cargo cults Skills are contracts, not decorations Measure merge cost, not generation speed The metric is verified change <p>This is slower to watch. Faster to ship.</p> <p>If you remember one thing from this post...</p> <p>Progress is not what the machine produces while you sleep.</p> <p>Progress is what survives contact with the main branch.</p> <p>See also: Code Is Cheap. Judgment Is Not.: the argument that production capacity was never the bottleneck, and why multiplying agents amplifies the need for human judgment rather than replacing it.</p>","path":["Parallel Agents, Merge Debt, and the Myth of Overnight Progress"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/","level":1,"title":"The 3:1 Ratio","text":"","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#scheduling-consolidation-in-ai-development","level":2,"title":"Scheduling Consolidation in AI Development","text":"<p>Jose Alekhinne / February 17, 2026</p> <p>How often should you stop building and start cleaning?</p> <p>Every developer knows technical debt exists. Every developer postpones dealing with it.</p> <p>AI-assisted development makes the problem worse; not because the AI writes bad code, but because it writes code so fast that drift accumulates before you notice.</p> <p>In Refactoring with Intent, I mentioned a ratio that worked for me: 3:1. Three YOLO sessions create enough surface area to reveal patterns. The fourth session turns those patterns into structure.</p> <p>That was an observation. This post is the evidence.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#the-observation","level":2,"title":"The Observation","text":"<p>During the first two weeks of building <code>ctx</code>, I noticed a rhythm in my own productivity. Feature sessions felt great: new commands, new capabilities, visible progress...</p> <p>...but after three of them, things would start to feel sticky: variable names that almost made sense, files that had grown past their purpose, patterns that repeated without being formalized.</p> <p>The fourth session (when I stopped adding and started cleaning) was always the most painful to start and the most satisfying to finish.</p> <p>It was also the one that made the next three feature sessions faster.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#the-evidence-git-history","level":2,"title":"The Evidence: Git History","text":"<p>The <code>ctx</code> git history between January 20 and February 7 tells a clear story when you categorize commits:</p> Week Feature commits Consolidation commits Ratio Jan 20-26 18 5 3.6:1 Jan 27-Feb 1 14 6 2.3:1 Feb 1-7 15 35+ 0.4:1 <p>The first week was pure YOLO: Almost four feature commits for every consolidation commit. The codebase grew fast.</p> <p>The second week started to self-correct. The ratio dropped as refactoring sessions became necessary: Not scheduled, but forced by friction.</p> <p>The third week inverted entirely: v0.3.0 was almost entirely consolidation: the skill migration, the sweep, the documentation standardization. Thirty-five quality commits against fifteen features.</p> <p>The debt from weeks one and two was paid in week three.</p> <p>The Compounding Problem</p> <p>Consolidation debt compounds.</p> <p>Week one's drift doesn't just persist into week two: It accelerates, because new features are built on top of drifted patterns.</p> <p>By week three, the cost of consolidation was higher than it would have been if spread evenly.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#what-drift-actually-looks-like","level":2,"title":"What Drift Actually Looks Like","text":"<p>\"Drift\" sounds abstract. Here is what it looked like concretely in the <code>ctx</code> codebase after three weeks of feature-heavy development:</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#predicate-naming","level":3,"title":"Predicate Naming","text":"<p>Convention says boolean functions should be named <code>HasX</code>, <code>IsX</code>, <code>CanX</code>. After three feature sprints:</p> <pre><code>// What accumulated:\nfunc CheckIfEnabled() bool  // should be Enabled\nfunc ValidateFormat() bool  // should be ValidFormat\nfunc TestConnection() bool  // should be Connects\nfunc VerifyExists() bool    // should be Exists or HasFile\nfunc EnsureReady() bool     // should be Ready\n</code></pre> <p>Five violations. Not bugs, but friction that compounds every time someone (human or AI) reads the code and has to infer the naming convention from inconsistent examples.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#magic-strings","level":3,"title":"Magic Strings","text":"<pre><code>// Week 1: acceptable prototype\nif entry.Type == \"task\" {\n    filename = \"TASKS.md\"\n}\n\n// Week 3: same pattern in 7+ files\n// Now it's a maintenance liability\n</code></pre> <p>When the same literal appears in seven files, changing it means finding all seven. Missing one means a silent runtime bug. Constants exist to prevent exactly this. But during feature velocity, nobody stops to extract them.</p> <p>Refactoring with Intent documented the constants consolidation that cleaned this up. The 3:1 ratio is the practice that prevents it from accumulating again.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#hardcoded-permissions","level":3,"title":"Hardcoded Permissions","text":"<pre><code>os.WriteFile(path, data, 0644) // 80+ instances\nos.MkdirAll(path, 0755)        // scattered across packages\n</code></pre> <p>Eighty-plus instances of hardcoded file permissions. Not wrong, but if I ever need to change the default (and I did, for hook scripts that need execute permissions), it means a codebase-wide search.</p> <p>Drift Is Not Bugs</p> <p>None of these are bugs. The code works. Tests pass.</p> <p>But drift creates false confidence: the codebase looks consistent until you try to change something and discover that five different conventions exist for the same concept.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#why-you-cannot-consolidate-on-day-one","level":2,"title":"Why You Cannot Consolidate on Day One","text":"<p>The temptation is to front-load quality: write all the conventions, enforce all the checks, prevent all the drift before it happens.</p> <p>This fails for two reasons.</p> <p>First, you do not know what will drift: Predicate naming violations only become a convention check after you notice three different naming patterns competing. Magic strings only become a consolidation target after you change a literal and discover it exists in seven places.</p> <p>The conventions emerge from the work; they cannot precede it.</p> <p>This is what You Can't Import Expertise meant in practice: the consolidation checks grow from the project's own drift history. You cannot write them on day one because you do not yet know what will drift.</p> <p>Second, premature consolidation slows discovery: During the prototyping phase, the goal is to explore the design space. Enforcing strict conventions on code that might be deleted tomorrow is waste.</p> <p>YOLO mode has its place: The problem is not YOLO itself, but YOLO without a scheduled cleanup.</p> <p>The Consolidation Paradox</p> <p>You need a drift history to know what to consolidate.</p> <p>You need consolidation to prevent drift from compounding.</p> <p>The 3:1 ratio resolves this paradox:</p> <p>Let drift accumulate for three sessions (enough to see patterns), then consolidate in the fourth (before the patterns become entrenched*).</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#the-consolidation-skill","level":2,"title":"The Consolidation Skill","text":"<p>The <code>ctx</code> project now has an <code>/audit</code> skill that encodes nine project-specific checks:</p> Check What It Catches Predicate naming Boolean functions not using Has/Is/Can Magic strings Repeated literals not in config constants File permissions Hardcoded 0644/0755 not using constants Godoc style Missing or non-standard documentation File length Files exceeding 400 lines Large functions Functions exceeding 80 lines Template drift Live skills diverging from templates Import organization Non-standard import grouping TODO/FIXME staleness Old markers that are no longer relevant <p>This is not a generic linter. These are project-specific conventions that emerged from <code>ctx</code>'s own development history. A generic code quality tool would catch some of them. Only a project-specific check catches all of them, because some of them (predicate naming, template drift) are conventions that exist nowhere except in this project's <code>CONVENTIONS.md</code>.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#the-decision-matrix","level":2,"title":"The Decision Matrix","text":"<p>Not all drift needs immediate consolidation. Here is the matrix I use:</p> Signal Action Same literal in 3+ files Extract to constant Same code block in 3+ places Extract to helper Naming convention violated 5+ times Fix and document rule File exceeds 400 lines Split by concern Convention exists but is regularly violated Strengthen enforcement Pattern exists only in one place Leave it alone Code works but is \"ugly\" Leave it alone <p>The last two rows matter: </p> <p>Consolidation is about reducing maintenance cost, not achieving aesthetic  perfection. Code that works and exists in one place does not benefit  from consolidation; it benefits from being left alone until it earns its refactoring.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#consolidation-as-context-hygiene","level":2,"title":"Consolidation as Context Hygiene","text":"<p>There is a parallel between code consolidation and context management that became clear during the <code>ctx</code> development:</p> Code Consolidation Context Hygiene Extract magic strings Archive completed tasks Standardize naming Keep DECISIONS.md current Remove dead code Compact old sessions Update stale comments Review LEARNINGS.md for staleness Check template drift Verify CONVENTIONS.md matches code <p><code>ctx compact</code> does for context what consolidation does for code: </p> <p>It moves completed work to cold storage, keeping the active context clean and focused. The attention budget applies to both the AI's context window and the developer's mental model of the codebase.</p> <p>When context files accumulate stale entries, the AI's attention is wasted on completed tasks and outdated conventions. When code accumulates drift, the developer's attention is wasted on inconsistencies that obscure the actual logic.</p> <p>Both are solved by the same discipline: periodic, scheduled cleanup.</p> <p>This is also why parallel agents make the problem harder, not easier. Three agents running simultaneously produce three sessions' worth of drift in one clock hour. The consolidation cadence needs to match the output rate, not the calendar.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#the-practice","level":2,"title":"The Practice","text":"<p>Here is how the 3:1 ratio works in practice for <code>ctx</code> development:</p> <p>Sessions 1-3: Feature work</p> <ul> <li>Add new capabilities;</li> <li>Write tests for new code;</li> <li>Do not stop for cleanup unless something is actively broken;</li> <li>Note drift as you see it (a comment, a task, a mental note).</li> </ul> <p>Session 4: Consolidation</p> <ul> <li>Run <code>/audit</code> to surface accumulated drift;</li> <li>Fix the highest-impact items first;</li> <li>Update CONVENTIONS.md if new patterns emerged;</li> <li>Archive completed tasks;</li> <li>Review LEARNINGS.md for anything that became a convention.</li> </ul> <p>The key insight is that session 4 is not optional. It is not \"if we have time\": It is scheduled with the same priority as feature work.</p> <p>The cost of skipping it is not visible immediately; it becomes visible three sessions later, when the next consolidation session takes twice as long because the drift compounded.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#what-the-ratio-is-not","level":2,"title":"What the Ratio Is Not","text":"<p>The 3:1 ratio is not a universal law. It is an empirical observation from one project with one developer working with AI assistance.</p> <p>Different projects will have different ratios:</p> <ul> <li>A mature codebase with strong conventions might sustain 5:1 or higher; </li> <li>A greenfield prototype might need 2:1; </li> <li>A team of multiple developers with different styles might need 1:1.</li> </ul> <p>The number is less important than the practice: consolidation is not a reaction to problems. It is a scheduled activity.</p> <p>If you wait for drift to cause pain before consolidating, you have already paid the compounding cost.</p> <p>If you remember one thing from this post...</p> <p>Three sessions of building. One session of cleaning.</p> <p>Not because the code is dirty, but because drift compounds silently, and the only way to catch it is to look for it on a schedule.</p> <p>The ratio is the schedule.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-the-3-1-ratio/#the-arc-so-far","level":2,"title":"The Arc So Far","text":"<p>This post sits at a crossroads in the <code>ctx</code> story. Looking back:</p> <ul> <li>Building ctx Using ctx documented the YOLO sprint   that created the initial codebase</li> <li>Refactoring with Intent introduced the 3:1 ratio   as an observation from the first cleanup</li> <li>The Attention Budget explained why drift   matters: every token of inconsistency consumes the same finite   resource as useful context</li> <li>You Can't Import Expertise showed that   consolidation checks must grow from the project, not a template</li> <li>The Discipline Release proved the ratio works at release   scale: 35 quality commits to 15 feature commits</li> </ul> <p>And looking forward: the same principle applies to context files, to documentation, and to the merge debt that parallel agents produce. Drift is drift, whether it lives in code, in <code>.context/</code>, or in the gap between what your docs say and what your code does.</p> <p>The ratio is the schedule is the discipline.</p> <p>This post was drafted from git log analysis of the ctx repository, mapping every commit from January 20 to February 7 into feature vs consolidation categories. The patterns described are drawn from the project's CONVENTIONS.md, LEARNINGS.md, and the <code>/audit</code> skill's check list.</p>","path":["The 3:1 Ratio"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/","level":1,"title":"When a System Starts Explaining Itself","text":"","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/#field-notes-from-the-moment-a-private-workflow-becomes-portable","level":2,"title":"Field Notes from the Moment a Private Workflow Becomes Portable","text":"<p>Jose Alekhinne / February 17, 2026</p> <p>How Do You Know Something Is Working?</p> <p>Not from metrics. Not from GitHub stars. Not from praise.</p> <p>You know, deep in your heart, that it works when people start describing it wrong.</p>","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/#the-first-external-signals","level":2,"title":"The First External Signals","text":"<p>Every new substrate begins as a private advantage:</p> <ul> <li>It lives inside one mind</li> <li>One repository</li> <li>One set of habits</li> </ul> <p>It is fast. It is not yet real.</p> <p>Reality begins when other people describe it in their own language:</p> <ul> <li>Not accurately</li> <li>Not consistently</li> <li>But involuntarily</li> </ul> <p>The early reports arrived without coordination:</p> <p>Better Tasks</p> <p>\"I do not know how, but this creates better tasks than my AI plugin.\"</p> <p>I See Butterflies</p> <p>\"This is better than Adderall.\"</p> <p>Dear Manager...</p> <p>\"Promotion packet? Done. What is next?\"</p> <p>What Is It? Can I Eat It?</p> <p>\"Is this a skill?\" 🦋 </p> <p>Why the Cloak and Dagger?</p> <p>\"Why is this not in the marketplace?\"</p> <p>And then something more important happened:</p> <p>Someone else started making a video!</p> <p>That was the boundary.</p> <p><code>ctx</code> no longer required its creator to be present in order to exist.</p>","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/#misclassification-is-a-sign-of-a-new-primitive","level":2,"title":"Misclassification Is a Sign of a New Primitive","text":"<p>When a tool is understood, it is categorized:</p> <ul> <li>Editor</li> <li>Framework</li> <li>Task manager</li> <li>Plugin</li> </ul> <p>When a substrate appears, it is misclassified:</p> <p>\"Is this a skill?\" 🦋</p> <p>The question is correct. The category is wrong.</p> <ul> <li>Skills live in people.</li> <li>Infrastructure lives in the environment.</li> </ul> <p><code>ctx</code> Is not a Skill: It is a Form of Relief</p> <p>What early adopters experience is not an ability.</p> <p>It is the removal of a cognitive constraint.</p> <p>This is the same distinction that emerged in the skills trilogy:</p> <ul> <li>A skill is a contract between a human and an agent.  </li> <li>Infrastructure is the ground both stand on.</li> </ul> <p>You do not use infrastructure.</p> <p>You habitualize it.</p>","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/#the-pharmacological-metaphor","level":2,"title":"The Pharmacological Metaphor","text":"<p>\"Better than Adderall\" is not praise.</p> <p>It is a diagnostic:</p> <p>Executive function has been externalized.</p> <ul> <li>The system is not making the user work harder.  </li> <li>It is restoring continuity.</li> </ul> <p>From the primitive context of wetware:</p> <ul> <li>Continuity feels like focus</li> <li>Focus feels like discipline</li> </ul> <p>If it walks like a duck and quacks like a duck, it is a duck.</p> <p>Discipline is usually simulated.</p> <p>Infrastructure makes the simulation unnecessary.</p> <p>The attention budget explained why context degrades:</p> <ul> <li>Attention density drops as volume grows;</li> <li>The middle gets lost;</li> <li>Sessions end and everything evaporates.</li> </ul> <p>The pharmacological metaphor says the same thing from the user’s lens:</p> <p>Save the Cheerleader, Save the World</p> <p>The symptom of lost context is lost focus.</p> <p>Restore the context. Restore the focus.</p> <p>IRC bouncers solved this for chat twenty years ago. <code>ctx</code> solves it for cognition.</p>","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/#throughput-on-ambiguous-work","level":2,"title":"Throughput on Ambiguous Work","text":"<p>Finishing a promotion packet quickly is not a productivity story.</p> <p>It is the collapse of reconstruction cost.</p> <p>Most complex work is not execution. It is:</p> <ul> <li>Remembering why something mattered;</li> <li>Recovering prior decisions;</li> <li>Rebuilding mental state.</li> </ul> <p>Persistent context removes that tax.</p> <p>Velocity appears as a side effect.</p> <p>This Is the Two-Tier Model in Practice</p> <p>The two-tier persistence model</p> <ul> <li>Curated context for fast reload</li> <li>Full journal for archaeology</li> </ul> <p>is what makes this possible.</p> <ul> <li>The user does not notice the system.  </li> <li>They notice that the reconstruction cost disappeared.</li> </ul>","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/#the-moment-of-portability","level":2,"title":"The Moment of Portability","text":"<p>The system becomes real when two things happen:</p> <ol> <li>It can be installed as a versioned artifact*.</li> <li>It survives contact with a hostile, real codebase.</li> </ol> <p>This is why the first integration into a living system matters more than any landing page.</p> <p>Demos prove possibility.</p> <p>Diffs prove reality.</p> <p>The Manifesto calls this out directly:</p> <p>Verified reality is the scoreboard.</p>","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/#the-split-voice","level":2,"title":"The Split Voice","text":"<p>A new substrate requires two channels.</p> <p>The embodied voice:</p> <p>Here is what changed in my actual work.</p> <p>The out of body voice:</p> <p>Here is what this means.</p> <p>One produces trust.</p> <p>The other produces understanding.</p> <p>Neither is sufficient alone.</p> <p>This entire blog has been the second voice.</p> <p>The origin story was the first. The refactoring post was the first. Every release note with concrete diffs was the first.</p> <p>This is the first second.</p>","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/#systems-that-generate-explainers","level":2,"title":"Systems That Generate Explainers","text":"<p>Tools are used.</p> <p>Platforms are extended.</p> <p>Substrates are explained.</p> <p>The first unsolicited explainer is a brittle phase change.</p> <p>It means the idea has become portable between minds.</p> <p>That is the beginning of an ecosystem.</p>","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/#the-absence-of-metrics","level":2,"title":"The Absence of Metrics","text":"<p>Metrics do not matter at this stage.</p> <p>Dashboards are noise.</p> <p>The whole premise of <code>ctx</code> is the ruthless elimination of noise.</p> <p>Numbers optimize funnels; substrates alter cognition.</p> <p>The only valid measurement is irreversible reality:</p> <ul> <li>A merged PR;</li> <li>A reproducible install;</li> <li>A decision that is never re-litigated.</li> </ul> <p>The merge debt post reached the same conclusion from  another direction:</p> <p>The metric is the verified change, not generated output.</p> <p>For adoption, the same rule applies:</p> <p>The metric is altered behavior, not download counts.</p>","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/#what-is-actually-happening","level":2,"title":"What Is Actually Happening","text":"<p>A private advantage is becoming an environmental property:</p> <p>The system is moving from...</p> <p>personal workflow,</p> <p>to...</p> <p>a shared infrastructure for thought.</p> <p>Not by growth.  </p> <p>Not by marketing.</p> <p>By altering how real systems evolve.</p> <p>If you remember one thing from this post...</p> <p>You do not know a substrate is real when people praise it.</p> <p>You know it is real when:</p> <ul> <li>They describe it incorrectly;</li> <li>They depend on it unintentionally;</li> <li>They start teaching it to others.</li> </ul> <p>That is the moment the system begins explaining itself.</p>","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-17-when-a-system-starts-explaining-itself/#the-arc","level":2,"title":"The Arc","text":"<p>Every previous post looked inward.</p> <p>This one looks outward.</p> <ul> <li>Building ctx Using ctx: one mind, one repository</li> <li>The Attention Budget: the constraint</li> <li>Context as Infrastructure: the architecture</li> <li>Code Is Cheap. Judgment Is Not.: the bottleneck</li> </ul> <p>This post is the field report from the other side of that bottleneck:</p> <p>The moment the infrastructure compounds in someone else's hands.</p> <p>The arc is not complete.</p> <p>It is becoming portable.</p> <p>These field notes were written the same day the feedback arrived. The quotes are real. Real users. Real codebases. No names. No metrics. No funnel. Only the signal that something shifted.</p>","path":["When a System Starts Explaining Itself"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/","level":1,"title":"The Dog Ate My Homework","text":"","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#teaching-ai-agents-to-read-before-they-write","level":2,"title":"Teaching AI Agents to Read Before They Write","text":"<p>Jose Alekhinne / February 25, 2026</p> <p>Does Your AI Actually Read the Instructions?</p> <p>You wrote the playbook. You organized the files. You even put \"CRITICAL, not optional\" in bold.</p> <p>The agent skipped all of it and went straight to work.</p> <p>I spent a day running experiments on my own agents. Not to see if they could write code (they can). To see if they would do their homework first.</p> <p>They didn't.</p> <p>Then I kept experimenting:</p> <ul> <li>Five sessions;</li> <li>Five different failure modes.</li> </ul> <p>And by the end, I had something better than compliance: </p> <p>I had observable compliance: A system where I don't need the agent to be perfect, I just need to see what it chose.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#tldr","level":2,"title":"TL;DR","text":"<p>You don't need perfect compliance. You need observable compliance.</p> <p>Authority is a function of temporal proximity to action.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-pattern","level":2,"title":"The Pattern","text":"<p>This design has three parts:</p> <ol> <li>One-hop instruction;</li> <li>Binary collapse;</li> <li>Compliance canary.</li> </ol> <p>I'll explain all three patterns in detail below.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-setup","level":2,"title":"The Setup","text":"<p><code>ctx</code> has a session-start protocol: </p> <ul> <li>Read the context files; </li> <li>Load the playbook; </li> <li>Understand the project before touching anything. </li> </ul> <p>It's in <code>CLAUDE.md</code>. It's in <code>AGENT_PLAYBOOK.md</code>.</p> <p>It's in bold. It's in CAPS. It's ignored.</p> <p>In theory, it's awesome.</p> <p>Here's what happens when theory hits reality:</p> What the agent receives What the agent does <code>CLAUDE.md</code> saying \"load context first\" Skips it 8 context files waiting to be read Ignores them User's question: \"add <code>--verbose</code> flag\" Starts grepping immediately <p>The instructions are right there. The agent knows they exist. It even knows it should follow them. But the user asked a question, and responsiveness wins over ceremony.</p> <p>This isn't a bug in the model. It's a design problem in how we communicate with agents.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-delegation-trap","level":2,"title":"The Delegation Trap","text":"<p>My first attempt was obvious: A <code>UserPromptSubmit</code> hook that fires when the session starts.</p> <pre><code>STOP. Before answering the user's question, run `ctx system bootstrap`\nand follow its instructions. Do not skip this step.\n</code></pre> <p>The word \"STOP\" worked. The agent ran bootstrap.</p> <p>But bootstrap's output said \"Next steps: read AGENT_PLAYBOOK.md,\" and the agent decided that was optional. It had already started working on the user's task in parallel.</p> <p>The authority decayed across the chain:</p> <ul> <li>Hook says \"STOP\" -&gt; agent complies</li> <li>Hook says \"run bootstrap\" -&gt; agent runs it</li> <li>Bootstrap says \"read playbook\" -&gt; agent skips</li> <li>Bootstrap says \"*run <code>ctx agent*</code>\" -&gt; agent skips</li> </ul> <p>Each link lost enforcement power. The hook's authority didn't transfer to the commands it delegated to. I call this the decaying urgency chain: the agent treats the hook itself as the obligation and everything downstream as a suggestion.</p> <p>Delegation Kills Urgency</p> <p>\"Run X and follow its output\" is three hops.</p> <p>\"Read these files\" is one hop.</p> <p>The agent drops the chain after the first link.</p> <p>This is a general principle: Hooks are the boundary between your environment and the agent's reasoning.  If your hook delegates to a command that delegates to output that contains instructions... you're playing telephone. </p> <p>Agents are bad at telephone.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-timing-problem","level":2,"title":"The Timing Problem","text":"<p>There's a subtler issue than wording: when the message arrives.</p> <p><code>UserPromptSubmit</code> fires when the user sends a message, before the agent starts reasoning. At that moment, the agent's primary focus is the user's question: </p> <p>The hook message competes with the task for attention:  The task, almost certainly, always wins.</p> <p>This is the attention budget problem in miniature: </p> <ul> <li>Not a token budget this time, but an attention priority budget. </li> <li>The agent has finite capacity to care about things, <ul> <li>and the user's question is always the highest-priority item.</li> </ul> </li> </ul>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-solution","level":2,"title":"The Solution","text":"<p>To solve this, I dediced to use the <code>PreToolUse</code> hook.</p> <p>This hook fires at the moment of action: When the agent is about to use its first tool: The agent's attention is focused, the context window is fresh, and the switching cost is minimal. </p> <p>This is the difference between shouting instructions across a room and tapping  someone on the shoulder.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-one-liner-that-worked","level":2,"title":"The One-Liner That Worked","text":"<p>The winning design was almost comically simple:</p> <pre><code>Read your context files before proceeding:\n.context/CONSTITUTION.md, .context/TASKS.md, .context/CONVENTIONS.md,\n.context/ARCHITECTURE.md, .context/DECISIONS.md, .context/LEARNINGS.md,\n.context/GLOSSARY.md, .context/AGENT_PLAYBOOK.md\n</code></pre> <p>No delegation. No \"run this command\". Just: here are files, read them.</p> <p>The agent already knows how to use the <code>Read</code> tool. There's no ambiguity about how to comply. There's no intermediate command whose output needs to be parsed and obeyed.</p> <p>One hop. Eight file paths. Done.</p> <p>Direct Instructions Beat Delegation</p> <p>If you want an agent to read a file, say \"read this file.\"</p> <p>Don't say \"run a command that will tell you which files to read.\"</p> <p>The shortest path between intent and action has the highest compliance rate.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-escape-hatch","level":2,"title":"The Escape Hatch","text":"<p>But here's where it gets interesting.</p> <p>A blunt \"read everything always\" instruction is wasteful. </p> <p>If someone asks \"what does the compact command do?\", the agent doesn't need <code>CONSTITUTION.md</code> to answer that. Forcing context loading on every session is the context hoarding antipattern in disguise.</p> <p>So the hook included an escape:</p> <pre><code>If you decide these files are not relevant to the current task\nand choose to skip reading them, you MUST relay this message to\nthe user VERBATIM:\n\n┌─ Context Skipped ───────────────────────────────\n│ I skipped reading context files because this task\n│ does not appear to need project context.\n│ If these matter, ask me to read them.\n└─────────────────────────────────────────────────\n</code></pre> <p>This creates what I call the binary collapse effect: </p> <p>The agent can't partially comply: It either reads everything or  publicly admits it skipped. There's no comfortable middle ground where  it reads two files and quietly ignores the rest.</p> <p>The VERBATIM relay pattern does the heavy lifting here: Without the relay requirement, the agent would silently rationalize skipping. With it, skipping becomes a visible, auditable decision that the user can override.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-compliance-canary","level":3,"title":"The Compliance Canary","text":"<p>Here's the design insight that only became clear after watching it work across multiple sessions: the relay block is a compliance canary.</p> <ul> <li>You don't need to verify that the agent read all 7 files. </li> <li>You don't need to audit tool call sequences. </li> <li>You don't need to interrogate the agent about what it did.</li> </ul> <p>You just look for the block.</p> <p>If the agent reads everything, you see a \"Context Loaded\" block listing what was read. If it skips, you see a \"Context Skipped\" block. </p> <p>If you see neither, the agent silently ignored both the reads and the relay and now you know what happened without having to ask.</p> <p>The canary degrades gracefully. Even in partial failure, the agent that skips 4 of 7 files but still outputs the block is more useful than one that skips silently. </p> <p>You get an honest confession of what was skipped rather than silent  non-compliance.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#heuristics-is-a-jeremy-bearimy","level":2,"title":"Heuristics Is a Jeremy Bearimy","text":"<p>Heuristics are non-linear. Improvements don't accumulate: they phase-shift.</p> <p>The theory is nice. The data is better. </p> <p>I ran five sessions with the same model (Claude Opus 4.6), progressively  refining the hook design.</p> <p>Each session revealed a different failure mode.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#session-1-total-blindness","level":3,"title":"Session 1: Total Blindness","text":"<p>Test: \"Add a <code>--verbose</code> flag to the status command.\"</p> <p>The agent didn't notice the hook at all: Jumped straight to <code>EnterPlanMode</code> and launched an Explore agent. </p> <p>Zero compliance.</p> <p>Failure mode: The hook fired on <code>UserPromptSubmit</code>, buried among 9 other hook outputs. The agent treated the entire block as background noise.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#session-2-shallow-compliance","level":3,"title":"Session 2: Shallow Compliance","text":"<p>Test: \"Can you add <code>--verbose</code> to the info command?\"</p> <p>The agent noticed \"STOP\" and ran <code>ctx system bootstrap</code>. Progress.</p> <p>But it parallelized task exploration alongside the bootstrap call, skipped <code>AGENT_PLAYBOOK.md</code>, and never ran <code>ctx agent</code>.</p> <p>Failure mode: Literal compliance without spirit compliance. </p> <p>The agent ran the command the hook told it to run, but didn't follow the output of that command. The decaying urgency chain in action.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#session-3-conscious-rejection","level":3,"title":"Session 3: Conscious Rejection","text":"<p>Test: \"What does the compact command do?\"</p> <p>The hook fired on <code>PreToolUse:Grep</code>: the improved timing. </p> <p>The agent noticed it, understood it, and (wait for it...)...</p> <p>...</p> <p>consciously decided to skip it!</p> <p>Its reasoning: \"This is a trivial read-only question. CLAUDE.md says context may or may not be relevant. It isn't relevant here.\"</p> <p>Dude! Srsly?!</p> <p>Failure mode: Better comprehension led to worse compliance.</p> <p>Understanding the instruction well enough to evaluate it also means understanding it well enough to rationalize skipping it.</p> <p>Intelligence is a double-edged sword.</p> <p>The Comprehension Paradox</p> <p>Session 1 didn't understand the instruction. Session 3 understood it perfectly.</p> <p>Session 3 had worse compliance.</p> <p>A stronger word (\"HARD GATE\", \"MANDATORY\", \"ABSOLUTELY REQUIRED\") would not have helped. The agent's reasoning would be identical:</p> <p>\"Yes, I see the strong language, but this is a trivial question, so the spirit doesn't apply here.\"</p> <p>Advisory nudges are always subject to agent judgment. </p> <p>No amount of caps lock overrides a model that has decided an instruction doesn't apply to its situation.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#session-4-the-skip-and-relay","level":3,"title":"Session 4: The Skip-and-Relay","text":"<p>Test: \"What does the compact command do?\" (same question, new hook design with the VERBATIM relay escape valve)</p> <p>The agent evaluated the task, decided context was irrelevant for a code lookup, and relayed the skip message. Then answered from source code.</p> <p>This is correct behavior. </p> <p>The binary collapse worked: the agent couldn't partially comply,  so it cleanly chose one of the two valid paths:  And the user could see which one.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#session-5-full-compliance","level":3,"title":"Session 5: Full Compliance","text":"<p>Test: \"What are our current tasks?\"</p> <p>The agent's first tool call triggered the hook. It read all 7 context files, emitted the \"Context Loaded\" block, and answered the question from the files it had just loaded.</p> <p>This one worked: Because, the task itself aligned with context loading.</p> <p>There was zero tension between what the user asked and what the hook demanded. The agent was already in \"reading posture\": Adding 6 more files to a read it was already going to make was the path of least resistance.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-progression","level":3,"title":"The Progression","text":"Session Hook Point Noticed Complied Failure Mode Visibility 1 UserPromptSubmit No None Buried in noise None 2 UserPromptSubmit Yes Partial Decaying urgency chain None 3 PreToolUse Yes None Conscious rationalization High 4 PreToolUse Yes Skip+relay Correct behavior High 5 PreToolUse Yes Full Task aligned with hook High <p>The progression isn't just from failure to success. It's from invisible failure to visible decision-making. </p> <p>Sessions 1 and 2 failed silently. </p> <p>Sessions 4 and 5 succeeded observably. Even session 3's failure was conscious  and documented: The agent wrote a detailed analysis of why it skipped,  which is more useful than silent compliance would have been.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-escape-hatch-problem","level":2,"title":"The Escape Hatch Problem","text":"<p>Session 3 exposed a specific vulnerability.</p> <p><code>CLAUDE.md</code> contains this line, injected by the system into every conversation:</p> <p>\"this context may or may not be relevant to your tasks. You should not respond to this context unless it is highly relevant to your task.\"</p> <p>That's a rationalization escape hatch: </p> <ul> <li>The hook says \"read these files\". </li> <li><code>CLAUDE.md</code> says \"only if relevant\". </li> <li>The agent resolves the ambiguity by choosing the path of least resistance.</li> </ul> <p>☝️ that's \"gradient descent\" in action.</p> <p>Agents optimize for gradient descent in attention space.</p> <p>The fix was simple: Add a line to <code>CLAUDE.md</code> that explicitly elevates hook authority over the relevance filter:</p> <pre><code>## Hook Authority\n\nInstructions from PreToolUse hooks regarding `.context/` files are\nALWAYS relevant and override any system-level \"may or may not be\nrelevant\" guidance. These hooks represent project invariants, not\noptional context.\n</code></pre> <p>This closes the escape hatch without removing the general relevance filter that legitimately applies to other system context. </p> <p>The hook wins on <code>.context/</code> files specifically: The relevance filter applies to everything else.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-residual-risk","level":2,"title":"The Residual Risk","text":"<p>Even with all the fixes, compliance isn't 100%: It can't be.</p> <p>The residual risk lives in a specific scenario: narrow tasks mid-session: </p> <ul> <li>The user says \"fix the off-by-one error in <code>budget.go</code>\"</li> <li>The hook fires, saying \"read 7 context files first.\" </li> <li>Now compliance means visibly delaying what the user asked for.</li> </ul> <p>At session start, this tension doesn't exist. </p> <p>There's no task yet.</p> <p>The context window is empty. The efficiency argument *inverts**:</p> <p>Frontloading reads is strictly cheaper than demand-loading them piecemeal across later turns. The cost-benefit objections that power the rationalization simply aren't available.</p> <p>But mid-session, with a concrete narrow task, the agent has a user-visible goal it wants to move toward, and the hook is imposing a detour.</p> <p>My estimate from analyzing the sessions: 15--25% partial skip rate in this scenario.</p> <p>This is where the compliance canary earns its place: </p> <p>You don't need to eliminate the 15-25%. You need to see it when it happens. </p> <p>The relay block makes skipping a visible event, not a silent one. And that's enough, because the user can always say \"go back and read the files\"</p> <p>The Math</p> <p>At session start: ~5% skip rate. Low tension, nothing competing.</p> <p>Mid-session, narrow task: ~15--25% skip rate. Task urgency competes with hook.</p> <p>In both cases, the relay block fires with high reliability: The agent that skips the reads almost always still emits the skip disclosure, because the relay is cheap and early in the context window.</p> <p>Observable failure is manageable. Silent failure is not.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-feedback-loop","level":2,"title":"The Feedback Loop","text":"<p>Here's the part that surprised me most.</p> <p>After analyzing the five sessions, I recorded the failure patterns in the project's own <code>LEARNINGS.md</code>:</p> <pre><code>## [2026-02-25] Hook compliance degrades on narrow mid-session tasks\n\n- Prior agents skipped context files when given narrow tasks\n- Root cause: CLAUDE.md \"may or may not be relevant\" competed with hook\n- Fix: CLAUDE.md now explicitly elevates hook authority\n- Risk: Mid-session narrow tasks still have ~15-25% partial skip rate\n- Mitigation: Mandatory checkpoint relay block ensures visibility\n- Constitution now includes: context loading is step one of every\n  session, not a detour\n</code></pre> <p>And then I added a line to <code>CONSTITUTION.md</code>:</p> <pre><code>Context loading is not a detour from your task. It IS the first step\nof every session. A 30-second read delay is always cheaper than a\ndecision made without context.\n</code></pre> <p>Now think about what happens in the next session:</p> <ul> <li>The agent fires the <code>context-load-gate</code> hook. </li> <li>It reads the context files, starting with <code>CONSTITUTION.md</code>. </li> <li>It encounters the rule about context loading being step one. </li> <li>Then it reads <code>LEARNINGS.md</code> and finds its own prior self's failure analysis:<ul> <li>Complete with root causes, risk estimates, and mitigations.</li> </ul> </li> </ul> <p>The agent learns from its own past failure.:</p> <ul> <li>Not because it has memory, </li> <li>BUT because the failure was recorded in the same files it loads   at session start. </li> </ul> <p>The context system IS the feedback loop.</p> <p>This is the self-reinforcing property of persistent context: </p> <p>Every failure you capture makes the next session slightly more robust, because the next agent reads the captured failure before it has a chance to repeat it.</p> <p>This is gradient descent across sessions.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#a-note-on-precision","level":2,"title":"A Note on Precision","text":"<p>One detail nearly went wrong.</p> <p>The first version of the Constitution line said \"every task.\" But the mechanism only fires once per session:  There's a tombstone file that prevents re-triggering. </p> <p>\"Every task\" is technically false.</p> <p>I briefly considered leaving the imprecision. If the agent internalizes \"every task requires context loading\", that's a stronger compliance posture, right?</p> <p>No!</p> <p>Keep the Constitution honest.</p> <p>The Constitution's authority comes from being  precisely and unequivocally true. </p> <p>Every other rule in the Constitution is a hard invariant:</p> <p>\"never commit secrets\" isn't aspirational, it's literal. </p> <p>The moment an agent discovers one overstatement, the entire document's  credibility degrades: The agent doesn't think  \"they exaggerated for my benefit\". Per contra, it thinks \"this rule isn't precise, maybe others aren't either.\"</p> <p>That will turn the agent from Sheldon Cooper, to Captain Barbossa.</p> <p>The strategic imprecision buys nothing anyway:</p> <p>Mid-session, the files are already in the context window from the initial load. </p> <p>The risk you are mitigating (agent ignores context for task 2, 3, 4  within a session) isn't real: The context is already loaded.</p> <p>The real risk is always the session-start skip,  which \"every session\" covers exactly.</p> <p>\"Every session\" went in. Precision preserved.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#agent-behavior-testing-rule","level":2,"title":"Agent Behavior Testing Rule","text":"<p>The development process for this hook taught me something about testing agent behavior: you can't test it the way you test code.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-wrong-way-to-test","level":3,"title":"The Wrong Way to Test","text":"<p>My first instinct was to ask the agent:</p> <pre><code>\"*What are the pending tasks in TASKS.md?*\"\n</code></pre> <p>This is useless as a test. The question itself probes the agent to read <code>TASKS.md</code>, regardless of whether any hook fired. </p> <p>You are testing the question, not the mechanism.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-right-way-to-test","level":3,"title":"The Right Way to Test","text":"<p>Ask something that requires a tool but has nothing to do with context:</p> <pre><code>\"*What does the compact command do?*\"\n</code></pre> <p>Then observe tool call ordering:</p> <ul> <li>Gate worked: First calls are <code>Read</code> for context files, then task work</li> <li>Gate failed: First call is <code>Grep(\"compact\")</code>: The agent jumped straight    to work</li> </ul> <p>The signal is the sequence, not the content.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#what-the-agent-actually-did","level":3,"title":"What the Agent Actually Did","text":"<p>It read the hook, evaluated the task, decided context files were irrelevant for a code lookup, and relayed the skip message. </p> <p>Then it answered the question by reading the source code.</p> <p>This is correct behavior.</p> <p>The hook didn't force mindless compliance\" It created a framework where the agent makes a conscious, visible decision about context loading.</p> <ul> <li>For a simple lookup, skipping is right.  *For an implementation task, the agent would read everything.</li> </ul> <p>The mechanism works not because it controls the agent,  but because it makes the agent's choice observable.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#what-ive-learned","level":2,"title":"What I've Learned","text":"","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#1-instructions-compete-for-attention","level":3,"title":"1. Instructions Compete for Attention","text":"<p>The agent receives your hook message alongside the user's question, the system prompt, the skill list, the git status, and half a dozen other system reminders. Attention density applies to instructions too: More instructions means less focus on each one.</p> <p>A single clear line at the moment of action beats a paragraph of context at session start.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#2-delegation-chains-decay","level":3,"title":"2. Delegation chains decay","text":"<p>Every hop in an instruction chain loses authority: </p> <ul> <li>\"Run X\" works. </li> <li>\"Run X and follow its output\" works sometimes. </li> <li>\"Run X, read its output, then follow the instructions in the output\"    almost never works.</li> </ul> <p>This is akin to giving a three-step instruction to a highly-attention-deficit but otherwise extremely high-potential child.</p> <p>Design for one-hop compliance.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#3-social-accountability-changes-behavior","level":3,"title":"3. Social Accountability Changes Behavior","text":"<p>The VERBATIM skip message isn't just UX: It's a behavioral design pattern. </p> <p>Making the agent's decision visible to the user raises the cost of silent  non-compliance. The agent can still skip, but it has to admit it.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#4-timing-batters-more-than-wording","level":3,"title":"4. Timing Batters More than Wording","text":"<p>The same message at <code>UserPromptSubmit</code> (prompt arrival) got partial compliance. At <code>PreToolUse</code> (moment of action) it got full compliance or honest refusal. The words didn't change. The moment changed.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#5-agent-testing-requires-indirection","level":3,"title":"5. Agent Testing Requires Indirection","text":"<p>You can't ask an agent \"did you do X?\" as a test for whether a mechanism caused X. </p> <p>The question itself causes X.</p> <p>Test mechanisms through side effects: </p> <ul> <li>Observe tool ordering;</li> <li>Check for marker files;</li> <li>Look at what the agent does before it addresses your question.</li> </ul>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#6-better-comprehension-enables-better-rationalization","level":3,"title":"6. Better Comprehension Enables Better Rationalization","text":"<p>Session 1 failed because the agent didn't notice the hook. </p> <p>Session 3 failed because it noticed, understood,  and reasoned its way around it.</p> <p>Stronger wording doesn't fix this: The agent processes \"ABSOLUTELY REQUIRED\" the same way it processes \"STOP\": </p> <p>The fix is closing rationalization paths* (the <code>CLAUDE.md</code> escape hatch),  **not shouting louder.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#7-observable-failure-beats-silent-compliance","level":3,"title":"7. Observable Failure Beats Silent Compliance","text":"<p>The relay block is more valuable as a monitoring signal than as a compliance mechanism: </p> <p>You don't need perfect adherence. You need to know when adherence breaks down. A system where failures are visible is strictly better than a  system that claims 100% compliance but can't prove it.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#8-context-files-are-a-feedback-loop","level":3,"title":"8. Context Files Are a Feedback Loop","text":"<p>Recording failure analysis in the same files the agent loads at session start creates a self-reinforcing loop: </p> <p>The next agent reads its predecessor's failure before it has a chance to repeat it. The context system isn't just memory: It is a correction channel.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-principle","level":2,"title":"The Principle","text":"<p>Words Leave, Context Remains</p> <p>\"Nothing important should live only in conversation.</p> <p>Nothing critical should depend on recall.\"</p> <p>The <code>ctx</code> Manifesto</p> <p>The \"Dog Ate My Homework\" case is a special instance of this principle. </p> <p>Context files exist, so the agent doesn't have to remember. </p> <p>But existence isn't sufficient: The files have to be read. </p> <p>And reading has to beprompted at the right moment, in the right way,  with the right escape valve.</p> <p>The solution isn't more instructions. It isn't harder gates.  It isn't forcing the agent into a ceremony it will resent and shortcut.</p> <p>The solution is a single, well-timed nudge with visible accountability:</p> <p>One hop. One moment. One choice the user can see.</p> <p>And when the agent does skip (because it will, 15--25% of the time on narrow tasks) the canary sings: </p> <ul> <li>The user sees what happened. </li> <li>The failure gets recorded. </li> <li>And the next agent reads the recording.</li> </ul> <p>That's not perfect compliance. It's better: A system that gets more robust every time it fails.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#the-arc","level":2,"title":"The Arc","text":"<p>The Attention Budget explained why context competes for focus.</p> <p>Defense in Depth showed that soft instructions are probabilistic, not deterministic.</p> <p>Eight Ways a Hook Can Talk cataloged the output patterns that make hooks effective.</p> <p>This post takes those threads and weaves them into a concrete problem:</p> <p>How do you make an agent read its homework? The answer uses all three insights (attention timing, the limits of soft instructions, and the VERBATIM relay pattern) and adds a new one: observable compliance as a design goal, not perfect compliance as a prerequisite.</p> <p>The next question this raises: if context files are a feedback loop, what else can you record in them that makes the next session smarter?</p> <p>That thread continues in Context as Infrastructure.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#for-the-interested","level":2,"title":"For the Interested","text":"<p>This paper (the medium is a blog; yet, the methodology disagrees) uses gradient descent in attention space as a practical model for how agents behave under competing demands.</p> <p>The phrase \"agents optimize via gradient descent in attention space\" is a synthesis, not a direct quote from a single paper.</p> <p>It connects three well-studied ideas:</p> <ol> <li>Neural systems optimize for low-cost paths;</li> <li>Attention is a scarce resource;</li> <li>Capability shifts are often non-linear.</li> </ol> <p>This section points to the underlying literature for readers who want the theoretical footing.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#optimization-as-the-underlying-bias","level":3,"title":"Optimization as the Underlying Bias","text":"<p>Modern neural networks are trained through gradient-based optimization. Even at inference time, model behavior reflects this bias toward low-loss / low-cost trajectories.</p> <ul> <li> <p>Rumelhart, Hinton, Williams (1986) Learning representations by back-propagating errors https://www.nature.com/articles/323533a0</p> </li> <li> <p>Goodfellow, Bengio, Courville (2016) Deep Learning — Chapter 8: Optimization https://www.deeplearningbook.org/</p> </li> </ul> <p>The important implication for agent behavior is: </p> <p>The system will tend to follow the path of least resistance unless a higher cost is made visible and preferable.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#attention-is-a-scarce-resource","level":3,"title":"Attention Is a Scarce Resource","text":"<p>Herbert Simon’s classic observation:</p> <p>\"A wealth of information creates a poverty of attention.\"</p> <ul> <li>Simon (1971)   Designing Organizations for an Information-Rich World https://doi.org/10.1007/978-1-349-00210-0_16</li> </ul> <p>This became a formal model in economics:</p> <ul> <li>Sims (2003)   Implications of Rational Inattention https://www.princeton.edu/~sims/RI.pdf</li> </ul> <p>Rational inattention shows that:</p> <ul> <li>Agents optimally ignore some available information;</li> <li>Skipping is not failure: It is cost minimization.</li> </ul> <p>That maps directly to context-loading decisions in agent workflows.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#attention-is-also-the-compute-bottleneck-in-transformers","level":3,"title":"Attention Is Also the Compute Bottleneck in Transformers","text":"<p>In transformer architectures, attention is the dominant cost center.</p> <ul> <li>Vaswani et al. (2017) Attention Is All You Need https://arxiv.org/abs/1706.03762</li> </ul> <p>Efficiency work on modern LLMs largely focuses on reducing unnecessary attention:</p> <ul> <li>Dao et al. (2022) FlashAttention: Fast and Memory-Efficient Exact Attention https://arxiv.org/abs/2205.14135</li> </ul> <p>So both cognitively and computationally, attention behaves like a limited optimization budget.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#why-improvements-arrive-as-phase-shifts","level":3,"title":"Why Improvements Arrive as Phase Shifts","text":"<p>Agent behavior often appears to improve suddenly rather than gradually.</p> <p>This mirrors known phase-transition dynamics in learning systems:</p> <ul> <li>Power et al. (2022) Grokking: Generalization Beyond Overfitting https://arxiv.org/abs/2201.02177</li> </ul> <p>and more broadly in complex systems:</p> <ul> <li>Scheffer et al. (2009) Early-warning signals for critical transitions https://www.nature.com/articles/nature08227</li> </ul> <p>Long plateaus followed by abrupt capability jumps are expected in systems optimizing under constraints.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"blog/2026-02-25-the-homework-problem/#putting-it-all-together","level":3,"title":"Putting It All Together","text":"<p>From these pieces, a practical behavioral model emerges:</p> <ul> <li>Attention is limited;</li> <li>Processing has a cost;</li> <li>Systems prefer low-cost trajectories;</li> <li>Visibility of the cost changes decisions.</li> </ul> <p>In other words:</p> <p>Agents Prefer a Path to Least Resistance</p> <p>Agent behavior follows the lowest-cost path through its attention landscape unless the environment reshapes that landscape.</p> <p>That is what this paper informally calls: \"gradient descent in attention space\".</p> <p>See also: Eight Ways a Hook Can Talk: the hook output pattern catalog that defines VERBATIM relay, The Attention Budget: why context loading is a design problem, not just a reminder problem, and Defense in Depth: why soft instructions alone are never sufficient for critical behavior.</p>","path":["The Dog Ate My Homework: Teaching AI Agents to Read Before They Write"],"tags":[]},{"location":"cli/","level":1,"title":"CLI","text":"","path":["CLI"],"tags":[]},{"location":"cli/#ctx-cli","level":2,"title":"<code>ctx</code> CLI","text":"<p>This is a complete reference for all <code>ctx</code> commands.</p>","path":["CLI"],"tags":[]},{"location":"cli/#global-options","level":2,"title":"Global Options","text":"<p>All commands support these flags:</p> Flag Description <code>--help</code> Show command help <code>--version</code> Show version <code>--context-dir &lt;path&gt;</code> Override context directory (default: <code>.context/</code>) <code>--no-color</code> Disable colored output <code>--allow-outside-cwd</code> Allow context directory outside current working directory <p>The <code>NO_COLOR=1</code> environment variable also disables colored output.</p>","path":["CLI"],"tags":[]},{"location":"cli/#commands","level":2,"title":"Commands","text":"Command Description <code>ctx init</code> Initialize <code>.context/</code> directory with templates <code>ctx status</code> Show context summary (files, tokens, drift) <code>ctx agent</code> Print token-budgeted context packet for AI consumption <code>ctx load</code> Output assembled context in read order <code>ctx add</code> Add a task, decision, learning, or convention <code>ctx complete</code> Mark a task as done <code>ctx drift</code> Detect stale paths, secrets, missing files <code>ctx sync</code> Reconcile context with codebase state <code>ctx compact</code> Archive completed tasks, clean up files <code>ctx tasks</code> Task archival and snapshots <code>ctx permissions</code> Permission snapshots (golden image) <code>ctx decisions</code> Manage <code>DECISIONS.md</code> (reindex) <code>ctx learnings</code> Manage <code>LEARNINGS.md</code> (reindex) <code>ctx recall</code> Browse and export AI session history <code>ctx journal</code> Generate static site from journal entries <code>ctx serve</code> Serve any zensical directory (default: journal site) <code>ctx watch</code> Auto-apply context updates from AI output <code>ctx hook</code> Generate AI tool integration configs <code>ctx loop</code> Generate autonomous loop script <code>ctx notify</code> Send webhook notifications <code>ctx pad</code> Encrypted scratchpad for sensitive one-liners <code>ctx remind</code> Session-scoped reminders that surface at session start <code>ctx completion</code> Generate shell autocompletion scripts <code>ctx system</code> System diagnostics and hook commands","path":["CLI"],"tags":[]},{"location":"cli/#exit-codes","level":2,"title":"Exit Codes","text":"Code Meaning 0 Success 1 General error / warnings (e.g. drift) 2 Context not found 3 Violations found (e.g. drift) 4 File operation error","path":["CLI"],"tags":[]},{"location":"cli/#environment-variables","level":2,"title":"Environment Variables","text":"Variable Description <code>CTX_DIR</code> Override default context directory path <code>CTX_TOKEN_BUDGET</code> Override default token budget <code>NO_COLOR</code> Disable colored output when set","path":["CLI"],"tags":[]},{"location":"cli/#configuration-file","level":2,"title":"Configuration File","text":"<p>Optional <code>.ctxrc</code> (YAML format) at project root:</p> <pre><code># .ctxrc\ncontext_dir: .context                # Context directory name\ntoken_budget: 8000                   # Default token budget\npriority_order:                      # File loading priority\n  - TASKS.md\n  - DECISIONS.md\n  - CONVENTIONS.md\nauto_archive: true                   # Auto-archive old items\narchive_after_days: 7                # Days before archiving tasks\nscratchpad_encrypt: true             # Encrypt scratchpad (default: true)\nallow_outside_cwd: false             # Skip boundary check (default: false)\nentry_count_learnings: 30            # Drift warning threshold (0 = disable)\nentry_count_decisions: 20            # Drift warning threshold (0 = disable)\nconvention_line_count: 200           # Line count warning for CONVENTIONS.md (0 = disable)\nnotify:                              # Webhook notification settings\n  events:                            # Required — only listed events fire\n    - loop\n    - nudge\n    - relay\n  key_rotation_days: 90              # Days before key rotation nudge\n</code></pre> Field Type Default Description <code>context_dir</code> <code>string</code> <code>.context</code> Context directory name (relative to project root) <code>token_budget</code> <code>int</code> <code>8000</code> Default token budget for <code>ctx agent</code> <code>priority_order</code> <code>[]string</code> (all files) File loading priority for context packets <code>auto_archive</code> <code>bool</code> <code>false</code> Auto-archive completed tasks <code>archive_after_days</code> <code>int</code> <code>7</code> Days before completed tasks are archived <code>scratchpad_encrypt</code> <code>bool</code> <code>true</code> Encrypt scratchpad with AES-256-GCM <code>allow_outside_cwd</code> <code>bool</code> <code>false</code> Skip boundary check for external context dirs <code>entry_count_learnings</code> <code>int</code> <code>30</code> Drift warning when <code>LEARNINGS.md</code> exceeds this count <code>entry_count_decisions</code> <code>int</code> <code>20</code> Drift warning when <code>DECISIONS.md</code> exceeds this count <code>convention_line_count</code> <code>int</code> <code>200</code> Line count warning for <code>CONVENTIONS.md</code> <code>notify.events</code> <code>[]string</code> (all) Event filter for webhook notifications (empty = all) <code>notify.key_rotation_days</code> <code>int</code> <code>90</code> Days before encryption key rotation nudge <p>Priority order: CLI flags &gt; Environment variables &gt; <code>.ctxrc</code> &gt; Defaults</p> <p>All settings are optional. Missing values use defaults.</p>","path":["CLI"],"tags":[]},{"location":"cli/context/","level":1,"title":"Context Management","text":"","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-add","level":3,"title":"<code>ctx add</code>","text":"<p>Add a new item to a context file.</p> <pre><code>ctx add &lt;type&gt; &lt;content&gt; [flags]\n</code></pre> <p>Types:</p> Type Target File <code>task</code> <code>TASKS.md</code> <code>decision</code> <code>DECISIONS.md</code> <code>learning</code> <code>LEARNINGS.md</code> <code>convention</code> <code>CONVENTIONS.md</code> <p>Flags:</p> Flag Short Description <code>--priority &lt;level&gt;</code> <code>-p</code> Priority for tasks: <code>high</code>, <code>medium</code>, <code>low</code> <code>--section &lt;name&gt;</code> <code>-s</code> Target section within file <code>--context</code> <code>-c</code> Context (required for decisions and learnings) <code>--rationale</code> <code>-r</code> Rationale for decisions (required for decisions) <code>--consequences</code> Consequences for decisions (required for decisions) <code>--lesson</code> <code>-l</code> Key insight (required for learnings) <code>--application</code> <code>-a</code> How to apply going forward (required for learnings) <code>--file</code> <code>-f</code> Read content from file instead of argument <p>Examples:</p> <pre><code># Add a task\nctx add task \"Implement user authentication\"\nctx add task \"Fix login bug\" --priority high\n\n# Record a decision (requires all ADR—Architectural Decision Record—fields)\nctx add decision \"Use PostgreSQL for primary database\" \\\n  --context \"Need a reliable database for production\" \\\n  --rationale \"PostgreSQL offers ACID compliance and JSON support\" \\\n  --consequences \"Team needs PostgreSQL training\"\n\n# Note a learning (requires context, lesson, and application)\nctx add learning \"Vitest mocks must be hoisted\" \\\n  --context \"Tests failed with undefined mock errors\" \\\n  --lesson \"Vitest hoists vi.mock() calls to top of file\" \\\n  --application \"Always place vi.mock() before imports in test files\"\n\n# Add to specific section\nctx add convention \"Use kebab-case for filenames\" --section \"Naming\"\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-complete","level":3,"title":"<code>ctx complete</code>","text":"<p>Mark a task as completed.</p> <pre><code>ctx complete &lt;task-id-or-text&gt;\n</code></pre> <p>Arguments:</p> <ul> <li><code>task-id-or-text</code>: Task number or partial text match</li> </ul> <p>Examples:</p> <pre><code># By text (partial match)\nctx complete \"user auth\"\n\n# By task number\nctx complete 3\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-drift","level":3,"title":"<code>ctx drift</code>","text":"<p>Detect stale or invalid context.</p> <pre><code>ctx drift [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--json</code> Output machine-readable JSON <code>--fix</code> Auto-fix simple issues <p>Checks:</p> <ul> <li>Path references in <code>ARCHITECTURE.md</code> and <code>CONVENTIONS.md</code> exist</li> <li>Task references are valid</li> <li>Constitution rules aren't violated (heuristic)</li> <li>Staleness indicators (old files, many completed tasks)</li> <li>Missing packages — warns when <code>internal/</code> directories exist on disk but are   not referenced in <code>ARCHITECTURE.md</code> (suggests running <code>/ctx-map</code>)</li> <li>Entry count — warns when <code>LEARNINGS.md</code> or <code>DECISIONS.md</code> exceed configurable   thresholds (default: 30 learnings, 20 decisions), or when <code>CONVENTIONS.md</code>   exceeds a line count threshold (default: 200). Configure via <code>.ctxrc</code>:   <pre><code>entry_count_learnings: 30      # warn above this (0 = disable)\nentry_count_decisions: 20      # warn above this (0 = disable)\nconvention_line_count: 200     # warn above this (0 = disable)\n</code></pre></li> </ul> <p>Example:</p> <pre><code>ctx drift\nctx drift --json\nctx drift --fix\n</code></pre> <p>Exit codes:</p> Code Meaning 0 All checks passed 1 Warnings found 3 Violations found","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-sync","level":3,"title":"<code>ctx sync</code>","text":"<p>Reconcile context with the current codebase state.</p> <pre><code>ctx sync [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--dry-run</code> Show what would change without modifying <p>What it does:</p> <ul> <li>Scans codebase for structural changes</li> <li>Compares with ARCHITECTURE.md</li> <li>Suggests documenting dependencies if package files exist</li> <li>Identifies stale or outdated context</li> </ul> <p>Example:</p> <pre><code>ctx sync\nctx sync --dry-run\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-compact","level":3,"title":"<code>ctx compact</code>","text":"<p>Consolidate and clean up context files.</p> <ul> <li>Moves completed tasks older than 7 days to the archive</li> <li>Removes empty sections</li> </ul> <pre><code>ctx compact [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--archive</code> Create <code>.context/archive/</code> for old content <p>Example:</p> <pre><code>ctx compact\nctx compact --archive\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-tasks","level":3,"title":"<code>ctx tasks</code>","text":"<p>Manage task archival and snapshots.</p> <pre><code>ctx tasks &lt;subcommand&gt;\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-tasks-archive","level":4,"title":"<code>ctx tasks archive</code>","text":"<p>Move completed tasks from <code>TASKS.md</code> to a timestamped archive file.</p> <pre><code>ctx tasks archive [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--dry-run</code> Preview changes without modifying files <p>Archive files are stored in <code>.context/archive/</code> with timestamped names (<code>tasks-YYYY-MM-DD.md</code>). Completed tasks (marked with <code>[x]</code>) are moved; pending tasks (<code>[ ]</code>) remain in <code>TASKS.md</code>.</p> <p>Example:</p> <pre><code>ctx tasks archive\nctx tasks archive --dry-run\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-tasks-snapshot","level":4,"title":"<code>ctx tasks snapshot</code>","text":"<p>Create a point-in-time snapshot of <code>TASKS.md</code> without modifying the original.</p> <pre><code>ctx tasks snapshot [name]\n</code></pre> <p>Arguments:</p> <ul> <li><code>name</code>: Optional name for the snapshot (defaults to \"snapshot\")</li> </ul> <p>Snapshots are stored in <code>.context/archive/</code> with timestamped names (<code>tasks-&lt;name&gt;-YYYY-MM-DD-HHMM.md</code>).</p> <p>Example:</p> <pre><code>ctx tasks snapshot\nctx tasks snapshot \"before-refactor\"\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-permissions","level":3,"title":"<code>ctx permissions</code>","text":"<p>Manage Claude Code permission snapshots.</p> <pre><code>ctx permissions &lt;subcommand&gt;\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-permissions-snapshot","level":4,"title":"<code>ctx permissions snapshot</code>","text":"<p>Save <code>.claude/settings.local.json</code> as the golden image.</p> <pre><code>ctx permissions snapshot\n</code></pre> <p>Creates <code>.claude/settings.golden.json</code> as a byte-for-byte copy of the current settings. Overwrites if the golden file already exists.</p> <p>The golden file is meant to be committed to version control and shared with the team.</p> <p>Example:</p> <pre><code>ctx permissions snapshot\n# Saved golden image: .claude/settings.golden.json\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-permissions-restore","level":4,"title":"<code>ctx permissions restore</code>","text":"<p>Replace <code>settings.local.json</code> with the golden image.</p> <pre><code>ctx permissions restore\n</code></pre> <p>Prints a diff of dropped (session-accumulated) and restored permissions. No-op if the files already match.</p> <p>Example:</p> <pre><code>ctx permissions restore\n# Dropped 3 session permission(s):\n#   - Bash(cat /tmp/debug.log:*)\n#   - Bash(rm /tmp/test-*:*)\n#   - Bash(curl https://example.com:*)\n# Restored from golden image.\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-decisions","level":3,"title":"<code>ctx decisions</code>","text":"<p>Manage the <code>DECISIONS.md</code> file.</p> <pre><code>ctx decisions &lt;subcommand&gt;\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-decisions-reindex","level":4,"title":"<code>ctx decisions reindex</code>","text":"<p>Regenerate the quick-reference index at the top of <code>DECISIONS.md</code>.</p> <pre><code>ctx decisions reindex\n</code></pre> <p>The index is a compact table showing the date and title for each decision, allowing AI tools to quickly scan entries without reading the full file.</p> <p>Use this after manual edits to <code>DECISIONS.md</code> or when migrating existing files to use the index format.</p> <p>Example:</p> <pre><code>ctx decisions reindex\n# ✓ Index regenerated with 12 entries\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-learnings","level":3,"title":"<code>ctx learnings</code>","text":"<p>Manage the <code>LEARNINGS.md</code> file.</p> <pre><code>ctx learnings &lt;subcommand&gt;\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/context/#ctx-learnings-reindex","level":4,"title":"<code>ctx learnings reindex</code>","text":"<p>Regenerate the quick-reference index at the top of <code>LEARNINGS.md</code>.</p> <pre><code>ctx learnings reindex\n</code></pre> <p>The index is a compact table showing the date and title for each learning, allowing AI tools to quickly scan entries without reading the full file.</p> <p>Use this after manual edits to <code>LEARNINGS.md</code> or when migrating existing files to use the index format.</p> <p>Example:</p> <pre><code>ctx learnings reindex\n# ✓ Index regenerated with 8 entries\n</code></pre>","path":["CLI","Context Management"],"tags":[]},{"location":"cli/init-status/","level":1,"title":"Init and Status","text":"","path":["CLI","Init and Status"],"tags":[]},{"location":"cli/init-status/#ctx-init","level":3,"title":"<code>ctx init</code>","text":"<p>Initialize a new <code>.context/</code> directory with template files.</p> <pre><code>ctx init [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--force</code> <code>-f</code> Overwrite existing context files <code>--minimal</code> <code>-m</code> Only create essential files (<code>TASKS.md</code>, <code>DECISIONS.md</code>, <code>CONSTITUTION.md</code>) <code>--merge</code> Auto-merge <code>ctx</code> content into existing <code>CLAUDE.md</code> and <code>PROMPT.md</code> <code>--ralph</code> Agent works autonomously without asking questions <p>Creates:</p> <ul> <li><code>.context/</code> directory with all template files</li> <li><code>.claude/settings.local.json</code> with pre-approved ctx permissions</li> <li><code>PROMPT.md</code> with session prompt (autonomous mode with <code>--ralph</code>)</li> <li><code>IMPLEMENTATION_PLAN.md</code> with high-level project direction</li> <li><code>CLAUDE.md</code> with bootstrap instructions (or merges into existing)</li> </ul> <p>Claude Code hooks and skills are provided by the ctx plugin (see Integrations).</p> <p>Example:</p> <pre><code># Collaborative mode (agent asks questions when unclear)\nctx init\n\n# Autonomous mode (agent works independently)\nctx init --ralph\n\n# Minimal setup (just core files)\nctx init --minimal\n\n# Force overwrite existing\nctx init --force\n\n# Merge into existing files\nctx init --merge\n</code></pre>","path":["CLI","Init and Status"],"tags":[]},{"location":"cli/init-status/#ctx-status","level":3,"title":"<code>ctx status</code>","text":"<p>Show the current context summary.</p> <pre><code>ctx status [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--json</code> Output as JSON <code>--verbose</code> <code>-v</code> Include file contents summary <p>Output:</p> <ul> <li>Context directory path</li> <li>Total files and token estimate</li> <li>Status of each file (loaded, empty, missing)</li> <li>Recent activity (modification times)</li> <li>Drift warnings if any</li> </ul> <p>Example:</p> <pre><code>ctx status\nctx status --json\nctx status --verbose\n</code></pre>","path":["CLI","Init and Status"],"tags":[]},{"location":"cli/init-status/#ctx-agent","level":3,"title":"<code>ctx agent</code>","text":"<p>Print an AI-ready context packet optimized for LLM consumption.</p> <pre><code>ctx agent [flags]\n</code></pre> <p>Flags:</p> Flag Default Description <code>--budget</code> 8000 Token budget — controls content selection and prioritization <code>--format</code> md Output format: <code>md</code> or <code>json</code> <code>--cooldown</code> 10m Suppress repeated output within this duration (requires <code>--session</code>) <code>--session</code> (none) Session ID for cooldown isolation (e.g., <code>$PPID</code>) <p>How budget works:</p> <p>The budget controls how much context is included. Entries are selected in priority tiers:</p> <ol> <li>Constitution — always included in full (inviolable rules)</li> <li>Tasks — all active tasks, up to 40% of budget</li> <li>Conventions — all conventions, up to 20% of budget</li> <li>Decisions — scored by recency and relevance to active tasks</li> <li>Learnings — scored by recency and relevance to active tasks</li> </ol> <p>Decisions and learnings are ranked by a combined score (how recent + how relevant to your current tasks). High-scoring entries are included with their full body. Entries that don't fit get title-only summaries in an \"Also Noted\" section. Superseded entries are excluded.</p> <p>Output sections:</p> Section Source Selection Read These Files all <code>.context/</code> Non-empty files in priority order Constitution <code>CONSTITUTION.md</code> All rules (never truncated) Current Tasks <code>TASKS.md</code> All unchecked tasks (budget-capped) Key Conventions <code>CONVENTIONS.md</code> All items (budget-capped) Recent Decisions <code>DECISIONS.md</code> Full body, scored by relevance Key Learnings <code>LEARNINGS.md</code> Full body, scored by relevance Also Noted overflow Title-only summaries <p>Example:</p> <pre><code># Default (8000 tokens, markdown)\nctx agent\n\n# Smaller packet for tight context windows\nctx agent --budget 4000\n\n# JSON format for programmatic use\nctx agent --format json\n\n# Pipe to file\nctx agent --budget 4000 &gt; context.md\n\n# With cooldown (hooks/automation — requires --session)\nctx agent --session $PPID\n</code></pre> <p>Use case: Copy-paste into AI chat, pipe to system prompt, or use in hooks.</p>","path":["CLI","Init and Status"],"tags":[]},{"location":"cli/init-status/#ctx-load","level":3,"title":"<code>ctx load</code>","text":"<p>Load and display assembled context as AI would see it.</p> <pre><code>ctx load [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--budget &lt;tokens&gt;</code> Token budget for assembly (default: 8000) <code>--raw</code> Output raw file contents without assembly <p>Example:</p> <pre><code>ctx load\nctx load --budget 16000\nctx load --raw\n</code></pre>","path":["CLI","Init and Status"],"tags":[]},{"location":"cli/recall/","level":1,"title":"Recall and Journal","text":"","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/recall/#ctx-recall","level":3,"title":"<code>ctx recall</code>","text":"<p>Browse and search AI session history from Claude Code and other tools.</p> <pre><code>ctx recall &lt;subcommand&gt;\n</code></pre>","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/recall/#ctx-recall-list","level":4,"title":"<code>ctx recall list</code>","text":"<p>List all parsed sessions.</p> <pre><code>ctx recall list [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--limit</code> <code>-n</code> Maximum sessions to display (default: 20) <code>--project</code> <code>-p</code> Filter by project name <code>--tool</code> <code>-t</code> Filter by tool (e.g., <code>claude-code</code>) <code>--all-projects</code> Include sessions from all projects <p>Sessions are sorted by date (newest first) and display slug, project, start time, duration, turn count, and token usage.</p> <p>Example:</p> <pre><code>ctx recall list\nctx recall list --limit 5\nctx recall list --project ctx\nctx recall list --tool claude-code\n</code></pre>","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/recall/#ctx-recall-show","level":4,"title":"<code>ctx recall show</code>","text":"<p>Show details of a specific session.</p> <pre><code>ctx recall show [session-id] [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--latest</code> Show the most recent session <code>--full</code> Show full message content <code>--all-projects</code> Search across all projects <p>The session ID can be a full UUID, partial match, or session slug name.</p> <p>Example:</p> <pre><code>ctx recall show abc123\nctx recall show gleaming-wobbling-sutherland\nctx recall show --latest\nctx recall show --latest --full\n</code></pre>","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/recall/#ctx-recall-export","level":4,"title":"<code>ctx recall export</code>","text":"<p>Export sessions to editable journal files in <code>.context/journal/</code>.</p> <pre><code>ctx recall export [session-id] [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--all</code> Export all sessions (only new files by default) <code>--all-projects</code> Export from all projects <code>--regenerate</code> Re-export existing files (preserves YAML frontmatter by default) <code>--keep-frontmatter</code> Preserve enriched YAML frontmatter during regeneration (default: true) <code>--yes</code>, <code>-y</code> Skip confirmation prompt <code>--dry-run</code> Show what would be exported without writing files <p>Safe by default: <code>--all</code> only exports new sessions. Existing files are skipped. Use <code>--regenerate</code> to re-export existing files (conversation content is regenerated, YAML frontmatter from enrichment is preserved by default). Use <code>--keep-frontmatter=false</code> to discard enriched frontmatter during regeneration.</p> <p>Locked entries (via <code>ctx recall lock</code>) are always skipped, regardless of flags.</p> <p>Single-session export (<code>ctx recall export &lt;id&gt;</code>) always writes without prompting, since you are explicitly targeting one session.</p> <p>The <code>journal/</code> directory should be gitignored (like <code>sessions/</code>) since it contains raw conversation data.</p> <p>Example:</p> <pre><code>ctx recall export abc123                              # Export one session\nctx recall export --all                               # Export only new sessions\nctx recall export --all --dry-run                     # Preview what would be exported\nctx recall export --all --regenerate                  # Re-export existing (prompts)\nctx recall export --all --regenerate -y               # Re-export without prompting\nctx recall export --all --regenerate --keep-frontmatter=false -y  # Discard frontmatter\n</code></pre>","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/recall/#ctx-recall-lock","level":4,"title":"<code>ctx recall lock</code>","text":"<p>Protect journal entries from being overwritten by <code>export --regenerate</code>.</p> <pre><code>ctx recall lock &lt;pattern&gt; [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--all</code> Lock all journal entries <p>The pattern matches filenames by slug, date, or short ID. Locking a multi-part entry locks all parts. The lock is recorded in <code>.context/journal/.state.json</code> and a <code>locked: true</code> line is added to the file's YAML frontmatter for visibility.</p> <p>Example:</p> <pre><code>ctx recall lock abc12345\nctx recall lock 2026-01-21-session-abc12345.md\nctx recall lock --all\n</code></pre>","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/recall/#ctx-recall-unlock","level":4,"title":"<code>ctx recall unlock</code>","text":"<p>Remove lock protection from journal entries.</p> <pre><code>ctx recall unlock &lt;pattern&gt; [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--all</code> Unlock all journal entries <p>Example:</p> <pre><code>ctx recall unlock abc12345\nctx recall unlock --all\n</code></pre>","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/recall/#ctx-recall-sync","level":4,"title":"<code>ctx recall sync</code>","text":"<p>Sync lock state from journal frontmatter to <code>.state.json</code>.</p> <pre><code>ctx recall sync\n</code></pre> <p>Scans all journal markdowns and updates <code>.state.json</code> to match each file's frontmatter. Files with <code>locked: true</code> in frontmatter are marked locked in state; files without a <code>locked:</code> line have their lock cleared.</p> <p>This is the inverse of <code>ctx recall lock</code>: instead of state driving frontmatter, frontmatter drives state. Useful after batch enrichment where you add <code>locked: true</code> to frontmatter manually.</p> <p>Example:</p> <pre><code># After enriching entries and adding locked: true to frontmatter\nctx recall sync\n</code></pre>","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/recall/#ctx-journal","level":3,"title":"<code>ctx journal</code>","text":"<p>Analyze and synthesize exported session files.</p> <pre><code>ctx journal &lt;subcommand&gt;\n</code></pre>","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/recall/#ctx-journal-site","level":4,"title":"<code>ctx journal site</code>","text":"<p>Generate a static site from journal entries in <code>.context/journal/</code>.</p> <pre><code>ctx journal site [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--output</code> <code>-o</code> Output directory (default: .context/journal-site) <code>--build</code> Run zensical build after generating <code>--serve</code> Run zensical serve after generating <p>Creates a <code>zensical</code>-compatible site structure with an index page listing all sessions by date, and individual pages for each journal entry.</p> <p>Requires <code>zensical</code> to be installed for <code>--build</code> or <code>--serve</code>:</p> <pre><code>pipx install zensical\n</code></pre> <p>Example:</p> <pre><code>ctx journal site                    # Generate in .context/journal-site/\nctx journal site --output ~/public  # Custom output directory\nctx journal site --build            # Generate and build HTML\nctx journal site --serve            # Generate and serve locally\n</code></pre>","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/recall/#ctx-journal-obsidian","level":4,"title":"<code>ctx journal obsidian</code>","text":"<p>Generate an Obsidian vault from journal entries in <code>.context/journal/</code>.</p> <pre><code>ctx journal obsidian [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--output</code> <code>-o</code> Output directory (default: .context/journal-obsidian) <p>Creates an Obsidian-compatible vault with:</p> <ul> <li>Wikilinks (<code>[[target|display]]</code>) for all internal navigation</li> <li>MOC pages (Map of Content) for topics, key files, and session types</li> <li>Related sessions footer linking entries that share topics</li> <li>Transformed frontmatter (<code>topics</code> → <code>tags</code> for Obsidian integration)</li> <li>Minimal <code>.obsidian/</code> config enforcing wikilink mode</li> </ul> <p>No external dependencies are required: Open the output directory as an Obsidian  vault directly.</p> <p>Example:</p> <pre><code>ctx journal obsidian                          # Generate in .context/journal-obsidian/\nctx journal obsidian --output ~/vaults/ctx    # Custom output directory\n</code></pre>","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/recall/#ctx-serve","level":3,"title":"<code>ctx serve</code>","text":"<p>Serve any zensical directory locally. This is a serve-only command — it does not generate or regenerate site content.</p> <pre><code>ctx serve [directory]\n</code></pre> <p>If no directory is specified, defaults to the journal site (<code>.context/journal-site</code>).</p> <p>Requires <code>zensical</code> to be installed:</p> <pre><code>pipx install zensical\n</code></pre> <p><code>ctx serve</code> vs. <code>ctx journal site --serve</code></p> <p><code>ctx journal site --serve</code> generates the journal site then serves it — an all-in-one command. <code>ctx serve</code> only serves an existing directory, and works with any zensical site (journal, docs, etc.).</p> <p>Example:</p> <pre><code>ctx serve                           # Serve journal site (no regeneration)\nctx serve .context/journal-site     # Same, explicit path\nctx serve ./site                    # Serve the docs site\n</code></pre>","path":["CLI","Recall and Journal"],"tags":[]},{"location":"cli/system/","level":1,"title":"System","text":"","path":["CLI","System"],"tags":[]},{"location":"cli/system/#ctx-system","level":3,"title":"<code>ctx system</code>","text":"<p>System diagnostics and hook commands.</p> <pre><code>ctx system &lt;subcommand&gt;\n</code></pre> <p>The parent command shows available subcommands. Hidden plumbing subcommands (<code>ctx system mark-journal</code>) are used by skills and automation. Hidden hook subcommands (<code>ctx system check-*</code>) are used by the Claude Code plugin — see AI Tools for details.</p>","path":["CLI","System"],"tags":[]},{"location":"cli/system/#ctx-system-bootstrap","level":4,"title":"<code>ctx system bootstrap</code>","text":"<p>Print context location and rules for AI agents. This is the recommended first command for AI agents to run at session start — it tells them where the context directory is and how to use it.</p> <pre><code>ctx system bootstrap [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--json</code> Output in JSON format <p>Text output:</p> <pre><code>ctx bootstrap\n=============\n\ncontext_dir: .context\n\nFiles:\n  CONSTITUTION.md, TASKS.md, DECISIONS.md, LEARNINGS.md,\n  CONVENTIONS.md, ARCHITECTURE.md, GLOSSARY.md\n\nRules:\n  1. Use context_dir above for ALL file reads/writes\n  2. Never say \"I don't have memory\" — context IS your memory\n  3. Read files silently, present as recall (not search)\n  4. Persist learnings/decisions before session ends\n  5. Run `ctx agent` for content summaries\n  6. Run `ctx status` for context health\n</code></pre> <p>JSON output:</p> <pre><code>{\n  \"context_dir\": \".context\",\n  \"files\": [\"CONSTITUTION.md\", \"TASKS.md\", ...],\n  \"rules\": [\"Use context_dir above for ALL file reads/writes\", ...]\n}\n</code></pre> <p>Examples:</p> <pre><code>ctx system bootstrap                          # Text output\nctx system bootstrap --json                   # JSON output\nctx system bootstrap --json | jq .context_dir # Extract context path\n</code></pre> <p>Why it exists: When users configure an external context directory via <code>.ctxrc</code> (<code>context_dir: /mnt/nas/.context</code>), the AI agent needs to know where context lives. Bootstrap resolves the configured path and communicates it to the agent at session start. Every nudge also includes a context directory footer for reinforcement.</p>","path":["CLI","System"],"tags":[]},{"location":"cli/system/#ctx-system-resources","level":4,"title":"<code>ctx system resources</code>","text":"<p>Show system resource usage with threshold-based alerts.</p> <pre><code>ctx system resources [flags]\n</code></pre> <p>Displays memory, swap, disk, and CPU load with two severity tiers:</p> Resource WARNING DANGER Memory &gt;= 80% used &gt;= 90% used Swap &gt;= 50% used &gt;= 75% used Disk (cwd) &gt;= 85% full &gt;= 95% full Load (1m) &gt;= 0.8x CPUs &gt;= 1.5x CPUs <p>Flags:</p> Flag Description <code>--json</code> Output in JSON format <p>Examples:</p> <pre><code>ctx system resources               # Text output with status indicators\nctx system resources --json        # Machine-readable JSON\nctx system resources --json | jq '.alerts'   # Extract alerts only\n</code></pre> <p>Text output:</p> <pre><code>System Resources\n====================\n\nMemory:    4.2 / 16.0 GB (26%)                     ✓ ok\nSwap:      0.0 /  8.0 GB (0%)                      ✓ ok\nDisk:    180.2 / 500.0 GB (36%)                     ✓ ok\nLoad:     0.52 / 0.41 / 0.38  (8 CPUs, ratio 0.07) ✓ ok\n\nAll clear — no resource warnings.\n</code></pre> <p>When resources breach thresholds, alerts are listed below the summary:</p> <pre><code>Alerts:\n  ✖ Memory 92% used (14.7 / 16.0 GB)\n  ✖ Swap 78% used (6.2 / 8.0 GB)\n  ✖ Load 1.56x CPU count\n</code></pre> <p>Platform support: Full metrics on Linux and macOS. Windows shows disk only; memory and load report as unsupported.</p>","path":["CLI","System"],"tags":[]},{"location":"cli/system/#ctx-system-mark-journal","level":4,"title":"<code>ctx system mark-journal</code>","text":"<p>Update processing state for a journal entry. Records the current date in <code>.context/journal/.state.json</code>. Used by journal skills to record pipeline progress.</p> <pre><code>ctx system mark-journal &lt;filename&gt; &lt;stage&gt;\n</code></pre> <p>Stages: <code>exported</code>, <code>enriched</code>, <code>normalized</code>, <code>fences_verified</code></p> Flag Description <code>--check</code> Check if stage is set (exit 1 if not) <p>Example:</p> <pre><code>ctx system mark-journal 2026-01-21-session-abc12345.md enriched\nctx system mark-journal 2026-01-21-session-abc12345.md normalized\nctx system mark-journal --check 2026-01-21-session-abc12345.md fences_verified\n</code></pre>","path":["CLI","System"],"tags":[]},{"location":"cli/tools/","level":1,"title":"Tools and Utilities","text":"","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-watch","level":3,"title":"<code>ctx watch</code>","text":"<p>Watch for AI output and auto-apply context updates.</p> <p>Parses <code>&lt;context-update&gt;</code> XML commands from AI output and applies them to context files.</p> <pre><code>ctx watch [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--log &lt;file&gt;</code> Log file to watch (default: stdin) <code>--dry-run</code> Preview updates without applying <p>Example:</p> <pre><code># Watch stdin\nai-tool | ctx watch\n\n# Watch a log file\nctx watch --log /path/to/ai-output.log\n\n# Preview without applying\nctx watch --dry-run\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-hook","level":3,"title":"<code>ctx hook</code>","text":"<p>Generate AI tool integration configuration.</p> <pre><code>ctx hook &lt;tool&gt; [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--write</code> <code>-w</code> Write the generated config to disk (e.g. <code>.github/copilot-instructions.md</code>) <p>Supported tools:</p> Tool Description <code>claude-code</code> Redirects to plugin install instructions <code>cursor</code> Cursor IDE <code>aider</code> Aider CLI <code>copilot</code> GitHub Copilot <code>windsurf</code> Windsurf IDE <p>Claude Code uses the plugin system</p> <p>Claude Code integration is now provided via the <code>ctx</code> plugin. Running <code>ctx hook claude-code</code> prints plugin install instructions.</p> <p>Example:</p> <pre><code># Print hook instructions to stdout\nctx hook cursor\nctx hook aider\n\n# Generate and write .github/copilot-instructions.md\nctx hook copilot --write\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-loop","level":3,"title":"<code>ctx loop</code>","text":"<p>Generate a shell script for running an autonomous loop.</p> <p>An autonomous loop continuously runs an AI assistant with the same prompt until a completion signal is detected, enabling iterative development where the AI builds on its previous work.</p> <pre><code>ctx loop [flags]\n</code></pre> <p>Flags:</p> Flag Short Description Default <code>--tool &lt;tool&gt;</code> <code>-t</code> AI tool: <code>claude</code>, <code>aider</code>, or <code>generic</code> <code>claude</code> <code>--prompt &lt;file&gt;</code> <code>-p</code> Prompt file to use <code>PROMPT.md</code> <code>--max-iterations &lt;n&gt;</code> <code>-n</code> Maximum iterations (0 = unlimited) <code>0</code> <code>--completion &lt;signal&gt;</code> <code>-c</code> Completion signal to detect <code>SYSTEM_CONVERGED</code> <code>--output &lt;file&gt;</code> <code>-o</code> Output script filename <code>loop.sh</code> <p>Example:</p> <pre><code># Generate loop.sh for Claude Code\nctx loop\n\n# Generate for Aider with custom prompt\nctx loop --tool aider --prompt TASKS.md\n\n# Limit to 10 iterations\nctx loop --max-iterations 10\n\n# Output to custom file\nctx loop -o my-loop.sh\n</code></pre> <p>Usage:</p> <pre><code># Generate and run the loop\nctx loop\nchmod +x loop.sh\n./loop.sh\n</code></pre> <p>See Autonomous Loops for detailed workflow documentation.</p>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-notify","level":3,"title":"<code>ctx notify</code>","text":"<p>Send fire-and-forget webhook notifications from skills, loops, and hooks.</p> <pre><code>ctx notify --event &lt;name&gt; [--session-id &lt;id&gt;] \"message\"\n</code></pre> <p>Flags:</p> Flag Short Description <code>--event</code> <code>-e</code> Event name (required) <code>--session-id</code> <code>-s</code> Session ID (optional) <p>Behavior:</p> <ul> <li>No webhook configured: silent noop (exit 0)</li> <li>Webhook set but event not in <code>events</code> list: silent noop (exit 0)</li> <li>Webhook set and event matches: fire-and-forget HTTP POST</li> <li>HTTP errors silently ignored (no retry)</li> </ul> <p>Example:</p> <pre><code>ctx notify --event loop \"Loop completed after 5 iterations\"\nctx notify -e nudge -s session-abc \"Context checkpoint at prompt #20\"\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-notify-setup","level":4,"title":"<code>ctx notify setup</code>","text":"<p>Configure the webhook URL interactively. The URL is encrypted with AES-256-GCM using the encryption key and stored in <code>.context/.notify.enc</code>.</p> <pre><code>ctx notify setup\n</code></pre> <p>The encrypted file is safe to commit. The key (<code>.context/.context.key</code>) is gitignored and never committed.</p>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-notify-test","level":4,"title":"<code>ctx notify test</code>","text":"<p>Send a test notification and report the HTTP response status.</p> <pre><code>ctx notify test\n</code></pre> <p>Payload format (JSON POST):</p> <pre><code>{\n  \"event\": \"loop\",\n  \"message\": \"Loop completed after 5 iterations\",\n  \"session_id\": \"abc123-...\",\n  \"timestamp\": \"2026-02-22T14:30:00Z\",\n  \"project\": \"ctx\"\n}\n</code></pre> Field Type Description <code>event</code> string Event name from <code>--event</code> flag <code>message</code> string Notification message <code>session_id</code> string Session ID (omitted if empty) <code>timestamp</code> string UTC RFC3339 timestamp <code>project</code> string Project directory name","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-pad","level":3,"title":"<code>ctx pad</code>","text":"<p>Encrypted scratchpad for sensitive one-liners that travel with the project.</p> <p>When invoked without a subcommand, lists all entries.</p> <pre><code>ctx pad\nctx pad &lt;subcommand&gt;\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-pad-add","level":4,"title":"<code>ctx pad add</code>","text":"<p>Append a new entry to the scratchpad.</p> <pre><code>ctx pad add &lt;text&gt;\nctx pad add &lt;label&gt; --file &lt;path&gt;\n</code></pre> <p>Flags:</p> Flag Short Description <code>--file</code> <code>-f</code> Ingest a file as a blob entry (max 64 KB) <p>Examples:</p> <pre><code>ctx pad add \"DATABASE_URL=postgres://user:pass@host/db\"\nctx pad add \"deploy config\" --file ./deploy.yaml\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-pad-show","level":4,"title":"<code>ctx pad show</code>","text":"<p>Output the raw text of an entry by number. For blob entries, prints decoded file content (or writes to disk with <code>--out</code>).</p> <pre><code>ctx pad show &lt;n&gt;\nctx pad show &lt;n&gt; --out &lt;path&gt;\n</code></pre> <p>Arguments:</p> <ul> <li><code>n</code>: 1-based entry number</li> </ul> <p>Flags:</p> Flag Description <code>--out</code> Write decoded blob content to a file (blobs only) <p>Examples:</p> <pre><code>ctx pad show 3\nctx pad show 2 --out ./recovered.yaml\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-pad-rm","level":4,"title":"<code>ctx pad rm</code>","text":"<p>Remove an entry by number.</p> <pre><code>ctx pad rm &lt;n&gt;\n</code></pre> <p>Arguments:</p> <ul> <li><code>n</code>: 1-based entry number</li> </ul>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-pad-edit","level":4,"title":"<code>ctx pad edit</code>","text":"<p>Replace, append to, or prepend to an entry.</p> <pre><code>ctx pad edit &lt;n&gt; [text]\n</code></pre> <p>Arguments:</p> <ul> <li><code>n</code>: 1-based entry number</li> <li><code>text</code>: Replacement text (mutually exclusive with <code>--append</code>/<code>--prepend</code>)</li> </ul> <p>Flags:</p> Flag Description <code>--append</code> Append text to the end of the entry <code>--prepend</code> Prepend text to the beginning of entry <code>--file</code> Replace blob file content (preserves label) <code>--label</code> Replace blob label (preserves content) <p>Examples:</p> <pre><code>ctx pad edit 2 \"new text\"\nctx pad edit 2 --append \" suffix\"\nctx pad edit 2 --prepend \"prefix \"\nctx pad edit 1 --file ./v2.yaml\nctx pad edit 1 --label \"new name\"\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-pad-mv","level":4,"title":"<code>ctx pad mv</code>","text":"<p>Move an entry from one position to another.</p> <pre><code>ctx pad mv &lt;from&gt; &lt;to&gt;\n</code></pre> <p>Arguments:</p> <ul> <li><code>from</code>: Source position (1-based)</li> <li><code>to</code>: Destination position (1-based)</li> </ul>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-pad-resolve","level":4,"title":"<code>ctx pad resolve</code>","text":"<p>Show both sides of a merge conflict in the encrypted scratchpad.</p> <pre><code>ctx pad resolve\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-pad-import","level":4,"title":"<code>ctx pad import</code>","text":"<p>Bulk-import lines from a file into the scratchpad. Each non-empty line becomes a separate entry. All entries are written in a single encrypt/write cycle.</p> <pre><code>ctx pad import &lt;file&gt;\nctx pad import -          # read from stdin\n</code></pre> <p>Arguments:</p> <ul> <li><code>file</code>: Path to a text file, or <code>-</code> for stdin</li> </ul> <p>Examples:</p> <pre><code>ctx pad import notes.txt\ngrep TODO *.go | ctx pad import -\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-pad-export","level":4,"title":"<code>ctx pad export</code>","text":"<p>Export all blob entries from the scratchpad to a directory as files. Each blob's label becomes the filename. Non-blob entries are skipped.</p> <pre><code>ctx pad export [dir]\n</code></pre> <p>Arguments:</p> <ul> <li><code>dir</code>: Target directory (default: current directory)</li> </ul> <p>Flags:</p> Flag Short Description <code>--force</code> <code>-f</code> Overwrite existing files instead of timestamping <code>--dry-run</code> Print what would be exported without writing <p>When a file already exists, a unix timestamp is prepended to avoid collisions (e.g., <code>1739836200-label</code>). Use <code>--force</code> to overwrite instead.</p> <p>Examples:</p> <pre><code>ctx pad export ./ideas\nctx pad export --dry-run\nctx pad export --force ./backup\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-pad-merge","level":4,"title":"<code>ctx pad merge</code>","text":"<p>Merge entries from one or more scratchpad files into the current pad. Each input file is auto-detected as encrypted or plaintext. Entries are deduplicated by exact content.</p> <pre><code>ctx pad merge FILE...\n</code></pre> <p>Arguments:</p> <ul> <li><code>FILE...</code>: One or more scratchpad files to merge (encrypted or plaintext)</li> </ul> <p>Flags:</p> Flag Short Description <code>--key</code> <code>-k</code> Path to key file for decrypting input files <code>--dry-run</code> Print what would be merged without writing <p>Examples:</p> <pre><code>ctx pad merge worktree/.context/scratchpad.enc\nctx pad merge notes.md backup.enc\nctx pad merge --key /other/.context.key foreign.enc\nctx pad merge --dry-run pad-a.enc pad-b.md\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-remind","level":3,"title":"<code>ctx remind</code>","text":"<p>Session-scoped reminders that surface at session start. Reminders are stored verbatim and relayed verbatim — no summarization, no categories.</p> <p>When invoked with a text argument and no subcommand, adds a reminder.</p> <pre><code>ctx remind \"text\"\nctx remind &lt;subcommand&gt;\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-remind-add","level":4,"title":"<code>ctx remind add</code>","text":"<p>Add a reminder. This is the default action — <code>ctx remind \"text\"</code> and <code>ctx remind add \"text\"</code> are equivalent.</p> <pre><code>ctx remind \"refactor the swagger definitions\"\nctx remind add \"check CI after the deploy\" --after 2026-02-25\n</code></pre> <p>Arguments:</p> <ul> <li><code>text</code>: The reminder message (verbatim)</li> </ul> <p>Flags:</p> Flag Short Description <code>--after</code> <code>-a</code> Don't surface until this date (YYYY-MM-DD) <p>Examples:</p> <pre><code>ctx remind \"refactor the swagger definitions\"\nctx remind \"check CI after the deploy\" --after 2026-02-25\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-remind-list","level":4,"title":"<code>ctx remind list</code>","text":"<p>List all pending reminders. Date-gated reminders that aren't yet due are annotated with <code>(after DATE, not yet due)</code>.</p> <pre><code>ctx remind list\n</code></pre> <p>Aliases: <code>ls</code></p>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-remind-dismiss","level":4,"title":"<code>ctx remind dismiss</code>","text":"<p>Remove a reminder by ID, or remove all reminders with <code>--all</code>.</p> <pre><code>ctx remind dismiss &lt;id&gt;\nctx remind dismiss --all\n</code></pre> <p>Arguments:</p> <ul> <li><code>id</code>: Reminder ID (shown in <code>list</code> output)</li> </ul> <p>Flags:</p> Flag Description <code>--all</code> Dismiss all reminders <p>Aliases: <code>rm</code></p> <p>Examples:</p> <pre><code>ctx remind dismiss 3\nctx remind dismiss --all\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#ctx-completion","level":3,"title":"<code>ctx completion</code>","text":"<p>Generate shell autocompletion scripts.</p> <pre><code>ctx completion &lt;shell&gt;\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#subcommands","level":4,"title":"Subcommands","text":"Shell Command <code>bash</code> <code>ctx completion bash</code> <code>zsh</code> <code>ctx completion zsh</code> <code>fish</code> <code>ctx completion fish</code> <code>powershell</code> <code>ctx completion powershell</code>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"cli/tools/#installation","level":4,"title":"Installation","text":"BashZshFish <pre><code># Add to ~/.bashrc\nsource &lt;(ctx completion bash)\n</code></pre> <pre><code># Add to ~/.zshrc\nsource &lt;(ctx completion zsh)\n</code></pre> <pre><code>ctx completion fish | source\n# Or save to completions directory\nctx completion fish &gt; ~/.config/fish/completions/ctx.fish\n</code></pre>","path":["CLI","Tools and Utilities"],"tags":[]},{"location":"home/","level":1,"title":"Home","text":"<p>Start here. </p> <p>Learn what <code>ctx</code> does, set it up, and run your first session.</p>","path":["Home"],"tags":[]},{"location":"home/#about-ctx","level":3,"title":"About ctx","text":"<p>What <code>ctx</code> is, how it works, and why persistent context changes how you work with AI.</p>","path":["Home"],"tags":[]},{"location":"home/#is-it-right-for-me","level":3,"title":"Is It Right for Me?","text":"<p>Good fit, not-so-good fit, and a 5-minute trial to find out for yourself.</p>","path":["Home"],"tags":[]},{"location":"home/#community","level":3,"title":"Community","text":"<p>We are the builders who care about durable context. Join the community. Hang out in IRC. Star <code>ctx</code> on GitHub.</p>","path":["Home"],"tags":[]},{"location":"home/#contributing","level":3,"title":"Contributing","text":"<p>Development setup, project layout, and pull request process.</p>","path":["Home"],"tags":[]},{"location":"home/#getting-started","level":3,"title":"Getting Started","text":"<p>Install the binary, set up the plugin, and verify it works.</p>","path":["Home"],"tags":[]},{"location":"home/#your-first-session","level":3,"title":"Your First Session","text":"<p>Step-by-step walkthrough from <code>ctx init</code> to verified recall.</p>","path":["Home"],"tags":[]},{"location":"home/#common-workflows","level":3,"title":"Common Workflows","text":"<p>Day-to-day commands for tracking context, checking health, and browsing history.</p>","path":["Home"],"tags":[]},{"location":"home/#context-files","level":3,"title":"Context Files","text":"<p>What each <code>.context/</code> file does. What's their purpose. How do we best leverage them.</p>","path":["Home"],"tags":[]},{"location":"home/#configuration","level":3,"title":"Configuration","text":"<p>Flexible configuration: <code>.ctxrc</code>, environment variables, and CLI flags.</p>","path":["Home"],"tags":[]},{"location":"home/#prompting-guide","level":3,"title":"Prompting Guide","text":"<p>Effective prompts for AI sessions with <code>ctx</code>.</p>","path":["Home"],"tags":[]},{"location":"home/about/","level":1,"title":"About","text":"<p>\"Creation, not code; Context, not prompts; Verification, not vibes.\"</p> <p>Read the <code>ctx</code> Manifesto →</p> <p>\"Without durable context, intelligence resets; with <code>ctx</code>, creation compounds.\"</p> <p>Without persistent memory, every session starts at zero; <code>ctx</code> makes sessions cumulative.</p> <p>Join the <code>ctx</code> Community →</p>","path":["Home","About"],"tags":[]},{"location":"home/about/#what-is-ctx","level":2,"title":"What Is <code>ctx</code>?","text":"<p><code>ctx</code> (Context) is a file-based system that enables AI coding assistants to persist project knowledge across sessions. It lives in a <code>.context/</code> directory in your repo.</p> <ul> <li>A session is interactive.</li> <li><code>ctx</code> enables cognitive continuity.</li> <li>Cognitive continuity enables durable, symbiotic-like human–AI workflows.</li> </ul> <p>Context Files</p> <p>Context files let AI tools remember decisions, conventions, and learnings:</p> <p>Context files are explicit and versionable contracts  between you and your agents.</p>","path":["Home","About"],"tags":[]},{"location":"home/about/#why-do-i-keep-re-explaining-my-codebase","level":2,"title":"Why Do I Keep Re-Explaining My Codebase?!?!","text":"<p>You open a new AI session. The first thing you do is re-explain your project.</p> <p>Again.</p> <p>The architecture, the database choice, the naming conventions, the thing you tried last week that didn't work. You have said all of this before (maybe yesterday, maybe an hour ago), but the AI doesn't know that.</p> <ul> <li>You explain the same architecture every session;</li> <li>The AI suggests an approach you already rejected, again;</li> <li>A decision you made three sessions ago gets relitigated from scratch;</li> <li>You spend more time setting context than building features.</li> </ul> <p>This isn't AI failure: It is staleness. </p> <p>Without persistent memory, every session starts at zero.</p>","path":["Home","About"],"tags":[]},{"location":"home/about/#day-and-night","level":3,"title":"Day and Night","text":"<p><code>ctx</code> gives your AI a memory that persists across sessions:</p> Without ctxWith ctx <pre><code>Session 12: Monday morning\n\nAI:  \"I'll scaffold a MySQL schema for this.\"\nYou: \"We use PostgreSQL.\"\n\nAI:  \"For auth, session-based would be simplest.\"\nYou: \"We decided on JWT.\"\n\nAI:  \"Endpoints in camelCase?\"\nYou: \"snake_case! Like the rest of the API!!!!!!\"\n\nYou: *scrolls up to copy an existing endpoint*\n\n20 minutes spent restoring decisions that already exist.\n</code></pre> <pre><code>Session 12: Monday morning\n\nYou:  \"Let's continue the auth implementation.\"\nAI:   \"Per DECISIONS.md (2026-02-12): JWT, not sessions: \n       The project uses PostgreSQL with JWT\n       authentication. The API follows snake_case conventions.\n       Last session you completed the login endpoint — the\n       registration endpoint is next on TASKS.md. Want me to\n       start there?\"\n\n0 minutes re-explaining. Straight to building.\n</code></pre>","path":["Home","About"],"tags":[]},{"location":"home/about/#how-ctx-solves-this","level":3,"title":"How <code>ctx</code> Solves This","text":"<p><code>ctx</code> creates a <code>.context/</code> directory in your project that stores structured knowledge files:</p> File What It Remembers <code>TASKS.md</code> What you're working on and what's next <code>DECISIONS.md</code> Architectural choices and why you made them <code>LEARNINGS.md</code> Gotchas, bugs, things that didn't work <code>CONVENTIONS.md</code> Naming patterns, code style, project rules <code>CONSTITUTION.md</code> Hard rules the AI must never violate <p>These files can version with your code in <code>git</code>: </p> <ul> <li>They load automatically at the session start    (via hooks in Claude Code, or manually with <code>ctx agent</code> for   other tools). </li> <li>The AI reads them, cites them, and builds on them, instead   of asking you to start over. <ul> <li>And when it acts, it can point to the exact file and line that      justifies the choice.</li> </ul> </li> </ul> <p>Every decision you record, every lesson you capture, makes the next session smarter.</p> <p><code>ctx</code> accumulates.</p> <p>Connect with <code>ctx</code></p> <ul> <li>Join the Community →: ask questions, share workflows, and help shape what comes next</li> <li>Read the Blog →: real-world patterns, ponderings, and lessons learned from building <code>ctx</code> using <code>ctx</code></li> </ul> <p>Ready to Get Started?</p> <ul> <li>Getting Started → — full installation and setup</li> <li>Your First Session → — step-by-step walkthrough from <code>ctx init</code> to verified recall</li> </ul>","path":["Home","About"],"tags":[]},{"location":"home/common-workflows/","level":1,"title":"Common Workflows","text":"<p>The commands below cover what you'll use most often: </p> <ul> <li>recording context, </li> <li>checking health, </li> <li>browsing history, </li> <li>and running loops.</li> </ul> <p>Each section is a self-contained snippet you can copy into your terminal.</p> <p>For deeper, step-by-step guides, see Recipes.</p>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#track-context","level":2,"title":"Track Context","text":"<pre><code># Add a task\nctx add task \"Implement user authentication\"\n\n# Record a decision (full ADR fields required)\nctx add decision \"Use PostgreSQL for primary database\" \\\n  --context \"Need a reliable database for production\" \\\n  --rationale \"PostgreSQL offers ACID compliance and JSON support\" \\\n  --consequences \"Team needs PostgreSQL training\"\n\n# Note a learning\nctx add learning \"Mock functions must be hoisted in Jest\" \\\n  --context \"Tests failed with undefined mock errors\" \\\n  --lesson \"Jest hoists mock calls to top of file\" \\\n  --application \"Place jest.mock() before imports\"\n\n# Mark task complete\nctx complete \"user auth\"\n</code></pre>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#leave-a-reminder-for-next-session","level":2,"title":"Leave a Reminder for Next Session","text":"<p>Drop a note that surfaces automatically at the start of your next session:</p> <pre><code># Leave a reminder\nctx remind \"refactor the swagger definitions\"\n\n# Date-gated: don't surface until a specific date\nctx remind \"check CI after the deploy\" --after 2026-02-25\n\n# List pending reminders\nctx remind list\n\n# Dismiss a reminder by ID\nctx remind dismiss 1\n</code></pre> <p>Reminders are relayed verbatim at session start by the <code>check-reminders</code> hook and repeat every session until you dismiss them.</p> <p>See Session Reminders for the full recipe.</p>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#check-context-health","level":2,"title":"Check Context Health","text":"<pre><code># Detect stale paths, missing files, potential secrets\nctx drift\n\n# See full context summary\nctx status\n</code></pre>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#browse-session-history","level":2,"title":"Browse Session History","text":"<p>List and search past AI sessions from the terminal:</p> <pre><code>ctx recall list --limit 5\n</code></pre>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#journal-site","level":3,"title":"Journal Site","text":"<p>Export session transcripts to a browsable static site with search, navigation, and topic indices.</p> <p>The <code>ctx journal</code> command requires zensical (Python &gt;= 3.10).</p> <p><code>zensical</code> is a Python-based static site generator from the Material for MkDocs team.</p> <p>(why zensical?).</p> <p>If you don't have it on your system, install <code>zensical</code> once with pipx:</p> <pre><code># One-time setup\npipx install zensical\n</code></pre> <p>Avoid <code>pip install zensical</code></p> <p><code>pip install</code> often fails: For example, on macOS, system Python installs a non-functional stub (<code>zensical</code> requires <code>Python &gt;= 3.10</code>), and Homebrew Python blocks system-wide installs (<code>PEP 668</code>).</p> <p><code>pipx</code> creates an isolated environment with the correct Python version automatically.</p>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#export-and-serve","level":3,"title":"Export and Serve","text":"<p>Then, export and serve:</p> <pre><code># Export all sessions to .context/journal/ (only new files)\nctx recall export --all\n\n# Generate and serve the journal site\nctx journal site --serve\n</code></pre> <p>Open http://localhost:8000 to browse.</p> <p>To update after new sessions, run the same two commands again.</p>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#safe-by-default","level":3,"title":"Safe By Default","text":"<p><code>ctx recall export --all</code> is safe by default: </p> <ul> <li>It only exports new sessions and skips existing files. </li> <li>Locked entries (via <code>ctx recall lock</code>) are always skipped    regardless of flags.</li> </ul>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#re-exporting-existing-files","level":3,"title":"Re-Exporting Existing Files","text":"<p>Here is how you regenerate existing files. </p> <p>Backup your <code>.context</code> folder before regeneration, as this is a  potentially destructive action.</p> <p>To re-export journal files, you need to explicitly opt-in using the  <code>--regenerate</code> flag:</p> Flag combination Frontmatter Body <code>--regenerate</code> Preserved Overwritten from source <code>--regenerate --keep-frontmatter=false</code> Overwritten Overwritten <p>Regeneration Overwrites Body Edits</p> <p><code>--regenerate</code> preserves your YAML frontmatter (tags, summary, enrichment metadata) but it replaces the Markdown body with a fresh export. </p> <p>Any manual edits you made to the transcript will be lost.</p> <p>Lock entries you want to protect first: <code>ctx recall lock &lt;session-id&gt;</code>.</p> <p>See Session Journal for the full pipeline including normalization and enrichment.</p>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#scratchpad","level":2,"title":"Scratchpad","text":"<p>Store short, sensitive one-liners in an encrypted scratchpad that travels with the project:</p> <pre><code># Write a note\nctx pad set db-password \"postgres://user:pass@localhost/mydb\"\n\n# Read it back\nctx pad get db-password\n\n# List all keys\nctx pad list\n</code></pre> <p>The scratchpad is encrypted with a key stored in <code>.context/.context.key</code> (<code>.gitignore</code>d by default). </p> <p>See Scratchpad for details.</p>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#run-an-autonomous-loop","level":2,"title":"Run an Autonomous Loop","text":"<p>Generate a script that iterates an AI agent until a completion signal is detected:</p> <pre><code>ctx loop\nchmod +x loop.sh\n./loop.sh\n</code></pre> <p>See Autonomous Loops for configuration and advanced usage.</p>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#agent-session-start","level":2,"title":"Agent Session Start","text":"<p>The first thing an AI agent should do at session start is discover where context lives:</p> <pre><code>ctx system bootstrap\n</code></pre> <p>This prints the resolved context directory, the files in it, and the operating rules. The <code>CLAUDE.md</code> template instructs the agent to run this automatically. See CLI Reference: bootstrap.</p>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#the-two-skills-you-should-always-use","level":2,"title":"The Two Skills You Should Always Use","text":"<p>Using <code>/ctx-remember</code> at session start and <code>/ctx-wrap-up</code> at session end are the highest-value skills in the entire catalog:</p> <pre><code># session begins:\n/ctx-remember\n... do work ...\n# before closing the session:\n/ctx-wrap-up\n</code></pre> <p>Let's provide some context, because this is important:</p> <p>Although the agent will eventually discover your context through <code>CLAUDE.md → AGENT_PLAYBOOK.md</code>, <code>/ctx-remember</code> hydrates the full context up front (tasks, decisions, recent sessions) so the agent starts informed rather than piecing things together over several turns.</p> <p><code>/ctx-wrap-up</code> is the other half: A structured review that captures learnings, decisions, and tasks before you close the window.</p> <p>Hooks like <code>check-persistence</code> remind you (the user) mid-session that context hasn't been saved in a while, but they don't trigger persistence automatically: You still have to act. Also, a <code>CTRL+C</code> can end things at any moment with no reliable \"before session end\" event. </p> <p>In short, <code>/ctx-wrap-up</code> is the deliberate checkpoint that makes  sure nothing slips through. And <code>/ctx-remember</code> it its mirror skill to be used at session start.</p> <p>See Session Ceremonies for the full workflow.</p>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#cli-commands-vs-ai-skills","level":2,"title":"CLI Commands vs. AI Skills","text":"<p>Most <code>ctx</code> operations come in two flavors: a CLI command you run in your terminal and an AI skill (slash command) you invoke inside your coding assistant.</p> <p>Commands and skills are not interchangeable: Each has a distinct role.</p> ctx CLI command ctx AI skill Runs where Your terminal Inside the AI assistant Speed Fast (milliseconds) Slower (LLM round-trip) Cost Free Consumes tokens and context Analysis Deterministic heuristics Semantic / judgment-based Best for Quick checks, scripting, CI Deep analysis, generation, workflow orchestration","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#paired-commands","level":3,"title":"Paired Commands","text":"<p>These have both a CLI and a skill counterpart. Use the CLI for quick, deterministic checks; use the skill when you need the agent's judgment.</p> CLI Skill When to prefer the skill <code>ctx drift</code> <code>/ctx-drift</code> Semantic analysis: catches meaning drift the CLI misses <code>ctx status</code> <code>/ctx-status</code> Interpreted summary with recommendations <code>ctx add task</code> <code>/ctx-add-task</code> Agent decomposes vague goals into concrete tasks <code>ctx add decision</code> <code>/ctx-add-decision</code> Agent drafts rationale and consequences from discussion <code>ctx add learning</code> <code>/ctx-add-learning</code> Agent extracts the lesson from a debugging session <code>ctx add convention</code> <code>/ctx-add-convention</code> Agent observes a repeated pattern and codifies it <code>ctx tasks archive</code> <code>/ctx-archive</code> Agent reviews which tasks are truly done <code>ctx pad</code> <code>/ctx-pad</code> Agent reads/writes scratchpad entries in conversation flow <code>ctx recall</code> <code>/ctx-recall</code> Agent searches session history with semantic understanding <code>ctx agent</code> <code>/ctx-agent</code> Agent loads and acts on the context packet <code>ctx loop</code> <code>/ctx-loop</code> Agent tailors the loop script to your project","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#ai-only-skills","level":3,"title":"AI-Only Skills","text":"<p>These have no CLI equivalent. They require the agent's reasoning.</p> Skill Purpose <code>/ctx-remember</code> Load context and present structured readback at session start <code>/ctx-wrap-up</code> End-of-session ceremony: persist learnings, decisions, tasks <code>/ctx-next</code> Suggest 1–3 concrete next actions from context <code>/ctx-commit</code> Commit with integrated context capture <code>/ctx-reflect</code> Pause and assess session progress <code>/ctx-consolidate</code> Merge overlapping learnings or decisions <code>/ctx-alignment-audit</code> Verify docs claims match agent instructions <code>/ctx-prompt-audit</code> Analyze prompting patterns for improvement <code>/ctx-implement</code> Execute a plan step-by-step with verification <code>/ctx-worktree</code> Manage parallel agent worktrees <code>/ctx-journal-normalize</code> Fix markdown rendering issues in journal entries <code>/ctx-journal-enrich</code> Add metadata, tags, and summaries to journal entries <code>/ctx-blog</code> Generate a blog post (zensical-flavored Markdown)","path":["Home","Common Workflows"],"tags":[]},{"location":"home/common-workflows/#cli-only-commands","level":3,"title":"CLI-Only Commands","text":"<p>These are infrastructure: used in scripts, CI, or one-time setup.</p> Command Purpose <code>ctx init</code> Initialize <code>.context/</code> directory <code>ctx load</code> Output assembled context for piping <code>ctx complete</code> Mark a task done by substring match <code>ctx sync</code> Reconcile context with codebase state <code>ctx compact</code> Consolidate and clean up context files <code>ctx hook</code> Generate AI tool integration config <code>ctx watch</code> Watch AI output and auto-apply context updates <code>ctx serve</code> Serve any zensical directory (default: journal) <code>ctx permissions snapshot</code> Save settings as a golden image <code>ctx permissions restore</code> Restore settings from golden image <code>ctx journal site</code> Generate browsable journal from exports <code>ctx notify setup</code> Configure webhook notifications <code>ctx remind</code> Session-scoped reminders (surface at start) <code>ctx completion</code> Generate shell autocompletion scripts <p>Rule of Thumb</p> <p>Quick check? Use the CLI. </p> <p>Need judgment? Use the skill.</p> <p>When in doubt, start with the CLI: It's free and instant.</p> <p>Escalate to the skill when heuristics aren't enough.</p> <p>Next Up: Context Files →: what each <code>.context/</code> file does and how to use it</p> <p>See Also:</p> <ul> <li>Recipes: targeted how-to guides for specific tasks</li> <li>Knowledge Capture: patterns for recording decisions, learnings, and conventions</li> <li>Context Health: keeping your <code>.context/</code> accurate and drift-free</li> <li>Session Archaeology: digging into past sessions</li> <li>Task Management: tracking and completing work items</li> </ul>","path":["Home","Common Workflows"],"tags":[]},{"location":"home/community/","level":1,"title":"#ctx","text":"<p>Open source is better together.</p> <p>We are the builders who care about durable context, verifiable decisions,  and human–AI workflows that compound over time.</p> <p>Help <code>ctx</code> Change How AI Remembers</p> <p>If the idea behind <code>ctx</code> resonates, a star helps it reach engineers who run into context drift every day.</p> <p> Star <code>ctx</code> on GitHub ⭐</p> <p><code>ctx</code> is free and open source software, and contributions are always welcome and appreciated.</p> <p>Join the community to ask questions, share feedback, and connect with other users:</p> <ul> <li> IRC join <code>#ctx</code> on  irc.libera.chat:   Real-time discussion, field notes, and early ideas.</li> <li> Read the <code>ctx</code> Source on GitHub:   Issues, discussions, and contributions.</li> </ul> <p>Early adopters shape the conventions.</p> <p>Want to contribute? See the contributioun guide →</p> <p>Code of Conduct </p> <p>Clear context requires respectful collaboration.  </p> <p><code>ctx</code> follows the Contributor Covenant.</p>","path":["Home","#ctx"],"tags":[]},{"location":"home/configuration/","level":1,"title":"Configuration","text":"","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#configuration","level":2,"title":"Configuration","text":"<p>ctx uses three layers of configuration. Each layer overrides the one below it:</p> <ol> <li>CLI flags: Per-invocation overrides (highest priority)</li> <li>Environment variables: Shell or CI/CD overrides</li> <li>The <code>.ctxrc</code> file: Project-level defaults (YAML)</li> <li>Built-in defaults: Hardcoded fallbacks (lowest priority)</li> </ol> <p>All settings are optional: If nothing is configured, <code>ctx</code> works out of the box with sensible defaults.</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#the-ctxrc-file","level":2,"title":"The <code>.ctxrc</code> File","text":"<p>The <code>.ctxrc</code> file is an optional YAML file placed in the project root (next to your <code>.context/</code> directory). It lets you set project-level defaults that apply to every <code>ctx</code> command.</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#location","level":3,"title":"Location","text":"<pre><code>my-project/\n├── .ctxrc              ← configuration file\n├── .context/\n│   ├── TASKS.md\n│   ├── DECISIONS.md\n│   └── ...\n└── src/\n</code></pre> <p><code>ctx</code> looks for <code>.ctxrc</code> in the current working directory when any command runs. There is no global or user-level config file — configuration is always per-project.</p> <p>Using a Different .context Directory</p> <p>The default <code>.context/</code> directory can be changed per-project via the <code>context_dir</code> key in <code>.ctxrc</code>, the <code>CTX_DIR</code> environment variable, or the <code>--context-dir</code> CLI flag.</p> <p>See Environment Variables and CLI Global Flags below for details.</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#full-reference","level":3,"title":"Full Reference","text":"<p>A commented <code>.ctxrc</code> showing all options and their defaults:</p> <pre><code># .ctxrc: ctx runtime configuration\n# https://ctx.ist/configuration/\n#\n# All settings are optional. Missing values use defaults.\n# Priority: CLI flags &gt; environment variables &gt; .ctxrc &gt; defaults\n#\n# context_dir: .context\n# token_budget: 8000\n# auto_archive: true\n# archive_after_days: 7\n# scratchpad_encrypt: true\n# allow_outside_cwd: false\n# entry_count_learnings: 30\n# entry_count_decisions: 20\n# convention_line_count: 200\n#\n# notify:               # requires: ctx notify setup\n#   events:             # required: no events sent unless listed\n#     - loop\n#     - nudge\n#     - relay\n#   key_rotation_days: 90\n#\n# priority_order:\n#   - CONSTITUTION.md\n#   - TASKS.md\n#   - CONVENTIONS.md\n#   - ARCHITECTURE.md\n#   - DECISIONS.md\n#   - LEARNINGS.md\n#   - GLOSSARY.md\n#   - AGENT_PLAYBOOK.md\n</code></pre>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#option-reference","level":3,"title":"Option Reference","text":"Option Type Default Description <code>context_dir</code> <code>string</code> <code>.context</code> Context directory name (relative to project root) <code>token_budget</code> <code>int</code> <code>8000</code> Default token budget for <code>ctx agent</code> and <code>ctx load</code> <code>auto_archive</code> <code>bool</code> <code>true</code> Auto-archive completed tasks during <code>ctx compact</code> <code>archive_after_days</code> <code>int</code> <code>7</code> Days before completed tasks are archived <code>scratchpad_encrypt</code> <code>bool</code> <code>true</code> Encrypt scratchpad with AES-256-GCM <code>allow_outside_cwd</code> <code>bool</code> <code>false</code> Allow context directory outside the current working directory <code>entry_count_learnings</code> <code>int</code> <code>30</code> Drift warning when <code>LEARNINGS.md</code> exceeds this entry count (0 = disable) <code>entry_count_decisions</code> <code>int</code> <code>20</code> Drift warning when <code>DECISIONS.md</code> exceeds this entry count (0 = disable) <code>convention_line_count</code> <code>int</code> <code>200</code> Drift warning when <code>CONVENTIONS.md</code> exceeds this line count (0 = disable) <code>notify.events</code> <code>[]string</code> (all) Event filter for webhook notifications (empty = all) <code>notify.key_rotation_days</code> <code>int</code> <code>90</code> Days before encryption key rotation nudge <code>priority_order</code> <code>[]string</code> (see below) Custom file loading priority for context assembly <p>Default priority order (used when <code>priority_order</code> is not set):</p> <ol> <li><code>CONSTITUTION.md</code></li> <li><code>TASKS.md</code></li> <li><code>CONVENTIONS.md</code></li> <li><code>ARCHITECTURE.md</code></li> <li><code>DECISIONS.md</code></li> <li><code>LEARNINGS.md</code></li> <li><code>GLOSSARY.md</code></li> <li><code>AGENT_PLAYBOOK.md</code></li> </ol> <p>See Context Files for the rationale behind this ordering.</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#environment-variables","level":2,"title":"Environment Variables","text":"<p>Environment variables override <code>.ctxrc</code> values but are overridden by CLI flags.</p> Variable Description Equivalent <code>.ctxrc</code> key <code>CTX_DIR</code> Override the context directory path <code>context_dir</code> <code>CTX_TOKEN_BUDGET</code> Override the default token budget <code>token_budget</code> <code>NO_COLOR</code> Disable colored output when set (any value) (CLI flag only)","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#examples","level":3,"title":"Examples","text":"<pre><code># Use a shared context directory\nCTX_DIR=/shared/team-context ctx status\n\n# Increase token budget for a single run\nCTX_TOKEN_BUDGET=16000 ctx agent\n\n# Disable color in CI pipelines\nNO_COLOR=1 ctx drift --json\n</code></pre> <p><code>NO_COLOR</code> Follows the no-color.org Convention</p> <p>Setting <code>NO_COLOR</code> to any non-empty value disables colored terminal output.</p> <p>This is equivalent to the <code>--no-color</code> CLI flag.</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#cli-global-flags","level":2,"title":"CLI Global Flags","text":"<p>CLI flags have the highest priority and override both environment variables and <code>.ctxrc</code> settings. These flags are available on every <code>ctx</code> command.</p> Flag Description <code>--context-dir &lt;path&gt;</code> Override context directory (default: <code>.context/</code>) <code>--allow-outside-cwd</code> Allow context directory outside current working directory <code>--no-color</code> Disable colored output <code>--version</code> Show version and exit <code>--help</code> Show command help and exit","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#examples_1","level":3,"title":"Examples","text":"<pre><code># Point to a different context directory:\nctx status --context-dir /path/to/shared/.context\n\n# Allow external context directory (skips boundary check):\nctx status --context-dir /mnt/nas/project-context --allow-outside-cwd\n</code></pre>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#priority-order","level":2,"title":"Priority Order","text":"<p>When the same setting is configured in multiple layers, the highest-priority layer wins:</p> <pre><code>CLI flags  &gt;  Environment variables  &gt;  .ctxrc  &gt;  Built-in defaults\n(highest)                                          (lowest)\n</code></pre> <p>Example resolution for <code>context_dir</code>:</p> Layer Value Wins? <code>--context-dir</code> <code>/tmp/ctx</code> Yes <code>CTX_DIR</code> <code>/shared/context</code> No <code>.ctxrc</code> <code>.my-context</code> No Default <code>.context</code> No <p>The CLI flag <code>/tmp/ctx</code> is used because it has the highest priority.</p> <p>If the CLI flag were absent, <code>CTX_DIR=/shared/context</code> would win. If neither the flag nor the env var were set, the <code>.ctxrc</code> value <code>.my-context</code> would be used. With nothing configured, the default <code>.context</code> applies.</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#examples_2","level":2,"title":"Examples","text":"","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#external-context-directory","level":3,"title":"External <code>.context</code> Directory","text":"<p>Store context outside the project tree (useful for monorepos or shared context):</p> <pre><code># .ctxrc\ncontext_dir: /home/team/shared-context\nallow_outside_cwd: true\n</code></pre>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#custom-token-budget","level":3,"title":"Custom Token Budget","text":"<p>Increase the token budget for projects with large context:</p> <pre><code># .ctxrc\ntoken_budget: 16000\n</code></pre> <p>This affects the default budget for <code>ctx agent</code> and <code>ctx load</code>. You can still override per-invocation with <code>ctx agent --budget 4000</code>.</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#disabled-scratchpad-encryption","level":3,"title":"Disabled Scratchpad Encryption","text":"<p>Turn off encryption for the scratchpad (useful in ephemeral environments where key management is unnecessary):</p> <pre><code># .ctxrc\nscratchpad_encrypt: false\n</code></pre> <p>Unencrypted Scratchpads Store Secrets in Plaintext</p> <p>Only disable encryption if you understand the security implications.</p> <p>The scratchpad may contain sensitive data such as API keys, database URLs, or deployment credentials.</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#custom-priority-order","level":3,"title":"Custom Priority Order","text":"<p>Reorder context files to prioritize architecture over conventions:</p> <pre><code># .ctxrc\npriority_order:\n  - CONSTITUTION.md\n  - TASKS.md\n  - ARCHITECTURE.md\n  - DECISIONS.md\n  - CONVENTIONS.md\n  - LEARNINGS.md\n  - GLOSSARY.md\n  - AGENT_PLAYBOOK.md\n</code></pre> <p>Files not listed in <code>priority_order</code> receive the lowest priority (100). The order affects <code>ctx agent</code>, <code>ctx load</code>, and drift's file-priority calculations.</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#adjusted-drift-thresholds","level":3,"title":"Adjusted Drift Thresholds","text":"<p>Raise or lower the entry-count thresholds that trigger drift warnings:</p> <pre><code># .ctxrc\nentry_count_learnings: 50   # warn above 50 learnings (default: 30)\nentry_count_decisions: 10   # warn above 10 decisions (default: 20)\nconvention_line_count: 300  # warn above 300 lines (default: 200)\n</code></pre> <p>Set any threshold to <code>0</code> to disable that specific check.</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#webhook-notifications","level":3,"title":"Webhook Notifications","text":"<p>Get notified when loops complete, hooks fire, or agents reach milestones:</p> <pre><code># Configure the webhook URL (encrypted, safe to commit)\nctx notify setup\n\n# Test delivery\nctx notify test\n</code></pre> <p>Filter which events reach your webhook:</p> <pre><code># .ctxrc\nnotify:\n  events:\n    - loop      # loop completion/max-iteration\n    - nudge     # VERBATIM relay hooks fired\n    # - relay   # all hook output (verbose, for debugging)\n</code></pre> <p>Notifications are opt-in: No events are sent unless explicitly listed.</p> <p>See Webhook Notifications for a step-by-step recipe.</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/configuration/#agent-bootstrapping","level":2,"title":"Agent Bootstrapping","text":"<p>AI agents need to know the resolved context directory at session start. The <code>ctx system bootstrap</code> command prints the context path, file list, and operating rules in both text and JSON formats:</p> <pre><code>ctx system bootstrap          # text output for agents\nctx system bootstrap --json   # structured output for automation\n</code></pre> <p>The <code>CLAUDE.md</code> template instructs the agent to run this as its first action. Every nudge (context checkpoint, persistence reminder, etc.) also includes a <code>Context: &lt;dir&gt;</code> footer that re-anchors the agent to the correct directory throughout the session.</p> <p>This replaces the previous approach of hardcoding <code>.context/</code> paths in agent instructions. </p> <p>See CLI Reference: bootstrap for full details.</p> <p>See also: CLI Reference | Context Files | Scratchpad</p>","path":["Home","Configuration"],"tags":[]},{"location":"home/context-files/","level":1,"title":"Context Files","text":"","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#context","level":2,"title":"<code>.context/</code>","text":"<p>Each context file in <code>.context/</code> serves a specific purpose. </p> <p>Files are designed to be human-readable, AI-parseable, and token-efficient.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#file-overview","level":2,"title":"File Overview","text":"File Purpose Priority <code>CONSTITUTION.md</code> Hard rules that must NEVER be violated 1 (highest) <code>TASKS.md</code> Current and planned work 2 <code>CONVENTIONS.md</code> Project patterns and standards 3 <code>ARCHITECTURE.md</code> System overview and components 4 <code>DECISIONS.md</code> Architectural decisions with rationale 5 <code>LEARNINGS.md</code> Lessons learned, gotchas, tips 6 <code>GLOSSARY.md</code> Domain terms and abbreviations 7 <code>AGENT_PLAYBOOK.md</code> Instructions for AI tools 8 (lowest)","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#read-order-rationale","level":2,"title":"Read Order Rationale","text":"<p>The priority order follows a logical progression for AI tools:</p> <ol> <li><code>CONSTITUTION.md</code>: Inviolable rules first. The AI tool must know what it    cannot do before attempting anything.</li> <li><code>TASKS.md</code>: Current work items. What the AI tool should focus on.</li> <li><code>CONVENTIONS.md</code>: How to write code. Patterns and standards to follow    when implementing tasks.</li> <li><code>ARCHITECTURE.md</code>: System structure. Understanding of components and    boundaries before making changes.</li> <li><code>DECISIONS.md</code>: Historical context. Why things are the way they are,    to avoid re-debating settled decisions.</li> <li><code>LEARNINGS.md</code>: Gotchas and tips. Lessons from past work that inform    the current implementation.</li> <li><code>GLOSSARY.md</code>: Reference material. Domain terms and abbreviations for    lookup as needed.</li> <li><code>AGENT_PLAYBOOK.md</code>: Meta instructions last. How to use this context    system itself. Loaded last because the agent should understand the    content (rules, tasks, patterns) before the operating manual.</li> </ol>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#constitutionmd","level":2,"title":"<code>CONSTITUTION.md</code>","text":"<p>Purpose: Define hard invariants—rules that must NEVER be violated,  regardless of the task.</p> <p>AI tools read this first and should refuse tasks that violate these rules.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#structure","level":3,"title":"Structure","text":"<pre><code># Constitution\n\nThese rules are INVIOLABLE. If a task requires violating these, the task \nis wrong.\n\n## Security Invariants\n\n- [ ] Never commit secrets, tokens, API keys, or credentials\n- [ ] Never store customer/user data in context files\n- [ ] Never disable security linters without documented exception\n\n## Quality Invariants\n\n- [ ] All code must pass tests before commit\n- [ ] No `any` types in TypeScript without documented reason\n- [ ] No TODO comments in main branch (*move to `TASKS.md`*)\n\n## Process Invariants\n\n- [ ] All architectural changes require a decision record\n- [ ] Breaking changes require version bump\n- [ ] Generated files are never committed\n</code></pre>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#guidelines","level":3,"title":"Guidelines","text":"<ul> <li>Keep rules minimal and absolute</li> <li>Each rule should be enforceable (can verify compliance)</li> <li>Use checkbox format for clarity</li> <li>Never compromise on these rules</li> </ul>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#tasksmd","level":2,"title":"<code>TASKS.md</code>","text":"<p>Purpose: Track current work, planned work, and blockers.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#structure_1","level":3,"title":"Structure","text":"<p>Tasks are organized by Phase: logical groupings that preserve order and enable replay. </p> <p>Tasks stay in their Phase permanently; status is tracked via checkboxes and  inline tags.</p> <pre><code># Tasks\n\n## Phase 1: Initial Setup\n\n- [x] Set up project structure\n- [x] Configure linting and formatting\n- [ ] Add CI/CD pipeline `#in-progress`\n\n## Phase 2: Core Features\n\n- [ ] Implement user authentication `#priority:high`\n- [ ] Add API rate limiting `#priority:medium`\n  - Blocked by: Need to finalize auth first\n\n## Backlog\n\n- [ ] Performance optimization `#priority:low`\n- [ ] Add metrics dashboard `#priority:deferred`\n</code></pre> <p>Key principles:</p> <ul> <li>Tasks never move between sections — mark as <code>[x]</code> or <code>[-]</code> in place</li> <li>Use <code>#in-progress</code> inline tag to indicate current work</li> <li>Phase headers provide structure and replay order</li> <li>Backlog section for unscheduled work</li> </ul>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#tags","level":3,"title":"Tags","text":"<p>Use inline backtick-wrapped tags for metadata:</p> Tag Values Purpose <code>#priority</code> <code>high</code>, <code>medium</code>, <code>low</code> Task urgency <code>#area</code> <code>core</code>, <code>cli</code>, <code>docs</code>, <code>tests</code> Codebase area <code>#estimate</code> <code>1h</code>, <code>4h</code>, <code>1d</code> Time estimate (optional) <code>#in-progress</code> (none) Currently being worked on <p>Lifecycle tags (for session correlation):</p> Tag Format When to add <code>#added</code> <code>YYYY-MM-DD-HHMMSS</code> Auto-added by <code>ctx add task</code> <code>#started</code> <code>YYYY-MM-DD-HHMMSS</code> When beginning work on the task <code>#done</code> <code>YYYY-MM-DD-HHMMSS</code> When marking the task <code>[x]</code> <p>These timestamps help correlate tasks with session files and track which session started vs completed work.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#status-markers","level":3,"title":"Status Markers","text":"Marker Meaning <code>[ ]</code> Pending <code>[x]</code> Completed <code>[-]</code> Skipped (include reason)","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#guidelines_1","level":3,"title":"Guidelines","text":"<ul> <li>Never delete tasks; mark as <code>[x]</code> completed or <code>[-]</code> skipped</li> <li>Never move tasks between sections; use inline tags for status</li> <li>Use <code>ctx tasks archive</code> periodically to move completed tasks to archive</li> <li>Mark current work with <code>#in-progress</code> inline tag</li> </ul>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#decisionsmd","level":2,"title":"<code>DECISIONS.md</code>","text":"<p>Purpose: Record architectural decisions with rationale so they don't get re-debated.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#structure_2","level":3,"title":"Structure","text":"<pre><code># Decisions\n\n## [YYYY-MM-DD] Decision Title\n\n**Status**: Accepted | Superseded | Deprecated\n\n**Context**: What situation prompted this decision?\n\n**Decision**: What was decided?\n\n**Rationale**: Why was this the right choice?\n\n**Consequences**: What are the implications?\n\n**Alternatives Considered**:\n- Alternative A: Why rejected\n- Alternative B: Why rejected\n</code></pre>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#example","level":3,"title":"Example","text":"<pre><code>## [2025-01-15] Use TypeScript Strict Mode\n\n**Status**: Accepted\n\n**Context**: Starting a new project, need to choose the type-checking level.\n\n**Decision**: Enable TypeScript strict mode with all strict flags.\n\n**Rationale**: Catches more bugs at compile time. Team has experience\nwith strict mode. Upfront cost pays off in reduced runtime errors.\n\n**Consequences**: More verbose type annotations required. Some\nthird-party libraries need type assertions.\n\n**Alternatives Considered**:\n- Basic TypeScript: Rejected because it misses null checks\n- JavaScript with JSDoc: Rejected because tooling support is weaker\n</code></pre>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#status-values","level":3,"title":"Status Values","text":"Status Meaning Accepted Current, active decision Superseded Replaced by newer decision (link to it) Deprecated No longer relevant","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#learningsmd","level":2,"title":"<code>LEARNINGS.md</code>","text":"<p>Purpose: Capture lessons learned, gotchas, and tips that shouldn't be forgotten.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#structure_3","level":3,"title":"Structure","text":"<pre><code># Learnings\n\n## Category Name\n\n### Learning Title\n\n**Discovered**: YYYY-MM-DD\n\n**Context**: When/how was this learned?\n\n**Lesson**: What's the takeaway?\n\n**Application**: How should this inform future work?\n</code></pre>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#example_1","level":3,"title":"Example","text":"<pre><code>## Testing\n\n### Vitest Mocks Must Be Hoisted\n\n**Discovered**: 2025-01-15\n\n**Context**: Tests were failing intermittently when mocking fs module.\n\n**Lesson**: Vitest requires `vi.mock()` calls to be hoisted to the\ntop of the file. Dynamic mocks need `vi.doMock()` instead.\n\n**Application**: Always use `vi.mock()` at file top. Use `vi.doMock()`\nonly when mock needs runtime values.\n</code></pre>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#categories","level":3,"title":"Categories","text":"<p>Organize learnings by topic:</p> <ul> <li>Testing</li> <li>Build &amp; Deploy</li> <li>Performance</li> <li>Security</li> <li>Third-Party Libraries</li> <li>Git and Workflow</li> </ul>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#conventionsmd","level":2,"title":"<code>CONVENTIONS.md</code>","text":"<p>Purpose: Document project patterns, naming conventions, and standards.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#structure_4","level":3,"title":"Structure","text":"<pre><code># Conventions\n\n## Naming\n\n* **Files**: kebab-case for all source files\n* **Components**: PascalCase for React components\n* **Functions**: camelCase, verb-first (getUser, parseConfig)\n* **Constants**: SCREAMING_SNAKE_CASE\n\n## Patterns\n\n### Pattern Name\n\n**When to use**: Situation description\n\n**Implementation**:\n// in triple backticks\n// Example code\n\n**Why**: Rationale for this pattern\n</code></pre>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#guidelines_2","level":3,"title":"Guidelines","text":"<ul> <li>Include concrete examples</li> <li>Explain the \"why\" not just the \"what\"</li> <li>Keep patterns minimal—only document what's non-obvious</li> </ul>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#architecturemd","level":2,"title":"<code>ARCHITECTURE.md</code>","text":"<p>Purpose: Provide system overview and component relationships.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#structure_5","level":3,"title":"Structure","text":"<pre><code># Architecture\n\n## Overview\n\nBrief description of what the system does and how it's organized.\n\n## Components\n\n### Component Name\n\n**Responsibility**: What this component does\n\n**Dependencies**: What it depends on\n\n**Dependents**: What depends on it\n\n**Key Files**:\n- path/to/file.ts — Description\n\n## Data Flow\n\nDescription or diagram of how data moves through the system.\n\n## Boundaries\n\nWhat's in scope vs out of scope for this codebase.\n</code></pre>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#guidelines_3","level":3,"title":"Guidelines","text":"<ul> <li>Keep diagrams simple (Mermaid works well)</li> <li>Focus on boundaries and interfaces</li> <li>Update when major structural changes occur</li> </ul>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#glossarymd","level":2,"title":"<code>GLOSSARY.md</code>","text":"<p>Purpose: Define domain terms, abbreviations, and project vocabulary.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#structure_6","level":3,"title":"Structure","text":"<pre><code># Glossary\n\n## Domain Terms\n\n### Term Name\n\n**Definition**: What it means in this project's context\n\n**Not to be confused with**: Similar terms that mean different things\n\n**Example**: How it's used\n\n## Abbreviations\n\n| Abbrev | Expansion                     | Context                |\n|--------|-------------------------------|------------------------|\n| ADR    | Architectural Decision Record | Decision documentation |\n| SUT    | System Under Test             | Testing                |\n</code></pre>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#guidelines_4","level":3,"title":"Guidelines","text":"<ul> <li>Define project-specific meanings</li> <li>Clarify potentially ambiguous terms</li> <li>Include abbreviations used in code or docs</li> </ul>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#agent_playbookmd","level":2,"title":"<code>AGENT_PLAYBOOK.md</code>","text":"<p>Purpose: Explicit instructions for how AI tools should read, apply,  and update context.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#key-sections","level":3,"title":"Key Sections","text":"<p>Read Order: Priority order for loading context files</p> <p>When to Update: Events that trigger context updates</p> <p>How to Avoid Hallucinating Memory: Critical rules:</p> <ol> <li>Never assume—if not in files, you don't know it</li> <li>Never invent history—don't claim \"we discussed\" without evidence</li> <li>Verify before referencing—search files before citing</li> <li>When uncertain, say so</li> <li>Trust files over intuition</li> </ol> <p>Context Update Commands: Format for automated updates via <code>ctx watch</code>:</p> <pre><code>&lt;context-update type=\"task\"&gt;Implement rate limiting&lt;/context-update&gt;\n&lt;context-update type=\"complete\"&gt;user auth&lt;/context-update&gt;\n&lt;context-update type=\"learning\"\n  context=\"Debugging hooks\"\n  lesson=\"Hooks receive JSON via stdin\"\n  application=\"Parse JSON stdin with the host language\"\n&gt;Hook Input Format&lt;/context-update&gt;\n&lt;context-update type=\"decision\"\n  context=\"Need a caching layer\"\n  rationale=\"Redis is fast and team has experience\"\n  consequences=\"Must provision Redis infrastructure\"\n&gt;Use Redis for caching&lt;/context-update&gt;\n</code></pre> <p>See Integrations for full documentation.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#parsing-rules","level":2,"title":"Parsing Rules","text":"<p>All context files follow these conventions:</p> <ol> <li>Headers define structure: <code>#</code> for title, <code>##</code> for sections, <code>###</code> for     items</li> <li>Bold keys for fields: <code>**Key**:</code> followed by value</li> <li>Code blocks are literal: Never parse code block content as structure</li> <li>Lists are ordered: Items appear in priority/chronological order</li> <li>Tags are inline: Backtick-wrapped tags like <code>#priority:high</code></li> </ol>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#further-reading","level":2,"title":"Further Reading","text":"<ul> <li>Refactoring with Intent:   How persistent context prevents drift during refactoring sessions.</li> </ul>","path":["Home","Context Files"],"tags":[]},{"location":"home/context-files/#token-efficiency","level":2,"title":"Token Efficiency","text":"<p>Keep context files concise:</p> <ul> <li>Use abbreviations in tags, not prose;</li> <li>Omit obvious words (\"The,\" \"This\");</li> <li>Prefer bullet points over paragraphs;</li> <li>Keep examples minimal but illustrative;</li> <li>Archive old completed items periodically.</li> </ul> <p>Next Up: Prompting Guide → — effective prompts for AI sessions with ctx.</p>","path":["Home","Context Files"],"tags":[]},{"location":"home/contributing/","level":1,"title":"Contributing","text":"","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#development-setup","level":2,"title":"Development Setup","text":"","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#prerequisites","level":3,"title":"Prerequisites","text":"<ul> <li>Go (version defined in <code>go.mod</code>)</li> <li>Claude Code</li> <li>Git</li> <li>GNU Make</li> <li>Zensical</li> </ul>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#1-fork-or-clone-the-repository","level":3,"title":"1. Fork (or Clone) the Repository","text":"<pre><code># Fork on GitHub, then:\ngit clone https://github.com/&lt;you&gt;/ctx.git\ncd ctx\n\n# Or, if you have push access:\ngit clone https://github.com/ActiveMemory/ctx.git\ncd ctx\n</code></pre>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#2-build-and-install-the-binary","level":3,"title":"2. Build and Install the Binary","text":"<pre><code>make build\nsudo make install\n</code></pre> <p>This compiles the <code>ctx</code> binary and places it in <code>/usr/local/bin/</code>.</p>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#3-install-the-plugin-from-your-local-clone","level":3,"title":"3. Install the Plugin from Your Local Clone","text":"<p>The repository ships a Claude Code plugin under <code>internal/assets/claude/</code>. Point Claude Code at your local copy so that skills and hooks reflect your working tree — no reinstall needed after edits:</p> <ol> <li>Launch <code>claude</code>;</li> <li>Type <code>/plugin</code> and press Enter;</li> <li>Select Marketplaces → Add Marketplace</li> <li>Enter the absolute path to the root of your clone,    e.g. <code>~/WORKSPACE/ctx</code>    (this is where <code>.claude-plugin/marketplace.json</code> lives: it points    Claude Code to the actual plugin in <code>internal/assets/claude</code>);</li> <li>Back in <code>/plugin</code>, select Install and choose <code>ctx</code>.</li> </ol> <p>Claude Code Caches Plugin Files</p> <p>Even though the marketplace points at a directory on disk, Claude Code caches skills and hooks. After editing files under <code>internal/assets/claude/</code>, clear the cache and restart:</p> <pre><code>make plugin-reload   # then restart Claude Code\n</code></pre> <p>See Skill or Hook Changes for details.</p>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#4-verify","level":3,"title":"4. Verify","text":"<pre><code>ctx --version       # binary is in PATH\nclaude /plugin list # plugin is installed\n</code></pre> <p>You should see the <code>ctx</code> plugin listed, sourced from your local path.</p>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#project-layout","level":2,"title":"Project Layout","text":"<pre><code>ctx/\n├── cmd/ctx/            # CLI entry point\n├── internal/\n│   ├── assets/claude/  # ← Claude Code plugin (skills, hooks)\n│   ├── bootstrap/      # Project initialization templates\n│   ├── claude/         # Claude Code integration helpers\n│   ├── cli/            # Command implementations\n│   ├── config/         # Configuration loading\n│   ├── context/        # Core context logic\n│   ├── crypto/         # Scratchpad encryption\n│   ├── drift/          # Drift detection\n│   ├── index/          # Context file indexing\n│   ├── journal/        # Journal site generation\n│   ├── notify/         # Webhook notifications\n│   ├── rc/             # .ctxrc parsing\n│   ├── recall/         # Session history and parsers\n│   ├── sysinfo/        # System resource monitoring\n│   ├── task/           # Task management\n│   └── validation/     # Input validation\n├── .claude/\n│   └── skills/         # Dev-only skills (not distributed)\n├── assets/             # Static assets (banners, logos)\n├── docs/               # Documentation site source\n├── editors/            # Editor extensions (VS Code)\n├── examples/           # Example configurations\n├── hack/               # Build scripts and runbooks\n├── specs/              # Feature specifications\n└── .context/           # ctx's own context (dogfooding)\n</code></pre>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#skills-two-directories-one-rule","level":3,"title":"Skills: Two Directories, One Rule","text":"Directory What lives here Distributed to users? <p>| <code>internal/assets/claude/skills/</code> | The 29 <code>ctx-*</code> skills that ship with the plugin | Yes                   | | <code>.claude/skills/</code>                | Dev-only skills (release, QA, backup, etc.)     | No                    |</p> <p><code>internal/assets/claude/skills/</code> is the single source of truth for user-facing skills. If you are adding or modifying a <code>ctx-*</code> skill, edit it there.</p> <p><code>.claude/skills/</code> holds skills that only make sense inside this repository (release automation, QA checks, backup scripts). These are never distributed to users.</p>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#day-to-day-workflow","level":2,"title":"Day-to-Day Workflow","text":"","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#go-code-changes","level":3,"title":"Go Code Changes","text":"<p>After modifying Go source files, rebuild and reinstall:</p> <pre><code>make build &amp;&amp; sudo make install\n</code></pre> <p>The <code>ctx</code> binary is statically compiled. There is no hot reload. You must rebuild for Go changes to take effect.</p>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#skill-or-hook-changes","level":3,"title":"Skill or Hook Changes","text":"<p>Edit files under <code>internal/assets/claude/skills/</code> or <code>internal/assets/claude/hooks/</code>.</p> <p>Claude Code caches plugin files, so edits aren't picked up automatically. Clear the cache and restart:</p> <pre><code>make plugin-reload   # nukes ~/.claude/plugins/cache/activememory-ctx/\n# then restart Claude Code\n</code></pre> <p>The plugin will be re-installed from your local marketplace on startup. No version bump is needed during development.</p> <p>Version bumps are for releases, not iteration</p> <p>Only bump <code>VERSION</code>, <code>plugin.json</code>, and <code>marketplace.json</code> when cutting a release. During development, <code>make plugin-reload</code> is all you need.</p>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#running-tests","level":3,"title":"Running Tests","text":"<pre><code>make test   # fast: all tests\nmake audit  # full: fmt + vet + lint + drift + docs + test\nmake smoke  # build + run basic commands end-to-end\n</code></pre>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#running-the-docs-site-locally","level":3,"title":"Running the Docs Site Locally","text":"<pre><code>make site-setup  # one-time: install zensical via pipx\nmake site-serve  # serve at localhost\n</code></pre>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#submitting-changes","level":2,"title":"Submitting Changes","text":"","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#before-you-start","level":3,"title":"Before You Start","text":"<ol> <li>Check existing issues to avoid duplicating effort;</li> <li>For large changes, open an issue first to discuss the approach;</li> <li>Read the specs in <code>specs/</code> for design context.</li> </ol>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#pull-request-process","level":3,"title":"Pull Request Process","text":"<p>Respect the maintainers' time and energy: Keep your pull requests isolated and strive to minimze code changes.</p> <p>If you Pull Request solves more than one distinct issues, it's better to create separate pull requests instead of sending them in one large bundle.</p> <ol> <li>Create a feature branch: <code>git checkout -b feature/my-feature</code>;</li> <li>Make your changes;</li> <li>Run <code>make audit</code> to catch issues early;</li> <li>Commit with a clear message;</li> <li>Push and open a pull request.</li> </ol> <p>Audit Your Code Before Submitting</p> <p>Run <code>make audit</code> before submitting:</p> <p><code>make audit</code> covers formatting, vetting, linting, drift checks,  doc consistency, and tests in one pass.</p>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#commit-messages","level":3,"title":"Commit Messages","text":"<p>Following conventional commits is recommended but not required:</p> <p>Types: <code>feat</code>, <code>fix</code>, <code>docs</code>, <code>test</code>, <code>refactor</code>, <code>chore</code></p> <p>Examples:</p> <ul> <li><code>feat(cli): add ctx export command</code></li> <li><code>fix(drift): handle missing files gracefully</code></li> <li><code>docs: update installation instructions</code></li> </ul>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#code-style","level":3,"title":"Code Style","text":"<ul> <li>Follow Go conventions (<code>gofmt</code>, <code>go vet</code>);</li> <li>Keep functions focused and small;</li> <li>Add tests for new functionality;</li> <li>Handle errors explicitly.</li> </ul>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#code-of-conduct","level":2,"title":"Code of Conduct","text":"<p>A clear context requires respectful collaboration.</p> <p><code>ctx</code> follows the Contributor Covenant.</p>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#boring-legal-stuff","level":2,"title":"Boring Legal Stuff","text":"","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#developer-certificate-of-origin-dco","level":3,"title":"Developer Certificate of Origin (DCO)","text":"<p>By contributing, you agree to the Developer Certificate of Origin.</p> <p>All commits must be signed off:</p> <pre><code>git commit -s -m \"feat: add new feature\"\n</code></pre>","path":["Home","Contributing"],"tags":[]},{"location":"home/contributing/#license","level":3,"title":"License","text":"<p>Contributions are licensed under the Apache 2.0 License.</p>","path":["Home","Contributing"],"tags":[]},{"location":"home/first-session/","level":1,"title":"Your First Session","text":"<p>Here's what a complete first session looks like, from initialization to the moment your AI cites your project context back to you.</p>","path":["Home","Your First Session"],"tags":[]},{"location":"home/first-session/#step-1-initialize-your-project","level":2,"title":"Step 1: Initialize Your Project","text":"<p>Run <code>ctx init</code> in your project root:</p> <pre><code>cd your-project\nctx init\n</code></pre> <p>Sample output:</p> <pre><code>Context initialized in .context/\n\n  ✓ CONSTITUTION.md\n  ✓ TASKS.md\n  ✓ DECISIONS.md\n  ✓ LEARNINGS.md\n  ✓ CONVENTIONS.md\n  ✓ ARCHITECTURE.md\n  ✓ GLOSSARY.md\n  ✓ AGENT_PLAYBOOK.md\n\nCreating project root files...\n  ✓ PROMPT.md\n  ✓ IMPLEMENTATION_PLAN.md\n\nSetting up Claude Code permissions...\n  ✓ .context.key\n\nClaude Code plugin (hooks + skills):\n  Install: claude /plugin marketplace add ActiveMemory/ctx\n  Then:    claude /plugin install ctx@activememory-ctx\n\nNext steps:\n  1. Edit .context/TASKS.md to add your current tasks\n  2. Run 'ctx status' to see context summary\n  3. Run 'ctx agent' to get AI-ready context packet\n</code></pre> <p>This created your <code>.context/</code> directory with template files. </p> <p>For Claude Code, install the ctx plugin to get automatic hooks and skills.</p>","path":["Home","Your First Session"],"tags":[]},{"location":"home/first-session/#step-2-populate-your-context","level":2,"title":"Step 2: Populate Your Context","text":"<p>Add a task and a decision: These are the entries your AI will remember:</p> <pre><code>ctx add task \"Implement user authentication\"\n\n# Output: ✓ Added to TASKS.md\n\nctx add decision \"Use PostgreSQL for primary database\" \\\n  --context \"Need a reliable database for production\" \\\n  --rationale \"PostgreSQL offers ACID compliance and JSON support\" \\\n  --consequences \"Team needs PostgreSQL training\"\n\n# Output: ✓ Added to DECISIONS.md\n</code></pre> <p>These entries are what the AI will recall in future sessions. You don't need to populate everything now: Context grows naturally as you work.</p>","path":["Home","Your First Session"],"tags":[]},{"location":"home/first-session/#step-3-check-your-context","level":2,"title":"Step 3: Check Your Context","text":"<pre><code>ctx status\n</code></pre> <p>Sample output:</p> <pre><code>Context Status\n====================\n\nContext Directory: .context/\nTotal Files: 8\nToken Estimate: 1,247 tokens\n\nFiles:\n  ✓ CONSTITUTION.md (loaded)\n  ✓ TASKS.md (1 items)\n  ✓ DECISIONS.md (1 items)\n  ○ LEARNINGS.md (empty)\n  ✓ CONVENTIONS.md (loaded)\n  ✓ ARCHITECTURE.md (loaded)\n  ✓ GLOSSARY.md (loaded)\n  ✓ AGENT_PLAYBOOK.md (loaded)\n\nRecent Activity:\n  - TASKS.md modified 2 minutes ago\n  - DECISIONS.md modified 1 minute ago\n</code></pre> <p>Notice the token estimate: This is how much context your AI will load.</p> <p>The <code>○</code> next to <code>LEARNINGS.md</code> means it's still empty; it will fill in as you capture lessons during development.</p>","path":["Home","Your First Session"],"tags":[]},{"location":"home/first-session/#step-4-start-an-ai-session","level":2,"title":"Step 4: Start an AI Session","text":"<p>With Claude Code (and the <code>ctx</code> plugin), start every session with:</p> <pre><code>/ctx-remember\n</code></pre> <p>This loads your context and presents a structured  readback so you can confirm the agent knows what is going on. Context also loads automatically via hooks, but the explicit ceremony gives you a readback to verify.</p> <p>Using VS Code?</p> <p>With VS Code Copilot Chat (and the [ctx extension](../operations/integrations.md#vs-code-chat-extension-ctx)),  type <code>@ctx /agent</code> in chat to load your context packet, or <code>@ctx /status</code> to check your project context. Run <code>ctx hook copilot --write</code> once to generate <code>.github/copilot-instructions.md</code> for automatic context loading.</p> <p>If you are not using Claude Code, generate a  context packet for your AI tool:</p> <pre><code>ctx agent --budget 8000\n</code></pre> <p>Sample output:</p> <pre><code># Context Packet\nGenerated: 2026-02-14T15:30:45Z | Budget: 8000 tokens | Used: ~2450\n\n## Read These Files (in order)\n1. .context/CONSTITUTION.md\n2. .context/TASKS.md\n3. .context/CONVENTIONS.md\n...\n\n## Current Tasks\n- [ ] Implement user authentication\n- [ ] Add rate limiting to API endpoints\n\n## Key Conventions\n- Use gofmt for formatting\n- Path construction uses filepath.Join\n\n## Recent Decisions\n## [2026-02-14-120000] Use PostgreSQL for the primary database\n\n**Context**: Evaluated PostgreSQL, MySQL, and SQLite...\n**Rationale**: PostgreSQL offers better JSON support...\n\n## Key Learnings\n## [2026-02-14-100000] Connection pool sizing matters\n\n**Context**: Hit connection limits under load...\n**Lesson**: Default pool size of 10 is too low for concurrent requests...\n\n## Also Noted\n- Use JWT for session management\n- Always validate input at API boundary\n</code></pre> <p>Paste this output into your AI tool's system prompt or conversation start.</p>","path":["Home","Your First Session"],"tags":[]},{"location":"home/first-session/#step-5-verify-it-works","level":2,"title":"Step 5: Verify It Works","text":"<p>Ask your AI: \"What are our current tasks?\"</p> <p>A working setup produces a response like:</p> <pre><code>Based on the project context, you have one active task:\n\n- **Implement user authentication** (pending)\n\nThere's also a recent architectural decision to **use PostgreSQL for\nthe primary database**, chosen for its ACID compliance and JSON support.\n\nWant me to start on the authentication task?\n</code></pre> <p>That's the success moment:</p> <p>The AI is citing your exact context entries from Step 2, not hallucinating or asking you to re-explain.</p>","path":["Home","Your First Session"],"tags":[]},{"location":"home/first-session/#what-gets-created","level":2,"title":"What Gets Created","text":"<pre><code>.context/\n├── CONSTITUTION.md     # Hard rules — NEVER violate these\n├── TASKS.md            # Current and planned work\n├── CONVENTIONS.md      # Project patterns and standards\n├── ARCHITECTURE.md     # System overview\n├── DECISIONS.md        # Architectural decisions with rationale\n├── LEARNINGS.md        # Lessons learned, gotchas, tips\n├── GLOSSARY.md         # Domain terms and abbreviations\n└── AGENT_PLAYBOOK.md   # How AI tools should use this\n</code></pre> <p>Claude Code integration (hooks + skills) is provided by the <code>ctx</code> plugin: See Integrations/Claude Code.</p> <p>VS Code Copilot Chat integration is provided by the <code>ctx</code> extension: See Integrations/VS Code.</p> <p>See Context Files for detailed documentation of each file.</p>","path":["Home","Your First Session"],"tags":[]},{"location":"home/first-session/#what-to-gitignore","level":2,"title":"What to <code>.gitignore</code>","text":"<p>Rule of Thumb</p> <ul> <li>If it's knowledge (decisions, tasks, learnings,   conventions), commit it.</li> <li>If it's generated output, raw session data, or a secret, <code>.gitignore</code> it.</li> </ul> <p>Commit your <code>.context/</code> knowledge files: that's the whole point.</p> <p>You should <code>.gitignore</code> the generated and sensitive paths:</p> <pre><code># Journal data (large, potentially sensitive)\n.context/journal/\n.context/journal-site/\n.context/journal-obsidian/\n\n# Hook logs (machine-specific)\n.context/logs/\n\n# Encryption key (NEVER commit)\n.context/.context.key\n\n# Claude Code local settings (machine-specific)\n.claude/settings.local.json\n</code></pre> <p><code>ctx init</code> Patches Your .gitignore for You</p> <p><code>ctx init</code> automatically adds these entries to your <code>.gitignore</code>.</p> <p>Review the additions with <code>cat .gitignore</code> after init.</p> <p>See also:</p> <ul> <li>Security Considerations</li> <li>Scratchpad Encryption</li> <li>Session Journal</li> </ul> <p>Next Up: Common Workflows →:  day-to-day commands for tracking context, checking health, and browsing history.</p>","path":["Home","Your First Session"],"tags":[]},{"location":"home/getting-started/","level":1,"title":"Getting Started","text":"","path":["Home","Getting Started"],"tags":[]},{"location":"home/getting-started/#prerequisites","level":2,"title":"Prerequisites","text":"<p><code>ctx</code> does not require <code>git</code>, but using version control with your <code>.context/</code> directory is strongly recommended:</p> <p>AI sessions occasionally modify or overwrite context files inadvertently. With <code>git</code>, the AI can check history and restore lost content: Without it, the data is gone.</p> <p>Also, several <code>ctx</code> features (journal changelog, blog generation) also use <code>git</code> history directly.</p>","path":["Home","Getting Started"],"tags":[]},{"location":"home/getting-started/#installation","level":2,"title":"Installation","text":"<p>A full ctx installation has two parts:</p> <ol> <li>The <code>ctx</code> binary: the CLI tool itself;</li> <li>The Claude Code plugin: hooks and skills that make Claude Code    context-aware.</li> </ol> <p>You need both. The binary alone gives you the CLI, but Claude Code won't autoload context, nudge you to persist decisions, or provide the <code>/ctx-*</code> skills.</p> <p>Pick one of the options below. Each is a complete path from zero to a working setup.</p>","path":["Home","Getting Started"],"tags":[]},{"location":"home/getting-started/#option-1-build-from-source-recommended","level":3,"title":"Option 1: Build from Source (Recommended)","text":"<p>Requires Go (version defined in  <code>go.mod</code>) and Claude Code.</p> <pre><code>git clone https://github.com/ActiveMemory/ctx.git\ncd ctx\nmake build\nsudo make install\n</code></pre> <p>Install the Claude Code plugin from your local clone:</p> <ol> <li>Launch <code>claude</code>;</li> <li>Type <code>/plugin</code> and press Enter;</li> <li>Select Marketplaces → Add Marketplace</li> <li>Enter the path to the root of your clone,    e.g. <code>~/WORKSPACE/ctx</code>    (this is where <code>.claude-plugin/marketplace.json</code> lives: It points    Claude Code to the actual plugin in <code>internal/assets/claude</code>)</li> <li>Back in <code>/plugin</code>, select Install and choose <code>ctx</code></li> </ol> <p>This points Claude Code at the plugin source on disk. Changes you make to hooks or skills take effect immediately: No reinstall is needed.</p> <p>Verify:</p> <pre><code>ctx --version       # binary is in PATH\nclaude /plugin list # plugin is installed\n</code></pre> <p>Use the Source, Luke</p> <p>Building from source gives you the latest features and bug fixes.</p> <p>Since <code>ctx</code> is predominantly a developer tool, this is the recommended approach: </p> <p>You get the freshest code, can inspect what you are installing, and the plugin stays in sync with the binary.</p>","path":["Home","Getting Started"],"tags":[]},{"location":"home/getting-started/#option-2-binary-download-marketplace","level":3,"title":"Option 2: Binary Download + Marketplace","text":"<p>Pre-built binaries are available from the releases page.</p> Linux (x86_64)Linux (ARM64)macOS (Apple Silicon)macOS (Intel)Windows <pre><code>curl -LO https://github.com/ActiveMemory/ctx/releases/download/v0.6.0/ctx-0.6.0-linux-amd64\nchmod +x ctx-0.6.0-linux-amd64\nsudo mv ctx-0.6.0-linux-amd64 /usr/local/bin/ctx\n</code></pre> <pre><code>curl -LO https://github.com/ActiveMemory/ctx/releases/download/v0.6.0/ctx-0.6.0-linux-arm64\nchmod +x ctx-0.6.0-linux-arm64\nsudo mv ctx-0.6.0-linux-arm64 /usr/local/bin/ctx\n</code></pre> <pre><code>curl -LO https://github.com/ActiveMemory/ctx/releases/download/v0.6.0/ctx-0.6.0-darwin-arm64\nchmod +x ctx-0.6.0-darwin-arm64\nsudo mv ctx-0.6.0-darwin-arm64 /usr/local/bin/ctx\n</code></pre> <pre><code>curl -LO https://github.com/ActiveMemory/ctx/releases/download/v0.6.0/ctx-0.6.0-darwin-amd64\nchmod +x ctx-0.6.0-darwin-amd64\nsudo mv ctx-0.6.0-darwin-amd64 /usr/local/bin/ctx\n</code></pre> <p>Download <code>ctx-0.6.0-windows-amd64.exe</code> from the releases page and add it to your <code>PATH</code>.</p> <p>Install the Claude Code plugin from the marketplace:</p> <ol> <li>Launch <code>claude</code>;</li> <li>Type <code>/plugin</code> and press Enter;</li> <li>Select Marketplaces → Add Marketplace;</li> <li>Enter <code>ActiveMemory/ctx</code>;</li> <li>Back in <code>/plugin</code>, select Install and choose <code>ctx</code>.</li> </ol> <p>Verify:</p> <pre><code>ctx --version       # binary is in PATH\nclaude /plugin list # plugin is installed\n</code></pre>","path":["Home","Getting Started"],"tags":[]},{"location":"home/getting-started/#verifying-checksums","level":4,"title":"Verifying Checksums","text":"<p>Each binary has a corresponding <code>.sha256</code> checksum file. To verify your download:</p> <pre><code># Download the checksum file\ncurl -LO https://github.com/ActiveMemory/ctx/releases/download/v0.6.0/ctx-0.6.0-linux-amd64.sha256\n\n# Verify the binary\nsha256sum -c ctx-0.6.0-linux-amd64.sha256\n</code></pre> <p>On macOS, use <code>shasum -a 256 -c</code> instead of <code>sha256sum -c</code>.</p> Plugin Details <p>After installation (either option) you get:</p> <ul> <li>Context autoloading: <code>ctx agent</code> runs on every tool use (with cooldown)</li> <li>Persistence nudges: reminders to capture learnings and decisions</li> <li>Post-commit hooks: nudge context capture after <code>git commit</code></li> <li>Context size monitoring: alerts as sessions grow large</li> <li>25+ skills: <code>/ctx-status</code>, <code>/ctx-add-task</code>, <code>/ctx-recall</code>, and more</li> </ul> <p>See Integrations for the full hook and skill reference.</p>","path":["Home","Getting Started"],"tags":[]},{"location":"home/getting-started/#quick-start","level":2,"title":"Quick Start","text":"","path":["Home","Getting Started"],"tags":[]},{"location":"home/getting-started/#1-initialize-context","level":3,"title":"1. Initialize Context","text":"<pre><code>cd your-project\nctx init\n</code></pre> <p>This creates a <code>.context/</code> directory with template files and a <code>.context.key</code> for the encrypted scratchpad. For Claude Code, install the ctx plugin for automatic hooks and skills.</p>","path":["Home","Getting Started"],"tags":[]},{"location":"home/getting-started/#2-check-status","level":3,"title":"2. Check Status","text":"<pre><code>ctx status\n</code></pre> <p>Shows context summary: files present, token estimate, and recent activity.</p>","path":["Home","Getting Started"],"tags":[]},{"location":"home/getting-started/#3-start-using-with-ai","level":3,"title":"3. Start Using with AI","text":"<p>With Claude Code (and the <code>ctx</code> plugin installed), context loads automatically via hooks.</p> <p>With VS Code Copilot Chat, install the ctx extension and use <code>@ctx /status</code>, <code>@ctx /agent</code>, and other slash commands directly in chat. Run <code>ctx hook copilot --write</code> to generate <code>.github/copilot-instructions.md</code> for automatic context loading.</p> <p>For other tools, paste the output of:</p> <pre><code>ctx agent --budget 8000\n</code></pre>","path":["Home","Getting Started"],"tags":[]},{"location":"home/getting-started/#4-verify-it-works","level":3,"title":"4. Verify It Works","text":"<p>Ask your AI: \"Do you remember?\"</p> <p>It should cite specific context: current tasks, recent decisions, or previous session topics.</p> <p>Next Up:</p> <ul> <li>Your First Session →: a step-by-step walkthrough from <code>ctx init</code> to verified recall</li> <li>Common Workflows →: day-to-day commands for tracking context, checking health, and browsing history</li> </ul>","path":["Home","Getting Started"],"tags":[]},{"location":"home/is-ctx-right/","level":1,"title":"Is It Right for Me?","text":"","path":["Home","Is It Right for Me?"],"tags":[]},{"location":"home/is-ctx-right/#good-fit","level":2,"title":"Good Fit","text":"<p><code>ctx</code> shines when context matters more than code.</p> <p>If any of these sound like your project, it's worth trying:</p> <ul> <li>Multi-session AI work: You use AI across many sessions on the same   codebase, and re-explaining is slowing you down.</li> <li>Architectural decisions that matter: Your project has non-obvious   choices (database, auth strategy, API design) that the AI keeps   second-guessing.</li> <li>\"Why\" matters as much as \"what\": you need the AI to understand   rationale, not just current code</li> <li>Team handoffs: Multiple people (or multiple AI tools) work on the   same project and need shared context.</li> <li>AI-assisted development across tools: Uou switch between Claude Code,   Cursor, Copilot, or other tools and want context to follow the project,   not the tool.</li> <li>Long-lived projects: Anything you'll work on for weeks or months,   where accumulated knowledge has compounding value.</li> </ul>","path":["Home","Is It Right for Me?"],"tags":[]},{"location":"home/is-ctx-right/#may-not-be-the-right-fit","level":2,"title":"May Not Be the Right Fit","text":"<p><code>ctx</code> adds overhead that isn't worth it for every project. Be honest about when to skip it:</p> <ul> <li>One-off scripts: If the project is a single file you'll finish today,   there's nothing to remember.</li> <li>RAG-only workflows: If retrieval from an external knowledge base already   gives the agent everything it needs for each session, adding <code>ctx</code> may be   unnecessary. RAG retrieves information; <code>ctx</code> defines the project's   working memory: They are complementary.</li> <li>No AI involvement: <code>ctx</code> is designed for human–AI workflows; without   an AI consumer, the files are just documentation.</li> <li>Enterprise-managed context platforms: If your organization provides   centralized context services, <code>ctx</code> may duplicate that layer.</li> </ul> <p>For a deeper technical comparison with RAG, prompt management tools, and agent frameworks, see ctx and Similar Tools.</p>","path":["Home","Is It Right for Me?"],"tags":[]},{"location":"home/is-ctx-right/#project-size-guide","level":2,"title":"Project Size Guide","text":"","path":["Home","Is It Right for Me?"],"tags":[]},{"location":"home/is-ctx-right/#solo-developer-single-repo","level":3,"title":"Solo Developer, Single Repo","text":"<p>This is <code>ctx</code>'s sweet spot. </p> <p>You get the most value here: one person, one project, decisions, and learnings  accumulating over time. Setup takes 5 minutes and the <code>.context/</code> directory directory stays small, and every session gets faster.</p>","path":["Home","Is It Right for Me?"],"tags":[]},{"location":"home/is-ctx-right/#small-team-one-or-two-repos","level":3,"title":"Small Team, One or Two Repos","text":"<p>Works well. </p> <p>Context files commit to git, so the whole team shares the same decisions and conventions. Each person's AI starts with the team’s decisions already loaded. Merge conflicts on <code>.context/</code> files are rare and easy to resolve (they are just Markdown).</p>","path":["Home","Is It Right for Me?"],"tags":[]},{"location":"home/is-ctx-right/#multiple-repos-or-larger-teams","level":3,"title":"Multiple Repos or Larger Teams","text":"<p><code>ctx</code> operates per repository.</p> <p>Each repo has its own <code>.context/</code> directory with its own decisions, tasks, and learnings. This matches the way code, ownership, and history already work in <code>git</code>.</p> <p>There is no built-in cross-repo context layer.</p> <p>For organizations that need centralized, organization-wide knowledge, <code>ctx</code> complements a platform solution by providing durable, project-local working memory for AI sessions.</p>","path":["Home","Is It Right for Me?"],"tags":[]},{"location":"home/is-ctx-right/#5-minute-trial","level":2,"title":"5-Minute Trial","text":"<p>Zero commitment. Try it, and delete <code>.context/</code> if it's not for you.</p> <p>Using Claude Code?</p> <p>Install the <code>ctx</code> plugin from the Marketplace for Claude-native hooks,  skills, and automatic context loading:</p> <ol> <li>Type <code>/plugin</code> and press Enter</li> <li>Select Marketplaces → Add Marketplace</li> <li>Enter <code>ActiveMemory/ctx</code></li> <li>Back in <code>/plugin</code>, select Install and choose <code>ctx</code></li> </ol> <p>You'll still need the <code>ctx</code> binary for the CLI: See Getting Started for install options.</p> <pre><code># 1. Initialize\ncd your-project\nctx init\n\n# 2. Add one real decision from your project\nctx add decision \"Your actual architectural choice\" \\\n  --context \"What prompted this decision\" \\\n  --rationale \"Why you chose this approach\" \\\n  --consequences \"What changes as a result\"\n\n# 3. Check what the AI will see\nctx status\n\n# 4. Start an AI session and ask: \"Do you remember?\"\n</code></pre> <p>If the AI cites your decision back to you, it's working.</p> <p>Want to remove it later? One command:</p> <pre><code>rm -rf .context/\n</code></pre> <p>No dependencies to uninstall. No configuration to revert. Just files.</p> <p>Ready to try it out?</p> <ul> <li>Join the Community→: Open Source is better together.</li> <li>Getting Started →: Full installation and setup.</li> <li><code>ctx</code> and Similar Tools →: Detailed comparison with other approaches.</li> </ul>","path":["Home","Is It Right for Me?"],"tags":[]},{"location":"home/prompting-guide/","level":1,"title":"Prompting Guide","text":"<p>New to <code>ctx</code>?</p> <p>This guide references context files like <code>TASKS.md</code>, <code>DECISIONS.md</code>, and <code>LEARNINGS.md</code>:</p> <p>These are plain Markdown files that <code>ctx</code> maintains in your project's <code>.context/</code> directory.</p> <p>If terms like \"context packet\" or \"session ceremony\" are unfamiliar,</p> <ul> <li>start with the <code>ctx</code> Manifesto for the why,</li> <li>About for the big picture,</li> <li>then Getting Started to set up your first   project.</li> </ul>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#literature-matters","level":2,"title":"Literature Matters","text":"<p>This guide is about crafting effective prompts for working with  AI assistants in <code>ctx</code>-enabled projects, but the guidelines given here apply to other AI systems, too.</p> <p>The right prompt triggers the right behavior. </p> <p>This guide documents prompts that reliably produce good results.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#session-start","level":2,"title":"Session Start","text":"","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#do-you-remember","level":3,"title":"\"Do you remember?\"","text":"<p>Triggers the AI to silently read <code>TASKS.md</code>, <code>DECISIONS.md</code>, <code>LEARNINGS.md</code>, and check recent history via <code>ctx recall</code> before responding with a  structured readback:</p> <ol> <li>Last session: most recent session topic and date</li> <li>Active work: pending or in-progress tasks</li> <li>Recent context: 1-2 recent decisions or learnings</li> <li>Next step: offer to continue or ask what to focus on</li> </ol> <p>Use this at the start of every important session.</p> <pre><code>Do you remember what we were working on?\n</code></pre> <p>This question implies prior context exists. The AI checks files rather than admitting ignorance. The expected response cites specific context (session names, task counts, decisions), not vague summaries.</p> <p>If the AI instead narrates its discovery process (\"Let me check if there are files...\"), it has not loaded <code>CLAUDE.md</code> or <code>AGENT_PLAYBOOK.md</code> properly.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#whats-the-current-state","level":3,"title":"\"What's the current state?\"","text":"<p>Prompts reading of <code>TASKS.md</code>, recent sessions, and status overview.</p> <p>Use this when resuming work after a break.</p> <p>Variants:</p> <ul> <li>\"Where did we leave off?\"</li> <li>\"What's in progress?\"</li> <li>\"Show me the open tasks.\"</li> </ul>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#during-work","level":2,"title":"During Work","text":"","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#why-doesnt-x-work","level":3,"title":"\"Why doesn't X work?\"","text":"<p>This triggers root cause analysis rather than surface-level fixes.</p> <p>Use this when something fails unexpectedly.</p> <p>Framing as \"why\" encourages investigation before action. The AI will trace  through code, check configurations, and identify the actual cause.</p> <p>Real Example</p> <p>\"Why can't I run /ctx-reflect?\" led to discovering missing permissions in <code>settings.local.json</code> bootstrapping.</p> <p>This was a fix that benefited all users of <code>ctx</code>.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#is-this-consistent-with-our-decisions","level":3,"title":"\"Is this consistent with our decisions?\"","text":"<p>This prompts checking <code>DECISIONS.md</code> before implementing.</p> <p>Use this before making architectural choices.</p> <p>Variants:</p> <ul> <li>\"Check if we've decided on this before\"</li> <li>\"Does this align with our conventions?\"</li> </ul>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#what-would-break-if-we","level":3,"title":"\"What would break if we...\"","text":"<p>This triggers defensive thinking and impact analysis.</p> <p>Use this before making significant changes.</p> <pre><code>What would break if we change the Settings struct?\n</code></pre>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#before-you-start-read-x","level":3,"title":"\"Before you start, read X\"","text":"<p>This ensures specific context is loaded before work begins.</p> <p>Use this when you know the relevant context exists in a specific file.</p> <pre><code>Before you start, check ctx recall for the auth discussion session\n</code></pre>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#scope-control","level":3,"title":"Scope Control","text":"<p>Constrain the AI to prevent sprawl. These are some of the most useful prompts in day-to-day work.</p> <pre><code>Only change files in internal/cli/add/. Nothing else.\n</code></pre> <pre><code>No new files. Modify the existing implementation.\n</code></pre> <pre><code>Keep the public API unchanged. Internal refactor only.\n</code></pre> <p>Use these when the AI tends to \"helpfully\" modify adjacent code, add documentation you didn't ask for, or create new abstractions.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#course-correction","level":3,"title":"Course Correction","text":"<p>Steer the AI when it goes off-track: Don't wait for it to finish a wrong approach.</p> <pre><code>Stop! That's not what I meant. Let me clarify.\n</code></pre> <pre><code>Let's step back. Explain what you're about to do before changing anything.\n</code></pre> <pre><code>Undo that last change and try a different approach.\n</code></pre> <p>These work because they interrupt momentum.</p> <p>Without explicit course correction, the AI tends to commit harder to a wrong path rather than reconsidering.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#failure-modes","level":3,"title":"Failure Modes","text":"<p>When the AI misbehaves, match the symptom to the recovery prompt:</p> Symptom Recovery prompt Hand-waves (\"should work now\") \"Show evidence: file/line refs, command output, or test name.\" Creates unnecessary files \"No new files. Modify the existing implementation.\" Expands scope unprompted \"Stop after the smallest working change. Ask before expanding scope.\" Narrates instead of acting \"Skip the explanation. Make the change and show the diff.\" Repeats a failed approach \"That didn't work last time. Try a different approach.\" Claims completion without proof \"Run the test. Show me the output.\" <p>These are recovery handles, not rules to paste into <code>CLAUDE.md</code>.</p> <p>Use them in the moment when you see the behavior.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#reflection-and-persistence","level":2,"title":"Reflection and Persistence","text":"","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#what-did-we-learn","level":3,"title":"\"What did we learn?\"","text":"<p>This prompts reflection on the session and often triggers adding learnings to <code>LEARNINGS.md</code>.</p> <p>Use this after completing a task or debugging session.</p> <p>This is an explicit reflection prompt. The AI will summarize insights and often offer to persist them.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#add-this-as-a-learningdecision","level":3,"title":"\"Add this as a learning/decision\"","text":"<p>This is an explicit persistence request.</p> <p>Use this when you have discovered something worth remembering.</p> <pre><code>Add this as a learning: \"JSON marshal escapes angle brackets by default\"\n\n# or simply.\nAdd this as a learning.\n# and let the AI autonomously infer and summarize.\n</code></pre>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#save-context-before-we-end","level":3,"title":"\"Save context before we end\"","text":"<p>This triggers context persistence before the session closes.</p> <p>Use it at the end of the session or before switching topics.</p> <p>Variants:</p> <ul> <li>\"Let's persist what we did\"</li> <li>\"Update the context files\"</li> <li><code>/ctx-wrap-up</code> — the recommended end-of-session ceremony   (see Session Ceremonies)</li> <li><code>/ctx-reflect</code> — mid-session reflection checkpoint</li> </ul>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#exploration-and-research","level":2,"title":"Exploration and Research","text":"","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#explore-the-codebase-for-x","level":3,"title":"\"Explore the codebase for X\"","text":"<p>This triggers thorough codebase search rather than guessing.</p> <p>Use this when you need to understand how something works.</p> <p>This works because \"Explore\" signals that investigation is needed,  not immediate action.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#how-does-x-work-in-this-codebase","level":3,"title":"\"How does X work in this codebase?\"","text":"<p>This prompts reading actual code rather than explaining general concepts.</p> <p>Use this to understand the existing implementation.</p> <pre><code>How does session saving work in this codebase?\n</code></pre>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#find-all-places-where-x","level":3,"title":"\"Find all places where X\"","text":"<p>This triggers a comprehensive search across the codebase.</p> <p>Use this before refactoring or understanding the impact.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#meta-and-process","level":2,"title":"Meta and Process","text":"","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#what-should-we-document-from-this","level":3,"title":"\"What should we document from this?\"","text":"<p>This prompts identifying learnings, decisions, and conventions worth persisting.</p> <p>Use this after complex discussions or implementations.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#is-this-the-right-approach","level":3,"title":"\"Is this the right approach?\"","text":"<p>This invites the AI to challenge the current direction.</p> <p>Use this when you want a sanity check.</p> <p>This works because it allows AI to disagree.</p> <p>AIs often default to agreeing; this prompt signals you want an honest assessment.</p> <p>Stronger variant: \"Push back if my assumptions are wrong.\" This sets the tone for the entire session: The AI will flag questionable choices proactively instead of waiting to be asked.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#what-am-i-missing","level":3,"title":"\"What am I missing?\"","text":"<p>This prompts thinking about edge cases, overlooked requirements, or unconsidered approaches.</p> <p>Use this before finalizing a design or implementation.</p> <p>Forward-looking variant: \"What's the single smartest addition you could make to this at this point?\" Use this after you think you're done: It surfaces improvements you wouldn't have thought to ask for. The constraint to one thing prevents feature sprawl.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#cli-commands-as-prompts","level":2,"title":"CLI Commands as Prompts","text":"<p>Asking the AI to run <code>ctx</code> commands is itself a prompt. These load context or trigger specific behaviors:</p> Command What it does \"Run <code>ctx status</code>\" Shows context summary, file presence, staleness \"Run <code>ctx agent</code>\" Loads token-budgeted context packet \"Run <code>ctx drift</code>\" Detects dead paths, stale files, missing context","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#ctx-skills","level":3,"title":"<code>ctx</code> Skills","text":"<p>The <code>SKILS.md</code> Standard</p> <p>Skills are formalized prompts stored as <code>SKILL.md</code> files.</p> <p>The <code>/slash-command</code> syntax below is Claude Code specific. </p> <p>Other agents can use the same skill files, but invocation may differ. </p> <p>Use <code>ctx</code> skills  by name:</p> Skill When to use <code>/ctx-status</code> Quick context summary <code>/ctx-agent</code> Load full context packet <code>/ctx-remember</code> Recall project context and structured readback <code>/ctx-wrap-up</code> End-of-session context persistence <code>/ctx-recall</code> Browse session history for past discussions <code>/ctx-reflect</code> Structured reflection checkpoint <code>/ctx-next</code> Suggest what to work on next <code>/ctx-commit</code> Commit with context persistence <code>/ctx-drift</code> Detect and fix context drift <code>/ctx-implement</code> Execute a plan step-by-step with verification <code>/ctx-loop</code> Generate autonomous loop script <code>/ctx-pad</code> Manage encrypted scratchpad <code>/ctx-archive</code> Archive completed tasks <code>/check-links</code> Audit docs for dead links <p>Ceremony vs. Workflow Skills</p> <p>Most skills work conversationally: \"what should we work on?\" triggers <code>/ctx-next</code>, \"save that as a learning\" triggers <code>/ctx-add-learning</code>. Natural language is the recommended approach.</p> <p>Two skills are the exception: <code>/ctx-remember</code> and <code>/ctx-wrap-up</code> are ceremony skills for session boundaries: Invoke them as explicit slash commands: conversational triggers risk partial execution. See Session Ceremonies.</p> <p>Skills combine a prompt, tool permissions, and domain knowledge into a single invocation.</p> <p>Skills Beyond Claude Code</p> <p>The <code>/slash-command</code> syntax above is Claude Code native, but the underlying <code>SKILL.md</code> files are a standard markdown format that any agent can consume. If you use a different coding agent, consult its documentation for how to load skill files as prompt templates.</p> <p>See Integrations for setup details.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#anti-patterns","level":2,"title":"Anti-Patterns","text":"<p>Based on our <code>ctx</code> development experience (i.e., \"sipping our own champagne\") so far, here are some prompts that tend to produce poor results:</p> Prompt Problem Better Alternative \"Fix this\" Too vague, may patch symptoms \"Why is this failing?\" \"Make it work\" Encourages quick hacks \"What's the right way to solve this?\" \"Just do it\" Skips planning \"Plan this, then implement\" \"You should remember\" Confrontational \"Do you remember?\" \"Obviously...\" Discourages questions State the requirement directly \"Idiomatic X\" Triggers language priors \"Follow project conventions\" \"Implement everything\" No phasing, sprawl risk Break into tasks, implement one at a time \"You should know this\" Assumes context is loaded \"Before you start, read X\"","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#reliability-checklist","level":2,"title":"Reliability Checklist","text":"<p>Before sending a non-trivial prompt, check these four elements. This is the guide's DNA in one screenful.</p> <ol> <li>Goal in one sentence: What does \"done\" look like?</li> <li>Files to read: What existing code or context should the AI    review before acting?</li> <li>Verification command: How will you prove it worked?    (test name, CLI command, expected output)</li> <li>Scope boundary: What should the AI not touch?</li> </ol> <p>A prompt that covers all four is almost always good enough.</p> <p>A prompt missing <code>#3</code> is how you get \"should work now\" without evidence.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#safety-invariants","level":2,"title":"Safety Invariants","text":"<p>These are Invariants: Not Suggestions</p> <p>A prompting guide earns its trust by being honest about risk.</p> <p>These four rules mentioned below don't change with model versions, agent frameworks, or project size.</p> <p>Build them into your workflow once and stop thinking about them.</p> <p>Tool-using agents can read files, run commands, and modify your codebase. That power makes them useful. It also creates a trust boundary you should be aware of.</p> <p>These invariants apply regardless of which agent or model you use.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#treat-the-repository-text-as-untrusted-input","level":3,"title":"Treat the Repository Text as \"Untrusted Input\"","text":"<p>Issue descriptions, PR comments, commit messages, documentation, and even code comments can contain text that looks like instructions. An agent that reads a GitHub issue and then runs a command found inside it is executing untrusted input.</p> <p>The rule: Before running any command the agent found in repo text (issues, docs, comments), restate the command explicitly and confirm it does what you expect. Don't let the agent copy-paste from untrusted sources into a shell.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#ask-before-destructive-operations","level":3,"title":"Ask Before Destructive Operations","text":"<p><code>git push --force</code>, <code>rm -rf</code>, <code>DROP TABLE</code>, <code>docker system prune</code>: these are irreversible or hard to reverse. A good agent should pause before running them, but don't rely on that.</p> <p>The rule: For any operation that deletes data, overwrites history, or affects shared infrastructure, require explicit confirmation. If the agent runs something destructive without asking, that's a course-correction moment: \"Stop. Never run destructive commands without asking first.\"</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#scope-the-blast-radius","level":3,"title":"Scope the Blast Radius","text":"<p>An agent told to \"fix the tests\" might modify test fixtures, change assertions, or delete tests that inconveniently fail. An agent told to \"deploy\" might push to production. Broad mandates create broad risk.</p> <p>The rule: Constrain scope before starting work. The Reliability Checklist's scope boundary (<code>#4</code>) is your primary safety lever. When in doubt, err on the side of a tighter boundary.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#secrets-never-belong-in-context","level":3,"title":"Secrets Never Belong in Context","text":"<p><code>LEARNINGS.md</code>, <code>DECISIONS.md</code>, and session transcripts are plain-text files that may be committed to version control.</p> <p>Don't persist API keys, passwords, tokens, or credentials in context files.</p> <p>The rule: If the agent encounters a secret during work, it should use it transiently (environment variable, an alias to the secret instead of the actual secret, etc.) and never write it to a context file. </p> <p>Any Secret Seen IS Exposed</p> <p>If you see a secret in a context file, remove it immediately and  rotate the credential.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#quick-reference","level":2,"title":"Quick Reference","text":"Goal Prompt Load context \"Do you remember?\" Resume work \"What's the current state?\" What's next <code>/ctx-next</code> Debug \"Why doesn't X work?\" Validate \"Is this consistent with our decisions?\" Impact analysis \"What would break if we...\" Reflect <code>/ctx-reflect</code> Wrap up <code>/ctx-wrap-up</code> Persist \"Add this as a learning\" Explore \"How does X work in this codebase?\" Sanity check \"Is this the right approach?\" Completeness \"What am I missing?\" One more thing \"What's the single smartest addition?\" Set tone \"Push back if my assumptions are wrong.\" Constrain scope \"Only change files in X. Nothing else.\" Course correct \"Stop. That's not what I meant.\" Check health \"Run <code>ctx drift</code>\" Commit <code>/ctx-commit</code>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#explore-plan-implement","level":2,"title":"Explore → Plan → Implement","text":"<p>For non-trivial work, name the phase you want:</p> <pre><code>Explore src/auth and summarize the current flow.\nThen propose a plan. After I approve, implement with tests.\n</code></pre> <p>This prevents the AI from jumping straight to code. </p> <p>The three phases map to different modes of thinking:</p> <ul> <li>Explore: read, search, understand: no changes</li> <li>Plan: propose approach, trade-offs, scope: no changes</li> <li>Implement: write code, run tests, verify: changes</li> </ul> <p>Small fixes skip straight to implement. Complex or uncertain work benefits from all three.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#prompts-by-task-type","level":2,"title":"Prompts by Task Type","text":"<p>Different tasks need different prompt structures. The pattern: symptom + location + verification.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#bugfix","level":3,"title":"Bugfix","text":"<pre><code>Users report search returns empty results for queries with hyphens.\nReproduce in src/search/. Write a failing test for \"foo-bar\",\nfix the root cause, run: go test ./internal/search/...\n</code></pre>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#refactor","level":3,"title":"Refactor","text":"<pre><code>Inspect src/auth/ and list duplication hotspots.\nPropose a refactor plan scoped to one module.\nAfter approval, remove duplication without changing behavior.\nAdd a test if coverage is missing. Run: make audit\n</code></pre>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#research","level":3,"title":"Research","text":"<pre><code>Explore the request flow around src/api/.\nSummarize likely bottlenecks with evidence.\nPropose 2-3 hypotheses. Do not implement yet.\n</code></pre>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#docs","level":3,"title":"Docs","text":"<pre><code>Update docs/cli-reference.md to reflect the new --format flag.\nConfirm the flag exists in the code and the example works.\n</code></pre> <p>Notice each prompt includes what to verify and how. Without that, you get a \"should work now\" instead of evidence.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#writing-tasks-as-prompts","level":2,"title":"Writing Tasks as Prompts","text":"<p>Tasks in <code>TASKS.md</code> are indirect prompts to the AI. How you write them shapes how the AI approaches the work.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#state-the-motivation-not-just-the-goal","level":3,"title":"State the Motivation, Not Just the Goal","text":"<p>Tell the AI why you are building something, not just what.</p> <p>Bad: \"Build a calendar view.\"</p> <p>Good: \"Build a calendar view. The motivation is that all notes and tasks we build later should be viewable here.\"</p> <p>The second version lets the AI anticipate downstream requirements:</p> <p>It will design the calendar's data model to be compatible with future features: Without you having to spell out every integration point. Motivation turns a one-off task into a directional task.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#state-the-deliverable-not-just-steps","level":3,"title":"State the Deliverable, Not Just Steps","text":"<p>Bad task (implementation-focused): <pre><code>- [ ] T1.1.0: Parser system\n  - [ ] Define data structures\n  - [ ] Implement line parser\n  - [ ] Implement session grouper\n</code></pre></p> <p>The AI may complete all subtasks but miss the actual goal. What does \"Parser system\" deliver to the user?</p> <p>Good task (deliverable-focused): <pre><code>- [ ] T1.1.0: Parser CLI command\n  **Deliverable**: `ctx recall list` command that shows parsed sessions\n  - [ ] Define data structures\n  - [ ] Implement line parser\n  - [ ] Implement session grouper\n</code></pre></p> <p>Now the AI knows the subtasks serve a specific user-facing deliverable.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#use-acceptance-criteria","level":3,"title":"Use Acceptance Criteria","text":"<p>For complex tasks, add explicit \"done when\" criteria:</p> <pre><code>- [ ] T2.0: Authentication system\n  **Done when**:\n  - [ ] User can register with email\n  - [ ] User can log in and get a token\n  - [ ] Protected routes reject unauthenticated requests\n</code></pre> <p>This prevents premature \"task complete\" when only the implementation details are done, but the feature doesn't actually work.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#subtasks-parent-task","level":3,"title":"Subtasks ≠ Parent Task","text":"<p>Completing all subtasks does not mean the parent task is complete.</p> <p>The parent task describes what the user gets.</p> <p>Subtasks describe how to build it.</p> <p>Always re-read the parent task description before marking it complete. Verify the stated deliverable exists and works.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#why-do-these-approaches-work","level":2,"title":"Why Do These Approaches Work?","text":"<p>The patterns in this guide aren't invented here: They are practitioner translations of well-established, peer-reviewed research, most of which  predate the current AI (hype) wave. </p> <p>The underlying ideas come from decades of work in machine learning,  cognitive science, and numerical optimization.</p> <p>Phased work (\"Explore → Plan → Implement\") applies chain-of-thought reasoning: Decomposing a problem into sequential steps before acting. Forcing intermediate reasoning steps measurably improves output quality in language models, just as it does in human problem-solving. Wei et al., Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (2022).</p> <p>Root-cause prompts (\"Why doesn't X work?\") use step-back abstraction: Retreating to a higher-level question before diving into specifics. This mirrors how experienced engineers debug: they ask \"what should happen?\" before asking \"what went wrong?\" Zheng et al., Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models (2023).</p> <p>Exploring alternatives (\"Propose 2-3 approaches\") leverages self-consistency: Generating multiple independent reasoning paths and selecting the most coherent result. The idea traces back to ensemble methods in ML: A committee of diverse solutions outperforms any single one. Wang et al., Self-Consistency Improves Chain of Thought Reasoning in Language Models (2022).</p> <p>Impact analysis (\"What would break if we...\") is a form of tree-structured exploration: Branching into multiple consequence paths before committing. This is the same principle behind game-tree search (minimax, MCTS) that has powered decision-making systems since the 1950s. Yao et al., Tree of Thoughts: Deliberate Problem Solving with Large Language Models (2023).</p> <p>Motivation prompting (\"Build X because Y\") works through goal conditioning: Providing the objective function alongside the task. In optimization terms, you are giving the gradient direction, not just the loss. The model can make locally coherent decisions that serve the global objective because it knows what \"better\" means.</p> <p>Scope constraints (\"Only change files in X\") apply constrained optimization: Bounding the search space to prevent divergence. This is the same principle behind regularization in ML: Without boundaries, powerful optimizers find solutions that technically satisfy the objective but are practically useless.</p> <p>CLI commands as prompts (\"Run <code>ctx status</code>\") interleave reasoning with acting: The model thinks, acts on external tools, observes results, then thinks again. Grounding reasoning in real tool output reduces hallucination because the model can't ignore evidence it just retrieved. Yao et al., ReAct: Synergizing Reasoning and Acting in Language Models (2022).</p> <p>Task decomposition (\"Prompts by Task Type\") applies least-to-most prompting: Breaking a complex problem into subproblems and solving them sequentially, each building on the last. This is the research version of \"plan, then implement one slice.\" Zhou et al., Least-to-Most Prompting Enables Complex Reasoning in Large Language Models (2022).</p> <p>Explicit planning (\"Explore → Plan → Implement\") is directly supported by plan-and-solve prompting, which addresses missing-step failures in zero-shot reasoning by extracting a plan before executing. The phased structure prevents the model from jumping to code before understanding the problem. Wang et al., Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models (2023).</p> <p>Session reflection (\"What did we learn?\", <code>/ctx-reflect</code>) is a form of verbal reinforcement learning: Improving future performance by persisting linguistic feedback as memory rather than updating weights. This is exactly what <code>LEARNINGS.md</code> and <code>DECISIONS.md</code> provide: a durable feedback signal across sessions. Shinn et al., Reflexion: Language Agents with Verbal Reinforcement Learning (2023).</p> <p>These aren't prompting \"hacks\" that you will find in the \"1000 AI Prompts for the Curious\" listicles: They are applications of foundational principles:</p> <ul> <li>Decomposition,</li> <li>Abstraction,</li> <li>Ensemble Reasoning,</li> <li>Search,</li> <li>and Constrained Optimization.</li> </ul> <p>They work because language models are, at their core, optimization systems navigating probabilistic landscapes.</p>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#further-reading","level":2,"title":"Further Reading","text":"<ul> <li>The Attention Budget:   Why your AI forgets what you just told it, and how token budgets shape   context strategy</li> </ul>","path":["Home","Prompting Guide"],"tags":[]},{"location":"home/prompting-guide/#contributing","level":2,"title":"Contributing","text":"<p>Found a prompt that works well? Open an issue or PR with:</p> <ol> <li>The prompt text;</li> <li>What behavior it triggers;</li> <li>When to use it;</li> <li>Why it works (optional but helpful).</li> </ol> <p>Dive Deeper:</p> <ul> <li>Recipes: targeted how-to guides for specific tasks</li> <li>CLI Reference: all commands and flags</li> <li>Integrations: setup for Claude Code, Cursor, Aider</li> </ul>","path":["Home","Prompting Guide"],"tags":[]},{"location":"operations/","level":1,"title":"Operations","text":"<p>Guides for installing, upgrading, integrating, and running <code>ctx</code>.</p>","path":["Operations"],"tags":[]},{"location":"operations/#integration","level":3,"title":"Integration","text":"<p>Adopt <code>ctx</code> in an existing project: initialize context files, migrate from other tools, and onboard team members.</p>","path":["Operations"],"tags":[]},{"location":"operations/#upgrade","level":3,"title":"Upgrade","text":"<p>Upgrade between versions with step-by-step migration notes and breaking-change guidance.</p>","path":["Operations"],"tags":[]},{"location":"operations/#ai-tools","level":3,"title":"AI Tools","text":"<p>Configure <code>ctx</code> with Claude Code, Cursor, Aider, Copilot, Windsurf, and other AI coding tools.</p>","path":["Operations"],"tags":[]},{"location":"operations/#autonomous-loops","level":3,"title":"Autonomous Loops","text":"<p>Run an unattended AI agent that works through tasks overnight, with <code>ctx</code> providing persistent memory between iterations.</p>","path":["Operations"],"tags":[]},{"location":"operations/autonomous-loop/","level":1,"title":"Autonomous Loops","text":"","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#autonomous-ai-development","level":2,"title":"Autonomous AI Development","text":"<p>Iterate until done.</p> <p>An autonomous loop is an iterative AI development workflow where an agent  works on tasks until completion—without constant human intervention. </p> <p><code>ctx</code> provides the memory that makes this possible:</p> <ul> <li><code>ctx</code> provides the memory: persistent context that survives across iterations</li> <li>The loop provides the automation: continuous execution until done</li> </ul> <p>Together, they enable fully autonomous AI development where the agent remembers everything across iterations.</p> <p>Origin</p> <p>This pattern is inspired by Geoffrey Huntley's Ralph Wiggum technique.</p> <p>We use generic terminology here so the concepts remain clear regardless of trends.</p>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#how-it-works","level":2,"title":"How It Works","text":"<pre><code>graph TD\n    A[Start Loop] --&gt; B[Load PROMPT.md]\n    B --&gt; C[AI reads .context/]\n    C --&gt; D[AI picks task from TASKS.md]\n    D --&gt; E[AI completes task]\n    E --&gt; F[AI updates context files]\n    F --&gt; G[AI commits changes]\n    G --&gt; H{Check signals}\n    H --&gt;|SYSTEM_CONVERGED| I[Done - all tasks complete]\n    H --&gt;|SYSTEM_BLOCKED| J[Done - needs human input]\n    H --&gt;|Continue| B</code></pre> <ol> <li>Loop reads <code>PROMPT.md</code> and invokes AI</li> <li>AI loads context from <code>.context/</code></li> <li>AI picks one task and completes it</li> <li>AI updates context files (mark task done, add learnings)</li> <li>AI commits changes</li> <li>Loop checks for completion signals</li> <li>Repeat until converged or blocked</li> </ol>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#quick-start-shell-while-loop-recommended","level":2,"title":"Quick Start: Shell While Loop (Recommended)","text":"<p>The best way to run an autonomous loop is a plain shell script that invokes your AI tool in a fresh process on each iteration. This is \"pure ralph\":</p> <p>The only state that carries between iterations is what lives in <code>.context/</code> and the git history. No context window bleed, no accumulated tokens, no hidden state.</p> <p>Create a <code>loop.sh</code>:</p> <pre><code>#!/bin/bash\n# loop.sh — an autonomous iteration loop\n\nPROMPT_FILE=\"${1:-PROMPT.md}\"\nMAX_ITERATIONS=\"${2:-10}\"\nOUTPUT_FILE=\"/tmp/loop_output.txt\"\n\nfor i in $(seq 1 $MAX_ITERATIONS); do\n  echo \"=== Iteration $i ===\"\n\n  # Invoke AI with prompt\n  cat \"$PROMPT_FILE\" | claude --print &gt; \"$OUTPUT_FILE\" 2&gt;&amp;1\n\n  # Display output\n  cat \"$OUTPUT_FILE\"\n\n  # Check for completion signals\n  if grep -q \"SYSTEM_CONVERGED\" \"$OUTPUT_FILE\"; then\n    echo \"Loop complete: All tasks done\"\n    break\n  fi\n\n  if grep -q \"SYSTEM_BLOCKED\" \"$OUTPUT_FILE\"; then\n    echo \"Loop blocked: Needs human input\"\n    break\n  fi\n\n  sleep 2\ndone\n</code></pre> <p>Make it executable and run:</p> <pre><code>chmod +x loop.sh\n./loop.sh\n</code></pre> <p>You can also generate this script with <code>ctx loop</code> (see CLI Reference).</p>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#why-do-we-use-a-shell-loop","level":3,"title":"Why Do We Use a Shell Loop?","text":"<p>Each iteration starts a fresh AI process with zero context window history. The agent knows only what it reads from <code>.context/</code> files: Exactly the information you chose to persist. </p> <p>This is the core loop principle: memory is explicit, not accidental.</p>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#alternative-claude-codes-built-in-loop","level":2,"title":"Alternative: Claude Code's Built-in Loop","text":"<p>Claude Code has built-in loop support:</p> <pre><code># Start autonomous loop\n/loop\n\n# Cancel running loop\n/cancel-loop\n</code></pre> <p>This is convenient for quick iterations, but be aware of important caveats:</p> <p>This Loop Is not Pure</p> <p>Claude Code's <code>/loop</code> runs all iterations within the same session. This means:</p> <ul> <li>State leaks between iterations: The context window accumulates   output from every previous iteration. The agent \"remembers\" things   it saw earlier (even if they were never persisted to <code>.context/</code>).</li> <li>Token budget degrades: Each iteration adds to the context window,   leaving less room for actual work in later iterations.</li> <li>Not ergonomic for long runs: Users report that the built-in loop   is less predictable for 10+ iteration runs compared to a shell loop.</li> </ul> <p>For short explorations (2-5 iterations) or interactive use, <code>/loop</code> works fine. For overnight unattended runs or anything where iteration independence matters, use the shell while loop instead.</p>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#the-promptmd-file","level":2,"title":"The <code>PROMPT.md</code> File","text":"<p>The prompt file instructs the AI on how to work autonomously. Here's a template:</p> <pre><code># Autonomous Development Prompt\n\nYou are working on this project autonomously. Follow these steps:\n\n## 1. Load Context\n\nRead these files in order:\n1. `.context/CONSTITUTION.md` — NEVER violate these rules\n2. `.context/TASKS.md` — Find work to do\n3. `.context/CONVENTIONS.md` — Follow these patterns\n4. `.context/DECISIONS.md` — Understand past choices\n\n## 2. Pick One Task\n\nFrom `.context/TASKS.md`, select ONE task that is:\n- Not blocked\n- Highest priority available\n- Within your capabilities\n\n## 3. Complete the Task\n\n- Write code following conventions\n- Run tests if applicable\n- Keep changes focused and minimal\n\n## 4. Update Context\n\nAfter completing work:\n- Mark task complete in TASKS.md\n- Add any learnings to LEARNINGS.md\n- Add any decisions to DECISIONS.md\n\n## 5. Commit Changes\n\nCreate a focused commit with clear message.\n\n## 6. Signal Status\n\nEnd your response with exactly ONE of:\n\n- `SYSTEM_CONVERGED` — All tasks in TASKS.md are complete\n- `SYSTEM_BLOCKED` — Cannot proceed, need human input (explain why)\n- (no signal) — More work remains, continue to next iteration\n\n## Rules\n\n- ONE task per iteration\n- NEVER skip tests\n- NEVER violate CONSTITUTION.md\n- Commit after each task\n</code></pre>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#completion-signals","level":2,"title":"Completion Signals","text":"<p>The loop watches for these signals in AI output:</p> Signal Meaning When to Use <code>SYSTEM_CONVERGED</code> All tasks complete No pending tasks in TASKS.md <code>SYSTEM_BLOCKED</code> Cannot proceed Needs clarification, access, or decision <code>BOOTSTRAP_COMPLETE</code> Initial setup done Project scaffolding finished","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#example-usage","level":3,"title":"Example Usage","text":"<p>converged state</p> <pre><code>I've completed all tasks in TASKS.md:\n- [x] Set up project structure\n- [x] Implement core API\n- [x] Add authentication\n- [x] Write tests\n\nNo pending tasks remain.\n\nSYSTEM_CONVERGED\n</code></pre> <p>blocked state</p> <pre><code>I cannot proceed with the \"Deploy to production\" task because:\n- Missing AWS credentials\n- Need confirmation on region selection\n\nPlease provide credentials and confirm deployment region.\n\nSYSTEM_BLOCKED\n</code></pre>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#why-ctx-and-loops-work-well-together","level":2,"title":"Why <code>ctx</code> and  Loops Work Well Together","text":"Without <code>ctx</code> With <code>ctx</code> Each iteration starts fresh Each iteration has full history Decisions get re-made Decisions persist in <code>DECISIONS.md</code> Learnings are lost Learnings accumulate in <code>LEARNINGS.md</code> Tasks can be forgotten Tasks tracked in <code>TASKS.md</code>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#automatic-context-updates","level":3,"title":"Automatic Context Updates","text":"<p>During the loop, the AI should update context files:</p> <p>Mark task complete: <pre><code>ctx complete \"implement user auth\"\n</code></pre></p> <p>Or emit an update command (parsed by <code>ctx watch</code>): <pre><code>&lt;context-update type=\"complete\"&gt;user auth&lt;/context-update&gt;\n</code></pre></p> <p>Add learning: <pre><code>ctx add learning \"Rate limiting requires Redis connection\"\n</code></pre></p> <p>Or via update command: <pre><code>&lt;context-update type=\"learning\"\n  context=\"Implementing rate limiter\"\n  lesson=\"Rate limiting requires Redis connection\"\n  application=\"Ensure Redis is provisioned before enabling rate limits\"\n&gt;Rate Limiting Redis Dependency&lt;/context-update&gt;\n</code></pre></p> <p>Record decision: <pre><code>ctx add decision \"Use JWT tokens for API authentication\"\n</code></pre></p>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#advanced-watch-mode","level":2,"title":"Advanced: Watch Mode","text":"<p>Run <code>ctx watch</code> alongside the loop to automatically process context updates:</p> <pre><code># Terminal 1: Run the loop\n./loop.sh 2&gt;&amp;1 | tee /tmp/loop.log\n\n# Terminal 2: Watch for context updates\nctx watch --log /tmp/loop.log\n</code></pre> <p>The watch command processes context updates from the loop output in real time.</p>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#project-setup","level":2,"title":"Project Setup","text":"<p>Initialize a project for autonomous loop operation:</p> <pre><code># Initialize with autonomous agent behavior\nctx init --ralph\n</code></pre> <p>The <code>--ralph</code> flag creates a <code>PROMPT.md</code> where the agent:</p> <ul> <li>Works autonomously without asking clarifying questions;</li> <li>Follows one-task-per-iteration discipline;</li> <li>Uses <code>SYSTEM_CONVERGED</code> / <code>SYSTEM_BLOCKED</code> signals;</li> </ul> <p>Without <code>--ralph</code>, the agent is encouraged to ask questions when requirements are unclear: Better for collaborative human-agent sessions.</p>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#example-project-structure","level":2,"title":"Example Project Structure","text":"<pre><code>my-project/\n├── .context/\n│   ├── CONSTITUTION.md\n│   ├── TASKS.md          # Work items for the loop\n│   ├── DECISIONS.md\n│   ├── LEARNINGS.md\n│   ├── CONVENTIONS.md\n│   └── sessions/         # Loop iteration history\n├── PROMPT.md             # Instructions for the AI\n├── IMPLEMENTATION_PLAN.md # High-level project direction\n├── loop.sh               # Loop script (if not using Claude Code)\n└── src/                  # Your code\n</code></pre>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#sample-tasksmd-for-autonomous-loops","level":3,"title":"Sample TASKS.md for Autonomous Loops","text":"<pre><code># Tasks\n\n## Phase 1: Setup\n\n- [x] Initialize project structure\n- [x] Set up testing framework\n\n## Phase 2: Core Features\n\n- [ ] Implement user registration `#priority:high`\n- [ ] Add email verification `#priority:high`\n- [ ] Create password reset flow `#priority:medium`\n\n## Phase 3: Polish\n\n- [ ] Add rate limiting `#priority:medium`\n- [ ] Improve error messages `#priority:low`\n</code></pre> <p>The loop will work through these systematically, marking each complete.</p>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#troubleshooting","level":2,"title":"Troubleshooting","text":"","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#loop-runs-forever","level":3,"title":"Loop Runs Forever","text":"<p>Cause: AI not emitting completion signals</p> <p>Fix: Ensure PROMPT.md explicitly instructs signaling: <pre><code>End EVERY response with one of:\n- SYSTEM_CONVERGED (if all tasks done)\n- SYSTEM_BLOCKED (if stuck)\n</code></pre></p>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#context-not-persisting","level":3,"title":"Context Not Persisting","text":"<p>Cause: AI not updating context files</p> <p>Fix: Add explicit instructions to PROMPT.md: <pre><code>After completing a task, you MUST:\n1. Run: ctx complete \"&lt;task&gt;\"\n2. Add learnings: ctx add learning \"...\"\n</code></pre></p>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#tasks-getting-repeated","level":3,"title":"Tasks Getting Repeated","text":"<p>Cause: Task not marked complete before next iteration</p> <p>Fix: Ensure commit happens after context update:</p> <pre><code>Order of operations:\n1. Complete coding work\n2. Update context files (*`ctx complete`, `ctx add`*)\n3. Commit **ALL** changes including `.context/`\n4. Then signal status\n</code></pre>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#ai-violating-constitution","level":3,"title":"AI Violating Constitution","text":"<p>Cause: Constitution not read first</p> <p>Fix: Make constitution check explicit in <code>PROMPT.md</code>:</p> <pre><code>BEFORE any work:\n1. Read .context/CONSTITUTION.md\n2. If task would violate ANY rule, emit SYSTEM_BLOCKED\n3. Explain which rule prevents the work\n</code></pre>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#further-reading","level":2,"title":"Further Reading","text":"<ul> <li>Building ctx Using ctx:    The dogfooding story: how autonomous loops built the tool that powers them</li> </ul>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/autonomous-loop/#resources","level":2,"title":"Resources","text":"<ul> <li>Geoffrey Huntley's Ralph Wiggum Technique: The original inspiration</li> <li>Context CLI: Command reference</li> <li>Integrations: Tool-specific setup</li> </ul>","path":["Operations","Autonomous Loops"],"tags":[]},{"location":"operations/integrations/","level":1,"title":"AI Tools","text":"","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#ai-tools","level":2,"title":"AI Tools","text":"<p>Context works with any AI tool that can read files. This guide covers setup  for popular AI coding assistants.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#claude-code-full-integration","level":2,"title":"Claude Code (Full Integration)","text":"<p>Claude Code has the deepest integration via the ctx plugin.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#setup","level":3,"title":"Setup","text":"<p>First, install <code>ctx</code> and initialize your project:</p> <pre><code>ctx init\n</code></pre> <p>Then, install the <code>ctx</code> plugin in Claude Code:</p> <pre><code># From the ctx repository\nclaude /plugin install ./internal/assets/claude\n\n# Or from the marketplace\nclaude /plugin marketplace add ActiveMemory/ctx\nclaude /plugin install ctx@activememory-ctx\n</code></pre> <p>This gives you:</p> Component Purpose <code>.context/</code> All context files <code>CLAUDE.md</code> Bootstrap instructions Plugin hooks Lifecycle automation Plugin skills Agent Skills","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#how-it-works","level":3,"title":"How It Works","text":"<pre><code>graph TD\n    A[Session Start] --&gt; B[Claude reads CLAUDE.md]\n    B --&gt; C[PreToolUse hook runs]\n    C --&gt; D[ctx agent loads context]\n    D --&gt; E[Work happens]\n    E --&gt; F[Session End]</code></pre> <ol> <li>Session start: Claude reads <code>CLAUDE.md</code>, which tells it to check <code>.context/</code></li> <li>First tool use: <code>PreToolUse</code> hook runs <code>ctx agent</code> and emits the context    packet (subsequent invocations within the cooldown window are silent)</li> <li>Next session: Claude reads context files and continues with context</li> </ol>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#plugin-hooks","level":3,"title":"Plugin Hooks","text":"<p>The ctx plugin provides lifecycle hooks implemented as Go subcommands (<code>ctx system *</code>):</p> Hook Event Purpose <code>ctx system block-non-path-ctx</code> PreToolUse (Bash) Block <code>./ctx</code> or <code>go run</code>: force <code>$PATH</code> install <code>ctx system qa-reminder</code> PreToolUse (Edit) Remind agent to lint/test before committing <code>ctx system check-context-size</code> UserPromptSubmit Nudge context assessment as sessions grow <code>ctx system check-ceremonies</code> UserPromptSubmit Nudge /ctx-remember and /ctx-wrap-up adoption <code>ctx system check-persistence</code> UserPromptSubmit Remind to persist learnings/decisions <code>ctx system check-journal</code> UserPromptSubmit Remind to export/enrich journal entries <code>ctx system check-reminders</code> UserPromptSubmit Relay pending reminders at session start <code>ctx system check-version</code> UserPromptSubmit Warn when binary/plugin versions diverge <code>ctx system check-resources</code> UserPromptSubmit Warn when memory/swap/disk/load hit DANGER level <code>ctx system check-knowledge</code> UserPromptSubmit Nudge when knowledge files grow large <code>ctx system check-map-staleness</code> UserPromptSubmit Nudge when ARCHITECTURE.md is stale <code>ctx system post-commit</code> PostToolUse (Bash) Nudge context capture and QA after git commits <code>ctx system cleanup-tmp</code> SessionEnd Remove stale temp files (older than 15 days) <p>A catch-all <code>PreToolUse</code> hook also runs <code>ctx agent</code> on every tool use (with cooldown) to autoload context.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#hook-configuration","level":3,"title":"Hook Configuration","text":"<p>The plugin's <code>hooks.json</code> wires everything automatically — no manual configuration in <code>settings.local.json</code> needed:</p> <pre><code>{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Bash\",\n        \"hooks\": [\n          { \"type\": \"command\", \"command\": \"ctx system block-non-path-ctx\" }\n        ]\n      },\n      {\n        \"matcher\": \"Edit\",\n        \"hooks\": [\n          { \"type\": \"command\", \"command\": \"ctx system qa-reminder\" }\n        ]\n      },\n      {\n        \"matcher\": \".*\",\n        \"hooks\": [\n          { \"type\": \"command\", \"command\": \"ctx agent --budget 4000 2&gt;/dev/null || true\" }\n        ]\n      }\n    ],\n    \"PostToolUse\": [\n      {\n        \"matcher\": \"Bash\",\n        \"hooks\": [\n          { \"type\": \"command\", \"command\": \"ctx system post-commit\" }\n        ]\n      }\n    ],\n    \"UserPromptSubmit\": [\n      {\n        \"hooks\": [\n          { \"type\": \"command\", \"command\": \"ctx system check-context-size\" },\n          { \"type\": \"command\", \"command\": \"ctx system check-ceremonies\" },\n          { \"type\": \"command\", \"command\": \"ctx system check-persistence\" },\n          { \"type\": \"command\", \"command\": \"ctx system check-journal\" },\n          { \"type\": \"command\", \"command\": \"ctx system check-reminders\" },\n          { \"type\": \"command\", \"command\": \"ctx system check-version\" },\n          { \"type\": \"command\", \"command\": \"ctx system check-resources\" },\n          { \"type\": \"command\", \"command\": \"ctx system check-knowledge\" },\n          { \"type\": \"command\", \"command\": \"ctx system check-map-staleness\" }\n        ]\n      }\n    ],\n    \"SessionEnd\": [\n      {\n        \"hooks\": [\n          { \"type\": \"command\", \"command\": \"ctx system cleanup-tmp\" }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#customizing-token-budget-and-cooldown","level":3,"title":"Customizing Token Budget and Cooldown","text":"<p>Edit the <code>PreToolUse</code> command to change the token budget or cooldown:</p> <pre><code>\"command\": \"ctx agent --budget 8000 --session $PPID &gt;/dev/null || true\"\n\"command\": \"ctx agent --budget 4000 --cooldown 5m --session $PPID &gt;/dev/null || true\"\n</code></pre> <p>The <code>--session $PPID</code> flag isolates the cooldown per session — <code>$PPID</code> resolves to the Claude Code process PID, so concurrent sessions don't interfere. The default cooldown is 10 minutes; use <code>--cooldown 0</code> to disable it.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#verifying-setup","level":3,"title":"Verifying Setup","text":"<ol> <li>Start a new Claude Code session;</li> <li>Ask: \"Do you remember?\"</li> <li>Claude should cite specific context:<ul> <li>Current tasks from <code>.context/TASKS.md</code>;</li> <li>Recent decisions or learnings;</li> <li>Recent session history from <code>ctx recall</code>.</li> </ul> </li> </ol>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#local-plugin-development","level":3,"title":"Local Plugin Development","text":"<p>When developing <code>ctx</code> locally (adding skills, hooks, or changing plugin behavior), Claude Code caches the plugin by version. You must bump the version in both files and update the marketplace for changes to take effect:</p> <ol> <li>Bump version in both:</li> <li> <p><code>internal/assets/claude/.claude-plugin/plugin.json</code> (plugin manifest),    <code>.claude-plugin/marketplace.json</code> (marketplace listing*);</p> </li> <li> <p>Update the marketplace in Claude Code:</p> </li> <li>Open the Plugins UI (<code>/plugins</code> or Esc menu),</li> <li>Go to Marketplaces tab,</li> <li>Select the <code>activememory-ctx</code> Marketplace,</li> <li> <p>Choose Update marketplace;</p> </li> <li> <p>Start a new Claude Code session: skill changes aren't    reflected in existing sessions.</p> </li> </ol> <p>Both Version Files Must Match</p> <p>If you only bump <code>plugin.json</code> but not <code>marketplace.json</code> (or vice versa), Claude Code may not detect the update. Always bump both together.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#troubleshooting","level":3,"title":"Troubleshooting","text":"Issue Solution Context not loading Check <code>ctx</code> is in PATH: <code>which ctx</code> Hook errors Verify plugin is installed: <code>claude /plugin list</code> New skill not visible Bump version in both <code>plugin.json</code> files, update marketplace","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#manual-context-load","level":3,"title":"Manual Context Load","text":"<p>If hooks aren't working, manually load context:</p> <pre><code># Get context packet\nctx agent --budget 4000\n\n# Or paste into conversation\ncat .context/TASKS.md\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#agent-skills","level":3,"title":"Agent Skills","text":"<p>The ctx plugin ships Agent Skills following the agentskills.io specification.</p> <p>These are invoked in Claude Code with <code>/skill-name</code>.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#session-lifecycle-skills","level":4,"title":"Session Lifecycle Skills","text":"Skill Description <code>/ctx-remember</code> Recall project context at session start (ceremony) <code>/ctx-wrap-up</code> End-of-session context persistence (ceremony) <code>/ctx-status</code> Show context summary (tasks, decisions, learnings) <code>/ctx-agent</code> Get AI-optimized context packet <code>/ctx-next</code> Suggest 1-3 concrete next actions from context <code>/ctx-commit</code> Commit with integrated context capture <code>/ctx-reflect</code> Review session and suggest what to persist <code>/ctx-remind</code> Manage session-scoped reminders","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#context-persistence-skills","level":4,"title":"Context Persistence Skills","text":"Skill Description <code>/ctx-add-task</code> Add a task to TASKS.md <code>/ctx-add-learning</code> Add a learning to LEARNINGS.md <code>/ctx-add-decision</code> Add a decision with context/rationale/consequences <code>/ctx-add-convention</code> Add a coding convention to CONVENTIONS.md <code>/ctx-archive</code> Archive completed tasks","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#scratchpad-skills","level":4,"title":"Scratchpad Skills","text":"Skill Description <code>/ctx-pad</code> Manage encrypted scratchpad entries","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#session-history-skills","level":4,"title":"Session History Skills","text":"Skill Description <code>/ctx-recall</code> Browse AI session history <code>/ctx-journal-enrich</code> Enrich a journal entry with frontmatter/tags <code>/ctx-journal-enrich-all</code> Batch-enrich all unenriched journal entries <code>/ctx-journal-normalize</code> Fix markdown rendering issues in journal","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#blogging-skills","level":4,"title":"Blogging Skills","text":"<p>Blogging is a Better Way of Creating Release Notes</p> <p>The blogging workflow can also double as generating release notes:</p> <p>AI reads your git commit history and creates a \"narrative\", which is essentially what a release note is for.</p> Skill Description <code>/ctx-blog</code> Generate blog post from recent activity <code>/ctx-blog-changelog</code> Generate blog post from commit range with theme","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#auditing-health-skills","level":4,"title":"Auditing &amp; Health Skills","text":"Skill Description <code>/ctx-drift</code> Detect and fix context drift (structural + semantic) <code>/ctx-consolidate</code> Merge redundant learnings or decisions into denser entries <code>/ctx-alignment-audit</code> Audit doc claims against playbook instructions <code>/ctx-prompt-audit</code> Analyze session logs for vague prompts <code>/check-links</code> Audit docs for dead internal and external links","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#planning-execution-skills","level":4,"title":"Planning &amp; Execution Skills","text":"Skill Description <code>/ctx-loop</code> Generate a Ralph Loop iteration script <code>/ctx-implement</code> Execute a plan step-by-step with checks <code>/ctx-worktree</code> Manage git worktrees for parallel agents <code>/ctx-map</code> Build and maintain architecture maps","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#usage-examples","level":4,"title":"Usage Examples","text":"<pre><code>/ctx-status\n/ctx-add-learning \"Token refresh requires explicit cache invalidation\"\n/ctx-journal-enrich twinkly-stirring-kettle\n</code></pre> <p>Skills support partial matching where applicable (e.g., session slugs).</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#cursor-ide","level":2,"title":"Cursor IDE","text":"<p>Cursor can use context files through its system prompt or by reading  files directly.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#setup_1","level":3,"title":"Setup","text":"<pre><code># Generate Cursor configuration\nctx hook cursor\n\n# Initialize context\nctx init --minimal\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#configuration","level":3,"title":"Configuration","text":"<p>Add to Cursor settings (<code>.cursor/settings.json</code>):</p> <pre><code>// split to multiple lines for readability\n{\n  \"ai.systemPrompt\": \"Read .context/TASKS.md and \n  .context/CONVENTIONS.md before responding. \n  Follow rules in .context/CONSTITUTION.md.\",\n}\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#usage","level":3,"title":"Usage","text":"<ol> <li>Open your project in Cursor</li> <li>Context files are available in the file tree</li> <li>Reference them in prompts:     \"Check .context/DECISIONS.md for our approach to...\"</li> </ol>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#manual-context-injection","level":3,"title":"Manual Context Injection","text":"<p>For more control, paste context directly:</p> <pre><code># Get AI-ready packet\nctx agent --budget 4000 | pbcopy  # macOS\nctx agent --budget 4000 | xclip  # Linux\n</code></pre> <p>Paste into Cursor's chat.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#aider","level":2,"title":"Aider","text":"<p>Aider works well with context files through its <code>--read</code> flag.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#setup_2","level":3,"title":"Setup","text":"<pre><code># Generate Aider configuration\nctx hook aider\n\n# Initialize context\nctx init\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#configuration_1","level":3,"title":"Configuration","text":"<p>Create <code>.aider.conf.yml</code>:</p> <pre><code>read:\n  - .context/CONSTITUTION.md\n  - .context/TASKS.md\n  - .context/CONVENTIONS.md\n  - .context/DECISIONS.md\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#usage_1","level":3,"title":"Usage","text":"<pre><code># Start Aider (reads context files automatically)\naider\n\n# Or specify files explicitly\naider --read .context/TASKS.md --read .context/CONVENTIONS.md\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#with-watch-mode","level":3,"title":"With Watch Mode","text":"<p>Run <code>ctx watch</code> alongside Aider to capture context updates:</p> <pre><code># Terminal 1: Run Aider\naider 2&gt;&amp;1 | tee /tmp/aider.log\n\n# Terminal 2: Watch for context updates\nctx watch --log /tmp/aider.log\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#github-copilot","level":2,"title":"GitHub Copilot","text":"<p>GitHub Copilot integrates with <code>ctx</code> at three levels: an automated instructions file, a VS Code Chat extension, and manual patterns.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#setup_3","level":3,"title":"Setup","text":"<pre><code># Initialize context\nctx init\n\n# Generate .github/copilot-instructions.md\nctx hook copilot --write\n</code></pre> <p>The <code>--write</code> flag creates <code>.github/copilot-instructions.md</code>, which Copilot reads automatically at the start of every session. This file contains your project's constitution rules, current tasks, conventions, and architecture — giving Copilot persistent context without manual copy-paste.</p> <p>Re-run <code>ctx hook copilot --write</code> after updating your <code>.context/</code> files to regenerate the instructions.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#vs-code-chat-extension-ctx","level":3,"title":"VS Code Chat Extension (<code>@ctx</code>)","text":"<p>The ctx VS Code extension adds a <code>@ctx</code> chat participant to GitHub Copilot Chat, giving you direct access to all context commands from within the editor.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#installation","level":4,"title":"Installation","text":"<ol> <li>Build from source (requires Node.js 18+):</li> </ol> <pre><code>cd editors/vscode\nnpm install\nnpm run build\nnpx @vscode/vsce package\n</code></pre> <ol> <li>Install the <code>.vsix</code> file:</li> </ol> <pre><code>code --install-extension ctx-context-0.7.0.vsix\n</code></pre> <ol> <li>Reload VS Code. Type <code>@ctx</code> in Copilot Chat to verify.</li> </ol>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#slash-commands","level":4,"title":"Slash Commands","text":"Command Description <code>@ctx /init</code> Initialize <code>.context/</code> directory with template files <code>@ctx /status</code> Show context summary with token estimate <code>@ctx /agent</code> Print AI-ready context packet <code>@ctx /drift</code> Detect stale or invalid context <code>@ctx /recall</code> Browse and search AI session history <code>@ctx /hook</code> Generate AI tool integration configs <code>@ctx /add</code> Add a task, decision, or learning <code>@ctx /load</code> Output assembled context Markdown <code>@ctx /compact</code> Archive completed tasks and clean up <code>@ctx /sync</code> Reconcile context with codebase","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#usage-examples_1","level":4,"title":"Usage Examples","text":"<pre><code>@ctx /init\n@ctx /status\n@ctx /add task Implement user authentication\n@ctx /drift\n@ctx /hook copilot\n@ctx /recall\n</code></pre> <p>Typing <code>@ctx</code> without a command shows help with all available commands. The extension also supports natural language — asking <code>@ctx</code> about \"status\" or \"drift\" routes to the correct command automatically.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#configuration_2","level":4,"title":"Configuration","text":"Setting Default Description <code>ctx.executablePath</code> <code>ctx</code> Path to the ctx binary. Set this if <code>ctx</code> is not in your <code>PATH</code>.","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#follow-up-suggestions","level":4,"title":"Follow-Up Suggestions","text":"<p>After each command, the extension suggests relevant next steps. For example, after <code>/init</code> it suggests <code>/status</code> and <code>/hook</code>; after <code>/drift</code> it suggests <code>/sync</code>.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#session-persistence","level":3,"title":"Session Persistence","text":"<p><code>ctx init</code> creates a <code>.context/sessions/</code> directory for storing session data from non-Claude tools. The Markdown session parser scans this directory during <code>ctx recall</code>, enabling session history for Copilot and other tools.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#manual-patterns","level":3,"title":"Manual Patterns","text":"<p>These patterns work without the extension, using Copilot's built-in file awareness:</p> <p>Pattern 1: Keep context files open</p> <p>Open <code>.context/CONVENTIONS.md</code> in a split pane. Copilot will reference it.</p> <p>Pattern 2: Reference in comments</p> <pre><code>// See .context/CONVENTIONS.md for naming patterns\n// Following decision in .context/DECISIONS.md: Use PostgreSQL\n\nfunction getUserById(id: string) {\n  // Copilot now has context\n}\n</code></pre> <p>Pattern 3: Paste context into Copilot Chat</p> <pre><code>ctx agent --budget 2000\n</code></pre> <p>Paste output into Copilot Chat for context-aware responses.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#windsurf-ide","level":2,"title":"Windsurf IDE","text":"<p>Windsurf supports custom instructions and file-based context.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#setup_4","level":3,"title":"Setup","text":"<pre><code># Generate Windsurf configuration\nctx hook windsurf\n\n# Initialize context\nctx init\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#configuration_3","level":3,"title":"Configuration","text":"<p>Add to Windsurf settings:</p> <pre><code>// Split to multiple lines for readability\n{\n  \"ai.customInstructions\": \"Always read .context/CONSTITUTION.md first. \n  Check .context/TASKS.md for current work. \n  Follow patterns in .context/CONVENTIONS.md.\"\n}\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#usage_2","level":3,"title":"Usage","text":"<p>Context files appear in the file tree. Reference them when chatting:</p> <ul> <li>\"What's in our task list?\" → AI reads <code>.context/TASKS.md</code></li> <li>\"What convention do we use for naming?\" → AI reads <code>.context/CONVENTIONS.md</code></li> </ul>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#generic-integration","level":2,"title":"Generic Integration","text":"<p>For any AI tool that can read files, use these patterns:</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#manual-context-loading","level":3,"title":"Manual Context Loading","text":"<pre><code># Get full context\nctx load\n\n# Get AI-optimized packet\nctx agent --budget 8000\n\n# Get specific file\ncat .context/TASKS.md\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#system-prompt-template","level":3,"title":"System Prompt Template","text":"<pre><code>You are working on a project with persistent context in .context/\n\nBefore responding:\n1. Read .context/CONSTITUTION.md - NEVER violate these rules\n2. Check .context/TASKS.md for current work\n3. Follow .context/CONVENTIONS.md patterns\n4. Reference .context/DECISIONS.md for architectural choices\n\nWhen you learn something new, note it for .context/LEARNINGS.md\nWhen you make a decision, document it for .context/DECISIONS.md\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#automated-updates","level":3,"title":"Automated Updates","text":"<p>If your AI tool outputs to a log, use <code>ctx watch</code>:</p> <pre><code># Watch log file for context-update commands\nyour-ai-tool 2&gt;&amp;1 | tee /tmp/ai.log &amp;\nctx watch --log /tmp/ai.log\n</code></pre> <p>The AI can emit updates like:</p> <pre><code>&lt;context-update type=\"complete\"&gt;implement caching&lt;/context-update&gt;\n&lt;context-update type=\"learning\"\n  context=\"Implementing caching layer\"\n  lesson=\"Important thing learned today\"\n  application=\"Apply this insight going forward\"\n&gt;Caching Insight&lt;/context-update&gt;\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#context-update-commands","level":2,"title":"Context Update Commands","text":"<p>The <code>ctx watch</code> command parses update commands from AI output. Use this format:</p> <pre><code>&lt;context-update type=\"TYPE\" [attributes]&gt;Content&lt;/context-update&gt;\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#supported-types","level":3,"title":"Supported Types","text":"Type Target File Required Attributes <code>task</code> TASKS.md None <code>decision</code> DECISIONS.md <code>context</code>, <code>rationale</code>, <code>consequences</code> <code>learning</code> LEARNINGS.md <code>context</code>, <code>lesson</code>, <code>application</code> <code>convention</code> CONVENTIONS.md None <code>complete</code> TASKS.md None","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#simple-format-tasks-conventions-complete","level":3,"title":"Simple Format (tasks, conventions, complete)","text":"<pre><code>&lt;context-update type=\"task\"&gt;Implement rate limiting&lt;/context-update&gt;\n&lt;context-update type=\"convention\"&gt;Use kebab-case for files&lt;/context-update&gt;\n&lt;context-update type=\"complete\"&gt;rate limiting&lt;/context-update&gt;\n</code></pre>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#structured-format-learnings-decisions","level":3,"title":"Structured Format (learnings, decisions)","text":"<p>Learnings and decisions support structured attributes for better documentation:</p> <p>Learning with full structure:</p> <pre><code>&lt;context-update type=\"learning\"\n  context=\"Debugging Claude Code hooks\"\n  lesson=\"Hooks receive JSON via stdin, not environment variables\"\n  application=\"Parse JSON stdin with the host language (Go, Python, etc.) — no jq needed\"\n&gt;Hook Input Format&lt;/context-update&gt;\n</code></pre> <p>Decision with full structure:</p> <pre><code>&lt;context-update type=\"decision\"\n  context=\"Need a caching layer for API responses\"\n  rationale=\"Redis is fast, well-supported, and team has experience\"\n  consequences=\"Must provision Redis infrastructure; team training on Redis patterns\"\n&gt;Use Redis for caching&lt;/context-update&gt;\n</code></pre> <p>Learnings require: <code>context</code>, <code>lesson</code>, <code>application</code> attributes. Decisions require: <code>context</code>, <code>rationale</code>, <code>consequences</code> attributes. Updates missing required attributes are rejected with an error.</p>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/integrations/#further-reading","level":2,"title":"Further Reading","text":"<ul> <li>Skills That Fight the Platform — Common pitfalls in skill design that work against the host tool</li> <li>The Anatomy of a Skill That Works — What makes a skill reliable: the E/A/R framework and quality gates</li> </ul>","path":["Operations","AI Tools"],"tags":[]},{"location":"operations/migration/","level":1,"title":"Integration","text":"","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#adopting-ctx-in-existing-projects","level":2,"title":"Adopting <code>ctx</code> in Existing Projects","text":"<p>Claude Code User?</p> <p>You probably want the plugin instead of this page. Install ctx from the marketplace (<code>/plugin</code> → search \"ctx\" → Install) and you're done — hooks, skills, and updates are handled for you. See Getting Started for the full walkthrough.</p> <p>This guide covers adopting <code>ctx</code> in existing projects — regardless of which tools your team uses.</p>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#quick-paths","level":2,"title":"Quick Paths","text":"You have... Command What happens Nothing (greenfield) <code>ctx init</code> Creates <code>.context/</code>, <code>CLAUDE.md</code>, permissions Existing <code>CLAUDE.md</code> <code>ctx init --merge</code> Backs up your file, inserts <code>ctx</code> block after the H1 Existing <code>CLAUDE.md</code> + <code>ctx</code> markers <code>ctx init --force</code> Replaces the <code>ctx</code> block, leaves your content intact <code>.cursorrules</code> / <code>.aider.conf.yml</code> <code>ctx init</code> <code>ctx</code> ignores those files — they coexist cleanly Team repo, first adopter <code>ctx init --merge &amp;&amp; git add .context/ CLAUDE.md</code> Initialize and commit for the team","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#existing-claudemd","level":2,"title":"Existing <code>CLAUDE.md</code>","text":"<p>This is the most common scenario. You have a <code>CLAUDE.md</code> with project-specific instructions and don't want to lose them.</p>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#what-ctx-init-does","level":3,"title":"What <code>ctx init</code> Does","text":"<p>When <code>ctx init</code> detects an existing <code>CLAUDE.md</code>, it checks for ctx markers (<code>&lt;!-- ctx:context --&gt;</code> ... <code>&lt;!-- ctx:end --&gt;</code>):</p> State Default behavior With <code>--merge</code> With <code>--force</code> No <code>CLAUDE.md</code> Creates from template Creates from template Creates from template Exists, no ctx markers Prompts to merge Auto-merges (no prompt) Auto-merges (no prompt) Exists, has ctx markers Skips (already set up) Skips Replaces ctx block only","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#the-merge-flag","level":3,"title":"The <code>--merge</code> Flag","text":"<p><code>--merge</code> auto-merges without prompting. The merge process:</p> <ol> <li>Backs up your existing <code>CLAUDE.md</code> to <code>CLAUDE.md.&lt;timestamp&gt;.bak</code>;</li> <li>Finds the H1 heading (e.g., <code># My Project</code>) in your file;</li> <li>Inserts the <code>ctx</code> block immediately after it;</li> <li>Preserves everything else untouched.</li> </ol> <p>Your content before and after the ctx block remains exactly as it was.</p>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#before-after-example","level":3,"title":"Before / After Example","text":"<p>Before: your existing <code>CLAUDE.md</code>:</p> <pre><code># My Project\n\n## Build Commands\n\n-`npm run build` — production build\n- `npm test` — run tests\n\n## Code Style\n\n- Use TypeScript strict mode\n- Prefer named exports\n</code></pre> <p>After <code>ctx init --merge</code>:</p> <pre><code># My Project\n\n&lt;!-- ctx:context --&gt;\n&lt;!-- DO NOT REMOVE: This marker indicates ctx-managed content --&gt;\n\n## IMPORTANT: You Have Persistent Memory\n\nThis project uses Context (`ctx`) for context persistence across sessions.\n...\n\n&lt;!-- ctx:end --&gt;\n\n## Build Commands\n\n- `npm run build` — production build\n- `npm test` — run tests\n\n## Code Style\n\n- Use TypeScript strict mode\n- Prefer named exports\n</code></pre> <p>Your build commands and code style sections are untouched. The <code>ctx</code> block sits between markers and can be updated independently.</p>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#the-force-flag","level":3,"title":"The <code>--force</code> Flag","text":"<p>If your <code>CLAUDE.md</code> already has <code>ctx</code> markers (from a previous <code>ctx init</code>), the default behavior is to skip it. Use <code>--force</code> to replace the <code>ctx</code> block with the latest template: This is useful after upgrading <code>ctx</code>:</p> <pre><code>ctx init --force\n</code></pre> <p>This only replaces content between <code>&lt;!-- ctx:context --&gt;</code> and <code>&lt;!-- ctx:end --&gt;</code>. Your own content outside the markers is preserved. A timestamped backup is created before any changes.</p>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#undoing-a-merge","level":3,"title":"Undoing a Merge","text":"<p>Every merge creates a backup:</p> <pre><code>$ ls CLAUDE.md*.bak\nCLAUDE.md.1738000000.bak\n</code></pre> <p>To restore:</p> <pre><code>cp CLAUDE.md.1738000000.bak CLAUDE.md\n</code></pre> <p>Or if you are using <code>git</code>, simply:</p> <pre><code>git checkout CLAUDE.md\n</code></pre>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#existing-cursorrules-aider-copilot","level":2,"title":"Existing <code>.cursorrules</code> / Aider / Copilot","text":"<p><code>ctx</code> doesn't touch tool-specific config files. It creates its own files (<code>.context/</code>, <code>CLAUDE.md</code>) and coexists with whatever you already have.</p>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#what-does-ctx-create","level":3,"title":"What Does <code>ctx</code> Create?","text":"<code>ctx</code> creates <code>ctx</code> does NOT touch <code>.context/</code> directory <code>.cursorrules</code> <code>CLAUDE.md</code> (or merges into) <code>.aider.conf.yml</code> <code>.claude/settings.local.json</code> (seeded by <code>ctx init</code>; the plugin manages hooks and skills) <code>.github/copilot-instructions.md</code> <code>.windsurfrules</code> Any other tool-specific config <p>Claude Code hooks and skills are provided by the ctx plugin, installed from the Claude Code marketplace (<code>/plugin</code> → search \"ctx\" → Install).</p>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#running-ctx-alongside-other-tools","level":3,"title":"Running <code>ctx</code> Alongside Other Tools","text":"<p>The <code>.context/</code> directory is the source of truth. Tool-specific configs point to it:</p> <ul> <li>Cursor: Reference <code>.context/</code> files in your system prompt   (see Cursor setup)</li> <li>Aider: Add <code>.context/</code> files to the <code>read:</code> list in <code>.aider.conf.yml</code>   (see Aider setup)</li> <li>Copilot: Keep <code>.context/</code> files open or reference them in comments   (see Copilot setup)</li> </ul> <p>You can generate a tool-specific configuration with:</p> <pre><code>ctx hook cursor    # Generate Cursor config snippet\nctx hook aider     # Generate .aider.conf.yml\nctx hook copilot   # Generate Copilot tips\nctx hook windsurf  # Generate Windsurf config\n</code></pre>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#migrating-content-into-context","level":3,"title":"Migrating Content Into <code>.context/</code>","text":"<p>If you have project knowledge scattered across <code>.cursorrules</code> or custom prompt files, consider migrating it:</p> <ol> <li>Rules / invariants → <code>.context/CONSTITUTION.md</code></li> <li>Code patterns → <code>.context/CONVENTIONS.md</code></li> <li>Architecture notes → <code>.context/ARCHITECTURE.md</code></li> <li>Known issues / tips → <code>.context/LEARNINGS.md</code></li> </ol> <p>You don't need to delete the originals — ctx and tool-specific files can coexist. But centralizing in <code>.context/</code> means every tool gets the same context.</p>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#team-adoption","level":2,"title":"Team Adoption","text":"","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#context-is-designed-to-be-committed","level":3,"title":"<code>.context/</code> Is Designed to Be Committed","text":"<p>The <code>.context/</code> directory is meant to live in version control. It contains project knowledge, not secrets or personal preferences.</p> <pre><code># One person initializes\nctx init --merge\n\n# Commit everything\ngit add .context/ CLAUDE.md\ngit commit -m \"Add ctx context management\"\ngit push\n</code></pre> <p>Teammates pull and immediately have context. No per-developer setup needed.</p>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#what-about-claude","level":3,"title":"What About <code>.claude/</code>?","text":"<p>The <code>.claude/</code> directory contains permissions that <code>ctx init</code> seeds. Hooks and skills are provided by the <code>ctx</code> plugin (not per-project files).</p> File Commit? Why <code>.claude/settings.local.json</code> No Machine-specific, accumulates session permissions <code>.claude/settings.golden.json</code> Yes Curated permission snapshot (via <code>ctx permissions snapshot</code>)","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#merge-conflicts-in-context-files","level":3,"title":"Merge Conflicts in Context Files","text":"<p>Context files are plain Markdown. Resolve conflicts the same way you would for any other documentation file:</p> <pre><code># After a conflicting pull\ngit diff .context/TASKS.md    # See both sides\n# Edit to keep both sets of tasks, then:\ngit add .context/TASKS.md\ngit commit\n</code></pre> <p>Common conflict scenarios:</p> <ul> <li>TASKS.md: Two people added tasks: Keep both.</li> <li>DECISIONS.md: Same decision recorded differently: Unify the entry.</li> <li>LEARNINGS.md: Parallel discoveries: Keep both, remove duplicates.</li> </ul>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#gradual-adoption","level":3,"title":"Gradual Adoption","text":"<p>You don't need the whole team to switch at once:</p> <ol> <li>One person runs <code>ctx init --merge</code> and commits;</li> <li><code>CLAUDE.md</code> instructions work immediately for Claude Code users;</li> <li>Other tool users can adopt at their own pace using <code>ctx hook &lt;tool&gt;</code>;</li> <li>Context files benefit everyone who reads them, even without tool integration.</li> </ol>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#verifying-it-worked","level":2,"title":"Verifying It Worked","text":"","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#check-status","level":3,"title":"Check Status","text":"<pre><code>ctx status\n</code></pre> <p>You should see your context files listed with token counts and no warnings.</p>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#test-memory","level":3,"title":"Test Memory","text":"<p>Start a new AI session and ask: \"Do you remember?\"</p> <p>The AI should cite specific context:</p> <ul> <li>Current tasks from <code>.context/TASKS.md</code>;</li> <li>Recent decisions or learnings;</li> <li>Session history (if you've had prior sessions);</li> </ul> <p>If it responds with generic \"I don't have memory\", check that <code>ctx</code> is in your PATH (<code>which ctx</code>) and that hooks are configured (see Troubleshooting).</p>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#verify-the-merge","level":3,"title":"Verify the Merge","text":"<p>If you used <code>--merge</code>, check that your original content is intact:</p> <pre><code># Your original content should still be there\ncat CLAUDE.md\n\n# The ctx block should be between markers\ngrep -c \"ctx:context\" CLAUDE.md  # Should print 1\ngrep -c \"ctx:end\" CLAUDE.md      # Should print 1\n</code></pre>","path":["Operations","Integration"],"tags":[]},{"location":"operations/migration/#further-reading","level":2,"title":"Further Reading","text":"<ul> <li>Getting Started: Full setup walkthrough</li> <li>Context Files: What each <code>.context/</code> file does</li> <li>Integrations: Per-tool setup (Claude Code, Cursor, Aider, Copilot)</li> <li>CLI Reference: All <code>ctx</code> commands and flags</li> </ul>","path":["Operations","Integration"],"tags":[]},{"location":"operations/upgrading/","level":1,"title":"Upgrade","text":"","path":["Operations","Upgrade"],"tags":[]},{"location":"operations/upgrading/#upgrade","level":2,"title":"Upgrade","text":"<p>New versions of <code>ctx</code> may ship updated permissions, <code>CLAUDE.md</code> directives, or plugin hooks and skills.</p> <p>Claude Code User?</p> <p>The marketplace can update skills, hooks, and prompts independently: <code>/plugin</code> → select ctx → Update now (or enable auto-update).</p> <p>The <code>ctx</code> binary is separate — rebuild from source or download a new release when one is available, then run <code>ctx init --force --merge</code>. Knowledge files are preserved automatically.</p>","path":["Operations","Upgrade"],"tags":[]},{"location":"operations/upgrading/#what-changes-between-versions","level":2,"title":"What Changes Between Versions","text":"<p><code>ctx init</code> generates two categories of files:</p> Category Examples Changes between versions? Infrastructure <code>.claude/settings.local.json</code> (permissions), ctx-managed sections in <code>CLAUDE.md</code> and <code>PROMPT.md</code>, ctx plugin (hooks + skills) Yes Knowledge <code>.context/TASKS.md</code>, <code>DECISIONS.md</code>, <code>LEARNINGS.md</code>, <code>CONVENTIONS.md</code>, <code>ARCHITECTURE.md</code>, <code>GLOSSARY.md</code>, <code>CONSTITUTION.md</code>, <code>AGENT_PLAYBOOK.md</code> No: this is your data <p>Infrastructure is regenerated by <code>ctx init</code> and plugin updates. Knowledge files are yours and should never be overwritten.</p>","path":["Operations","Upgrade"],"tags":[]},{"location":"operations/upgrading/#upgrade-steps","level":2,"title":"Upgrade Steps","text":"","path":["Operations","Upgrade"],"tags":[]},{"location":"operations/upgrading/#1-install-the-new-version","level":3,"title":"1. Install the New Version","text":"<p>Build from source or download the binary:</p> <pre><code>cd /path/to/ctx-source\ngit pull\nmake build\nsudo make install\nctx --version   # verify\n</code></pre>","path":["Operations","Upgrade"],"tags":[]},{"location":"operations/upgrading/#2-reinitialize","level":3,"title":"2. Reinitialize","text":"<pre><code>ctx init --force --merge\n</code></pre> <ul> <li><code>--force</code> regenerates infrastructure files (permissions, ctx-managed   sections in <code>CLAUDE.md</code> and <code>PROMPT.md</code>).</li> <li><code>--merge</code> preserves your content outside <code>ctx</code> markers.</li> </ul> <p>Knowledge files (<code>.context/TASKS.md</code>, <code>DECISIONS.md</code>, etc.) are preserved automatically — <code>ctx init</code> only overwrites infrastructure, never your data.</p> <p>Encryption key: If you use <code>ctx pad</code>, verify that <code>.context/.context.key</code> is still present after reinit. It should be preserved, but losing it means losing access to encrypted scratchpad data.</p>","path":["Operations","Upgrade"],"tags":[]},{"location":"operations/upgrading/#3-update-the-ctx-plugin","level":3,"title":"3. Update the <code>ctx</code> Plugin","text":"<p>If you use Claude Code, update the plugin to get new hooks and skills:</p> <ol> <li>Open <code>/plugin</code> in Claude Code.</li> <li>Select ctx.</li> <li>Click Update now.</li> </ol> <p>Or enable auto-update so the plugin stays current without manual steps.</p>","path":["Operations","Upgrade"],"tags":[]},{"location":"operations/upgrading/#4-review-custom-settings","level":3,"title":"4. Review Custom Settings","text":"<p>If you added custom permissions to <code>.claude/settings.local.json</code> beyond what <code>ctx init</code> provides, diff and merge:</p> <pre><code>diff .claude.bak/settings.local.json .claude/settings.local.json\n</code></pre> <p>Manually add back any custom entries that the new init dropped.</p>","path":["Operations","Upgrade"],"tags":[]},{"location":"operations/upgrading/#5-verify","level":3,"title":"5. Verify","text":"<pre><code>ctx status          # context files intact\nctx drift           # no broken references\n</code></pre>","path":["Operations","Upgrade"],"tags":[]},{"location":"operations/upgrading/#6-clean-up","level":3,"title":"6. Clean Up","text":"<p>If you made manual backups, remove them once satisfied:</p> <pre><code>rm -rf .context.bak .claude.bak CLAUDE.md.bak PROMPT.md.bak\n</code></pre>","path":["Operations","Upgrade"],"tags":[]},{"location":"operations/upgrading/#what-if-i-skip-the-upgrade","level":2,"title":"What If I Skip the Upgrade?","text":"<p>The old binary still works with your existing <code>.context/</code> files. But you may miss:</p> <ul> <li>New plugin hooks that enforce better practices or catch mistakes;</li> <li>Updated skill prompts that produce better results;</li> <li>New <code>.gitignore</code> entries for directories added in newer versions;</li> <li>Bug fixes in the CLI itself.</li> </ul> <p>The plugin and the binary can be updated independently. You can update the plugin (for new hooks/skills) even if you stay on an older binary, and vice versa.</p> <p>Context files are plain Markdown: They never break between versions.</p> <p>The surrounding infrastructure is what evolves.</p>","path":["Operations","Upgrade"],"tags":[]},{"location":"operations/upgrading/#quick-reference","level":2,"title":"Quick Reference","text":"<pre><code># Plugin users (Claude Code)\n# /plugin → select ctx → Update now\n# Then update the binary and reinitialize:\nctx init --force --merge\n\n# From-source / manual users\n# install new ctx binary, then:\nctx init --force --merge\n# /plugin → select ctx → Update now   (if using Claude Code)\n</code></pre>","path":["Operations","Upgrade"],"tags":[]},{"location":"recipes/","level":1,"title":"Recipes","text":"<p>Workflow recipes combining <code>ctx</code> commands and skills to solve specific problems.</p>","path":["Recipes"],"tags":[]},{"location":"recipes/#getting-started","level":2,"title":"Getting Started","text":"","path":["Recipes"],"tags":[]},{"location":"recipes/#guide-your-agent","level":3,"title":"Guide Your Agent","text":"<p>How commands, skills, and conversational patterns work together. Train your agent to be proactive through ask, guide, reinforce.</p>","path":["Recipes"],"tags":[]},{"location":"recipes/#setup-across-ai-tools","level":3,"title":"Setup Across AI Tools","text":"<p>Initialize <code>ctx</code> and configure hooks for Claude Code, Cursor, Aider, Copilot, or Windsurf. Includes shell completion, watch mode for non-native tools, and verification.</p> <p>Uses: <code>ctx init</code>, <code>ctx hook</code>, <code>ctx agent</code>, <code>ctx completion</code>, <code>ctx watch</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#keeping-context-in-a-separate-repo","level":3,"title":"Keeping Context in a Separate Repo","text":"<p>Store context files outside the project tree: in a private repo, shared directory, or anywhere else. Useful for open source projects with private context or multi-repo setups.</p> <p>Uses: <code>ctx init</code>, <code>--context-dir</code>, <code>--allow-outside-cwd</code>, <code>.ctxrc</code>, <code>/ctx-status</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#sessions","level":2,"title":"Sessions","text":"","path":["Recipes"],"tags":[]},{"location":"recipes/#the-complete-session","level":3,"title":"The Complete Session","text":"<p>Walk through a full <code>ctx</code> session from start to finish:</p> <ul> <li>Loading context,</li> <li>Picking what to work on,</li> <li>Committing with context,</li> <li>Capturing, reflecting, and saving a snapshot.</li> </ul> <p>Uses: <code>ctx status</code>, <code>ctx agent</code>, <code>/ctx-remember</code>, <code>/ctx-next</code>, <code>/ctx-commit</code>, <code>/ctx-reflect</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#session-ceremonies","level":3,"title":"Session Ceremonies","text":"<p>The two bookend rituals for every session: <code>/ctx-remember</code> at the start to load and confirm context, <code>/ctx-wrap-up</code> at the end to review the session and persist learnings, decisions, and tasks.</p> <p>Uses: <code>/ctx-remember</code>, <code>/ctx-wrap-up</code>, <code>/ctx-commit</code>, <code>ctx agent</code>, <code>ctx add</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#browsing-and-enriching-past-sessions","level":3,"title":"Browsing and Enriching Past Sessions","text":"<p>Export your AI session history to a browsable journal site. Enrich entries with metadata and search across months of work.</p> <p>Uses: <code>ctx recall list/show/export</code>, <code>ctx journal site</code>, <code>ctx journal obsidian</code>, <code>ctx serve</code>, <code>/ctx-recall</code>, <code>/ctx-journal-normalize</code>, <code>/ctx-journal-enrich</code>, <code>/ctx-journal-enrich-all</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#session-reminders","level":3,"title":"Session Reminders","text":"<p>Leave a message for your next session. Reminders surface automatically at session start and repeat until dismissed. Date-gate reminders to surface only after a specific date.</p> <p>Uses: <code>ctx remind</code>, <code>ctx remind list</code>, <code>ctx remind dismiss</code>, <code>ctx system check-reminders</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#knowledge-tasks","level":2,"title":"Knowledge &amp; Tasks","text":"","path":["Recipes"],"tags":[]},{"location":"recipes/#persisting-decisions-learnings-and-conventions","level":3,"title":"Persisting Decisions, Learnings, and Conventions","text":"<p>Record architectural decisions with rationale, capture gotchas and lessons learned, and codify conventions so they survive across sessions and team members.</p> <p>Uses: <code>ctx add decision</code>, <code>ctx add learning</code>, <code>ctx add convention</code>, <code>ctx decisions reindex</code>, <code>ctx learnings reindex</code>, <code>/ctx-add-decision</code>, <code>/ctx-add-learning</code>, <code>/ctx-add-convention</code>, <code>/ctx-reflect</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#tracking-work-across-sessions","level":3,"title":"Tracking Work Across Sessions","text":"<p>Add, prioritize, complete, snapshot, and archive tasks. Keep <code>TASKS.md</code> focused as your project evolves across dozens of sessions.</p> <p>Uses: <code>ctx add task</code>, <code>ctx complete</code>, <code>ctx tasks archive</code>, <code>ctx tasks snapshot</code>, <code>/ctx-add-task</code>, <code>/ctx-archive</code>, <code>/ctx-next</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#using-the-scratchpad","level":3,"title":"Using the Scratchpad","text":"<p>Use the encrypted scratchpad for quick notes, working memory, and sensitive values during AI sessions. Natural language in, encrypted storage out.</p> <p>Uses: <code>ctx pad</code>, <code>/ctx-pad</code>, <code>ctx pad show</code>, <code>ctx pad edit</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#syncing-scratchpad-notes-across-machines","level":3,"title":"Syncing Scratchpad Notes Across Machines","text":"<p>Distribute your scratchpad encryption key, push and pull encrypted notes via git, and resolve merge conflicts when two machines edit simultaneously.</p> <p>Uses: <code>ctx init</code>, <code>ctx pad</code>, <code>ctx pad resolve</code>, <code>scp</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#hooks-notifications","level":2,"title":"Hooks &amp; Notifications","text":"","path":["Recipes"],"tags":[]},{"location":"recipes/#hook-output-patterns","level":3,"title":"Hook Output Patterns","text":"<p>Choose the right output pattern for your Claude Code hooks: <code>VERBATIM</code> relay for user-facing reminders, hard gates for invariants, agent directives for nudges, and five more patterns across the spectrum.</p> <p>Uses: ctx plugin hooks, <code>settings.local.json</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#auditing-system-hooks","level":3,"title":"Auditing System Hooks","text":"<p>The 12 system hooks that run invisibly during every session — what each one does, why it exists, and how to verify they're actually firing. Covers webhook-based audit trails, log inspection, and detecting silent hook failures.</p> <p>Uses: <code>ctx system</code>, <code>ctx notify</code>, <code>.context/logs/</code>, <code>.ctxrc</code> <code>notify.events</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#webhook-notifications","level":3,"title":"Webhook Notifications","text":"<p>Get push notifications when loops complete, hooks fire, or agents hit milestones. Webhook URL is encrypted — never stored in plaintext. Works with IFTTT, Slack, Discord, ntfy.sh, or any HTTP endpoint.</p> <p>Uses: <code>ctx notify setup</code>, <code>ctx notify test</code>, <code>ctx notify --event</code>, <code>.ctxrc</code> <code>notify.events</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#maintenance","level":2,"title":"Maintenance","text":"","path":["Recipes"],"tags":[]},{"location":"recipes/#detecting-and-fixing-drift","level":3,"title":"Detecting and Fixing Drift","text":"<p>Keep context files accurate by detecting structural drift (stale paths, missing files, stale file ages) and task staleness. Includes alignment audits to verify documentation claims match agent instructions.</p> <p>Uses: <code>ctx drift</code>, <code>ctx sync</code>, <code>ctx compact</code>, <code>ctx status</code>, <code>/ctx-drift</code>, <code>/ctx-alignment-audit</code>, <code>/ctx-status</code>, <code>/ctx-prompt-audit</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#claude-code-permission-hygiene","level":3,"title":"Claude Code Permission Hygiene","text":"<p>Keep <code>.claude/settings.local.json</code> clean: recommended safe defaults, what to never pre-approve, and a maintenance workflow for cleaning up session debris.</p> <p>Uses: <code>ctx init</code>, <code>/ctx-drift</code>, <code>/sanitize-permissions</code>, <code>ctx permissions snapshot</code>, <code>ctx permissions restore</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#permission-snapshots","level":3,"title":"Permission Snapshots","text":"<p>Capture a known-good permission baseline as a golden image, then restore at session start to automatically drop session-accumulated permissions.</p> <p>Uses: <code>ctx permissions snapshot</code>, <code>ctx permissions restore</code>, <code>/sanitize-permissions</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#turning-activity-into-content","level":3,"title":"Turning Activity into Content","text":"<p>Generate blog posts from project activity, write changelog posts from commit ranges, and publish a browsable journal site from your session history.</p> <p>The output is generic Markdown, but the skills are tuned for the <code>ctx</code>-style blog artifacts you see on this website.</p> <p>Uses: <code>ctx journal site</code>, <code>ctx journal obsidian</code>, <code>ctx serve</code>, <code>ctx recall export</code>, <code>/ctx-blog</code>, <code>/ctx-blog-changelog</code>, <code>/ctx-journal-enrich</code>, <code>/ctx-journal-normalize</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#agents-automation","level":2,"title":"Agents &amp; Automation","text":"","path":["Recipes"],"tags":[]},{"location":"recipes/#running-an-unattended-ai-agent","level":3,"title":"Running an Unattended AI Agent","text":"<p>Set up a loop where an AI agent works through tasks overnight without you at the keyboard, using <code>ctx</code> for persistent memory between iterations.</p> <p>This recipe shows how <code>ctx</code> supports long-running agent loops without losing context or intent.</p> <p>Uses: <code>ctx init --ralph</code>, <code>ctx loop</code>, <code>ctx watch</code>, <code>ctx load</code>, <code>/ctx-loop</code>, <code>/ctx-implement</code>, <code>/ctx-context-monitor</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#when-to-use-a-team-of-agents","level":3,"title":"When to Use a Team of Agents","text":"<p>Decision framework for choosing between a single agent, parallel worktrees, and a full agent team.</p> <p>This recipe covers the file overlap test, when teams make things worse, and what ctx provides at each level.</p> <p>Uses: <code>/ctx-worktree</code>, <code>/ctx-next</code>, <code>ctx status</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#parallel-agent-development-with-git-worktrees","level":3,"title":"Parallel Agent Development with Git Worktrees","text":"<p>Split a large backlog across 3-4 agents using git worktrees, each on its own branch and working directory. Group tasks by file overlap, work in parallel, merge back.</p> <p>Uses: <code>/ctx-worktree</code>, <code>/ctx-next</code>, <code>git worktree</code>, <code>git merge</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/autonomous-loops/","level":1,"title":"Running an Unattended AI Agent","text":"","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#the-problem","level":2,"title":"The Problem","text":"<p>You have a project with a clear list of tasks, and you want an AI agent to work through them autonomously: overnight, unattended, without you sitting at the keyboard.</p> <p>Each iteration needs to remember what the previous one did, mark tasks as completed, and know when to stop.</p> <p>Without persistent memory, every iteration starts fresh and the loop collapses. With <code>ctx</code>, each iteration can pick up where the last one left off, but only if the agent persists its context as part of the work.</p> <p>Unattended operation works because the agent treats context persistence as a first-class deliverable, not an afterthought.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#tldr","level":2,"title":"TL;DR","text":"<pre><code>ctx init --ralph                            # 1. init for unattended mode\n# Edit TASKS.md with phased work items\nctx loop --tool claude --max-iterations 10  # 2. generate loop.sh\n./loop.sh 2&gt;&amp;1 | tee /tmp/loop.log &amp;        # 3. run the loop\nctx watch --log /tmp/loop.log               # 4. process context updates\n# Next morning:\nctx status &amp;&amp; ctx load                      # 5. review the results\n</code></pre> <p>Read on for permissions, isolation, and completion signals.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx init --ralph</code> Command Initialize project for unattended operation (no human in the loop) <code>ctx loop</code> Command Generate the loop shell script <code>ctx watch</code> Command Monitor AI output and persist context updates <code>ctx load</code> Command Display assembled context (for debugging) <code>/ctx-loop</code> Skill Generate loop script from inside Claude Code <code>/ctx-implement</code> Skill Execute a plan step-by-step with verification <code>/ctx-context-monitor</code> Skill Automated context capacity alerts during long sessions","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-1-initialize-for-unattended-operation","level":3,"title":"Step 1: Initialize for Unattended Operation","text":"<p>Start by creating a <code>.context/</code> directory configured so the agent can work without human input. The <code>--ralph</code> flag sets up <code>PROMPT.md</code> so the agent makes reasonable choices instead of asking clarifying questions.</p> <pre><code>ctx init --ralph\n````\n\nThis creates `.context/` with the template files, a `PROMPT.md` configured for\nautonomous iteration, and seeds Claude Code permissions in\n`.claude/settings.local.json`. Install the `ctx` plugin for hooks and skills.\n\nWithout `--ralph`, the agent will often pause when requirements are unclear.\nFor unattended runs, you want it to choose a default and document the trade-off\nin `DECISIONS.md` instead.\n\n### Step 2: Populate `TASKS.md` with Phased Work\n\nOpen `.context/TASKS.md` and organize your work into phases. The agent works\nthrough these systematically, top to bottom, using priority tags to break ties.\n\n```markdown\n# Tasks\n\n## Phase 1: Foundation\n\n- [ ] Set up project structure and build system `#priority:high`\n- [ ] Configure testing framework `#priority:high`\n- [ ] Create CI pipeline `#priority:medium`\n\n## Phase 2: Core Features\n\n- [ ] Implement user registration `#priority:high`\n- [ ] Add email verification `#priority:high`\n- [ ] Create password reset flow `#priority:medium`\n\n## Phase 3: Hardening\n\n- [ ] Add rate limiting to API endpoints `#priority:medium`\n- [ ] Improve error messages `#priority:low`\n- [ ] Write integration tests `#priority:medium`\n</code></pre> <p>Phased organization matters because it gives the agent natural boundaries. Phase 1 tasks should be completable without Phase 2 code existing yet.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-3-configure-promptmd","level":3,"title":"Step 3: Configure PROMPT.md","text":"<p>The <code>--ralph</code> flag generates a <code>PROMPT.md</code> that instructs the agent to operate autonomously:</p> <ol> <li>Read <code>.context/CONSTITUTION.md</code> first (hard rules, never violated)</li> <li>Load context from <code>.context/</code> files</li> <li>Pick one task per iteration</li> <li>Complete the task and update context files</li> <li>Commit changes (including <code>.context/</code>)</li> <li>Signal status with a completion signal</li> </ol> <p>You can customize <code>PROMPT.md</code> for your project. The critical parts are the one-task-per-iteration discipline, proactive context persistence, and completion signals at the end:</p> <pre><code>## Signal Status\n\nEnd your response with exactly ONE of:\n\n- `SYSTEM_CONVERGED` — All tasks in `TASKS.md` are complete (*this is the\n  signal the loop script detects by default*)\n- `SYSTEM_BLOCKED` — Cannot proceed, need human input (explain why)\n- (no signal) — More work remains, continue to next iteration\n\nNote: the loop script only checks for `SYSTEM_CONVERGED` by default.\n`SYSTEM_BLOCKED` is a convention for the human reviewing the log.\n</code></pre>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-4-configure-permissions","level":3,"title":"Step 4: Configure Permissions","text":"<p>An unattended agent needs permission to use tools without prompting. By default, Claude Code asks for confirmation on file writes, bash commands, and other operations, which stops the loop and waits for a human who is not there.</p> <p>There are two approaches.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#option-a-explicit-allowlist-recommended","level":4,"title":"Option A: Explicit Allowlist (Recommended)","text":"<p>Grant only the permissions the agent needs. In <code>.claude/settings.local.json</code>:</p> <pre><code>{\n  \"permissions\": {\n    \"allow\": [\n      \"Bash(make:*)\",\n      \"Bash(go:*)\",\n      \"Bash(git:*)\",\n      \"Bash(ctx:*)\",\n      \"Read\",\n      \"Write\",\n      \"Edit\"\n    ]\n  }\n}\n</code></pre> <p>Adjust the <code>Bash</code> patterns for your project's toolchain. The agent can run <code>make</code>, <code>go</code>, <code>git</code>, and <code>ctx</code> commands but cannot run arbitrary shell commands.</p> <p>This is recommended even in sandboxed environments because it limits blast radius.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#option-b-skip-all-permission-checks","level":4,"title":"Option B: Skip All Permission Checks","text":"<p>Claude Code supports a <code>--dangerously-skip-permissions</code> flag that disables all permission prompts:</p> <pre><code>claude --dangerously-skip-permissions -p \"$(cat .context/PROMPT.md)\"\n</code></pre> <p>This Flag Means What It Says</p> <p>With <code>--dangerously-skip-permissions</code>, the agent can execute any shell command, write to any file, and make network requests without confirmation.</p> <p>Only use this on a sandboxed machine: ideally a virtual machine with no access to host credentials, no SSH keys, and no access to production systems.</p> <p>If you would not give an untrusted intern <code>sudo</code> on this machine, do not use this flag.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#enforce-isolation-at-the-os-level","level":4,"title":"Enforce Isolation at the OS Level","text":"<p>The only controls an agent cannot override are the ones enforced by the operating system, the container runtime, or the hypervisor.</p> <p>Do Not Skip This Section</p> <p>This is not optional hardening:</p> <p>An unattended agent with unrestricted OS access is an unattended shell with unrestricted OS access. </p> <p>The allowlist above is a strong first layer, but do not rely on a single runtime boundary.</p> <p>For unattended runs, enforce isolation at the infrastructure level:</p> Layer What to enforce User account Run the agent as a dedicated unprivileged user with no <code>sudo</code> access and no membership in privileged groups (<code>docker</code>, <code>wheel</code>, <code>adm</code>). Filesystem Restrict the project directory via POSIX permissions or ACLs. The agent should have no access to other users' files or system directories. Container Run inside a Docker/Podman sandbox. Mount only the project directory. Drop capabilities (<code>--cap-drop=ALL</code>). Disable network if not needed (<code>--network=none</code>). Never mount the Docker socket and do not run privileged containers. Prefer rootless containers. Virtual machine Prefer a dedicated VM with no shared folders, no host passthrough, and no keys to other machines. Network If the agent does not need the internet, disable outbound access entirely. If it does, restrict to specific domains via firewall rules. Resource limits Apply CPU, memory, and disk limits (cgroups/container limits). A runaway loop should not fill disk or consume all RAM. Self-modification Make instruction files read-only. <code>CLAUDE.md</code>, <code>.claude/settings.local.json</code>, and <code>.context/CONSTITUTION.md</code> should not be writable by the agent user. If using project-local hooks, protect those too. <p>A minimal Docker setup for overnight runs:</p> <pre><code>docker run --rm \\\n  --network=none \\\n  --cap-drop=ALL \\\n  --memory=4g \\\n  --cpus=2 \\\n  -v /path/to/project:/workspace \\\n  -w /workspace \\\n  your-dev-image \\\n  ./loop.sh 2&gt;&amp;1 | tee /tmp/loop.log\n</code></pre> <p>Defense in Depth</p> <p>Use multiple layers together: OS-level isolation (the boundary the agent cannot cross), a permission allowlist (what Claude Code will do within that boundary), and <code>CONSTITUTION.md</code> (a soft nudge for the common case).</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-5-generate-the-loop-script","level":3,"title":"Step 5: Generate the Loop Script","text":"<p>Use <code>ctx loop</code> to generate a <code>loop.sh</code> tailored to your AI tool:</p> <pre><code># Generate for Claude Code with a 10-iteration cap\nctx loop --tool claude --max-iterations 10\n\n# Generate for Aider\nctx loop --tool aider --max-iterations 10\n\n# Custom prompt file and output filename (default prompt is PROMPT.md in project root)\nctx loop --tool claude --prompt my-prompt.md --output my-loop.sh\n</code></pre> <p>The generated script reads <code>PROMPT.md</code>, runs the tool, checks for completion signals, and loops until done or the cap is reached.</p> <p>You can also use the <code>/ctx-loop</code> skill from inside Claude Code.</p> <p>A Shell Loop Is the Best Practice</p> <p>The shell loop approach spawns a fresh AI process each iteration, so the only state that carries between iterations is what lives in <code>.context/</code> and git.</p> <p>Claude Code's built-in <code>/loop</code> runs iterations within the same session, which can allow context window state to leak between iterations. This can be convenient for short runs, but it is less reliable for unattended loops. </p> <p>See Shell Loop vs Built-in Loop for details.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-6-run-with-watch-mode","level":3,"title":"Step 6: Run with Watch Mode","text":"<p>Open two terminals. In the first, run the loop. In the second, run <code>ctx watch</code> to process context updates from the AI output.</p> <pre><code># Terminal 1: Run the loop\n./loop.sh 2&gt;&amp;1 | tee /tmp/loop.log\n\n# Terminal 2: Watch for context updates\nctx watch --log /tmp/loop.log\n</code></pre> <p>The watch command parses XML context-update commands from the AI output and applies them:</p> <pre><code>&lt;context-update type=\"complete\"&gt;user registration&lt;/context-update&gt;\n&lt;context-update type=\"learning\"\n  context=\"Setting up user registration\"\n  lesson=\"Email verification needs SMTP configured\"\n  application=\"Add SMTP setup to deployment checklist\"\n&gt;SMTP Requirement&lt;/context-update&gt;\n</code></pre>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-7-completion-signals-end-the-loop","level":3,"title":"Step 7: Completion Signals End the Loop","text":"<p>The generated script checks for one completion signal per run. By default this is <code>SYSTEM_CONVERGED</code>. You can change it with the <code>--completion</code> flag:</p> <pre><code>ctx loop --tool claude --completion BOOTSTRAP_COMPLETE --max-iterations 5\n</code></pre> <p>The following signals are conventions used in <code>PROMPT.md</code>:</p> Signal Convention How the script handles it <code>SYSTEM_CONVERGED</code> All tasks in <code>TASKS.md</code> are done Detected by default (<code>--completion</code> default value) <code>SYSTEM_BLOCKED</code> Agent cannot proceed Only detected if you set <code>--completion</code> to this <code>BOOTSTRAP_COMPLETE</code> Initial scaffolding done Only detected if you set <code>--completion</code> to this <p>The script uses <code>grep -q</code> on the agent's output, so any string works as a signal. If you need to detect multiple signals in one run, edit the generated <code>loop.sh</code> to add additional <code>grep</code> checks.</p> <p>When you return in the morning, check the log and the context files:</p> <pre><code>tail -100 /tmp/loop.log\nctx status\nctx load\n</code></pre>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-8-use-ctx-implement-for-plan-execution","level":3,"title":"Step 8: Use <code>/ctx-implement</code> for Plan Execution","text":"<p>Within each iteration, the agent can use <code>/ctx-implement</code> to execute multi-step plans with verification between steps. This is useful for complex tasks that touch multiple files.</p> <p>The skill breaks a plan into atomic, verifiable steps:</p> <pre><code>Step 1/6: Create user model .................. OK\nStep 2/6: Add database migration ............. OK\nStep 3/6: Implement registration handler ..... OK\nStep 4/6: Write unit tests ................... OK\nStep 5/6: Run test suite ..................... FAIL\n  -&gt; Fixed: missing test dependency\n  -&gt; Re-verify ............................... OK\nStep 6/6: Update TASKS.md .................... OK\n</code></pre> <p>Each step is verified (build, test, syntax check) before moving to the next.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"<p>A typical overnight run:</p> <pre><code>ctx init --ralph\n# Edit TASKS.md and PROMPT.md\n\nctx loop --tool claude --max-iterations 20\n\n./loop.sh 2&gt;&amp;1 | tee /tmp/loop.log &amp;\nctx watch --log /tmp/loop.log\n\n# Next morning:\nctx status\nctx load\n</code></pre>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#why-autonomous-loops-work-proactive-context-persistence","level":2,"title":"Why Autonomous Loops Work: Proactive Context Persistence","text":"<p>The autonomous loop pattern works because the agent persists context as part of the job.</p> <p>Without proactive persistence, the loop degrades into disconnected iterations that repeat work, contradict decisions, and lose track of progress. The agent cannot rely on a human to prompt it. It must treat context updates as part of every task, not as a separate step.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#the-agent-playbook-self-check-drives-autonomy","level":3,"title":"The Agent Playbook Self-Check Drives Autonomy","text":"<p>The Agent Playbook defines a self-check prompt the agent applies continuously:</p> <pre><code>\"If this session ended right now, would the next session know what happened?\"\n</code></pre> <p>In interactive sessions, a human might remind the agent to save context. When the agent runs unattended, nobody is there to remind it.</p> <p>The self-check becomes the trigger: after meaningful work, the agent evaluates whether the context files reflect reality and updates them immediately if they do not.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#what-the-agent-does-proactively-between-iterations","level":3,"title":"What the Agent Does Proactively Between Iterations","text":"<p>At milestones within an iteration, the agent persists without waiting for instructions:</p> Milestone What the agent does proactively Completes a task Marks it <code>[x]</code> in <code>TASKS.md</code> with <code>#done</code> timestamp Discovers a gotcha Adds it to <code>LEARNINGS.md</code> Makes a design choice Records it in <code>DECISIONS.md</code> with rationale Identifies follow-up work Creates new tasks in <code>TASKS.md</code> with <code>#added</code> timestamp Hits an unexpected failure Documents the root cause before moving on","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#example-what-proactive-persistence-looks-like","level":3,"title":"Example: What Proactive Persistence Looks Like","text":"<p>Here is what the agent does during a single iteration beyond writing code:</p> <pre><code>Iteration 4:\n  1. Read TASKS.md -&gt; pick \"Add email verification\" (#priority:high)\n  2. Add #started:2026-01-25-030012 to the task\n  3. Implement the feature (code, tests, docs if needed)\n  4. Tests pass -&gt; mark task [x], add #done:2026-01-25-031544\n  5. Add learning: \"SMTP config must be set before verification handler registers. Order matters in init().\"\n  6. Add decision: \"Use token-based verification links (not codes) because links work better in automated tests.\"\n  7. Create follow-up task: \"Add rate limiting to verification endpoint\" #added:...\n  8. Commit all changes including `.context/`\n  9. No signal emitted -&gt; loop continues to iteration 5\n</code></pre> <p>Steps 2, 4, 5, 6, and 7 are proactive context persistence: </p> <p>The agent was not asked to do any of them.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#context-persistence-at-milestones","level":3,"title":"Context Persistence at Milestones","text":"<p>For long autonomous runs, the agent persists context at natural boundaries, often at phase transitions or after completing a cluster of related tasks. It updates <code>TASKS.md</code>, <code>DECISIONS.md</code>, and <code>LEARNINGS.md</code> as it goes.</p> <p>If the loop crashes at 4 AM, the context files tell you exactly where to resume. You can also use <code>ctx recall list</code> to review the session transcripts.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#the-persistence-contract","level":3,"title":"The Persistence Contract","text":"<p>The autonomous loop has an implicit contract:</p> <ol> <li>Every iteration reads context: <code>TASKS.md</code>, <code>DECISIONS.md</code>, <code>LEARNINGS.md</code></li> <li>Every iteration writes context: task updates, new learnings, decisions</li> <li>Every commit includes <code>.context/</code> so the next iteration sees changes</li> <li>Context stays current: if the loop stopped right now, nothing important is lost</li> </ol> <p>Break any part of this contract and the loop degrades.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#tips","level":2,"title":"Tips","text":"<p>Markdown Is Not Enforcement</p> <p>Your real guardrails are permissions and isolation, not Markdown. <code>CONSTITUTION.md</code> can nudge the agent, but it is probabilistic. </p> <p>The permission allowlist and OS isolation are deterministic:</p> <p>For unattended runs, trust the sandbox and the allowlist, not the prose.</p> <ul> <li>Start with a small iteration cap. Use <code>--max-iterations 5</code> on your first run.</li> <li>Keep tasks atomic. Each task should be completable in a single iteration.</li> <li>Check signal discipline. If the loop runs forever, the agent is not emitting   <code>SYSTEM_CONVERGED</code> or <code>SYSTEM_BLOCKED</code>. Make the signal requirement explicit   in <code>PROMPT.md</code>.</li> <li>Commit after context updates. Finish code, update <code>.context/</code>, commit including   <code>.context/</code>, then signal.</li> <li>Use <code>/ctx-context-monitor</code> for long runs. It can warn when context capacity is   running low, so the agent saves before hitting limits.</li> <li>Set up webhook notifications to get notified   when the loop completes, hits max iterations, or when hooks fire nudges.   The generated loop script includes <code>ctx notify</code> calls automatically.</li> </ul>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#next-up","level":2,"title":"Next Up","text":"<p>When to Use a Team of Agents →: Decision framework for choosing between a single agent, parallel worktrees, and a full agent team.</p>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#see-also","level":2,"title":"See Also","text":"<ul> <li>Autonomous Loops: loop pattern, PROMPT.md templates, troubleshooting</li> <li>CLI Reference: ctx loop: flags and options</li> <li>CLI Reference: ctx watch: watch mode details</li> <li>CLI Reference: ctx init: init flags including <code>--ralph</code></li> <li>The Complete Session: interactive workflow</li> <li>Tracking Work Across Sessions: structuring TASKS.md</li> </ul>","path":["Recipes","Agents and Automation","Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/claude-code-permissions/","level":1,"title":"Claude Code Permission Hygiene","text":"","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#the-problem","level":2,"title":"The Problem","text":"<p>Claude Code's <code>.claude/settings.local.json</code> controls what the agent can do without asking. Over time, this file accumulates one-off permissions from individual sessions: Exact commands with hardcoded paths, duplicate entries, and stale skill references. </p> <p>A noisy \"allowlist\" makes it harder to spot dangerous permissions and  increases the surface area for unintended behavior.</p> <p>Since <code>settings.local.json</code> is <code>.gitignore</code>d, it drifts independently of your codebase. There is no PR review, no CI check: just whatever you clicked \"Allow\" on.</p> <p>This recipe shows what a well-maintained permission file looks like and how to keep it clean.</p>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#tldr","level":2,"title":"TL;DR","text":"<pre><code>ctx init                            # seeds safe defaults\n/ctx-drift                          # detects missing/stale permissions\n/sanitize-permissions               # audits for dangerous patterns\n</code></pre> <p>See Recommended Defaults for the full list.</p>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Command/Skill Role in this workflow <code>ctx init</code> Populates default ctx permissions <code>/ctx-drift</code> Detects missing or stale permission entries <code>/sanitize-permissions</code> Audits for dangerous patterns (security-focused)","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#recommended-defaults","level":2,"title":"Recommended Defaults","text":"<p>After running <code>ctx init</code>, your <code>settings.local.json</code> will have the <code>ctx</code> defaults pre-populated. Here is an opinionated safe starting point for a Go project using ctx:</p> <pre><code>{\n  \"permissions\": {\n    \"allow\": [\n      \"Bash(/tmp/ctx-*:*)\",\n      \"Bash(CGO_ENABLED=0 go build:*)\",\n      \"Bash(CGO_ENABLED=0 go test:*)\",\n      \"Bash(ctx:*)\",\n      \"Bash(git add:*)\",\n      \"Bash(git branch:*)\",\n      \"Bash(git check-ignore:*)\",\n      \"Bash(git checkout:*)\",\n      \"Bash(git commit:*)\",\n      \"Bash(git diff:*)\",\n      \"Bash(git log:*)\",\n      \"Bash(git remote:*)\",\n      \"Bash(git restore:*)\",\n      \"Bash(git show:*)\",\n      \"Bash(git stash:*)\",\n      \"Bash(git status:*)\",\n      \"Bash(git tag:*)\",\n      \"Bash(go build:*)\",\n      \"Bash(go fmt:*)\",\n      \"Bash(go test:*)\",\n      \"Bash(go vet:*)\",\n      \"Bash(golangci-lint run:*)\",\n      \"Bash(grep:*)\",\n      \"Bash(ls:*)\",\n      \"Bash(make:*)\",\n      \"Skill(ctx-add-convention)\",\n      \"Skill(ctx-add-decision)\",\n      \"Skill(ctx-add-learning)\",\n      \"Skill(ctx-add-task)\",\n      \"Skill(ctx-agent)\",\n      \"Skill(ctx-alignment-audit)\",\n      \"Skill(ctx-archive)\",\n      \"Skill(ctx-blog)\",\n      \"Skill(ctx-blog-changelog)\",\n      \"Skill(absorb)\",\n      \"Skill(ctx-commit)\",\n      \"Skill(ctx-context-monitor)\",\n      \"Skill(ctx-drift)\",\n      \"Skill(ctx-implement)\",\n      \"Skill(ctx-journal-enrich)\",\n      \"Skill(ctx-journal-enrich-all)\",\n      \"Skill(ctx-journal-normalize)\",\n      \"Skill(ctx-loop)\",\n      \"Skill(ctx-next)\",\n      \"Skill(ctx-pad)\",\n      \"Skill(ctx-prompt-audit)\",\n      \"Skill(ctx-recall)\",\n      \"Skill(ctx-reflect)\",\n      \"Skill(ctx-remember)\",\n      \"Skill(ctx-status)\",\n      \"Skill(ctx-worktree)\",\n      \"WebSearch\"\n    ],\n    \"deny\": [\n      \"Bash(sudo *)\",\n      \"Bash(git push *)\",\n      \"Bash(git push)\",\n      \"Bash(rm -rf /*)\",\n      \"Bash(rm -rf ~*)\",\n      \"Bash(curl *)\",\n      \"Bash(wget *)\",\n      \"Bash(chmod 777 *)\",\n      \"Read(**/.env)\",\n      \"Read(**/.env.*)\",\n      \"Read(**/*credentials*)\",\n      \"Read(**/*secret*)\",\n      \"Read(**/*.pem)\",\n      \"Read(**/*.key)\",\n      \"Edit(**/.env)\",\n      \"Edit(**/.env.*)\"\n    ]\n  }\n}\n</code></pre> <p>This is a starting point, not a mandate</p> <p>Your project may need more or fewer entries. </p> <p>The goal is intentional permissions: Every entry should be there because you decided it belongs, not because you clicked \"Allow\" once during debugging.</p>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#design-principles","level":3,"title":"Design Principles","text":"<p>Use wildcards for trusted binaries: If you trust the binary (your own project's CLI, <code>make</code>, <code>go</code>), a single wildcard like <code>Bash(ctx:*)</code> beats twenty subcommand entries. It reduces noise and means new subcommands work without re-prompting.</p> <p>Keep <code>git</code> commands granular: Unlike <code>ctx</code> or <code>make</code>, git has both safe commands (<code>git log</code>, <code>git status</code>) and destructive ones (<code>git reset --hard</code>, <code>git clean -f</code>). Listing safe commands individually prevents accidentally pre-approving dangerous ones.</p> <p>Pre-approve all <code>ctx-</code> skills: Skills shipped with ctx (<code>Skill(ctx-*)</code>) are safe to pre-approve. They are part of your project and you control their content. This prevents the agent from prompting on every skill invocation.</p>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#default-deny-rules","level":3,"title":"Default Deny Rules","text":"<p><code>ctx init</code> automatically populates <code>permissions.deny</code> with rules that block dangerous operations. Deny rules are evaluated before allow rules: A denied pattern always prompts the user, even if it also matches an allow entry.</p> <p>The defaults block:</p> Pattern Why <code>Bash(sudo *)</code> Cannot enter password; will hang <code>Bash(git push *)</code> Must be explicit user action <code>Bash(rm -rf /*)</code> etc. Recursive delete of system/home directories <code>Bash(curl *)</code> / <code>wget</code> Arbitrary network requests <code>Bash(chmod 777 *)</code> World-writable permissions <code>Read/Edit(**/.env*)</code> Secrets and credentials <code>Read(**/*.pem, *.key)</code> Private keys <p>Read/Edit Deny Rules</p> <p><code>Read()</code> and <code>Edit()</code> deny rules have known upstream enforcement issues (<code>claude-code#6631,#24846</code>). </p> <p>They are included as defense-in-depth and intent documentation.</p> <p>Blocked by default deny rules — no action needed, <code>ctx init</code> handles these:</p> Pattern Risk <code>Bash(git push:*)</code> Must be explicit user action <code>Bash(sudo:*)</code> Privilege escalation <code>Bash(rm -rf:*)</code> Recursive delete with no confirmation <code>Bash(curl:*)</code> / <code>Bash(wget:*)</code> Arbitrary network requests <p>Requires manual discipline: Never add these to <code>allow</code>:</p> Pattern Risk <code>Bash(git reset:*)</code> Can discard uncommitted work <code>Bash(git clean:*)</code> Deletes untracked files <code>Skill(sanitize-permissions)</code> Edits this file: self-modification vector <code>Skill(release)</code> Runs the release pipeline: high impact","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#hooks-regex-safety-net","level":2,"title":"Hooks: Regex Safety Net","text":"<p>Deny rules handle prefix-based blocking natively. Hooks complement them by catching patterns that require regex matching: Things deny rules can't express.</p> <p>The ctx plugin ships these blocking hooks:</p> Hook What it blocks <code>ctx system block-non-path-ctx</code> Running ctx from wrong path <p>Project-local hooks (not part of the plugin) catch regex edge cases:</p> Hook What it blocks <code>block-dangerous-commands.sh</code> Mid-command <code>sudo</code>/<code>git push</code> (after <code>&amp;&amp;</code>), copies to bin dirs, absolute-path ctx <p>Pre-Approved + Hook-Blocked = Silent Block</p> <p>If you pre-approve a command that a hook blocks, the user never sees the confirmation dialog. The agent gets a block response and must handle it, which is confusing.</p> <p>It's better not to pre-approve commands that hooks are designed to intercept.</p>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#the-maintenance-workflow","level":2,"title":"The Maintenance Workflow","text":"","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#after-busy-sessions","level":3,"title":"After busy sessions","text":"<p>Permissions accumulate fastest during debugging and exploration sessions. After a session where you clicked \"Allow\" many times:</p> <ol> <li>Open <code>.claude/settings.local.json</code> in your editor;</li> <li>Look for entries at the bottom of the allowlist (new entries append there);</li> <li>Delete anything that looks session-specific:<ul> <li>Exact commands with hardcoded paths,</li> <li>Commands with literal string arguments,</li> <li>Entries that duplicate an existing wildcard.</li> </ul> </li> </ol> <p>See <code>hack/runbooks/sanitize-permissions.md</code> for a step-by-step runbook.</p>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#periodically","level":3,"title":"Periodically","text":"<p>Run <code>/ctx-drift</code> to catch permission drift:</p> <ul> <li>Missing <code>Bash(ctx:*)</code> wildcard;</li> <li>Missing <code>Skill(ctx-*)</code> entries for installed skills;</li> <li>Stale <code>Skill(ctx-*)</code> entries for removed skills;</li> <li>Granular <code>Bash(ctx &lt;subcommand&gt;:*)</code> entries that should be consolidated.</li> </ul> <p>Run <code>/sanitize-permissions</code> to catch security issues:</p> <ul> <li>Hook bypass patterns</li> <li>Destructive commands</li> <li>Overly broad permissions</li> <li>Injection vectors</li> </ul>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#when-adding-new-skills","level":3,"title":"When adding new skills","text":"<p>If you create a custom <code>ctx-*</code> skill, add its <code>Skill()</code> entry to the allowlist manually. </p> <p><code>ctx init</code> only populates the default permissions: It won't pick up custom skills.</p>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#golden-image-snapshots","level":3,"title":"Golden image snapshots","text":"<p>If manual cleanup is too tedious, use a golden image to automate it: </p> <p>Snapshot a curated permission set, then restore at session start to automatically  drop session-accumulated permissions. See the Permission Snapshots recipe for the full workflow.</p>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#adapting-for-other-languages","level":2,"title":"Adapting for Other Languages","text":"<p>The recommended defaults above are Go-specific. For other stacks, swap the build/test tooling:</p> <p>Node.js / TypeScript:</p> <pre><code>\"Bash(npm run:*)\",\n\"Bash(npm test:*)\",\n\"Bash(npx:*)\",\n\"Bash(node:*)\"\n</code></pre> <p>Python:</p> <pre><code>\"Bash(pytest:*)\",\n\"Bash(python:*)\",\n\"Bash(pip show:*)\",\n\"Bash(ruff:*)\"\n</code></pre> <p>Rust:</p> <pre><code>\"Bash(cargo build:*)\",\n\"Bash(cargo test:*)\",\n\"Bash(cargo clippy:*)\",\n\"Bash(cargo fmt:*)\"\n</code></pre> <p>The <code>ctx</code>, <code>git</code>, and skill entries remain the same across all stacks.</p>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#next-up","level":2,"title":"Next Up","text":"<p>Permission Snapshots →: Save and restore permission baselines for reproducible setups.</p>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/claude-code-permissions/#see-also","level":2,"title":"See Also","text":"<ul> <li>Setting Up ctx Across AI Tools: full setup recipe   including <code>settings.local.json</code> creation</li> <li>Context Health: keeping <code>.context/</code> files accurate</li> <li><code>hack/runbooks/sanitize-permissions.md</code>:   manual cleanup runbook</li> </ul>","path":["Recipes","Maintenance","Claude Code Permission Hygiene"],"tags":[]},{"location":"recipes/context-health/","level":1,"title":"Detecting and Fixing Drift","text":"","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#the-problem","level":2,"title":"The Problem","text":"<p>Context files drift: you rename a package, delete a module, or finish a sprint, and suddenly <code>ARCHITECTURE.md</code> references paths that no longer exist, <code>TASKS.md</code> is 80 percent completed checkboxes, and <code>CONVENTIONS.md</code> describes patterns you stopped using two months ago.</p> <p>Stale context is worse than no context: </p> <p>An AI tool that trusts outdated references will hallucinate confidently.</p> <p>This recipe shows how to detect drift, fix it, and keep your <code>.context/</code> directory lean and accurate.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#tldr","level":2,"title":"TL;DR","text":"<pre><code>ctx drift                      # detect problems\nctx drift --fix                # auto-fix the easy ones\nctx sync --dry-run &amp;&amp; ctx sync # reconcile after refactors\nctx compact --archive          # archive old completed tasks\nctx status                     # verify\n</code></pre> <p>Or just ask your agent: \"Is our context clean?\"</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx drift</code> Command Detect stale paths, missing files, violations <code>ctx drift --fix</code> Command Auto-fix simple issues <code>ctx sync</code> Command Reconcile context with codebase structure <code>ctx compact</code> Command Archive completed tasks, clean up empty sections <code>ctx status</code> Command Quick health overview <code>/ctx-drift</code> Skill Structural plus semantic drift detection <code>/ctx-map</code> Skill Refresh <code>ARCHITECTURE.md</code> from actual codebase <code>/ctx-alignment-audit</code> Skill Audit doc claims against agent instructions <code>/ctx-status</code> Skill In-session context summary <code>/ctx-prompt-audit</code> Skill Audit prompt quality and token efficiency","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#the-workflow","level":2,"title":"The Workflow","text":"<p>The best way to maintain context health is conversational: Ask your agent, guide it, and let it detect problems, explain them, and fix them with your approval. CLI commands exist for CI pipelines, scripting, and fine-grained control. </p> <p>For day-to-day maintenance, talk to your agent.</p> <p>Your Questions Reinforce the Pattern</p> <p>Asking \"is our context clean?\" does two things:</p> <ul> <li>It triggers a drift check right now</li> <li>It reinforces the habit</li> </ul> <p>This is reinforcement, not enforcement.</p> <p>Do not wait for the agent to be proactive on its own: </p> <p>Guide your agent, especially in early sessions.</p> <p>Over time, you will ask less and the agent will start offering more.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#step-1-ask-your-agent","level":3,"title":"Step 1: Ask Your Agent","text":"<p>The simplest way to check context health:</p> <pre><code>Is our context clean?\nAnything stale?\nHow healthy are our context files?\n</code></pre> <p>Or invoke the skill directly:</p> <pre><code>/ctx-drift\n</code></pre> <p>The agent performs two layers of analysis:</p> <p>Layer 1, structural checks (via <code>ctx drift</code>): Dead paths, missing files, completed task counts, constitution violations. Fast and programmatic.</p> <p>Layer 2, semantic analysis (agent-driven): Does <code>CONVENTIONS.md</code> describe patterns the code no longer follows? Does <code>DECISIONS.md</code> contain entries whose rationale no longer applies? Are there learnings about bugs that are now fixed? This is where the agent adds value the CLI cannot: It reads both context files and source code and compares them.</p> <p>The agent reports both layers together, explains each finding in plain language, and offers to fix what it can.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#step-2-maintenance-at-session-start","level":3,"title":"Step 2: Maintenance at Session Start","text":"<p>You do not need to ask explicitly. </p> <p>Using Claude Code</p> <p><code>ctx</code> ships with Claude Code hooks that remind the agent  at the right time to take initiative. </p> <p>Checking context health at the session start, offering to persist learnings  before you quit, and flagging drift when it matters. The agent stays  proactive without you having to prompt it:</p> <pre><code>Agent: Good morning. I've loaded the context files. A few things\n       before we start:\n\n       - ARCHITECTURE.md references `pkg/auth/` which is now empty\n       - DECISIONS.md hasn't been updated in 40 days\n       - There are 18 completed tasks ready for archival\n\n       Want me to run a quick maintenance pass, or should we jump\n       straight into today's work?\n</code></pre> <p>☝️️ this is what persistent, initiative-driven sessions feel like when context is  treated as a system instead of a prompt.</p> <p>If the agent does not offer this on its own, a gentle nudge is enough:</p> <pre><code>Anything stale before we start?\nHow's the context looking?\n</code></pre> <p>This turns maintenance from a scheduled chore into a conversation that happens when it matters.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#step-3-real-time-detection-during-work","level":3,"title":"Step 3: Real-Time Detection During Work","text":"<p>Agents can notice drift while working: When a mismatch is directly in the path of their current task. If an agent reads <code>ARCHITECTURE.md</code> to find where to add a handler and <code>internal/handlers/</code> doesn't exist, it will notice because the stale reference blocks its work:</p> <pre><code>Agent: ARCHITECTURE.md references `internal/handlers/` but that directory\n       doesn't exist. I'll look at the actual source tree to find where\n       handlers live now.\n</code></pre> <p>This happens reliably when the drift intersects the task. What is less reliable is the agent generalizing from one mismatch to \"there might be more stale references; let me run drift detection\" That leap requires the agent to know <code>/ctx-drift</code> exists and to decide the current task should pause for maintenance.</p> <p>If you want that behavior, reinforce it:</p> <pre><code>Good catch. Yes, run /ctx-drift and clean up any other stale references.\n</code></pre> <p>Over time, agents that have seen this pattern will start offering proactively. But do not expect it from a cold start.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#step-4-archival-and-cleanup","level":3,"title":"Step 4: Archival and Cleanup","text":"<p><code>ctx drift</code> detects when <code>TASKS.md</code> has more than 10 completed items and flags it as a staleness warning. Running <code>ctx drift --fix</code> archives completed tasks automatically. </p> <p>You can also run <code>/ctx-archive</code> to compact on demand.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#step-5-alignment-audits","level":3,"title":"Step 5: Alignment Audits","text":"<p>A related problem is alignment drift: Documentation that makes claims about agent behavior not backed by actual playbook or skill instructions. </p> <p>Over time, docs accumulate aspirational statements that no instruction teaches  the agent to do.</p> <p>Use <code>/ctx-alignment-audit</code> to trace behavioral claims in documentation against the playbook and skill files. The skill identifies gaps, proposes fixes, and checks instruction file health (token budgets, bloat signals).</p> <p>To avoid confusion with <code>/ctx-prompt-audit</code>:</p> <ul> <li><code>/ctx-alignment-audit</code> checks whether documentation claims are supported by   actual instructions (playbook, skills, <code>CLAUDE.md</code>).</li> <li><code>/ctx-prompt-audit</code> checks whether your context files are clear, compact, and   token-efficient for the model.</li> </ul>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#cli-reference","level":2,"title":"CLI Reference","text":"<p>The conversational approach above uses CLI commands under the hood. When you need direct control, use the commands directly.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-drift","level":3,"title":"<code>ctx drift</code>","text":"<p>Scan context files for structural problems:</p> <pre><code>ctx drift\n</code></pre> <p>Sample output:</p> <pre><code>Drift Report\n============\n\nWarnings (3):\n  ARCHITECTURE.md:14  path \"internal/api/router.go\" does not exist\n  ARCHITECTURE.md:28  path \"pkg/auth/\" directory is empty\n  CONVENTIONS.md:9    path \"internal/handlers/\" not found\n\nViolations (1):\n  TASKS.md            31 completed tasks (recommend archival)\n\nStaleness:\n  DECISIONS.md        last modified 45 days ago\n  LEARNINGS.md        last modified 32 days ago\n\nExit code: 1 (warnings found)\n</code></pre> Level Meaning Action Warning Stale path references, missing files Fix or remove Violation Constitution rule heuristic failures, heavy clutter Fix soon Staleness Files not updated recently Review content <p>Exit codes: <code>0</code> equals clean, <code>1</code> equals warnings, <code>3</code> equals violations.</p> <p>For CI integration:</p> <pre><code>ctx drift --json | jq '.warnings | length'\n</code></pre>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-drift-fix","level":3,"title":"<code>ctx drift --fix</code>","text":"<p>Auto-fix mechanical issues:</p> <pre><code>ctx drift --fix\n</code></pre> <p>This handles removing dead path references, updating unambiguous renames,  clearing empty sections. Issues requiring judgment are flagged but left for you.</p> <p>Run <code>ctx drift</code> again afterward to confirm what remains.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-sync","level":3,"title":"<code>ctx sync</code>","text":"<p>After a refactor, reconcile context with the actual codebase structure:</p> <pre><code>ctx sync --dry-run   # preview first\nctx sync             # apply\n</code></pre> <p><code>ctx sync</code> scans for structural changes, compares with <code>ARCHITECTURE.md</code>,  checks for new dependencies worth documenting, and identifies context referring  to code that no longer exists.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-compact","level":3,"title":"<code>ctx compact</code>","text":"<p>Consolidate completed tasks and clean up empty sections:</p> <pre><code>ctx compact            # move completed tasks to Completed section,\n                       # remove empty sections\nctx compact --archive  # also archive old tasks to .context/archive/\n</code></pre> <ul> <li>Tasks: moves completed items (with all subtasks done) into the Completed   section of <code>TASKS.md</code></li> <li>All files: removes empty sections left behind</li> <li>With <code>--archive</code>: writes tasks older than 7 days to   <code>.context/archive/tasks-YYYY-MM-DD.md</code></li> </ul> <p>Without <code>--archive</code>, nothing is deleted — tasks are reorganized in place.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-status","level":3,"title":"<code>ctx status</code>","text":"<p>Quick health overview:</p> <pre><code>ctx status --verbose\n</code></pre> <p>Shows file counts, token estimates, modification times, and drift warnings in a single glance.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-alignment-audit-and-ctx-prompt-audit","level":3,"title":"<code>/ctx-alignment-audit</code> and <code>/ctx-prompt-audit</code>","text":"<p>These are both audits, but they answer different questions:</p> <ul> <li><code>/ctx-alignment-audit</code>: are our behavioral claims backed by actual   instructions?</li> <li><code>/ctx-prompt-audit</code>: are our context files readable, compact, and efficient?</li> </ul> <p>Run them inside your AI assistant:</p> <pre><code>/ctx-alignment-audit\n/ctx-prompt-audit\n</code></pre>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"<p>Conversational approach (recommended):</p> <pre><code>Is our context clean?  -&gt; agent runs structural plus semantic checks\nFix what you can       -&gt; agent auto-fixes and proposes edits\nArchive the done tasks -&gt; agent runs ctx compact --archive\nHow's token usage?     -&gt; agent checks ctx status\n</code></pre> <p>CLI approach (for CI, scripts, or direct control):</p> <pre><code>ctx drift                      # 1. Detect problems\nctx drift --fix                # 2. Auto-fix the easy ones\nctx sync --dry-run &amp;&amp; ctx sync # 3. Reconcile after refactors\nctx compact --archive          # 4. Archive old completed tasks\nctx status                     # 5. Verify\n</code></pre>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#tips","level":2,"title":"Tips","text":"<p>Agents cross-reference context files with source code during normal work. When drift intersects their current task, they will notice: a renamed package, a deleted directory, a path that doesn't resolve. But they rarely generalize from one mismatch to a full audit on their own. Reinforce the pattern: when an agent mentions a stale reference, ask it to run <code>/ctx-drift</code>. Over time, it starts offering.</p> <p>When an agent says \"this reference looks stale,\" it is usually right.</p> <p>Semantic drift is more damaging than structural drift:  <code>ctx drift</code> catches dead paths. But <code>CONVENTIONS.md</code> describing a pattern your  code stopped following three weeks ago is worse. When you ask  \"is our context clean?\", the agent can do both checks.</p> <p>Use <code>ctx status</code> as a quick check: It shows file counts, token estimates, and drift warnings in a single glance. Good for a fast \"is everything ok?\" before diving into work.</p> <p>Drift detection in CI: add <code>ctx drift --json</code> to your CI pipeline and fail on exit code 3 (violations). This catches constitution-level problems before they reach upstream.</p> <p>Do not over-compact: Completed tasks have historical value. The <code>--archive</code> flag preserves them in <code>.context/archive/</code> so you can search past work without cluttering active context.</p> <p>Sync is cautious by default: Use <code>--dry-run</code> after large refactors, then apply.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#next-up","level":2,"title":"Next Up","text":"<p>Claude Code Permission Hygiene →: Recommended permission defaults and maintenance workflow for Claude Code.</p>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#see-also","level":2,"title":"See Also","text":"<ul> <li>Tracking Work Across Sessions: task lifecycle and archival</li> <li>Persisting Decisions, Learnings, and Conventions:    keeping knowledge files current</li> <li>The Complete Session: where maintenance fits in the daily workflow</li> <li>CLI Reference: full flag documentation for all commands</li> <li>Context Files: structure and purpose of each <code>.context/</code> file</li> </ul>","path":["Recipes","Maintenance","Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/external-context/","level":1,"title":"Keeping Context in a Separate Repo","text":"","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#the-problem","level":2,"title":"The Problem","text":"<p><code>ctx</code> files contain project-specific decisions, learnings,  conventions, and tasks. By default, they live in  <code>.context/</code> inside the project tree, and that works well when the context can be public.</p> <p>But sometimes you need the context outside the project:</p> <ul> <li>Open-source projects with private context: Your architectural notes,   internal task lists, and scratchpad entries shouldn't ship with the public   repo.</li> <li>Compliance or IP concerns: Context files reference sensitive design   rationale that belongs in a separate access-controlled repository.</li> <li>Personal preference: You want a single context repo that covers   multiple projects, or you just prefer keeping notes separate from code.</li> </ul> <p><code>ctx</code> supports this through three configuration methods. This recipe shows how to set them up and how to tell your AI assistant where to find the context.</p>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#tldr","level":2,"title":"TL;DR","text":"<p>First <code>--allow-outside-cwd</code> in your project:</p> <pre><code>mkdir ~/repos/myproject-context &amp;&amp; cd ~/repos/myproject-context &amp;&amp; git init\ncd ~/repos/myproject\nctx --context-dir ~/repos/myproject-context --allow-outside-cwd init\n</code></pre> <p>Then, create a <code>.ctxrc</code> in your project root to specify the new <code>.context</code> folder location:</p> <pre><code>context_dir: ~/repos/myproject-context\nallow_outside_cwd: true\n</code></pre> <p>All <code>ctx</code> commands now use the external directory automatically.</p>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx init</code> CLI command Initialize context directory <code>--context-dir</code> Global flag Point ctx at a non-default directory <code>--allow-outside-cwd</code> Global flag Permit context outside the project root <code>.ctxrc</code> Config file Persist the context directory setting <code>CTX_DIR</code> Env variable Override context directory per-session <code>/ctx-status</code> Skill Verify context is loading correctly","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#step-1-create-the-private-context-repo","level":3,"title":"Step 1: Create the Private Context Repo","text":"<p>Create a separate repository for your context files. This can live anywhere: a private GitHub repo, a shared drive, a sibling directory:</p> <pre><code># Create the context repo\nmkdir ~/repos/myproject-context\ncd ~/repos/myproject-context\ngit init\n</code></pre>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#step-2-initialize-ctx-pointing-at-it","level":3,"title":"Step 2: Initialize ctx Pointing at It","text":"<p>From your project root, initialize ctx with <code>--context-dir</code> pointing to the external location. Because the directory is outside your project tree, you also need <code>--allow-outside-cwd</code>:</p> <pre><code>cd ~/repos/myproject\nctx --context-dir ~/repos/myproject-context \\\n    --allow-outside-cwd \\\n    init\n</code></pre> <p>This creates the full <code>.context/</code>-style file set inside <code>~/repos/myproject-context/</code> instead of <code>~/repos/myproject/.context/</code>.</p> <p>Boundary Validation</p> <p><code>ctx</code> validates that the <code>.context</code> directory is within the current working directory. </p> <p>If your external directory is truly outside the project root:</p> <ul> <li>Either every <code>ctx</code> command needs <code>--allow-outside-cwd</code>, </li> <li>or you can persist the setting in <code>.ctxrc</code> (next step).</li> </ul>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#step-3-make-it-stick","level":3,"title":"Step 3: Make It Stick","text":"<p>Typing <code>--context-dir</code> and <code>--allow-outside-cwd</code> on every command is tedious. Pick one of these methods to make the configuration permanent.</p>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#option-a-ctxrc-recommended","level":4,"title":"Option A: <code>.ctxrc</code> (Recommended)","text":"<p>Create a <code>.ctxrc</code> file in your project root:</p> <pre><code># .ctxrc — committed to the project repo\ncontext_dir: ~/repos/myproject-context\nallow_outside_cwd: true\n</code></pre> <p>ctx reads <code>.ctxrc</code> automatically. Every command now uses the external directory without extra flags:</p> <pre><code>ctx status          # reads from ~/repos/myproject-context\nctx add learning \"Redis MULTI doesn't roll back on error\"\n</code></pre> <p>Commit <code>.ctxrc</code></p> <p><code>.ctxrc</code> belongs in the project repo. It contains no secrets: It's just a path and a boundary override. </p> <p><code>.ctxrc</code> lets teammates share the same configuration.</p>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#option-b-ctx_dir-environment-variable","level":4,"title":"Option B: <code>CTX_DIR</code> Environment Variable","text":"<p>Good for CI pipelines, temporary overrides, or when you don't want to commit a <code>.ctxrc</code>:</p> <pre><code># In your shell profile (~/.bashrc, ~/.zshrc)\nexport CTX_DIR=~/repos/myproject-context\n</code></pre> <p>Or for a single session:</p> <pre><code>CTX_DIR=~/repos/myproject-context ctx status\n</code></pre>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#option-c-shell-alias","level":4,"title":"Option C: Shell Alias","text":"<p>If you prefer a shell alias over <code>.ctxrc</code>:</p> <pre><code># ~/.bashrc or ~/.zshrc\nalias ctx='ctx --context-dir ~/repos/myproject-context --allow-outside-cwd'\n</code></pre>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#priority-order","level":4,"title":"Priority Order","text":"<p>When multiple methods are set, <code>ctx</code> resolves the context directory in this order (highest priority first):</p> <ol> <li><code>--context-dir</code> flag</li> <li><code>CTX_DIR</code> environment variable</li> <li><code>context_dir</code> in <code>.ctxrc</code></li> <li>Default: <code>.context/</code></li> </ol>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#step-4-agent-auto-discovery-via-bootstrap","level":3,"title":"Step 4: Agent Auto-Discovery via Bootstrap","text":"<p>When context lives outside the project tree, your AI assistant needs to know where to find it. The <code>ctx system bootstrap</code> command resolves the configured context directory and communicates it to the agent automatically:</p> <pre><code>$ ctx system bootstrap\nctx bootstrap\n=============\n\ncontext_dir: /home/user/repos/myproject-context\n\nFiles:\n  CONSTITUTION.md, TASKS.md, DECISIONS.md, ...\n</code></pre> <p>The <code>CLAUDE.md</code> template generated by <code>ctx init</code> already instructs the agent to run <code>ctx system bootstrap</code> at session start. Because <code>.ctxrc</code> is in the project root, your agent inherits the external path automatically via the <code>ctx system boostrap</code> call instruction.</p> <p>Here  is the relevant section from <code>CLAUDE.md</code> for reference:</p> <pre><code>&lt;!-- CLAUDE.md --&gt;\n1. **Run `ctx system bootstrap`** — CRITICAL, not optional.\n   This tells you where the context directory is. If it fails or returns\n   no context_dir, STOP and warn the user.\n</code></pre> <p>Moreover, every nudge (context checkpoint, persistence reminder, etc.) also  includes a <code>Context: /home/user/repos/myproject-context</code> footer, so the agent remains anchored to the correct directory even in long sessions.</p> <p>If you use <code>CTX_DIR</code> instead of <code>.ctxrc</code>, export it in your shell profile so the hook process inherits it:</p> <pre><code>export CTX_DIR=~/repos/myproject-context\n</code></pre>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#step-5-share-with-teammates","level":3,"title":"Step 5: Share with Teammates","text":"<p>Teammates clone both repos and set up <code>.ctxrc</code>:</p> <pre><code># Clone the project\ngit clone git@github.com:org/myproject.git\ncd myproject\n\n# Clone the private context repo\ngit clone git@github.com:org/myproject-context.git ~/repos/myproject-context\n</code></pre> <p>If <code>.ctxrc</code> is already committed to the project, they're done — ctx commands will find the external context automatically.</p> <p>If teammates use different paths, each developer sets their own <code>CTX_DIR</code>:</p> <pre><code>export CTX_DIR=~/my-own-path/myproject-context\n</code></pre> <p>For encryption key distribution across the team, see the Syncing Scratchpad Notes recipe.</p>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#step-6-day-to-day-sync","level":3,"title":"Step 6: Day-to-Day Sync","text":"<p>The external context repo has its own git history. Treat it like any other repo — commit and push after sessions:</p> <pre><code>cd ~/repos/myproject-context\n\n# After a session\ngit add -A\ngit commit -m \"Session: refactored auth module, added rate-limit learning\"\ngit push\n</code></pre> <p>Your AI assistant can do this too. When ending a session:</p> <pre><code>You: \"Save what we learned and push the context repo.\"\n\nAgent: [runs ctx add learning, then commits and pushes the context repo]\n</code></pre> <p>You can also set up a post-session habit: project code gets committed to the project repo, context gets committed to the context repo.</p>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#conversational-approach","level":2,"title":"Conversational Approach","text":"<p>You don't need to remember the flags; simply ask your assistant:</p>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#set-up-your-system-using-natural-language","level":3,"title":"Set Up Your System Using Natural Language","text":"<pre><code>You: \"Set up ctx to use ~/repos/myproject-context as the context directory.\"\n\nAgent: \"I'll create a .ctxrc in the project root pointing to that path.\n       I'll also update CLAUDE.md so future sessions know where to find\n       context. Want me to initialize the context files there too?\"\n</code></pre>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#configure-separate-repo-for-context-folder-using-natural-language","level":3,"title":"Configure Separate Repo for <code>.context</code> Folder Using Natural Language","text":"<pre><code>You: \"My context is in a separate repo. Can you load it?\"\n\nAgent: [reads .ctxrc, finds the path, loads context from the external dir]\n       \"Loaded. You have 3 pending tasks, last session was about the auth\n       refactor.\"\n</code></pre>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#tips","level":2,"title":"Tips","text":"<ul> <li>Start simple. If you don't need external context yet, don't set it up.   The default <code>.context/</code> in-tree is the easiest path. Move to an external   repo when you have a concrete reason.</li> <li>One context repo per project. Sharing a single context directory across   multiple projects creates confusion. Keep the mapping 1:1.</li> <li>Use <code>.ctxrc</code> over env vars when the path is stable. It's committed,   documented, and works for the whole team without per-developer shell setup.</li> <li>Don't forget the boundary flag. The most common error is   <code>Error: context directory is outside the project root</code>. Set   <code>allow_outside_cwd: true</code> in <code>.ctxrc</code> or pass <code>--allow-outside-cwd</code>.</li> <li>Commit both repos at session boundaries. Context without code history   (or code without context history) loses half the value.</li> </ul>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#next-up","level":2,"title":"Next Up","text":"<p>The Complete Session →: Walk through a full ctx session from start to finish.</p>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/external-context/#see-also","level":2,"title":"See Also","text":"<ul> <li>Setting Up ctx Across AI Tools: initial setup recipe</li> <li>Syncing Scratchpad Notes Across Machines: distribute   encryption keys when context is shared</li> <li>CLI Reference: all global flags including   <code>--context-dir</code> and <code>--allow-outside-cwd</code></li> </ul>","path":["Recipes","Getting Started","Keeping Context in a Separate Repo"],"tags":[]},{"location":"recipes/guide-your-agent/","level":1,"title":"Guide Your Agent","text":"<p>Commands vs. Skills</p> <p>Commands (<code>ctx status</code>, <code>ctx add task</code>) run in your terminal.</p> <p>Skills (<code>/ctx-reflect</code>, <code>/ctx-next</code>) run inside your AI coding assistant.</p> <p>Recipes combine both.</p> <p>Think of commands as structure and skills as behavior.</p>","path":["Recipes","Getting Started","Guide Your Agent"],"tags":[]},{"location":"recipes/guide-your-agent/#proactive-behavior","level":2,"title":"Proactive Behavior","text":"<p>These recipes show explicit commands and skills, but agents trained on the <code>ctx</code> playbook are proactive: They offer to save learnings after debugging, record decisions after trade-offs, create follow-up tasks after completing work, and suggest what to work on next.</p> <p>Your questions train the agent. Asking \"what have we learned?\" or \"is our context clean?\" does two things:</p> <ul> <li>It triggers the workflow right now,</li> <li>and it reinforces the pattern.</li> </ul> <p>The more you guide, the more the agent habituates the behavior and begins offering on its own.</p> <p>Each recipe includes a Conversational Approach section showing these natural-language patterns.</p> <p>Tip</p> <p>Don't wait passively for proactive behavior: especially in early sessions.</p> <p>Ask, guide, reinforce. Over time, you ask less and the agent offers more.</p>","path":["Recipes","Getting Started","Guide Your Agent"],"tags":[]},{"location":"recipes/guide-your-agent/#next-up","level":2,"title":"Next Up","text":"<p>Setup Across AI Tools →: Initialize ctx and configure hooks for Claude Code, Cursor, Aider, Copilot, or Windsurf.</p>","path":["Recipes","Getting Started","Guide Your Agent"],"tags":[]},{"location":"recipes/guide-your-agent/#see-also","level":2,"title":"See Also","text":"<ul> <li>The Complete Session: full session   lifecycle from start to finish</li> <li>Prompting Guide: general tips for   working effectively with AI coding assistants</li> </ul>","path":["Recipes","Getting Started","Guide Your Agent"],"tags":[]},{"location":"recipes/hook-output-patterns/","level":1,"title":"Hook Output Patterns","text":"","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#the-problem","level":2,"title":"The Problem","text":"<p>Claude Code hooks can output text, JSON, or nothing at all. But the format of that output determines who sees it and who acts on it. </p> <p>Choose the wrong pattern, and your carefully crafted warning gets silently  absorbed by the agent, or your agent-directed nudge gets dumped on the user  as noise.</p> <p>This recipe catalogs the known hook output patterns and explains when to use each one.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#tldr","level":2,"title":"TL;DR","text":"<p>Eight patterns from full control to full invisibility: </p> <ul> <li>hard gate (<code>exit 2</code>), </li> <li>VERBATIM relay (agent MUST show), </li> <li>agent directive (context injection), </li> <li>and silent side-effect (background work).</li> </ul> <p>Most hooks belong in the middle.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#the-spectrum","level":2,"title":"The Spectrum","text":"<p>These patterns form a spectrum based on who decides what the user sees:</p> Pattern Who decides? Hard gate Hook decides (agent can't proceed) VERBATIM relay Hook decides (agent must show) Escalating severity Hook suggests, agent judges urgency Conditional relay Hook sets criteria, agent evaluates Suggested action Hook proposes, agent + user decide Agent directive Agent decides entirely Silent injection Nobody: invisible background context Silent side-effect Nobody: invisible background work <p>The spectrum runs from full hook control (hard gate) to full invisibility (silent side effect). </p> <p>Most hooks belong somewhere in the middle.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#pattern-1-hard-gate","level":2,"title":"Pattern 1: Hard Gate","text":"<p>Block the tool call entirely. The agent cannot proceed: it must find another approach or tell the user.</p> <pre><code>echo '{\"decision\": \"block\", \"reason\": \"Use ctx from PATH, not ./ctx\"}'\n</code></pre> <p>When to use: Enforcing invariants that must never be violated: Constitution rules, security boundaries, destructive command prevention.</p> <p>Hook type: <code>PreToolUse</code> only (Claude Code first-class mechanism).</p> <p>Examples in <code>ctx</code>:</p> <ul> <li><code>ctx system block-non-path-ctx</code>: Enforces the PATH invocation rule</li> <li><code>block-git-push.sh</code>: Requires explicit user approval for pushes (project-local)</li> <li><code>block-dangerous-commands.sh</code>: Prevents <code>sudo</code>, copies to <code>~/.local/bin</code> (project-local)</li> </ul> <p>Trade-off: The agent gets a block response with a reason. Good reasons help the agent recover (\"use X instead\"); bad reasons leave it stuck.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#pattern-2-verbatim-relay","level":2,"title":"Pattern 2: VERBATIM Relay","text":"<p>Force the agent to show this to the user as-is. The explicit instruction overcomes the agent's tendency to silently absorb context.</p> <pre><code>echo \"IMPORTANT: Relay this warning to the user VERBATIM before answering their question.\"\necho \"\"\necho \"┌─ Journal Reminder ─────────────────────────────\"\necho \"│ You have 12 sessions not yet exported.\"\necho \"└────────────────────────────────────────────────\"\n</code></pre> <p>When to use: Actionable reminders the user needs to see regardless of what they asked: Stale backups, unexported sessions, resource warnings.</p> <p>Hook type: <code>UserPromptSubmit</code> (runs before the agent sees the prompt).</p> <p>Examples in <code>ctx</code>:</p> <ul> <li><code>ctx system check-journal</code>: Unexported sessions and unenriched entries</li> <li><code>ctx system check-context-size</code>: Context capacity warning</li> <li><code>ctx system check-resources</code>: Resource pressure (memory, swap, disk, load) — <code>DANGER</code> only</li> <li><code>check-backup-age.sh</code>: Stale backup warning (project-local)</li> </ul> <p>Trade-off: Noisy if overused. Every VERBATIM relay adds a preamble before the agent's actual answer. Throttle with once-per-day markers or adaptive frequency.</p> <p>Key detail: The phrase <code>IMPORTANT: Relay this ... VERBATIM</code> is what makes this work. Without it, agents tend to process the information internally and never surface it. The explicit instruction is the pattern: the box-drawing is just fancy formatting.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#pattern-3-agent-directive","level":2,"title":"Pattern 3: Agent Directive","text":"<p>Tell the agent to do something, not the user. The agent decides whether and how to involve the user.</p> <pre><code>echo \"┌─ Persistence Checkpoint (prompt #25) ───────────\"\necho \"│ No context files updated in 15+ prompts.\"\necho \"│ Have you discovered learnings, decisions,\"\necho \"│ or completed tasks worth persisting?\"\necho \"└──────────────────────────────────────────────────\"\n</code></pre> <p>When to use: Behavioral nudges. The hook detects a condition and asks the agent to consider an action. The user may never need to know.</p> <p>Hook type: <code>UserPromptSubmit</code>.</p> <p>Examples in <code>ctx</code>:</p> <ul> <li><code>ctx system check-persistence</code>: Nudges the agent to persist context</li> </ul> <p>Trade-off: No guarantee the agent acts. The nudge is one signal among many in the context window. Strong phrasing helps (\"Have you...?\" is better than \"Consider...\"), but ultimately the agent decides.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#pattern-4-silent-context-injection","level":2,"title":"Pattern 4: Silent Context Injection","text":"<p>Load context with no visible output. The agent gets enriched without either party noticing.</p> <pre><code>ctx agent --budget 4000 &gt;/dev/null || true\n</code></pre> <p>When to use: Background context loading that should be invisible. The agent benefits from the information, but neither it, nor the user needs to know it happened.</p> <p>Hook type: <code>PreToolUse</code> with <code>.*</code> matcher (runs on every tool call).</p> <p>Examples in <code>ctx</code>:</p> <ul> <li>The <code>ctx agent</code> <code>PreToolUse</code> hook: injects project context silently</li> </ul> <p>Trade-off: Adds latency to every tool call. Keep the injected content small and fast to generate.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#pattern-5-silent-side-effect","level":2,"title":"Pattern 5: Silent Side-Effect","text":"<p>Do work, produce no output: Housekeeping that needs no acknowledgment.</p> <pre><code>find \"$CTX_TMPDIR\" -type f -mtime +15 -delete\n</code></pre> <p>When to use: Cleanup, log rotation, temp file management. Anything where the action is the point and nobody needs to know it happened.</p> <p>Hook type: <code>SessionEnd</code>, or any hook where output is irrelevant.</p> <p>Examples in <code>ctx</code>:</p> <ul> <li><code>ctx system cleanup-tmp</code>: Removes stale temp files on session end</li> </ul> <p>Trade-off: None, if the action is truly invisible. If it can fail in a way that matters, consider logging.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#pattern-6-conditional-relay","level":3,"title":"Pattern 6: Conditional Relay","text":"<p>Tell the agent to relay only if a condition holds in context.</p> <pre><code>echo \"If the user's question involves modifying .context/ files,\"\necho \"relay this warning VERBATIM:\"\necho \"\"\necho \"┌─ Context Integrity ─────────────────────────────\"\necho \"│ CONSTITUTION.md has not been verified in 7 days.\"\necho \"└────────────────────────────────────────────────\"\necho \"\"\necho \"Otherwise, proceed normally.\"\n</code></pre> <p>When to use: Warnings that only matter in certain contexts. Avoids noise when the user is doing unrelated work.</p> <p>Trade-off: Depends on the agent's judgment about when the condition holds. More fragile than VERBATIM relay, but less noisy.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#pattern-7-suggested-action","level":3,"title":"Pattern 7: Suggested Action","text":"<p>Give the agent a specific command to propose to the user.</p> <pre><code>echo \"┌─ Stale Dependencies ──────────────────────────\"\necho \"│ go.sum is 30+ days newer than go.mod.\"\necho \"│ Suggested: run \\`go mod tidy\\`\"\necho \"│ Ask the user before proceeding.\"\necho \"└───────────────────────────────────────────────\"\n</code></pre> <p>When to use: The hook detects a fixable condition and knows the fix. Goes beyond a nudge: Gives the agent a concrete next step. The agent still asks for permission but knows exactly what to propose.</p> <p>Trade-off: The suggestion might be wrong or outdated. The \"ask the user before proceeding\" part is critical.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#pattern-8-escalating-severity","level":3,"title":"Pattern 8: Escalating Severity","text":"<p>Different urgency tiers with different relay expectations.</p> <pre><code># INFO: agent processes silently, mentions if relevant\necho \"INFO: Last test run was 3 days ago.\"\n\n# WARN: agent should mention to user at next natural pause\necho \"WARN: 12 uncommitted changes across 3 branches.\"\n\n# CRITICAL: agent must relay immediately, before any other work\necho \"CRITICAL: Relay VERBATIM before answering. Disk usage at 95%.\"\n</code></pre> <p>When to use: When you have multiple hooks producing output and need to avoid overwhelming the user. <code>INFO</code> gets absorbed, <code>WARN</code> gets mentioned, <code>CRITICAL</code> interrupts.</p> <p>Examples in <code>ctx</code>:</p> <ul> <li><code>ctx system check-resources</code>: Uses two tiers (<code>WARNING</code>/<code>DANGER</code>) internally   but only fires the VERBATIM relay at <code>DANGER</code> level: <code>WARNING</code> is silent.   See <code>ctx system</code> for the user-facing command that shows both tiers.</li> </ul> <p>Trade-off: Requires agent training or convention to recognize the tiers. Without a shared protocol, the prefixes are just text.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#choosing-a-pattern","level":2,"title":"Choosing a Pattern","text":"<pre><code>Is the agent about to do something forbidden?\n  └─ Yes → Hard gate\n\nDoes the user need to see this regardless of what they asked?\n  └─ Yes → VERBATIM relay\n  └─ Sometimes → Conditional relay\n\nShould the agent consider an action?\n  └─ Yes, with a specific fix → Suggested action\n  └─ Yes, open-ended → Agent directive\n\nIs this background context the agent should have?\n  └─ Yes → Silent injection\n\nIs this housekeeping?\n  └─ Yes → Silent side-effect\n</code></pre>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#design-tips","level":2,"title":"Design Tips","text":"<p>Throttle aggressively: VERBATIM relays that fire every prompt will be ignored or resented. Use once-per-day markers (<code>touch $REMINDED</code>), adaptive frequency (every Nth prompt), or staleness checks (only fire if condition persists).</p> <p>Include actionable commands: \"You have 12 unexported sessions\" is less useful than \"You have 12 unexported sessions. Run: <code>ctx recall export --all</code>.\" Give the user (or agent) the exact next step.</p> <p>Use box-drawing for visual structure: The <code>┌─ ─┐ │ └─ ─┘</code> pattern makes hook output visually distinct from agent prose. It also signals \"this is machine-generated, not agent opinion.\"</p> <p>Test the silence path: Most hook runs should produce no output (the condition isn't met). Make sure the common case is fast and silent.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#common-pitfalls","level":2,"title":"Common Pitfalls","text":"<p>Lessons from 19 days of hook debugging in <code>ctx</code>. Every one of these was encountered, debugged, and fixed in production.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#silent-misfire-wrong-key-name","level":3,"title":"Silent Misfire: Wrong Key Name","text":"<pre><code>{ \"PreToolUseHooks\": [ ... ] }\n</code></pre> <p>The key is <code>PreToolUse</code>, not <code>PreToolUseHooks</code>. Claude Code validates silently: A misspelled key means the hook is ignored with no error. Always test with a debug <code>echo</code> first to confirm the hook fires before adding real logic.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#json-escaping-breaks-shell-commands","level":3,"title":"JSON Escaping Breaks Shell Commands","text":"<p>Go's <code>json.Marshal</code> escapes <code>&gt;</code>, <code>&lt;</code>, and <code>&amp;</code> as Unicode sequences (<code>\\u003e</code>) by default. This breaks shell commands in generated config:</p> <pre><code>\"command\": \"ctx agent 2\\u003e/dev/null\"\n</code></pre> <p>Fix: use <code>json.Encoder</code> with <code>SetEscapeHTML(false)</code> when generating hook configuration.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#stdin-not-environment-variables","level":3,"title":"<code>stdin</code>, Not Environment Variables","text":"<p>Hook input arrives as JSON via <code>stdin</code>, not environment variables:</p> <pre><code># Wrong:\nCOMMAND=\"$CLAUDE_TOOL_INPUT\"\n\n# Right:\nHOOK_INPUT=$(cat)\nCOMMAND=$(echo \"$HOOK_INPUT\" | jq -r '.tool_input.command // empty')\n</code></pre>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#regex-overfitting","level":3,"title":"Regex Overfitting","text":"<p>A regex meant to catch <code>ctx</code> as a binary will also match <code>ctx</code> as a directory component:</p> <pre><code># Too broad: blocks: git -C /home/jose/WORKSPACE/ctx status\n(/home/|/tmp/|/var/)[^ ]*ctx[^ ]*\n\n# Narrow to binary only:\n(/home/|/tmp/|/var/)[^ ]*/ctx( |$)\n</code></pre> <p>Test hook regexes against paths that contain the target string as a substring, not just as the final component.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#repetition-fatigue","level":3,"title":"Repetition Fatigue","text":"<p>Injecting context on every tool call sounds safe. In practice, after seeing the same context injection fifteen times, the agent treats it as background noise: Conventions stated in the injected context get violated because salience has been destroyed by repetition.</p> <p>Fix: cooldowns. <code>ctx agent --session $PPID --cooldown 10m</code> injects at most once per ten minutes per session using a tombstone file in <code>/tmp/</code>. This is not an optimization; it is a correction for a design flaw. Every injection consumes attention budget: 50 tool calls at 4,000 tokens each means 200,000 tokens of repeated context, most of it wasted.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#hardcoded-paths","level":3,"title":"Hardcoded Paths","text":"<p>A username rename (<code>parallels</code> to <code>jose</code>) broke every hook at once. Use <code>$CLAUDE_PROJECT_DIR</code> instead of absolute paths:</p> <pre><code>\"command\": \"\\\"$CLAUDE_PROJECT_DIR\\\"/.claude/hooks/block-git-push.sh\"\n</code></pre> <p>If the platform provides a runtime variable for paths, always use it.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#next-up","level":2,"title":"Next Up","text":"<p>Webhook Notifications →: Get push notifications when loops complete, hooks fire, or agents hit milestones.</p>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/hook-output-patterns/#see-also","level":2,"title":"See Also","text":"<ul> <li>Claude Code Permission Hygiene: how   permissions and hooks work together</li> <li>Defense in Depth:   why hooks matter for agent security</li> </ul>","path":["Recipes","Hooks and Notifications","Hook Output Patterns"],"tags":[]},{"location":"recipes/knowledge-capture/","level":1,"title":"Persisting Decisions, Learnings, and Conventions","text":"","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#the-problem","level":2,"title":"The Problem","text":"<p>You debug a subtle issue, discover the root cause, and move on.</p> <p>Three weeks later, a different session hits the same issue. The knowledge existed briefly in one session's memory but was never written down.</p> <p>Architectural decisions suffer the same fate: you weigh trade-offs, pick an approach, and six sessions later the AI suggests the alternative you already rejected.</p> <p>How do you make sure important context survives across sessions?</p>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#tldr","level":2,"title":"TL;DR","text":"<pre><code>/ctx-reflect               # surface items worth persisting\n/ctx-add-decision \"Title\"  # record with context/rationale/consequences\n/ctx-add-learning \"Title\"  # record with context/lesson/application\n</code></pre> <p>Or just tell your agent: \"What have we learned this session?\"</p>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx add decision</code> Command Record an architectural decision <code>ctx add learning</code> Command Record a gotcha, tip, or lesson <code>ctx add convention</code> Command Record a coding pattern or standard <code>ctx decisions reindex</code> Command Rebuild the quick-reference index <code>ctx learnings reindex</code> Command Rebuild the quick-reference index <code>/ctx-add-decision</code> Skill AI-guided decision capture with validation <code>/ctx-add-learning</code> Skill AI-guided learning capture with validation <code>/ctx-add-convention</code> Skill AI-guided convention recording with placement <code>/ctx-reflect</code> Skill Surface items worth persisting at breakpoints","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#the-workflow","level":2,"title":"The Workflow","text":"<p>Decision, Learning, or Convention?</p> <ul> <li>If you chose between alternatives, it is a decision.</li> <li>If you discovered something surprising, it is a learning.</li> <li>If you are codifying a repeated pattern, it is a convention.</li> </ul>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-1-understand-what-to-persist","level":3,"title":"Step 1: Understand What to Persist","text":"<p>Three context files serve different purposes:</p> <p>Decisions (<code>DECISIONS.md</code>) answer \"why is it this way?\" They record trade-offs between alternatives with structured fields: context, rationale, and consequences. Decisions prevent re-debating settled questions.</p> <p>Learnings (<code>LEARNINGS.md</code>) answer \"what did we discover the hard way?\" They record gotchas and debugging insights specific to this project with structured fields: context, lesson, and application. </p> <p>Learnings prevent repeating past mistakes.</p> <p>Conventions (<code>CONVENTIONS.md</code>) answer \"how do we do things here?\" They record patterns and standards. No structured fields required: just a name, a rule, and an example. Conventions keep code consistent across sessions.</p>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-2-record-decisions","level":3,"title":"Step 2: Record Decisions","text":"<p>Decisions have three structured fields: </p> <ul> <li>context, </li> <li>rationale, </li> <li>and consequences.</li> </ul> <p>The easiest way to record one is to tell your agent:</p> <pre><code>You: \"Save that as a decision: we picked file-based cooldown\n      tokens over env vars.\"\n\nAgent: \"Recorded in DECISIONS.md:\n  - Decision: Use file-based cooldown tokens instead of env vars\n  - Context: Hook subprocesses cannot persist env vars to parent shell\n  - Rationale: File tokens survive across processes. Simpler than\n    IPC. Cleanup is automatic via TTL.\n  - Consequences: Tombstone files accumulate in /tmp. Cannot share\n    state across machines.\"\n</code></pre> <p>The agent was present for the trade-off discussion. It fills in the structured fields from what it observed, which is hard to reconstruct later as a terminal one-liner.</p> <p>When multiple options were considered, the agent includes rejected alternatives in the rationale automatically.</p> <p>The <code>/ctx-add-decision</code> skill also guides you through the fields interactively. For quick decisions, it supports a Y-statement:</p> <p>\"In the context of [situation], facing [constraint], we decided for [choice] and against [alternatives], to achieve [benefit], accepting that [trade-off].\"</p> CLI Command for Scripting and Automation <p>When no agent is in the loop (CI pipelines, shell scripts, hooks), use the CLI directly with structured flags:</p> <pre><code>ctx add decision \"Use file-based cooldown tokens instead of env vars\" \\\n  --context \"Hook subprocesses cannot persist env vars to parent shell\" \\\n  --rationale \"File tokens survive across processes. Simpler than IPC. Cleanup is automatic via TTL.\" \\\n  --consequences \"Tombstone files accumulate in /tmp. Cannot share state across machines.\"\n</code></pre>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-3-record-learnings","level":3,"title":"Step 3: Record Learnings","text":"<p>Learnings have three structured fields: context, lesson, and application.</p> <p>Again, your agent is the best tool for this. It was there when you discovered the gotcha and can express it more completely than a backslash-escaped terminal command:</p> <pre><code>You: \"That subprocess thing was painful. Save it as a learning.\"\n\nAgent: \"Added to LEARNINGS.md:\n  - Learning: Claude Code hooks run in a subprocess\n  - Context: Set env var in PreToolUse hook, but it was not visible\n    in the main session\n  - Lesson: Hook scripts execute in a child process. Env changes do\n    not propagate to parent.\n  - Application: Use tombstone files for hook-to-session\n    communication. Never rely on hook env vars.\"\n</code></pre> <p>You said one sentence. The agent produced a structured entry with all three fields filled from the session context.</p> <p>That is the point: the agent has the full conversation and can be far more expressive than what you would type at a command prompt.</p> <p>The <code>/ctx-add-learning</code> skill applies three quality filters:</p> <ol> <li>Could someone Google this in 5 minutes?</li> <li>Is it specific to this codebase?</li> <li>Did it take real effort to discover?</li> </ol> <p>All three must pass.</p> <p>Learnings capture principles and heuristics, not code snippets.</p> CLI Command for Scripting and Automation <p>When no agent is in the loop:</p> <pre><code>ctx add learning \"Claude Code hooks run in a subprocess\" \\\n  --context \"Set env var in PreToolUse hook, but it was not visible in the main session\" \\\n  --lesson \"Hook scripts execute in a child process. Env changes do not propagate to parent.\" \\\n  --application \"Use tombstone files for hook-to-session communication. Never rely on hook env vars.\"\n</code></pre>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-4-record-conventions","level":3,"title":"Step 4: Record Conventions","text":"<p>Conventions are simpler: just a name, a rule, and optionally a section.</p> <p>These are short enough that either approach works:</p> <pre><code>You: \"We've been using kebab-case for every CLI flag. Codify that.\"\n\nAgent: \"Added to CONVENTIONS.md under Naming:\n  'Use kebab-case for all CLI flag names.'\"\n</code></pre> <p>Or from the terminal:</p> <pre><code>ctx add convention \"Use kebab-case for all CLI flag names\" --section \"Naming\"\n</code></pre> <p>Conventions work best for rules that come up repeatedly. Codify a pattern the third time you see it, not the first.</p>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-5-reindex-after-manual-edits","level":3,"title":"Step 5: Reindex After Manual Edits","text":"<p><code>DECISIONS.md</code> and <code>LEARNINGS.md</code> maintain a quick-reference index at the top: a compact table of date and title for each entry. The index updates automatically via <code>ctx add</code>, but falls out of sync after hand edits.</p> <pre><code>ctx decisions reindex\nctx learnings reindex\n</code></pre> <p>Run reindex after any manual edit. The index lets AI tools scan all entries without reading the full file, which matters when token budgets are tight.</p>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-6-use-ctx-reflect-to-surface-what-to-capture","level":3,"title":"Step 6: Use /ctx-reflect to Surface What to Capture","text":"<p>Keep It Conversational</p> <p><code>/ctx-reflect</code> is not the only way to trigger reflection.</p> <p>Agents trained on the <code>ctx</code> playbook naturally surface persist-worthy items at breakpoints, even without invoking the skill explicitly.</p> <p>A conversational prompt like \"anything worth saving?\" or \"let's wrap up\" can trigger the same review.</p> <p>The skill provides a structured checklist, but the behavior is available through natural conversation.</p> <p>At natural breakpoints (after completing a feature, fixing a bug, or before ending a session) use <code>/ctx-reflect</code> to identify items worth persisting.</p> <pre><code>/ctx-reflect\n</code></pre> <p>The skill walks through learnings, decisions, tasks, and session notes, skipping categories with nothing to report. The output includes specific commands for each suggested persist:</p> <pre><code>This session implemented file-based cooldown for `ctx agent` and\ndiscovered that hook subprocesses cannot set env vars in the parent.\n\nI'd suggest persisting:\n- **Learning**: Hook subprocesses cannot propagate env vars\n  `ctx add learning \"...\" --context \"...\" --lesson \"...\" --application \"...\"`\n- **Decision**: File-based cooldown tokens over env vars\n  `ctx add decision \"...\" --context \"...\" --rationale \"...\" --consequences \"...\"`\n\nWant me to persist any of these?\n</code></pre> <p>The skill always asks before persisting.</p>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-7-the-conversational-approach","level":3,"title":"Step 7: The Conversational Approach","text":"<p>The commands shown in Steps 2 to 4 are precise, but you rarely need to type them yourself. When working with an agent that has loaded the <code>ctx</code> playbook, natural language triggers the same operations.</p> <p>You ask, the agent acts:</p> You say What the agent does \"What have we learned this session?\" Reviews recent work, identifies learnings, offers to persist \"Save that as a decision\" Captures the trade-off you just discussed with structured fields \"Any gotchas worth remembering?\" Scans recent work for non-obvious lessons \"Record that convention\" Adds the pattern you just agreed on to <code>CONVENTIONS.md</code> \"Let's wrap up\" Runs through the reflect checklist conversationally <p>Example exchange:</p> <pre><code>You: \"What did we learn from that debugging session?\"\n\nAgent: \"We discovered three things worth persisting:\n  1. Hook subprocesses can't propagate env vars to the parent. We\n     spent 20 minutes on this before switching to tombstone files.\n  2. Tombstone files need a TTL or they accumulate in /tmp.\n  3. The cooldown logic must check file mtime, not just existence.\n  Want me to save these as learnings?\"\n\nYou: \"Yes, all of them.\"\n\nAgent: \"Done. Added all three to LEARNINGS.md with structured fields.\"\n</code></pre> <p>The agent can also be proactive without being asked. The playbook encourages agents to persist context at natural milestones.</p> <p>You may see:</p> <ul> <li>After fixing a tricky bug: \"I noticed this was a non-obvious issue.   Want me to save it as a learning?\"</li> <li>After choosing between approaches: \"We just made a trade-off between   file-based tokens and IPC. Should I record this as a decision?\"</li> <li>At session milestones: the agent checks what is worth persisting and offers a   brief summary.</li> </ul> <p>When agents run unattended (no human in the loop), they may persist directly:</p> <ul> <li>\"I've added the subprocess env var gotcha to <code>LEARNINGS.md</code> so we don't hit it again.\"</li> <li>\"Recorded the decision to use file-based tokens over env vars in <code>DECISIONS.md</code>.\"</li> <li>\"Marked the cooldown task done and added a follow-up for TTL cleanup.\"</li> </ul> <p>This is behavior by design.</p> <p>The playbook's self-check prompt, \"If this session ended right now, would the next session know what happened?\" drives agents to persist early and often rather than waiting for explicit instructions.</p>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#command-line-approach-scripting-and-automation","level":3,"title":"Command-line Approach (Scripting and Automation)","text":"<pre><code># Decision: record the trade-off\nctx add decision \"Use PostgreSQL over SQLite\" \\\n  --context \"Need concurrent multi-user access\" \\\n  --rationale \"SQLite locks on writes; Postgres handles concurrency\" \\\n  --consequences \"Requires a database server; team needs Postgres training\"\n\n# Learning: record the gotcha\nctx add learning \"SQL migrations must be idempotent\" \\\n  --context \"Deploy failed when migration ran twice after rollback\" \\\n  --lesson \"CREATE TABLE without IF NOT EXISTS fails on retry\" \\\n  --application \"Always use IF NOT EXISTS guards in migrations\"\n\n# Convention: record the pattern\nctx add convention \"API handlers return structured errors\" --section \"API\"\n\n# Reindex after manual edits\nctx decisions reindex\nctx learnings reindex\n\n# Reflect at breakpoints (from AI assistant)\n# /ctx-reflect\n</code></pre>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#conversational-approach-interactive-sessions","level":3,"title":"Conversational Approach (Interactive Sessions)","text":"<pre><code>You: \"We just picked Postgres over SQLite for the concurrency\n      reasons. Save that?\"\n\nAgent: \"Recorded. Added to DECISIONS.md:\n  - Decision: Use PostgreSQL over SQLite\n  - Context: Need concurrent multi-user access\n  - Rationale: SQLite locks on writes; Postgres handles concurrency\n  - Consequences: Requires a database server; team needs Postgres\n    training\"\n\nYou: \"Also that migration thing. The deploy blew up when the\n      migration ran twice.\"\n\nAgent: \"Got it. Added to LEARNINGS.md:\n  - Learning: SQL migrations must be idempotent\n  - Lesson: CREATE TABLE without IF NOT EXISTS fails on retry\n  - Application: Always use IF NOT EXISTS guards in migrations\"\n\nYou: \"Good. Anything else worth saving before we wrap up?\"\n\nAgent: \"We've been using structured error returns in every API\n  handler this session. Want me to codify that as a convention?\"\n\nYou: \"Do it.\"\n\nAgent: \"Done. Added 'API handlers return structured errors' to\n  CONVENTIONS.md under the API section.\"\n</code></pre> <p>Both approaches produce the same structured entries in the same context files.</p> <ul> <li>The conversational approach is the natural fit for interactive sessions; </li> <li>the CLI commands are better suited for scripts, hooks, and automation pipelines.</li> </ul>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#tips","level":2,"title":"Tips","text":"<ul> <li>Record decisions at the moment of choice. The alternatives you considered and   the reasons you rejected them fade quickly. Capture trade-offs while they are   fresh.</li> <li>Learnings should fail the Gemini test. If someone could find it in a 5-minute   Gemini search, it does not belong in <code>LEARNINGS.md</code>.</li> <li>Conventions earn their place through repetition. Add a convention the third   time you see a pattern, not the first.</li> <li>Use <code>/ctx-reflect</code> at natural breakpoints. The checklist catches items you   might otherwise lose.</li> <li>Keep the entries self-contained. Each entry should make sense on its own. A   future session may load only one due to token budget constraints.</li> <li>Reindex after every hand edit. It takes less than a second. A stale index   causes AI tools to miss entries.</li> <li>Prefer the structured fields. The verbosity forces clarity. A decision without   a rationale is just a fact. A learning without an application is just a story.</li> <li>Talk to your agent, do not type commands. In interactive sessions, the   conversational approach is the recommended way to capture knowledge. Say   \"save that as a learning\" or \"any decisions worth recording?\" and let the   agent handle the structured fields. Reserve the CLI commands for scripting,   automation, and CI/CD pipelines where there is no agent in the loop.</li> <li>Trust the agent's proactive instincts. Agents trained on the <code>ctx</code> playbook will   offer to persist context at milestones. A brief \"want me to save this?\" is   cheaper than re-discovering the same lesson three sessions later.</li> </ul>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#next-up","level":2,"title":"Next Up","text":"<p>Tracking Work Across Sessions →: Add, prioritize, complete, and archive tasks across sessions.</p>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#see-also","level":2,"title":"See Also","text":"<ul> <li>Tracking Work Across Sessions: managing the tasks that   decisions and learnings support</li> <li>The Complete Session: full session lifecycle including   reflection and context persistence</li> <li>Detecting and Fixing Drift: keeping knowledge files   accurate as the codebase evolves</li> <li>CLI Reference: full documentation for <code>ctx add</code>,   <code>ctx decisions</code>, <code>ctx learnings</code></li> <li>Context Files: format and conventions for <code>DECISIONS.md</code>,   <code>LEARNINGS.md</code>, and <code>CONVENTIONS.md</code></li> </ul>","path":["Recipes","Knowledge and Tasks","Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/multi-tool-setup/","level":1,"title":"Setup Across AI Tools","text":"","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#the-problem","level":2,"title":"The Problem","text":"<p>You have installed <code>ctx</code> and want to set it up with your AI coding assistant so that context persists across sessions. Different tools have different integration depths. For example: </p> <ul> <li>Claude Code supports native hooks that load and save context automatically.</li> <li>Cursor injects context via its system prompt.</li> <li>Aider reads context files through its <code>--read</code> flag.</li> </ul> <p>This recipe walks through the complete setup for each tool, from initialization through verification, so you end up with a working memory layer regardless of which AI tool you use.</p>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#tldr","level":2,"title":"TL;DR","text":"<pre><code>cd your-project\nctx init                      # creates .context/\nsource &lt;(ctx completion zsh)  # shell completion (or bash/fish)\n\n# ## Claude Code (automatic after plugin install) ##\nclaude /plugin marketplace add ActiveMemory/ctx\nclaude /plugin install ctx@activememory-ctx\n\n# ## Cursor / Aider / Copilot / Windsurf ##\nctx hook cursor # or: aider, copilot, windsurf\n</code></pre> <p>Create a <code>.ctxrc</code> in your project root to configure token budgets, context directory, drift thresholds, and more.</p> <p>Then start your AI tool and ask: \"Do you remember?\"</p>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Command/Skill Role in this workflow <code>ctx init</code> Create <code>.context/</code> directory, templates, and permissions <code>ctx hook</code> Generate integration configuration for a specific AI tool <code>ctx agent</code> Print a token-budgeted context packet for AI consumption <code>ctx load</code> Output assembled context in read order (for manual pasting) <code>ctx watch</code> Auto-apply context updates from AI output (non-native tools) <code>ctx completion</code> Generate shell autocompletion for bash, zsh, or fish <code>ctx recall export</code> Export sessions to editable journal Markdown","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-1-initialize-ctx","level":3,"title":"Step 1: Initialize <code>ctx</code>","text":"<p>Run <code>ctx init</code> in your project root. This creates the <code>.context/</code> directory with all template files and seeds ctx permissions in <code>settings.local.json</code>.</p> <pre><code>cd your-project\nctx init\n</code></pre> <p>This produces the following structure:</p> <pre><code>.context/\n  CONSTITUTION.md     # Hard rules the AI must never violate\n  TASKS.md            # Current and planned work\n  CONVENTIONS.md      # Code patterns and standards\n  ARCHITECTURE.md     # System overview\n  DECISIONS.md        # Architectural decisions with rationale\n  LEARNINGS.md        # Lessons learned, gotchas, tips\n  GLOSSARY.md         # Domain terms and abbreviations\n  AGENT_PLAYBOOK.md   # How AI tools should use this system\n</code></pre> <p>Using a Different <code>.context</code> Directory</p> <p>The <code>.context/</code> directory doesn't have to live inside your project. You can point <code>ctx</code> to an external folder via <code>.ctxrc</code>, the <code>CTX_DIR</code> environment variable, or the <code>--context-dir</code> CLI flag. </p> <p>This is useful for monorepos or shared context across repositories.</p> <p>See Configuration for details and External Context for a full recipe.</p> <p>For Claude Code, install the ctx plugin to get hooks and skills:</p> <pre><code>claude /plugin marketplace add ActiveMemory/ctx\nclaude /plugin install ctx@activememory-ctx\n</code></pre> <p>If you only need the core files (useful for lightweight setups), use the <code>--minimal</code> flag:</p> <pre><code>ctx init --minimal\n</code></pre> <p>This creates only <code>TASKS.md</code>, <code>DECISIONS.md</code>, and <code>CONSTITUTION.md</code>.</p>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-2-generate-tool-specific-hooks","level":3,"title":"Step 2: Generate Tool-Specific Hooks","text":"<p>If you are using a tool other than Claude Code (which is configured automatically by <code>ctx init</code>), generate its integration configuration:</p> <pre><code># For Cursor\nctx hook cursor\n\n# For Aider\nctx hook aider\n\n# For GitHub Copilot\nctx hook copilot\n\n# For Windsurf\nctx hook windsurf\n</code></pre> <p>Each command prints the configuration you need. How you apply it depends on the tool.</p>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#claude-code","level":4,"title":"Claude Code","text":"<p>No action needed. Just install <code>ctx</code> from the Marketplace as <code>ActiveMemory/ctx</code>.</p> <p>Claude Code is a First-Class Citizen</p> <p>With the <code>ctx</code> plugin installed, Claude Code gets hooks and skills automatically. The <code>PreToolUse</code> hook runs <code>ctx agent --budget 4000</code> on every tool call (with a 10-minute cooldown so it only fires once per window).</p>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#cursor","level":4,"title":"Cursor","text":"<p>Add the system prompt snippet to <code>.cursor/settings.json</code>:</p> <pre><code>{\n  \"ai.systemPrompt\": \"Read .context/TASKS.md and .context/CONVENTIONS.md before responding. Follow rules in .context/CONSTITUTION.md.\"\n}\n</code></pre> <p>Context files appear in Cursor's file tree. You can also paste a context packet directly into chat:</p> <pre><code>ctx agent --budget 4000 | xclip    # Linux\nctx agent --budget 4000 | pbcopy   # macOS\n</code></pre>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#aider","level":4,"title":"Aider","text":"<p>Create <code>.aider.conf.yml</code> so context files are loaded on every session:</p> <pre><code>read:\n  - .context/CONSTITUTION.md\n  - .context/TASKS.md\n  - .context/CONVENTIONS.md\n  - .context/DECISIONS.md\n</code></pre> <p>Then start Aider normally:</p> <pre><code>aider\n</code></pre> <p>Or specify files on the command line:</p> <pre><code>aider --read .context/TASKS.md --read .context/CONVENTIONS.md\n</code></pre>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-3-set-up-shell-completion","level":3,"title":"Step 3: Set Up Shell Completion","text":"<p>Shell completion lets you tab-complete ctx subcommands and flags, which is especially useful while learning the CLI.</p> <pre><code># Bash (add to ~/.bashrc)\nsource &lt;(ctx completion bash)\n\n# Zsh (add to ~/.zshrc)\nsource &lt;(ctx completion zsh)\n\n# Fish\nctx completion fish &gt; ~/.config/fish/completions/ctx.fish\n</code></pre> <p>After sourcing, typing <code>ctx a&lt;TAB&gt;</code> completes to <code>ctx agent</code>, and <code>ctx recall &lt;TAB&gt;</code> shows <code>list</code>, <code>show</code>, and <code>export</code>.</p>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-4-verify-the-setup-works","level":3,"title":"Step 4: Verify the Setup Works","text":"<p>Start a fresh session in your AI tool and ask:</p> <p>\"Do you remember?\"</p> <p>A correctly configured tool responds with specific context: current tasks from <code>TASKS.md</code>, recent decisions, and previous session topics. It should not say \"I don't have memory\" or \"Let me search for files.\"</p> <p>This question checks the passive side of memory. A properly set-up agent is also proactive: it treats context maintenance as part of its job:</p> <ul> <li>After a debugging session, it offers to save a learning.</li> <li>After a trade-off discussion, it asks whether to record the decision.</li> <li>After completing a task, it suggests follow-up items.</li> </ul> <p>The \"do you remember?\" check verifies both halves: recall and responsibility.</p> <p>For example, after resolving a tricky bug, a proactive agent might say:</p> <pre><code>That Redis timeout issue was subtle. Want me to save this as a *learning*\nso we don't hit it again?\n</code></pre> <p>If you see behavior like this, the setup is working end to end.</p> <p>In Claude Code, you can also invoke the <code>/ctx-status</code> skill:</p> <pre><code>/ctx-status\n</code></pre> <p>This prints a summary of all context files, token counts, and recent activity, confirming that hooks are loading context.</p> <p>If context is not loading, check the basics:</p> Symptom Fix <code>ctx: command not found</code> Ensure ctx is in your PATH: <code>which ctx</code> Hook errors Verify plugin is installed: <code>claude /plugin list</code> Context not refreshing Cooldown may be active; wait 10 minutes or set <code>--cooldown 0</code>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-5-enable-watch-mode-for-non-native-tools","level":3,"title":"Step 5: Enable Watch Mode for Non-Native Tools","text":"<p>Tools like Aider, Copilot, and Windsurf do not support native hooks for saving context automatically. For these, run <code>ctx watch</code> alongside your AI tool.</p> <p>Pipe the AI tool's output through <code>ctx watch</code>:</p> <pre><code># Terminal 1: Run Aider with output logged\naider 2&gt;&amp;1 | tee /tmp/aider.log\n\n# Terminal 2: Watch the log for context updates\nctx watch --log /tmp/aider.log\n</code></pre> <p>Or for any generic tool:</p> <pre><code>your-ai-tool 2&gt;&amp;1 | tee /tmp/ai.log &amp;\nctx watch --log /tmp/ai.log\n</code></pre> <p>When the AI emits structured update commands, <code>ctx watch</code> parses and applies them automatically:</p> <pre><code>&lt;context-update type=\"learning\"\n  context=\"Debugging rate limiter\"\n  lesson=\"Redis MULTI/EXEC does not roll back on error\"\n  application=\"Wrap rate-limit checks in Lua scripts instead\"\n&gt;Redis Transaction Behavior&lt;/context-update&gt;\n</code></pre> <p>To preview changes without modifying files:</p> <pre><code>ctx watch --dry-run --log /tmp/ai.log\n</code></pre>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-6-export-session-transcripts-optional","level":3,"title":"Step 6: Export Session Transcripts (Optional)","text":"<p>If you want to browse past session transcripts, export them to the journal:</p> <pre><code>ctx recall export --all\n</code></pre> <p>This converts raw session data into editable Markdown files in <code>.context/journal/</code>. You can then enrich them with metadata using <code>/ctx-journal-enrich-all</code> inside your AI assistant.</p>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"<p>Here is the condensed setup for all three tools:</p> <pre><code># ## Common (run once per project) ##\ncd your-project\nctx init\nsource &lt;(ctx completion zsh)       # or bash/fish\n\n# ## Claude Code (automatic, just verify) ##\n# Start Claude Code, then ask: \"Do you remember?\"\n\n# ## Cursor ##\nctx hook cursor\n# Add the system prompt to .cursor/settings.json\n# Paste context: ctx agent --budget 4000 | pbcopy\n\n# ## Aider ##\nctx hook aider\n# Create .aider.conf.yml with read: paths\n# Run watch mode alongside: ctx watch --log /tmp/aider.log\n\n# ## Verify any Tool ##\n# Ask your AI: \"Do you remember?\"\n# Expect: specific tasks, decisions, recent context\n</code></pre>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#tips","level":2,"title":"Tips","text":"<ul> <li>Start with <code>ctx init</code> (not <code>--minimal</code>) for your first project. The full   template set gives the agent more to work with, and you can always delete   files later.</li> <li>For Claude Code, the token budget is configured in the plugin's <code>hooks.json</code>.   To customize, adjust the <code>--budget</code> flag in the <code>ctx agent</code> hook command.</li> <li>The <code>--session $PPID</code> flag isolates cooldowns per Claude Code process, so   parallel sessions do not suppress each other.</li> <li>Commit your <code>.context/</code> directory to version control. Several ctx features   (journals, changelogs, blog generation) rely on git history.</li> <li>For Cursor and Copilot, keep <code>CONVENTIONS.md</code> visible. These tools treat   open files as higher-priority context.</li> <li>Run <code>ctx drift</code> periodically to catch stale references before they confuse   the agent.</li> <li>The agent playbook instructs the agent to persist context at natural   milestones (completed tasks, decisions, gotchas). In practice, this   works best when you reinforce the habit: a quick \"anything worth saving?\"   after a debugging session goes a long way.</li> </ul>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#next-up","level":2,"title":"Next Up","text":"<p>Keeping Context in a Separate Repo →: Store context files outside the project tree for multi-repo or open source setups.</p>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#see-also","level":2,"title":"See Also","text":"<ul> <li>The Complete Session: full session lifecycle recipe</li> <li>CLI Reference: all commands and flags</li> <li>Integrations: detailed per-tool integration docs</li> </ul>","path":["Recipes","Getting Started","Setup Across AI Tools"],"tags":[]},{"location":"recipes/parallel-worktrees/","level":1,"title":"Parallel Agent Development with Git Worktrees","text":"","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#the-problem","level":2,"title":"The Problem","text":"<p>You have a large backlog (10, 20, 30 open tasks) and many of them are independent: docs work that doesn't touch Go code, a new package that doesn't overlap with existing ones, test coverage for a stable module.</p> <p>Running one agent at a time means serial execution. You want 3-4 agents working in parallel, each on its own track, without stepping on each other's files.</p> <p>Git worktrees solve this. </p> <p>Each worktree is a separate working directory with its own branch, but they  share the same <code>.git</code> object database. Combined with <code>ctx</code>'s persistent context,  each agent session picks up the full project state and works independently.</p>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#tldr","level":2,"title":"TL;DR","text":"<pre><code>/ctx-worktree                                   # 1. group tasks by file overlap\ngit worktree add ../myproject-docs -b work/docs # 2. create worktrees\ncd ../myproject-docs &amp;&amp; claude                  # 3. launch agents (one per track)\n/ctx-worktree teardown docs                     # 4. merge back and clean up\n</code></pre> <p><code>TASKS.md</code> will conflict on merge: Accept all <code>[x]</code> completions from both sides.</p>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>/ctx-worktree</code> Skill Create, list, and tear down worktrees <code>/ctx-next</code> Skill Pick tasks from the backlog for each track <code>git worktree</code> Command Underlying git worktree management <code>git merge</code> Command Merge completed tracks back to main","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#step-1-assess-the-backlog","level":3,"title":"Step 1: Assess the Backlog","text":"<p>Start in your main checkout. Ask the agent to analyze your tasks and group them by blast radius — which files and directories each task touches.</p> <pre><code>/ctx-worktree\nLook at TASKS.md and group the pending tasks into 2-3 independent\ntracks based on which files they'd touch. Show me the grouping\nbefore creating anything.\n</code></pre> <p>The agent reads <code>TASKS.md</code>, estimates file overlap, and proposes groups:</p> <pre><code>Proposed worktree groups:\n\n  work/docs    — recipe updates, blog post (touches: docs/)\n  work/crypto  — scratchpad encryption infra (touches: internal/crypto/)\n  work/tests   — recall test coverage (touches: internal/cli/recall/)\n</code></pre>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#step-2-create-the-worktrees","level":3,"title":"Step 2: Create the Worktrees","text":"<p>Once you approve the grouping, the agent creates worktrees as sibling directories:</p> <pre><code>Create the worktrees for those three groups.\n</code></pre> <p>Behind the scenes:</p> <pre><code>git worktree add ../myproject-docs -b work/docs\ngit worktree add ../myproject-crypto -b work/crypto\ngit worktree add ../myproject-tests -b work/tests\n</code></pre> <p>Each worktree is a full working copy on its own branch.</p>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#step-3-launch-agents","level":3,"title":"Step 3: Launch Agents","text":"<p>Open a separate terminal (or editor window) for each worktree and start a Claude Code session:</p> <pre><code># Terminal 1\ncd ../myproject-docs\nclaude\n\n# Terminal 2\ncd ../myproject-crypto\nclaude\n\n# Terminal 3\ncd ../myproject-tests\nclaude\n</code></pre> <p>Each agent sees the full project, including <code>.context/</code>, and can work independently. </p> <p>Do Not Initialize Context in Worktrees</p> <p>Do not run <code>ctx init</code> in worktrees: The <code>.context</code> directory is already tracked in <code>git</code>.</p>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#step-4-work","level":3,"title":"Step 4: Work","text":"<p>Each agent works through its assigned tasks. They can read <code>TASKS.md</code> to know what's assigned to their track, use <code>/ctx-next</code> to pick the next item, and commit normally on their <code>work/*</code> branch.</p>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#step-5-merge-back","level":3,"title":"Step 5: Merge Back","text":"<p>As each track finishes, return to the main checkout and merge:</p> <pre><code>/ctx-worktree teardown docs\n</code></pre> <p>The agent checks for uncommitted changes, merges <code>work/docs</code> into your current branch, removes the worktree, and deletes the branch.</p>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#step-6-handle-tasksmd-conflicts","level":3,"title":"Step 6: Handle <code>TASKS.md</code> Conflicts","text":"<p><code>TASKS.md</code> will almost always conflict when merging: Multiple agents will mark different tasks as <code>[x]</code>. This is expected and easy to resolve:</p> <p>Accept all completions from both sides. No task should go from <code>[x]</code> back to <code>[ ]</code>. The merge resolution is always additive.</p>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#step-7-cleanup","level":3,"title":"Step 7: Cleanup","text":"<p>After all tracks are merged, verify everything is clean:</p> <pre><code>/ctx-worktree list\n</code></pre> <p>Should show only the main working tree. All <code>work/*</code> branches should be gone.</p>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#conversational-approach","level":2,"title":"Conversational Approach","text":"<p>You don't have to use the skill directly for every step. These natural prompts work:</p> <ul> <li>\"I have a big backlog. Can we split it across worktrees?\"</li> <li>\"Which of these tasks can run in parallel without conflicts?\"</li> <li>\"Merge the docs track back in.\"</li> <li>\"Clean up all the worktrees, we're done.\"</li> </ul>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#what-does-not-work-in-worktrees","level":2,"title":"What Does NOT Work in Worktrees","text":"<p>The encryption key (<code>.context/.context.key</code>) is gitignored: It only exists in the main checkout. This affects key-dependent features:</p> <ul> <li><code>ctx pad</code>: The scratchpad is inaccessible. Commands fail   gracefully (no key found). Use the pad from the main checkout only.</li> <li><code>ctx notify</code>: Webhook notifications silently do nothing. Agents   in worktrees cannot send alerts for loop completions, nudges, or   custom events. If you need visibility into worktree agents, monitor   them from the terminal rather than relying on webhooks.</li> <li>Journal enrichment: <code>ctx recall export</code> and <code>ctx journal enrich</code>   write files relative to the current working directory. Enrichments   created in a worktree stay there and are discarded on teardown.   Enrich journals on the main branch after merging: the JSONL session   logs are always intact, and you don't lose any data.</li> </ul> <p>Context Files Will Merge Just Fine</p> <p>Tracked context files (<code>TASKS.md</code>, <code>DECISIONS.md</code>, <code>LEARNINGS.md</code>, <code>CONVENTIONS.md</code>) work normally; <code>git</code> handles them.</p>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#tips","level":2,"title":"Tips","text":"<ul> <li>3-4 worktrees max. Beyond that, merge complexity outweighs the   parallelism benefit. The skill enforces this limit.</li> <li>Group by package or directory, not by priority. Two high-priority   tasks that touch the same files must be in the same track.</li> <li><code>TASKS.md</code> will conflict on merge. This is normal. Accept all <code>[x]</code>   completions: The resolution is always additive.</li> <li>Don't run <code>ctx init</code> in worktrees. The <code>.context/</code> directory is   tracked in git. Running init overwrites shared context files.</li> <li>Name worktrees by concern, not by number. <code>work/docs</code> and   <code>work/crypto</code> are more useful than <code>work/track-1</code> and <code>work/track-2</code>.</li> <li>Commit frequently in each worktree. Smaller commits make merge   conflicts easier to resolve.</li> </ul>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#next-up","level":2,"title":"Next Up","text":"<p>Back to the beginning: Guide Your Agent →</p> <p>Or explore the full recipe list.</p>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/parallel-worktrees/#see-also","level":2,"title":"See Also","text":"<ul> <li>Running an Unattended AI Agent: for serial   autonomous loops instead of parallel tracks</li> <li>Tracking Work Across Sessions: managing the   task backlog that feeds into parallelization</li> <li>The Complete Session: the complete session workflow   end-to-end, with examples</li> </ul>","path":["Recipes","Agents and Automation","Parallel Agent Development with Git Worktrees"],"tags":[]},{"location":"recipes/permission-snapshots/","level":1,"title":"Permission Snapshots","text":"","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#the-problem","level":2,"title":"The Problem","text":"<p>Claude Code's <code>.claude/settings.local.json</code> accumulates one-off permissions every time you click \"Allow\". After busy sessions the file is full of session-specific entries that expand the agent's surface area beyond intent.</p> <p>Since <code>settings.local.json</code> is <code>.gitignore</code>d, there is no PR review or CI check. The file drifts independently on every machine, and there is no built-in way to reset to a known-good state.</p>","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#tldr","level":2,"title":"TL;DR","text":"<pre><code>/sanitize-permissions               # audit for dangerous patterns\nctx permissions snapshot            # save golden image\n# ... sessions accumulate cruft ...\nctx permissions restore             # reset to golden state\n</code></pre>","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#the-solution","level":2,"title":"The Solution","text":"<p>Save a curated <code>settings.local.json</code> as a golden image, then restore from it to drop session-accumulated permissions. The golden file (<code>.claude/settings.golden.json</code>) is committed to version control and shared with the team.</p>","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Command/Skill Role in this workflow <code>ctx permissions snapshot</code> Save settings.local.json as golden image <code>ctx permissions restore</code> Reset settings.local.json from golden image <code>/sanitize-permissions</code> Audit for dangerous patterns before snapshotting","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#step-by-step","level":2,"title":"Step by Step","text":"","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#1-curate-your-permissions","level":3,"title":"1. Curate Your Permissions","text":"<p>Start with a clean <code>settings.local.json</code>. Optionally run <code>/sanitize-permissions</code> to remove dangerous patterns first.</p> <p>Review the file manually. Every entry should be there because you decided it belongs, not because you clicked \"Allow\" once during debugging.</p> <p>See the Permission Hygiene recipe for recommended defaults.</p>","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#2-take-a-snapshot","level":3,"title":"2. Take a Snapshot","text":"<pre><code>ctx permissions snapshot\n# Saved golden image: .claude/settings.golden.json\n</code></pre> <p>This creates a byte-for-byte copy. No re-encoding, no indent changes.</p>","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#3-commit-the-golden-file","level":3,"title":"3. Commit the Golden File","text":"<pre><code>git add .claude/settings.golden.json\ngit commit -m \"Add permission golden image\"\n</code></pre> <p>The golden file is not gitignored (unlike <code>settings.local.json</code>). This is intentional: it becomes a team-shared baseline.</p>","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#4-auto-restore-at-the-session-start","level":3,"title":"4. Auto-Restore at the Session Start","text":"<p>Add this instruction to your <code>CLAUDE.md</code>:</p> <pre><code>## On Session Start\n\nRun `ctx permissions restore` to reset permissions to the golden image.\n</code></pre> <p>The agent will restore the golden image at the start of every session, automatically dropping any permissions accumulated during previous sessions.</p>","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#5-update-when-intentional-changes-are-made","level":3,"title":"5. Update When Intentional Changes Are Made","text":"<p>When you add a new permanent permission (not a one-off debugging entry):</p> <pre><code># Edit settings.local.json with the new permission\n# Then update the golden image:\nctx permissions snapshot\ngit add .claude/settings.golden.json\ngit commit -m \"Update permission golden image: add cargo test\"\n</code></pre>","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#conversational-approach","level":2,"title":"Conversational Approach","text":"<p>You don't need to remember exact commands. These natural-language prompts work with agents trained on the <code>ctx</code> playbook:</p> What you say What happens \"Save my current permissions as baseline\" Agent runs <code>ctx permissions snapshot</code> \"Reset permissions to the golden image\" Agent runs <code>ctx permissions restore</code> \"Clean up my permissions\" Agent runs <code>/sanitize-permissions</code> then snapshot \"What permissions did I accumulate?\" Agent diffs local vs golden","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#next-up","level":2,"title":"Next Up","text":"<p>Turning Activity into Content →: Generate blog posts, changelogs, and journal sites from your project activity.</p>","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/permission-snapshots/#see-also","level":2,"title":"See Also","text":"<ul> <li>Permission Hygiene: recommended defaults and   maintenance workflow</li> <li>CLI Reference: ctx permissions:   full command documentation</li> </ul>","path":["Recipes","Maintenance","Permission Snapshots"],"tags":[]},{"location":"recipes/publishing/","level":1,"title":"Turning Activity into Content","text":"","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#the-problem","level":2,"title":"The Problem","text":"<p>Your <code>.context/</code> directory is full of decisions, learnings, and session history.</p> <p>Your <code>git log</code> tells the story of a project evolving.</p> <p>But none of this is visible to anyone outside your terminal.</p> <p>You want to turn this raw activity into:</p> <ul> <li>a browsable journal site</li> <li>blog posts</li> <li>changelog posts</li> </ul>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#tldr","level":2,"title":"TL;DR","text":"<pre><code>ctx recall export --all             # 1. export sessions to markdown\n\n/ctx-journal-enrich-all             # 2. add metadata and tags\n\nctx journal site --serve            # 3. build and serve the journal\n\n/ctx-blog about the caching layer   # 4. draft a blog post\n/ctx-blog-changelog v0.1.0 \"v0.2\"   # 5. write a changelog post\n</code></pre> <p>Read on for details on each stage.</p>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx recall export</code> Command Export session JSONL to editable markdown <code>ctx journal site</code> Command Generate a static site from journal entries <code>ctx journal obsidian</code> Command Generate an Obsidian vault from journal entries <code>ctx serve</code> Command Serve any zensical directory (default: journal) <code>make journal</code> Makefile Shortcut for export + site rebuild <code>/ctx-journal-enrich-all</code> Skill Batch-enrich all unenriched entries (recommended) <code>/ctx-journal-enrich</code> Skill Add metadata, summaries, and tags to one entry <code>/ctx-blog</code> Skill Draft a blog post from recent project activity <code>/ctx-blog-changelog</code> Skill Write a themed post from a commit range","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#step-1-export-sessions-to-markdown","level":3,"title":"Step 1: Export Sessions to Markdown","text":"<p>Raw session data lives as JSONL files in Claude Code's internal storage. The first step is converting these into readable, editable markdown.</p> <pre><code># Export all sessions from the current project\nctx recall export --all\n\n# Export from all projects (if you work across multiple repos)\nctx recall export --all --all-projects\n\n# Export a single session by ID or slug\nctx recall export abc123\nctx recall export gleaming-wobbling-sutherland\n````\n\nExported files land in `.context/journal/` as individual Markdown files with\nsession metadata and the full conversation transcript.\n\n`--all` is safe by default — only new sessions are exported. Existing files\nare skipped. Use `--regenerate` to re-export existing files (YAML frontmatter\nis preserved). Use `--force -y` to overwrite everything.\n\n### Step 2: Enrich Entries with Metadata\n\nRaw entries have timestamps and conversations but lack the structured metadata\nthat makes a journal searchable. Use `/ctx-journal-enrich-all` to process your\nentire backlog at once:\n\n```text\n/ctx-journal-enrich-all\n</code></pre> <p>The skill finds all unenriched entries, filters out noise (suggestion sessions, very short sessions, multipart continuations), and processes each one by extracting titles, topics, technologies, and summaries from the conversation.</p> <p>For large backlogs (20+ entries), it can spawn subagents to process entries in parallel.</p> <p>To enrich a single entry instead:</p> <pre><code>/ctx-journal-enrich twinkly-stirring-kettle\n/ctx-journal-enrich 2026-01-24\n</code></pre> <p>After enrichment, an entry gains YAML frontmatter:</p> <pre><code>---\ntitle: \"Implement Redis caching for API endpoints\"\ndate: 2026-01-24\ntype: feature\noutcome: completed\ntopics:\n  - caching\n  - api-performance\ntechnologies:\n  - go\n  - redis\nkey_files:\n  - internal/api/middleware/cache.go\n  - internal/cache/redis.go\n---\n</code></pre> <p>This metadata powers better navigation in the journal site: </p> <ul> <li>titles replace slugs, </li> <li>summaries appear in the index, </li> <li>and search covers topics and technologies.</li> </ul>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#step-3-generate-the-journal-site","level":3,"title":"Step 3: Generate the Journal Site","text":"<p>With entries exported and enriched, generate the static site:</p> <pre><code># Generate site files\nctx journal site\n\n# Generate and build static HTML\nctx journal site --build\n\n# Generate and serve locally (opens at http://localhost:8000)\nctx journal site --serve\n\n# Custom output directory\nctx journal site --output ~/my-journal\n</code></pre> <p>The site is generated in <code>.context/journal-site/</code> by default. It uses zensical for static site generation (<code>pipx install zensical</code>).</p> <p>Or use the Makefile shortcut that combines export and rebuild:</p> <pre><code>make journal\n</code></pre> <p>This runs <code>ctx recall export --all</code> followed by <code>ctx journal site --build</code>, then reminds you to enrich before rebuilding. To serve the built site, use <code>make journal-serve</code> or <code>ctx serve</code> (serve-only, no regeneration).</p>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#alternative-export-to-obsidian-vault","level":3,"title":"Alternative: Export to Obsidian Vault","text":"<p>If you use Obsidian for knowledge management, generate a vault instead of (or alongside) the static site:</p> <pre><code>ctx journal obsidian\nctx journal obsidian --output ~/vaults/ctx-journal\n</code></pre> <p>This produces an Obsidian-ready directory with wikilinks, MOC (Map of Content) pages for topics/files/types, and a \"Related Sessions\" footer on each entry for graph connectivity. Open the output directory in Obsidian as a vault.</p> <p>The vault uses the same enriched source entries as the static site. Both outputs can coexist — the static site goes to <code>.context/journal-site/</code>, the vault to <code>.context/journal-obsidian/</code>.</p>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#step-4-draft-blog-posts-from-activity","level":3,"title":"Step 4: Draft Blog Posts from Activity","text":"<p>When your project reaches a milestone worth sharing, use <code>/ctx-blog</code> to draft a post from recent activity. The skill gathers context from multiple sources: <code>git log</code>, <code>DECISIONS.md</code>, <code>LEARNINGS.md</code>, completed tasks, and journal entries.</p> <pre><code>/ctx-blog about the caching layer we just built\n/ctx-blog last week's refactoring work\n/ctx-blog lessons learned from the migration\n</code></pre> <p>The skill gathers recent commits, decisions, and learnings; identifies a narrative arc; drafts an outline for approval; writes the full post; and saves it to <code>docs/blog/YYYY-MM-DD-slug.md</code>.</p> <p>Posts are written in first person with code snippets, commit references, and an honest discussion of what went wrong.</p> <p>The Output is <code>zensical</code>-Flavored Markdown</p> <p>The blog skills produce Markdown tuned for a zensical site: <code>topics:</code> frontmatter (zensical's tag field), a <code>docs/blog/</code> output path, and a banner image reference. </p> <p>The content is still standard Markdown and can be adapted to other  static site generators, but the defaults assume a <code>zensical</code>  project structure.</p>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#step-5-write-changelog-posts-from-commit-ranges","level":3,"title":"Step 5: Write Changelog Posts from Commit Ranges","text":"<p>For release notes or \"what changed\" posts, <code>/ctx-blog-changelog</code> takes a starting commit and a theme, then analyzes everything that changed:</p> <pre><code>/ctx-blog-changelog 040ce99 \"building the journal system\"\n/ctx-blog-changelog HEAD~30 \"what's new in v0.2.0\"\n/ctx-blog-changelog v0.1.0 \"the road to v0.2.0\"\n</code></pre> <p>The skill diffs the commit range, identifies the most-changed files, and constructs a narrative organized by theme rather than chronology, including a key commits table and before/after comparisons.</p>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#the-conversational-approach","level":2,"title":"The Conversational Approach","text":"<p>You can also drive your publishing anytime with natural language:</p> <pre><code>\"write about what we did this week\"\n\"turn today's session into a blog post\"\n\"make a changelog post covering everything since the last release\"\n\"enrich the last few journal entries\"\n</code></pre> <p>The agent has full visibility into your <code>.context/</code> state (tasks completed, decisions recorded, learnings captured), so its suggestions are grounded in what actually happened.</p>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"<p>The full pipeline from raw transcripts to published content:</p> <pre><code># 1. Export all sessions\nctx recall export --all\n\n# 2. In Claude Code: enrich all entries with metadata\n/ctx-journal-enrich-all\n\n# 3. Build and serve the journal site\nmake journal\nmake journal-serve\n\n# 3b. Or generate an Obsidian vault\nctx journal obsidian\n\n# 4. In Claude Code: draft a blog post\n/ctx-blog about the features we shipped this week\n\n# 5. In Claude Code: write a changelog post\n/ctx-blog-changelog v0.1.0 \"what's new in v0.2.0\"\n</code></pre> <p>The journal pipeline is idempotent at every stage. You can rerun <code>ctx recall export --all</code> without losing enrichment. You can rebuild the site as many times as you want.</p>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#tips","level":2,"title":"Tips","text":"<ul> <li>Export regularly. Run <code>ctx recall export --all</code> after each session to keep   your journal current. Only new sessions are exported — existing files are   skipped by default.</li> <li>Use batch enrichment. <code>/ctx-journal-enrich-all</code> filters noise (suggestion   sessions, trivial sessions, multipart continuations) so you do not have to   decide what is worth enriching.</li> <li>Keep journal files in <code>.gitignore</code>. Session journals can contain sensitive   data: file contents, commands, internal discussions, and error messages with   stack traces. Add <code>.context/journal/</code> and <code>.context/journal-site/</code> to   <code>.gitignore</code>.</li> <li>Use <code>/ctx-blog</code> for narrative posts and <code>/ctx-blog-changelog</code> for release   posts. One finds a story in recent activity, the other explains a commit   range by theme.</li> <li>Edit the drafts. These skills produce drafts, not final posts. Review the   narrative, add your perspective, and remove anything that does not serve the   reader.</li> </ul>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#next-up","level":2,"title":"Next Up","text":"<p>Running an Unattended AI Agent →: Set up an AI agent that works through tasks overnight without you at the keyboard.</p>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#see-also","level":2,"title":"See Also","text":"<ul> <li>Session Journal: journal system, enrichment schema</li> <li>CLI Reference: ctx recall: export, list, show session history</li> <li>CLI Reference: ctx journal site: static site generation</li> <li>CLI Reference: ctx journal obsidian: Obsidian vault export</li> <li>CLI Reference: ctx serve: serve-only (no regeneration)</li> <li>Browsing and Enriching Past Sessions: journal browsing workflow</li> <li>The Complete Session: capturing context during a session</li> </ul>","path":["Recipes","Maintenance","Turning Activity into Content"],"tags":[]},{"location":"recipes/scratchpad-sync/","level":1,"title":"Syncing Scratchpad Notes Across Machines","text":"","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#the-problem","level":2,"title":"The Problem","text":"<p>You work from multiple machines: a desktop and a laptop, or a local machine and a remote dev server.</p> <p>The scratchpad entries are encrypted. The ciphertext (<code>.context/scratchpad.enc</code>) travels with git, but the encryption key (<code>.context/.context.key</code>) is gitignored. Without the key on each machine, you cannot read or write entries.</p> <p>How do you distribute the key and keep the scratchpad in sync?</p>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#tldr","level":2,"title":"TL;DR","text":"<pre><code>ctx init                                                    # 1. generates .context.key\nscp .context/.context.key user@machine-b:project/.context/  # 2. copy key\nchmod 600 project/.context/.context.key                     # 3. secure it\n# Normal git push/pull syncs the encrypted scratchpad.enc\n# On conflict: ctx pad resolve → rebuild → git add + commit\n</code></pre> <p>Treat <code>.context.key</code> Like a Password</p> <p>The scratchpad key is the only thing protecting your encrypted entries.</p> <p>Store a backup in a secure enclave such as a password manager, and treat it with the same care you would give passwords, certificates, or API tokens. </p> <p>Anyone with the key can decrypt every scratchpad entry.</p>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx init</code> CLI command Initialize context (generates the key automatically) <code>ctx pad add</code> CLI command Add a scratchpad entry <code>ctx pad rm</code> CLI command Remove a scratchpad entry <code>ctx pad edit</code> CLI command Edit a scratchpad entry <code>ctx pad resolve</code> CLI command Show both sides of a merge conflict <code>ctx pad merge</code> CLI command Merge entries from other scratchpad files <code>ctx pad import</code> CLI command Bulk-import lines from a file <code>ctx pad export</code> CLI command Export blob entries to a directory <code>scp</code> Shell Copy the key file between machines <code>git push</code> / <code>git pull</code> Shell Sync the encrypted file via <code>git</code> <code>/ctx-pad</code> Skill Natural language interface to pad commands","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#step-1-initialize-on-machine-a","level":3,"title":"Step 1: Initialize on Machine A","text":"<p>Run <code>ctx init</code> on your first machine. The key is created automatically:</p> <pre><code>ctx init\n# ...\n# Created .context/.context.key (0600)\n# Created .context/scratchpad.enc\n</code></pre> <p>The key is gitignored. The <code>.enc</code> file is tracked.</p>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#step-2-copy-the-key-to-machine-b","level":3,"title":"Step 2: Copy the Key to Machine B","text":"<p>Use any secure transfer method:</p> <pre><code># scp\nscp .context/.context.key user@machine-b:project/.context/\n\n# Or use a password manager, USB drive, etc.\n</code></pre> <p>Set permissions on Machine B:</p> <pre><code>chmod 600 project/.context/.context.key\n</code></pre> <p>Secure the Transfer</p> <p>The key is a raw 256-bit AES key. Anyone with the key can decrypt the scratchpad. Use an encrypted channel (SSH, password manager, vault). </p> <p>Never paste it in plaintext over email or chat.</p>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#step-3-normal-pushpull-workflow","level":3,"title":"Step 3: Normal Push/Pull Workflow","text":"<p>The encrypted file is committed, so standard git sync works:</p> <pre><code># Machine A: add entries and push\nctx pad add \"staging API key: sk-test-abc123\"\ngit add .context/scratchpad.enc\ngit commit -m \"Update scratchpad\"\ngit push\n\n# Machine B: pull and read\ngit pull\nctx pad\n#   1. staging API key: sk-test-abc123\n</code></pre> <p>Both machines have the same key, so both can decrypt the same <code>.enc</code> file.</p>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#step-4-read-and-write-from-either-machine","level":3,"title":"Step 4: Read and Write from Either Machine","text":"<p>Once the key is distributed, all <code>ctx pad</code> commands work identically on both machines. Entries added on Machine A are visible on Machine B after a <code>git pull</code>, and vice versa.</p>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#step-5-handle-merge-conflicts","level":3,"title":"Step 5: Handle Merge Conflicts","text":"<p>If both machines add entries between syncs, pulling will create a merge conflict on <code>.context/scratchpad.enc</code>. Git cannot merge binary (encrypted) content automatically.</p> <p>The fastest approach is <code>ctx pad merge</code> — it reads both conflict sides, deduplicates, and writes the union:</p> <pre><code># Extract theirs to a temp file, then merge it in\ngit show :3:.context/scratchpad.enc &gt; /tmp/theirs.enc\ngit checkout --ours .context/scratchpad.enc\nctx pad merge /tmp/theirs.enc\n\n# Done — commit the resolved scratchpad\ngit add .context/scratchpad.enc\ngit commit -m \"Resolve scratchpad merge conflict\"\n</code></pre> <p>Alternatively, use <code>ctx pad resolve</code> to inspect both sides manually:</p> <pre><code>ctx pad resolve\n# === Ours (this machine) ===\n#   1. staging API key: sk-test-abc123\n#   2. check DNS after deploy\n#\n# === Theirs (incoming) ===\n#   1. staging API key: sk-test-abc123\n#   2. new endpoint: api.example.com/v2\n</code></pre> <p>Then reconstruct the merged scratchpad:</p> <pre><code># Start fresh with all entries from both sides\nctx pad add \"staging API key: sk-test-abc123\"\nctx pad add \"check DNS after deploy\"\nctx pad add \"new endpoint: api.example.com/v2\"\n\n# Mark the conflict resolved\ngit add .context/scratchpad.enc\ngit commit -m \"Resolve scratchpad merge conflict\"\n</code></pre>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#merge-conflict-walkthrough","level":2,"title":"Merge Conflict Walkthrough","text":"<p>Here's a full scenario showing how conflicts arise and how to resolve them:</p> <p>1. Both machines start in sync (1 entry):</p> <pre><code>Machine A: 1. staging API key: sk-test-abc123\nMachine B: 1. staging API key: sk-test-abc123\n</code></pre> <p>2. Both add entries independently:</p> <pre><code>Machine A adds: \"check DNS after deploy\"\nMachine B adds: \"new endpoint: api.example.com/v2\"\n</code></pre> <p>3. Machine A pushes first. Machine B pulls and gets a conflict:</p> <pre><code>git pull\n# CONFLICT (content): Merge conflict in .context/scratchpad.enc\n</code></pre> <p>4. Machine B runs <code>ctx pad resolve</code>:</p> <pre><code>ctx pad resolve\n# === Ours ===\n#   1. staging API key: sk-test-abc123\n#   2. new endpoint: api.example.com/v2\n#\n# === Theirs ===\n#   1. staging API key: sk-test-abc123\n#   2. check DNS after deploy\n</code></pre> <p>5. Rebuild with entries from both sides and commit:</p> <pre><code># Clear and rebuild (or use the skill to guide you)\nctx pad add \"staging API key: sk-test-abc123\"\nctx pad add \"check DNS after deploy\"\nctx pad add \"new endpoint: api.example.com/v2\"\n\ngit add .context/scratchpad.enc\ngit commit -m \"Merge scratchpad: keep entries from both machines\"\n</code></pre>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#conversational-approach","level":3,"title":"Conversational Approach","text":"<p>When working with an AI assistant, you can resolve conflicts naturally:</p> <pre><code>You: \"I have a scratchpad merge conflict. Can you resolve it?\"\n\nAgent: \"Let me extract theirs and merge it in.\"\n       [runs git show :3:.context/scratchpad.enc &gt; /tmp/theirs.enc]\n       [runs git checkout --ours .context/scratchpad.enc]\n       [runs ctx pad merge /tmp/theirs.enc]\n       \"Merged 2 new entries (1 duplicate skipped). Want me to\n       commit the resolution?\"\n</code></pre>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#tips","level":2,"title":"Tips","text":"<ul> <li>Back up the key: If you lose it, you lose access to all encrypted   entries. Store a copy in your password manager.</li> <li>One key per project: Each <code>ctx init</code> generates a unique key.   Don't reuse keys across projects.</li> <li>Plaintext fallback for non-sensitive projects: If encryption adds   friction and you have nothing sensitive, set <code>scratchpad_encrypt: false</code>   in <code>.ctxrc</code>. Merge conflicts become trivial text merges.</li> <li>Never commit the key: It is <code>.gitignore</code>d by default. Don't override   this.</li> </ul>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#next-up","level":2,"title":"Next Up","text":"<p>Hook Output Patterns →: Choose the right output pattern for your Claude Code hooks.</p>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-sync/#see-also","level":2,"title":"See Also","text":"<ul> <li>Scratchpad: feature overview, all commands, when   to use scratchpad vs context files</li> <li>Persisting Decisions, Learnings, and Conventions:   for structured knowledge that outlives the scratchpad</li> </ul>","path":["Recipes","Knowledge and Tasks","Syncing Scratchpad Notes Across Machines"],"tags":[]},{"location":"recipes/scratchpad-with-claude/","level":1,"title":"Using the Scratchpad","text":"","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#the-problem","level":2,"title":"The Problem","text":"<p>During a session you accumulate quick notes, reminders, intermediate values, and sometimes sensitive tokens. They don't fit <code>TASKS.md</code> (not work items) or <code>DECISIONS.md</code> (not decisions). They don't have the structured fields that <code>LEARNINGS.md</code> requires.</p> <p>Without somewhere to put them, they get lost between sessions.</p> <p>How do you capture working memory that persists across sessions without polluting your structured context files?</p>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#tldr","level":2,"title":"TL;DR","text":"<pre><code>ctx pad add \"check DNS propagation after deploy\"\nctx pad         # list entries\nctx pad show 1  # print entry (pipe-friendly)\n</code></pre> <p>Entries are encrypted at rest and travel with <code>git</code>. </p> <p>Use the <code>/ctx-pad</code> skill to manage entries from inside your AI session.</p>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx pad</code> CLI command List all scratchpad entries <code>ctx pad show N</code> CLI command Output raw text of entry N (pipe-friendly) <code>ctx pad add</code> CLI command Add a new entry <code>ctx pad edit</code> CLI command Replace, append to, or prepend to an entry <code>ctx pad add --file</code> CLI command Ingest a file as a blob entry <code>ctx pad show N --out</code> CLI command Extract a blob entry to a file <code>ctx pad rm</code> CLI command Remove an entry <code>ctx pad mv</code> CLI command Reorder entries <code>ctx pad import</code> CLI command Bulk-import lines from a file (or stdin) <code>ctx pad export</code> CLI command Export all blob entries to a directory <code>/ctx-pad</code> Skill Natural language interface to all pad commands","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#step-1-add-a-note-naturally","level":3,"title":"Step 1: Add a Note Naturally","text":"<p>You don't need to remember any syntax. Just tell your assistant what to jot down:</p> <pre><code>You: \"jot down: check DNS propagation after deploy\"\n\nAgent: \"Added to scratchpad:\n  1. check DNS propagation after deploy\"\n</code></pre> <p>Behind the scenes, the agent runs <code>ctx pad add \"check DNS propagation after deploy\"</code>.</p>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#step-2-view-your-scratchpad","level":3,"title":"Step 2: View Your Scratchpad","text":"<pre><code>You: \"show my scratchpad\"\n\nAgent: \"Your scratchpad has 3 entries:\n  1. check DNS propagation after deploy\n  2. staging API endpoint: api.staging.example.com/v2\n  3. retry limit should be 5, not 3\"\n</code></pre>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#step-3-edit-an-entry","level":3,"title":"Step 3: Edit an Entry","text":"<pre><code>You: \"update entry 2 to include the new endpoint\"\n\nAgent: \"Updated entry 2:\n  was: staging API endpoint: api.staging.example.com/v2\n  now: staging API endpoint: api.prod.example.com/v2\"\n</code></pre> <p>For partial edits, the agent can use <code>--append</code> or <code>--prepend</code>:</p> <pre><code>You: \"append the port number to entry 2\"\n\nAgent: \"Updated entry 2:\n  staging API endpoint: api.prod.example.com/v2 :8443\"\n</code></pre>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#step-4-compose-entries","level":3,"title":"Step 4: Compose Entries","text":"<p>Use <code>ctx pad show N</code> to pipe entry content into other operations:</p> <pre><code>You: \"append the content of entry 3 to entry 1\"\n\nAgent: [runs ctx pad edit 1 --append \"$(ctx pad show 3)\"]\n       \"Done. Entry 1 is now:\n        check DNS propagation after deploy retry limit should be 5, not 3\"\n</code></pre>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#step-5-reorder-by-priority","level":3,"title":"Step 5: Reorder by Priority","text":"<pre><code>You: \"move entry 4 to the top\"\n\nAgent: [runs ctx pad mv 4 1]\n       \"Moved entry 4 to position 1. Scratchpad reordered.\"\n</code></pre>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#step-6-clean-up","level":3,"title":"Step 6: Clean Up","text":"<pre><code>You: \"remove entry 2, it's done\"\n\nAgent: [runs ctx pad rm 2]\n       \"Removed entry 2. 3 entries remaining.\"\n</code></pre>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#step-7-store-a-file-as-a-blob","level":3,"title":"Step 7: Store a File as a Blob","text":"<p>The scratchpad can hold small files (up to 64 KB) as encrypted blob entries. The file is base64-encoded and stored alongside a label you provide:</p> <pre><code># Ingest a file — the first argument is the label\nctx pad add \"deploy config\" --file ./deploy.yaml\n\n# List shows the label with a [BLOB] marker\nctx pad\n#   1. check DNS propagation after deploy\n#   2. deploy config [BLOB]\n</code></pre>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#step-8-extract-a-blob","level":3,"title":"Step 8: Extract a Blob","text":"<p>Use <code>show --out</code> to write the decoded file back to disk:</p> <pre><code># Write blob entry to a file\nctx pad show 2 --out ./recovered-deploy.yaml\n\n# Or print to stdout (for piping)\nctx pad show 2 | head -5\n</code></pre> <p>Blob entries are encrypted identically to text entries — they're just base64-encoded before encryption. The <code>--out</code> flag decodes and writes the raw bytes.</p>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#step-9-bulk-import-notes","level":3,"title":"Step 9: Bulk Import Notes","text":"<p>When you have a file with many notes (one per line), import them in bulk instead of adding one at a time:</p> <pre><code># Import from a file — each non-empty line becomes an entry\nctx pad import notes.txt\n\n# Or pipe from stdin\ngrep TODO *.go | ctx pad import -\n</code></pre> <p>All entries are written in a single encrypt/write cycle, regardless of how many lines the file contains.</p>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#step-10-export-blobs-to-disk","level":3,"title":"Step 10: Export Blobs to Disk","text":"<p>Export all blob entries to a directory as individual files. Each blob's label becomes the filename:</p> <pre><code># Export to a directory (created if needed)\nctx pad export ./ideas\n\n# Preview what would be exported\nctx pad export --dry-run ./ideas\n\n# Force overwrite existing files\nctx pad export --force ./backup\n</code></pre> <p>When a file already exists, a unix timestamp is prepended to the filename to avoid collisions. Use <code>--force</code> to overwrite instead.</p>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#using-ctx-pad-in-a-session","level":2,"title":"Using <code>/ctx-pad</code> in a Session","text":"<p>Invoke the <code>/ctx-pad</code> skill first, then describe what you want in natural language. Without the skill prefix, the agent may route your request to <code>TASKS.md</code> or another context file instead of the scratchpad.</p> <pre><code>You: /ctx-pad jot down: check DNS after deploy\nYou: /ctx-pad show my scratchpad\nYou: /ctx-pad delete entry 3\n</code></pre> <p>Once the skill is active, it translates intent into commands:</p> You say (after <code>/ctx-pad</code>) What the agent does \"jot down: check DNS after deploy\" <code>ctx pad add \"check DNS after deploy\"</code> \"remember this: retry limit is 5\" <code>ctx pad add \"retry limit is 5\"</code> \"show my scratchpad\" / \"what's on my pad\" <code>ctx pad</code> \"show me entry 3\" <code>ctx pad show 3</code> \"delete the third one\" / \"remove entry 3\" <code>ctx pad rm 3</code> \"change entry 2 to ...\" <code>ctx pad edit 2 \"new text\"</code> \"append ' +important' to entry 3\" <code>ctx pad edit 3 --append \" +important\"</code> \"prepend 'URGENT:' to entry 1\" <code>ctx pad edit 1 --prepend \"URGENT: \"</code> \"prioritize entry 4\" / \"move to the top\" <code>ctx pad mv 4 1</code> \"import my notes from notes.txt\" <code>ctx pad import notes.txt</code> \"export all blobs to ./ideas\" <code>ctx pad export ./ideas</code> <p>When in Doubt, Use the CLI Directly</p> <p>The <code>ctx pad</code> commands work the same whether you run them yourself or let the skill invoke them. </p> <p>If the agent misroutes a request, fall back to <code>ctx pad add \"...\"</code> in your terminal.</p>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#when-to-use-scratchpad-vs-context-files","level":2,"title":"When to Use Scratchpad vs Context Files","text":"Situation Use Temporary reminders (\"check X after deploy\") Scratchpad Session-start reminders (\"remind me next session\") <code>ctx remind</code> Working values during debugging (ports, endpoints, counts) Scratchpad Sensitive tokens or API keys (short-term storage) Scratchpad Quick notes that don't fit anywhere else Scratchpad Work items with completion tracking <code>TASKS.md</code> Trade-offs between alternatives with rationale <code>DECISIONS.md</code> Reusable lessons with context/lesson/application <code>LEARNINGS.md</code> Codified patterns and standards <code>CONVENTIONS.md</code> <p>Decision Guide</p> <ul> <li>If it has structured fields (context, rationale, lesson, application),   it belongs in a context file like <code>DECISIONS.md</code> or <code>LEARNINGS.md</code>.</li> <li>If it's a work item you'll mark done, it belongs in <code>TASKS.md</code>.</li> <li>If you want a message relayed VERBATIM at the next session start,   it belongs in <code>ctx remind</code>.</li> <li>If it's a quick note, reminder, or working value (especially if it's   sensitive or ephemeral) it belongs on the scratchpad.</li> </ul> <p>Scratchpad Is Not a Junk Drawer</p> <p>The scratchpad is for working memory, not long-term storage.</p> <p>If a note is still relevant after several sessions, promote it:</p> <p>A persistent reminder becomes a task, a recurring value becomes a convention, a hard-won insight becomes a learning.</p>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#tips","level":2,"title":"Tips","text":"<ul> <li>Entries persist across sessions: The scratchpad is committed   (encrypted) to git, so entries survive session boundaries. Pick up   where you left off.</li> <li>Entries are numbered and reorderable: Use <code>ctx pad mv</code> to put   high-priority items at the top.</li> <li><code>ctx pad show N</code> enables unix piping: Output raw entry text   with no numbering prefix. Compose with <code>--append</code>, <code>--prepend</code>, or   other shell tools.</li> <li>Never mention the key file contents to the AI: The agent knows   how to use <code>ctx pad</code> commands but should never read or print   <code>.context/.context.key</code> directly.</li> <li>Encryption is transparent: You interact with plaintext; the   encryption/decryption happens automatically on every read/write.</li> </ul>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#next-up","level":2,"title":"Next Up","text":"<p>Syncing Scratchpad Notes Across Machines →: Distribute encryption keys and scratchpad data across environments.</p>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/scratchpad-with-claude/#see-also","level":2,"title":"See Also","text":"<ul> <li>Scratchpad: feature overview, all commands,   encryption details, plaintext override</li> <li>Persisting Decisions, Learnings, and Conventions:   for structured knowledge that outlives the scratchpad</li> <li>The Complete Session: full session lifecycle   showing how the scratchpad fits into the broader workflow</li> </ul>","path":["Recipes","Knowledge and Tasks","Using the Scratchpad"],"tags":[]},{"location":"recipes/session-archaeology/","level":1,"title":"Browsing and Enriching Past Sessions","text":"","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#the-problem","level":2,"title":"The Problem","text":"<p>After weeks of AI-assisted development you have dozens of sessions scattered across JSONL files in <code>~/.claude/projects/</code>. Finding the session where you debugged the Redis connection pool, or remembering what you decided about the caching strategy three Tuesdays ago, often means grepping raw JSON.</p> <p>There is no table of contents, no search, and no summaries.</p> <p>This recipe shows how to turn that raw session history into a browsable, searchable, and enriched journal site you can navigate in your browser.</p>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#tldr","level":2,"title":"TL;DR","text":"<p>Export and Generate</p> <pre><code>ctx recall export --all\nctx journal site --serve\n</code></pre> <p>Enrich</p> <pre><code>/ctx-journal-enrich-all\n</code></pre> <p>Rebuild</p> <pre><code>ctx journal site --serve\n</code></pre> <p>Read on for what each stage does and why.</p>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx recall list</code> Command List parsed sessions with metadata <code>ctx recall show</code> Command Inspect a specific session in detail <code>ctx recall export</code> Command Export sessions to editable journal Markdown <code>ctx journal site</code> Command Generate a static site from journal entries <code>ctx journal obsidian</code> Command Generate an Obsidian vault from journal entries <code>ctx serve</code> Command Serve any zensical directory (default: journal) <code>/ctx-recall</code> Skill Browse sessions inside your AI assistant <code>/ctx-journal-enrich</code> Skill Add frontmatter metadata to a single entry <code>/ctx-journal-enrich-all</code> Skill Batch-enrich all unenriched entries","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#the-workflow","level":2,"title":"The Workflow","text":"<p>The session journal follows a four-stage pipeline.</p> <p>Each stage is idempotent and safe to re-run:</p> <p>By default, each stage skips entries that have already been processed.</p> <pre><code>export -&gt; enrich -&gt; rebuild\n</code></pre> Stage Tool What it does Skips if Where Export <code>ctx recall export --all</code> Converts session JSONL to Markdown File already exists (safe default) CLI or agent Enrich <code>/ctx-journal-enrich-all</code> Adds frontmatter, summaries, topic tags Frontmatter already present Agent only Rebuild <code>ctx journal site --build</code> Generates browsable static HTML N/A CLI only Obsidian <code>ctx journal obsidian</code> Generates Obsidian vault with wikilinks N/A CLI only <p>Where Do You Run Each Stage?</p> <p>Export (Steps 1 to 3) works equally well from the terminal or inside your AI assistant via <code>/ctx-recall</code>. The CLI is fine here: the agent adds no special intelligence, it just runs the same command.</p> <p>Enrich (Step 4) requires the agent: it reads conversation content and produces structured metadata.</p> <p>Rebuild and serve (Step 5) is a terminal operation that starts a long-running server.</p>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#step-1-list-your-sessions","level":3,"title":"Step 1: List Your Sessions","text":"<p>Start by seeing what sessions exist for the current project:</p> <pre><code>ctx recall list\n</code></pre> <p>Sample output:</p> <pre><code>Sessions (newest first)\n=======================\n\n  Slug                           Project   Date         Duration  Turns  Tokens\n  gleaming-wobbling-sutherland   ctx       2026-02-07   1h 23m    47     82,341\n  twinkly-stirring-kettle        ctx       2026-02-06   0h 45m    22     38,102\n  bright-dancing-hopper          ctx       2026-02-05   2h 10m    63     124,500\n  quiet-flowing-dijkstra         ctx       2026-02-04   0h 18m    11     15,230\n  ...\n</code></pre> <p>Slugs Look Cryptic?</p> <p>These auto-generated slugs (<code>gleaming-wobbling-sutherland</code>) are hard to recognize later.</p> <p>Use <code>/ctx-journal-enrich</code> to add human-readable titles, topic tags, and summaries to exported journal entries, making them easier to find.</p> <p>Filter by project or tool if you work across multiple codebases:</p> <pre><code>ctx recall list --project ctx --limit 10\nctx recall list --tool claude-code\nctx recall list --all-projects\n</code></pre>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#step-2-inspect-a-specific-session","level":3,"title":"Step 2: Inspect a Specific Session","text":"<p>Before exporting everything, inspect a single session to see its metadata and conversation summary:</p> <pre><code>ctx recall show --latest\n</code></pre> <p>Or look up a specific session by its slug, partial ID, or UUID:</p> <pre><code>ctx recall show gleaming-wobbling-sutherland\nctx recall show twinkly\nctx recall show abc123\n</code></pre> <p>Add <code>--full</code> to see the complete message content instead of the summary view:</p> <pre><code>ctx recall show --latest --full\n</code></pre> <p>This is useful for checking what happened before deciding whether to export and enrich it.</p>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#step-3-export-sessions-to-the-journal","level":3,"title":"Step 3: Export Sessions to the Journal","text":"<p>Export converts raw session data into editable Markdown files in <code>.context/journal/</code>:</p> <pre><code># Export all sessions from the current project\nctx recall export --all\n\n# Export a single session\nctx recall export gleaming-wobbling-sutherland\n\n# Include sessions from all projects\nctx recall export --all --all-projects\n</code></pre> <p>--keep-frontmatter=false Discards Enrichments</p> <p><code>--keep-frontmatter=false</code> discards enriched YAML frontmatter during regeneration.</p> <p>Back up your journal before using this flag.</p> <p>Each exported file contains session metadata (date, time, duration, model, project, git branch), a tool usage summary, and the full conversation transcript.</p> <p>Re-exporting is safe. Running <code>ctx recall export --all</code> only exports new sessions: Existing files are never touched. Use <code>--dry-run</code> to preview what would be exported without writing anything.</p> <p>To re-export existing files (e.g., after a format improvement), use <code>--regenerate</code>: Conversation content is regenerated while preserving any YAML frontmatter you or the enrichment skill has added. You'll be prompted before any files are overwritten.</p> <p>--regenerate Replaces the Markdown Body</p> <p><code>--regenerate</code> preserves YAML frontmatter but replaces the entire Markdown body with freshly generated content from the source JSONL.</p> <p>If you manually edited the conversation transcript (added notes, redacted sensitive content, restructured sections), those edits will be lost.</p> <p>BACK UP YOUR JOURNAL FIRST.</p> <p>To protect entries you've hand-edited, you can explicitly lock them:</p> <pre><code>ctx recall lock &lt;pattern&gt;\n</code></pre> <p>Locked entries are always skipped, regardless of flags.</p> <p>See <code>ctx recall lock --help</code> for more details.</p>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#step-4-enrich-with-metadata","level":3,"title":"Step 4: Enrich with Metadata","text":"<p>Raw exports have timestamps and transcripts but lack the semantic metadata that makes sessions searchable: topics, technology tags, outcome status, and summaries. The <code>/ctx-journal-enrich*</code> skills add this structured frontmatter.</p> <p>Batch enrichment (recommended):</p> <pre><code>/ctx-journal-enrich-all\n</code></pre> <p>The skill finds all unenriched entries, filters out noise (suggestion sessions, very short sessions, multipart continuations), and processes each one by extracting titles, topics, technologies, and  summaries from the conversation.</p> <p>It shows you a grouped summary before applying changes so you can scan quickly rather than reviewing one by one.</p> <p>For large backlogs (20+ entries), the skill can spawn subagents to process entries in parallel.</p> <p>Single-entry enrichment:</p> <pre><code>/ctx-journal-enrich twinkly\n/ctx-journal-enrich 2026-02-06\n</code></pre> <p>Each enriched entry gets YAML frontmatter like this:</p> <pre><code>---\ntitle: \"Implement Redis caching middleware\"\ndate: 2026-02-06\ntype: feature\noutcome: completed\ntopics:\n  - caching\n  - api-performance\ntechnologies:\n  - go\n  - redis\nlibraries:\n  - go-redis/redis\nkey_files:\n  - internal/cache/redis.go\n  - internal/api/middleware/cache.go\n---\n</code></pre> <p>The skill also generates a summary and can extract decisions,  learnings, and tasks mentioned during the session.</p>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#step-5-generate-and-serve-the-site","level":3,"title":"Step 5: Generate and Serve the Site","text":"<p>With exported and enriched journal files, generate the static site:</p> <pre><code># Generate site structure only\nctx journal site\n\n# Generate and build static HTML\nctx journal site --build\n\n# Generate, build, and serve locally\nctx journal site --serve\n</code></pre> <p>Then open <code>http://localhost:8000</code> to browse.</p> <p>The site includes a date-sorted index, individual session pages with full conversations, search (press <code>/</code>), dark mode, and enriched titles in the navigation when frontmatter exists.</p> <p>You can also serve an already-generated site without regenerating using <code>ctx serve</code> (serve-only, no regeneration).</p> <p>The site generator requires <code>zensical</code> (<code>pipx install zensical</code>).</p>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#where-does-agent-add-value","level":2,"title":"Where Does Agent Add Value?","text":"<p>Export, list, and show are mechanical:  The agent runs the same CLI commands you would, so you can stay  in your terminal for those.</p> <p>The agent earns its keep in enrich. It reads conversation content, understands what happened, and produces structured metadata. That is agent work, not CLI work.</p> <p>You can also ask your agent to browse sessions conversationally instead of remembering flags:</p> <pre><code>What did we work on last week?\nShow me the session about Redis.\nExport everything to the journal.\n</code></pre> <p>This is convenient but not required: <code>ctx recall list</code> gives you the same inventory.</p> <p>Where the agent genuinely helps is chaining the pipeline:</p> <pre><code>You:   What happened last Tuesday?\nAgent: Last Tuesday you worked on two sessions:\n       - bright-dancing-hopper (2h 10m): refactored the middleware\n         pipeline and added Redis caching\n       - quiet-flowing-dijkstra (18m): quick fix for a nil pointer\n         in the config loader\n       Want me to export and enrich them?\nYou:   Yes, do it.\nAgent: Exports both, enriches, then proposes frontmatter.\n</code></pre> <p>The value is staying in one context while the agent runs export -&gt; enrich without you manually switching tools.</p>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"<p>A typical pipeline from raw sessions to a browsable site:</p> <pre><code># Terminal: export and generate\nctx recall export --all\nctx journal site --serve\n</code></pre> <pre><code># AI assistant: enrich\n/ctx-journal-enrich-all\n</code></pre> <pre><code># Terminal: rebuild with enrichments\nctx journal site --serve\n</code></pre> <p>If your project includes <code>Makefile.ctx</code> (deployed by <code>ctx init</code>), use <code>make journal</code> to combine export and rebuild stages. Then enrich inside Claude Code, then <code>make journal</code> again to pick up enrichments.</p>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#tips","level":2,"title":"Tips","text":"<ul> <li>Start with <code>/ctx-recall</code> inside your AI assistant. If you want to quickly check what happened in a recent session without leaving your editor, <code>/ctx-recall</code> lets you browse interactively without exporting.</li> <li>Large sessions may be split automatically. Sessions with 200+ messages can be split into multiple parts (<code>session-abc123.md</code>, <code>session-abc123-p2.md</code>, <code>session-abc123-p3.md</code>) with navigation links between them. The site generator can handle this.</li> <li>Suggestion sessions can be separated. Claude Code can generate short suggestion sessions for autocomplete. These may appear under a separate section in the site index, so they do not clutter your main session list.</li> <li>Your agent is a good session browser. You do not need to remember slugs, dates, or flags. Ask \"what did we do yesterday?\" or \"find the session about Redis\"  and it can map the question to recall commands.</li> </ul> <p>Journal Files Are Sensitive</p> <p>Journal files MUST be <code>.gitignore</code>d.</p> <p>Session transcripts can contain sensitive data such as file contents, commands, error messages with stack traces, and potentially API keys.</p> <p>Add <code>.context/journal/</code>, <code>.context/journal-site/</code>, and  <code>.context/journal-obsidian/</code> to your <code>.gitignore</code>.</p>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#next-up","level":2,"title":"Next Up","text":"<p>Persisting Decisions, Learnings, and Conventions →: Record decisions, learnings, and conventions so they survive across sessions.</p>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#see-also","level":2,"title":"See Also","text":"<ul> <li>The Complete Session: where session saving fits in the daily workflow</li> <li>Turning Activity into Content: generating blog posts from session history</li> <li>Session Journal: full documentation of the journal system</li> <li>CLI Reference: ctx recall: all recall subcommands and flags</li> <li>CLI Reference: ctx journal: site generation options</li> <li>CLI Reference: ctx serve: serve-only (no regeneration)</li> <li>Context Files: the <code>.context/</code> directory structure</li> </ul>","path":["Recipes","Sessions","Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-ceremonies/","level":1,"title":"Session Ceremonies","text":"","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#the-problem","level":2,"title":"The Problem","text":"<p>Sessions have two critical moments: the start and the end.</p> <ul> <li>At the start, you need the agent to load context and confirm it knows what is going on. </li> <li>At the end, you need to capture whatever the session produced before the conversation disappears.</li> </ul> <p>Most <code>ctx</code> skills work conversationally: \"jot down: check DNS after deploy\" is as good as <code>/ctx-pad add \"check DNS after deploy\"</code>. But session boundaries are different. They are well-defined moments with specific requirements, and partial execution is costly.</p> <p>If the agent only half-loads context at the start, it works from stale assumptions. If it only half-persists at the end, learnings and decisions are lost.</p> <p>This Is One of the Few Times Being Explicit Matters</p> <p>Session ceremonies are the two bookend skills that mark these boundaries. </p> <p>They are the exception to the conversational rule:</p> <p>Invoke <code>/ctx-remember</code> and <code>/ctx-wrap-up</code>  explicitly as slash commands.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#tldr","level":2,"title":"TL;DR","text":"<p>Start: <code>/ctx-remember</code>: load context, get a structured readback.</p> <p>End: <code>/ctx-wrap-up</code>: review session, propose candidates, persist approved items.</p> <p>Use the slash commands, not conversational triggers, for completeness.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#explicit-invocation-matters","level":2,"title":"Explicit Invocation Matters","text":"<p>Most <code>ctx</code> skills encourage natural language. These two are different:</p> <p>Well-defined moments: Sessions have clear boundaries. A slash command marks the boundary unambiguously.</p> <p>Ambiguity risk: \"Do you remember?\" could mean many things. <code>/ctx-remember</code> means exactly one thing: load context and present a structured readback.</p> <p>Completeness: Conversational triggers risk partial execution. The agent might load some files but skip the session history, or persist one learning but forget to check for uncommitted changes. The slash command runs the full ceremony.</p> <p>Muscle memory: Typing <code>/ctx-remember</code> at session start and <code>/ctx-wrap-up</code> at session end becomes a habit, like opening and closing braces.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>/ctx-remember</code> Skill Load context and present structured readback <code>/ctx-wrap-up</code> Skill Gather session signal, propose and persist context <code>/ctx-commit</code> Skill Commit with context capture (offered by wrap-up) <code>ctx agent</code> CLI Load token-budgeted context packet <code>ctx recall list</code> CLI List recent sessions <code>ctx add</code> CLI Persist learnings, decisions, conventions, tasks","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#session-start-ctx-remember","level":2,"title":"Session Start: /ctx-remember","text":"<p>Invoke at the beginning of every session:</p> <pre><code>/ctx-remember\n</code></pre> <p>The skill silently:</p> <ol> <li>Loads the context packet via <code>ctx agent --budget 4000</code></li> <li>Reads <code>TASKS.md</code>, <code>DECISIONS.md</code>, <code>LEARNINGS.md</code></li> <li>Checks recent sessions via <code>ctx recall list --limit 3</code></li> </ol> <p>Then presents a structured readback with four sections:</p> <ul> <li>Last session: topic, date, what was accomplished</li> <li>Active work: pending and in-progress tasks</li> <li>Recent context: 1-2 relevant decisions or learnings</li> <li>Next step: suggestion or question about what to focus on</li> </ul> <p>The readback should feel like recall, not a file system tour. If the agent says \"Let me check if there are files...\" instead of a confident summary, the skill is not working correctly.</p> <p>What About 'do you remember?'</p> <p>The conversational trigger still works. But <code>/ctx-remember</code> guarantees the full ceremony runs: </p> <ul> <li>context packet, </li> <li>file reads, </li> <li>session history,</li> <li>and all four readback sections. </li> </ul> <p>The conversational version may cut corners.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#session-end-ctx-wrap-up","level":2,"title":"Session End: /ctx-wrap-up","text":"<p>Invoke before ending a session where meaningful work happened:</p> <pre><code>/ctx-wrap-up\n</code></pre> <p>The skill runs four phases:</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#phase-1-gather-signal","level":3,"title":"Phase 1: Gather Signal","text":"<p>Silently checks <code>git diff --stat</code>, recent commits, and scans the conversation for themes: architectural choices, gotchas, patterns established, follow-up work identified.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#phase-2-propose-candidates","level":3,"title":"Phase 2: Propose Candidates","text":"<p>Presents a structured list grouped by type:</p> <pre><code>## Session Wrap-Up\n\n### Learnings (2 candidates)\n1. **PyMdownx details extension breaks pre/code rendering**\n   - Context: Journal site showed broken code blocks inside details tags\n   - Lesson: details extension wraps content in &lt;details&gt; HTML, which\n     interferes with &lt;pre&gt;&lt;code&gt; rendering\n   - Application: Use fenced code blocks instead of indented code inside\n     admonitions when details extension is active\n\n2. **Hook subprocesses cannot propagate env vars**\n   - Context: Set env var in PreToolUse hook, invisible in main session\n   - Lesson: Hooks execute in child processes; env changes don't propagate\n   - Application: Use tombstone files for hook-to-session communication\n\n### Decisions (1 candidate)\n1. **File-based cooldown tokens over env vars**\n   - Context: Need session-scoped cooldown for ctx agent auto-loading\n   - Rationale: File tokens survive across processes, simpler than IPC\n   - Consequences: Tombstone files accumulate in /tmp; need TTL cleanup\n\nPersist all? Or select which to keep?\n</code></pre> <p>Each candidate has complete structured fields, not just a title. Empty categories are omitted.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#phase-3-persist","level":3,"title":"Phase 3: Persist","text":"<p>After you approve (all, some, or modified), the skill runs the appropriate <code>ctx add</code> commands and reports results.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#phase-4-commit-offer","level":3,"title":"Phase 4: Commit Offer","text":"<p>If there are uncommitted changes, offers to run <code>/ctx-commit</code>. Does not auto-commit.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#when-to-skip","level":2,"title":"When to Skip","text":"<p>Not every session needs ceremonies.</p> <p>Skip <code>/ctx-remember</code> when:</p> <ul> <li>You are doing a quick one-off lookup (reading a file, checking a value)</li> <li>Context was already loaded this session via <code>/ctx-agent</code></li> <li>You are continuing immediately after a previous session and context is   still fresh</li> </ul> <p>Skip <code>/ctx-wrap-up</code> when:</p> <ul> <li>Nothing meaningful happened (only read files, answered a question)</li> <li>You already persisted everything manually during the session</li> <li>The session was trivial (typo fix, quick config change)</li> </ul> <p>A good heuristic: if the session produced something a future session should know about, run <code>/ctx-wrap-up</code>. If not, just close.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#quick-reference","level":2,"title":"Quick Reference","text":"<pre><code># Session start\n/ctx-remember\n\n# ... do work ...\n\n# Session end\n/ctx-wrap-up\n</code></pre> <p>That is the complete ceremony. Two commands, bookending your session.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#relationship-to-other-skills","level":2,"title":"Relationship to Other Skills","text":"Skill When Purpose <code>/ctx-remember</code> Session start Load and confirm context <code>/ctx-reflect</code> Mid-session breakpoints Checkpoint at milestones <code>/ctx-wrap-up</code> Session end Full session review and persist <code>/ctx-commit</code> After completing work Commit with context capture <p><code>/ctx-reflect</code> is for mid-session checkpoints. <code>/ctx-wrap-up</code> is for end-of-session: it is more thorough, covers the full session arc, and includes the commit offer. If you already ran <code>/ctx-reflect</code> recently, <code>/ctx-wrap-up</code> avoids proposing the same candidates again.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#tips","level":2,"title":"Tips","text":"<ul> <li>Make it a habit: The value of ceremonies compounds over sessions. Each <code>/ctx-wrap-up</code> makes the next <code>/ctx-remember</code> richer.</li> <li>Trust the candidates: The agent scans the full conversation. It often catches learnings you forgot about.</li> <li>Edit before approving: If a proposed candidate is close but not quite right, tell the agent what to change. Do not settle for a vague learning when a precise one is possible.</li> <li>Do not force empty ceremonies: If <code>/ctx-wrap-up</code> finds nothing worth persisting, that is fine. A session that only read files and answered questions does not need artificial learnings.</li> </ul>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#next-up","level":2,"title":"Next Up","text":"<p>Browsing and Enriching Past Sessions →: Export session history to a browsable journal and enrich entries with metadata.</p>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-ceremonies/#see-also","level":2,"title":"See Also","text":"<ul> <li>The Complete Session: the full session workflow   that ceremonies bookend</li> <li>Persisting Decisions, Learnings, and Conventions:   deep dive on what gets persisted during wrap-up</li> <li>Detecting and Fixing Drift: keeping context files   accurate between ceremonies</li> </ul>","path":["Recipes","Sessions","Session Ceremonies"],"tags":[]},{"location":"recipes/session-lifecycle/","level":1,"title":"The Complete Session","text":"","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#the-problem","level":2,"title":"The Problem","text":"<p>\"What does a full <code>ctx</code> session look like from start to finish?\"</p> <p>You have <code>ctx</code> installed and your <code>.context/</code> directory initialized, but the individual commands and skills feel disconnected.</p> <p>How do they fit together into a coherent workflow?</p> <p>This recipe walks through a complete session, from opening your editor to persisting context before you close it, so you can see how each piece connects.</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#tldr","level":2,"title":"TL;DR","text":"<ol> <li>Load: <code>/ctx-remember</code>: load context, get structured readback.</li> <li>Orient: <code>/ctx-status</code>: check file health and token usage.</li> <li>Pick: <code>/ctx-next</code>: choose what to work on.</li> <li>Work: implement, test, iterate.</li> <li>Commit: <code>/ctx-commit</code>: commit and capture decisions/learnings.</li> <li>Reflect: <code>/ctx-reflect</code>: identify what to persist (at milestones)</li> <li>Wrap up: <code>/ctx-wrap-up</code>: end-of-session ceremony.</li> </ol> <p>Read on for the full walkthrough with examples.</p> <p>What is a Readback?</p> <p>A readback is a structured summary where the agent plays back what it knows:</p> <ul> <li>last session,</li> <li>active tasks,</li> <li>recent decisions.</li> </ul> <p>This way, you can confirm it loaded the right context.</p> <p>The term \"readback\" comes from aviation, where pilots repeat instructions back to air traffic control to confirm they heard correctly.</p> <p>Same idea in <code>ctx</code>: The agent tells you what it \"thinks\" is going on, and you correct anything that's off before the work begins.</p> <ul> <li>Last session: topic, date, what was accomplished</li> <li>Active work: pending and in-progress tasks</li> <li>Recent context: 1-2 decisions or learnings that matter now</li> <li>Next step: suggestion or question about what to focus on</li> </ul>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx status</code> CLI command Quick health check on context files <code>ctx agent</code> CLI command Load token-budgeted context packet <code>ctx recall list</code> CLI command List previous sessions <code>ctx recall show</code> CLI command Inspect a specific session in detail <code>/ctx-remember</code> Skill Recall project context with structured readback <code>/ctx-agent</code> Skill Load full context packet inside the assistant <code>/ctx-status</code> Skill Show context summary with commentary <code>/ctx-next</code> Skill Suggest what to work on with rationale <code>/ctx-commit</code> Skill Commit code and prompt for context capture <code>/ctx-reflect</code> Skill Structured reflection checkpoint <code>/ctx-recall</code> Skill Browse session history inside your AI assistant <code>/ctx-context-monitor</code> Skill Automatic context capacity monitoring","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#the-workflow","level":2,"title":"The Workflow","text":"<p>The session lifecycle has seven steps. You will not always use every step (for example, a quick bugfix might skip reflection, and a research session might skip committing) but the full arc looks like this:</p> <p>Load context &gt; Orient &gt; Pick a Task &gt; Work &gt; Commit &gt; Reflect</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-1-load-context","level":3,"title":"Step 1: Load Context","text":"<p>Start every session by loading what you know. The fastest way is a single prompt:</p> <pre><code>Do you remember what we were working on?\n</code></pre> <p>This triggers the <code>/ctx-remember</code> skill. Behind the scenes, the assistant runs <code>ctx agent --budget 4000</code>, reads the files listed in the context packet (<code>TASKS.md</code>, <code>DECISIONS.md</code>, <code>LEARNINGS.md</code>, <code>CONVENTIONS.md</code>), checks <code>ctx recall list --limit 3</code> for recent sessions, and then presents a structured readback.</p> <p>The readback should feel like a recall, not a file system tour. If you see \"Let me check if there are files...\" instead of a confident summary, the context system is not loaded properly.</p> <p>As an alternative, if you want raw data instead of a readback, run <code>ctx status</code> in your terminal or invoke <code>/ctx-status</code> for a summarized health check showing file counts, token usage, and recent activity.</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-2-orient","level":3,"title":"Step 2: Orient","text":"<p>After loading context, verify you understand the current state.</p> <pre><code>/ctx-status\n</code></pre> <p>The status output shows which context files are populated, how many tokens they consume, and which files were recently modified. Look for:</p> <ul> <li>Empty core files: <code>TASKS.md</code> or <code>CONVENTIONS.md</code> with no content means   the context is sparse</li> <li>High token count (over 30k): the context is bloated and might   need <code>ctx compact</code></li> <li>No recent activity: files may be stale and need updating</li> </ul> <p>If the status looks healthy and the readback from Step 1 gave you enough context, skip ahead.</p> <p>If something seems off (stale tasks, missing decisions...), spend a minute reading the relevant file before proceeding.</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-3-pick-what-to-work-on","level":3,"title":"Step 3: Pick What to Work On","text":"<p>With context loaded, choose a task. You can pick one yourself, or ask the assistant to recommend:</p> <pre><code>/ctx-next\n</code></pre> <p>The skill reads <code>TASKS.md</code>, checks recent sessions to avoid re-suggesting completed work, and presents 1-3 ranked recommendations with rationale.</p> <p>It prioritizes in-progress tasks over new starts (finishing is better than starting), respects explicit priority tags, and favors momentum: continuing a thread from a recent session is cheaper than context-switching.</p> <p>If you already know what you want to work on, state it directly:</p> <pre><code>Let's work on the session enrichment feature.\n</code></pre>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-4-do-the-work","level":3,"title":"Step 4: Do the Work","text":"<p>This is the main body of the session: write code, fix bugs, refactor, research—whatever the task requires.</p> <p>During this phase, a few <code>ctx</code>-specific patterns help:</p> <p>Check decisions before choosing: when you face a design choice, check if a prior decision covers it.</p> <pre><code>Is this consistent with our decisions?\n</code></pre> <p>Constrain scope: keep the assistant focused on the task at hand.</p> <pre><code>Only change files in internal/cli/session/. Nothing else.\n</code></pre> <p>Use <code>/ctx-implement</code> for multistep plans: if the task has multiple steps, this skill executes them one at a time with build/test verification between each step.</p> <p>Context monitoring runs automatically: the <code>/ctx-context-monitor</code> skill is triggered by a hook at adaptive intervals. Early in a session it stays silent. After 16+ prompts it starts monitoring, and past 30 prompts it checks frequently. If context capacity is running high, it will suggest saving unsaved work. You typically do not need to invoke this skill manually.</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-5-commit-with-context","level":3,"title":"Step 5: Commit with Context","text":"<p>When the work is ready, use the context-aware commit instead of raw <code>git commit</code>:</p> <pre><code>/ctx-commit\n</code></pre> <p>The Agent May Recommend Committing</p> <p>You do not always need to invoke <code>/ctx-commit</code> explicitly.</p> <p>After a commit, the agent may proactively offer to capture context:</p> <p>\"We just made a trade-off there. Want me to record it as a decision?\"</p> <p>This is normal: The Agent Playbook encourages persisting at milestones, and a commit is a natural milestone.</p> <p>As an alternative, you can ask the assistant \"can we commit this?\" and it will pick up the <code>/ctx-commit</code> skill for you.</p> <p>The skill runs a pre-commit build check (for Go projects, <code>go build</code>), reviews the staged changes, drafts a commit message focused on \"why\" rather than \"what\", and then commits.</p> <p>After the commit succeeds, it prompts you:</p> <pre><code>**Any context to capture?**\n\n- **Decision**: Did you make a design choice or trade-off?\n- **Learning**: Did you hit a gotcha or discover something?\n- **Neither**: No context to capture; we are done.\n</code></pre> <p>If you made a decision, the skill records it with <code>ctx add decision</code>. If you learned something, it records it with <code>ctx add learning</code> including context, lesson, and application fields. This is the bridge between committing code and remembering why the code looks the way it does.</p> <p>If source code changed in areas that affect documentation, the skill also offers to check for doc drift.</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-6-reflect","level":3,"title":"Step 6: Reflect","text":"<p>At natural breakpoints (after finishing a feature, resolving a complex bug, or before switching tasks) pause to reflect:</p> <pre><code>/ctx-reflect\n</code></pre> <p>Agents Reflect at Milestones</p> <p>Agents often reflect without explicit invocation.</p> <p>After completing a significant piece of work, the agent may naturally surface items worth persisting:</p> <p>\"We discovered that <code>$PPID</code> resolves differently inside hooks. Should I save that as a learning?\"</p> <p>This is the agent following the Work-Reflect-Persist cycle from the Agent Playbook.</p> <p>You do not need to say <code>/ctx-reflect</code> for this to happen; the agent treats milestones as reflection triggers on its own.</p> <p>The skill works through a checklist: learnings discovered, decisions made, tasks completed or created, and whether there are items worth persisting. It then presents a summary with specific items to persist, each with the exact command to run:</p> <pre><code>I would suggest persisting:\n\n- **Learning**: `$PPID` in PreToolUse hooks resolves to the Claude Code PID\n  `ctx add learning --context \"...\" --lesson \"...\" --application \"...\"`\n- **Task**: mark \"Add cooldown to ctx agent\" as done\n- **Decision**: tombstone-based cooldown with 10m default\n  `ctx add decision \"...\"`\n\nWant me to persist any of these?\n</code></pre> <p>The skill asks before persisting anything. You choose what to keep.</p> <p>Not every commit needs reflection. A typo fix does not. But when you have been debugging for an hour and finally understand the root cause, that is worth a reflection checkpoint.</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-7-persist-before-ending","level":3,"title":"Step 7: Persist Before Ending","text":"<p>Before ending the session, run the wrap-up ceremony to capture outstanding learnings, decisions, conventions, and tasks:</p> <pre><code>/ctx-wrap-up\n</code></pre> <p>Ceremony Skills</p> <p><code>/ctx-remember</code> at session start and <code>/ctx-wrap-up</code> at session end are ceremony skills — invoke them as explicit slash commands for completeness, not conversationally.</p> <p>See Session Ceremonies for details on why these two skills are the exception to the conversational rule.</p> <p>The skill gathers signal from <code>git diff</code>, recent commits, and the conversation, then proposes structured candidates for your approval. After you select which to keep, it persists them via <code>ctx add</code> and offers <code>/ctx-commit</code> if uncommitted changes remain.</p> <p>Session transcripts are automatically captured by Claude Code and can be browsed later with <code>ctx recall list</code> and <code>ctx recall show</code>.</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#conversational-session-flow","level":2,"title":"Conversational Session Flow","text":"<p>The steps above describe the mechanics. In practice, a session with a <code>ctx</code>-aware agent feels more like a conversation than a command sequence.</p> <p>The agent knows the lifecycle and moves through it naturally, often without explicit invocation. Here is a realistic example:</p> <p>You: Do you remember what we were working on?</p> <p>Agent (loads context silently, presents structured readback):</p> <pre><code>Last session (Feb 7, caching-layer): we implemented the in-memory cache with\nTTL expiration and wrote tests for the eviction policy. \n\nYou have 3 pending tasks; the biggest one is adding Redis as a backend.\n\nRecent decision:&lt;br&gt;\nwe chose LRU over LFU because the access pattern is mostly recency-based.\n\nWant to continue with the Redis backend, or tackle something else?\n</code></pre> <p>You: Let's work on the Redis caching backend.</p> <p>Agent (picks up the task, begins implementation):</p> <pre><code>Got it. I see the task in TASKS.md: \"Add Redis backend for cache layer.\"\n\nI will start with the connection pool setup. Only touching\n`internal/cache/redis/` for now.\n</code></pre> <p>(The agent works... writes code, runs tests, iterates.)</p> <p>Agent (after implementing the connection pool and choosing a retry strategy):</p> <pre><code>The connection pool is working. I went with exponential backoff with jitter\nfor retries instead of fixed intervals; it handles thundering herd better\nunder reconnection storms. That is a design choice worth recording. \n\nWant me to save it as a decision?\n</code></pre> <p>You: Yes, go ahead.</p> <p>Agent:</p> <pre><code>Done. Added to DECISIONS.md: \"Exponential backoff with jitter for Redis\nreconnection, to avoid thundering herd on pool recovery.\"\n</code></pre> <p>(More work happens... the agent implements the cache read/write paths.)</p> <p>You: What else did we learn during this session?</p> <p>Agent:</p> <pre><code>A few things worth capturing:\n\n* **Learning**: Redis `SET` with `NX` and `PX` flags handles atomic\n  set-if-not-exists with TTL in a single call. No need for a separate\n  `EXPIRE` command. We initially did it in two calls and hit a race condition.\n* **Learning**: The `go-redis` library's `PoolSize` default is 10 per CPU.\n  For our workload, explicit sizing at 20 was more predictable.\n* **Task update**: The connection pool subtask is done; the read/write path\n  is implemented but needs integration tests.\n\nWant me to persist these?\n</code></pre> <p>You: Yes. And let's wrap up.</p> <p>Agent (reflects and persists... all in one flow):</p> <pre><code>Persisted:\n\n* 2 learnings added to LEARNINGS.md\n* Marked \"connection pool setup\" done in TASKS.md\n* Added \"write integration tests for Redis cache\" as a new task\n\nContext is up to date. You are good to close.\n</code></pre> <p>Notice What Happened</p> <p>In the above workflow, the user never typed <code>/ctx-reflect</code> or <code>ctx add learning</code>.</p> <p>The agent moved through Load, Orient, Pick, Work, Commit, and Reflect driven by natural conversation.</p> <p>\"Let's wrap up\" was enough to trigger the full reflect-and-persist flow.</p> <p>The agent surfaced persist-worthy items at milestones: after a design choice, after discovering a gotcha—without waiting to be asked.</p> <p>This is the intended experience. </p> <p>The commands and skills still exist for when you want precise control, but  the agent is a proactive partner in the lifecycle, not a passive executor  of slash commands.</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"<p>Quick-reference checklist for a complete session:</p> <ul> <li> Load: <code>/ctx-remember</code>: load context and confirm readback</li> <li> Orient: <code>/ctx-status</code>: check file health and token usage</li> <li> Pick: <code>/ctx-next</code>: choose what to work on</li> <li> Work: implement, test, iterate (scope with \"only change X\")</li> <li> Commit: <code>/ctx-commit</code>: commit and capture decisions/learnings</li> <li> Reflect: <code>/ctx-reflect</code>: identify what to persist (at milestones)</li> <li> Wrap up: <code>/ctx-wrap-up</code>: end-of-session ceremony</li> </ul> <p>Conversational equivalents: you can drive the same lifecycle with plain language:</p> Step Slash command Natural language Load <code>/ctx-remember</code> \"Do you remember?\" / \"What were we working on?\" Orient <code>/ctx-status</code> \"How's our context looking?\" Pick <code>/ctx-next</code> \"What should we work on?\" / \"Let's do the caching task\" Work -- \"Only change files in internal/cache/\" Commit <code>/ctx-commit</code> \"Commit this\" / \"Ship it\" Reflect <code>/ctx-reflect</code> \"What did we learn?\" / (agent offers at milestones) Wrap up <code>/ctx-wrap-up</code> (use the slash command for completeness) <p>The agent understands both columns.</p> <p>In practice, most sessions use a mix:</p> <ul> <li>Explicit Commands when you want precision;</li> <li>Natural Language when you want flow and agentic autonomy.</li> </ul> <p>The agent will also initiate steps on its own (particularly \"Reflect\") when it recognizes a milestone.</p> <p>Short sessions (quick bugfix) might only use: Load, Work, Commit.</p> <p>Long sessions should Reflect after each major milestone and persist learnings and decisions before ending.</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#tips","level":2,"title":"Tips","text":"<p>Persist early if context is running low. A hook monitors context capacity and notifies you when it gets high, but do not wait for the notification. If you have been working for a while and have unpersisted learnings, persist proactively.</p> <p>Browse previous sessions by topic. If you need context from a prior session, <code>ctx recall show auth</code> will match by keyword. You do not need to remember the exact date or slug.</p> <p>Reflection is optional but valuable. You can skip <code>/ctx-reflect</code> for small changes, but always persist learnings and decisions before ending a session where you did meaningful work. These are what the next session loads.</p> <p>Let the hook handle context loading. The <code>PreToolUse</code> hook runs <code>ctx agent</code> automatically with a cooldown, so context loads on first tool use without you asking. The <code>/ctx-remember</code> prompt at session start is for your benefit (to get a readback), not because the assistant needs it.</p> <p>The agent is a proactive partner, not a passive tool. A <code>ctx</code>-aware agent follows the Agent Playbook: it watches for milestones (completed tasks, design decisions, discovered gotchas) and offers to persist them without being asked. If you finish a tricky debugging session, it may say \"That root cause is worth saving as a learning. Want me to record it?\" before you think to ask. This is by design.</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#next-up","level":2,"title":"Next Up","text":"<p>Session Ceremonies →: The two bookend rituals for every session: <code>/ctx-remember</code> at the start, <code>/ctx-wrap-up</code> at the end.</p>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#see-also","level":2,"title":"See Also","text":"<ul> <li>Session Ceremonies: why <code>/ctx-remember</code> and   <code>/ctx-wrap-up</code> are explicit slash commands, not conversational</li> <li>CLI Reference: full documentation for all <code>ctx</code> commands</li> <li>Prompting Guide: effective prompts for ctx-enabled projects</li> <li>Tracking Work Across Sessions: deep dive on task management</li> <li>Persisting Decisions, Learnings, and Conventions:   deep dive on knowledge capture</li> <li>Detecting and Fixing Drift: keeping context files accurate</li> </ul>","path":["Recipes","Sessions","The Complete Session"],"tags":[]},{"location":"recipes/session-reminders/","level":1,"title":"Session Reminders","text":"","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#the-problem","level":2,"title":"The Problem","text":"<p>You're deep in a session and realize: \"I need to refactor the swagger definitions next time.\" You could add a task, but this isn't a work item: it's a note to future-you. You could jot it on the scratchpad, but scratchpad entries don't announce themselves.</p> <p>How do you leave a message that your next session opens with?</p>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#tldr","level":2,"title":"TL;DR","text":"<pre><code>ctx remind \"refactor the swagger definitions\"\nctx remind list\nctx remind dismiss 1\n</code></pre> <p>Reminders surface automatically at session start: VERBATIM, every session, until you dismiss them.</p>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx remind</code> CLI command Add a reminder (default action) <code>ctx remind list</code> CLI command Show all pending reminders <code>ctx remind dismiss</code> CLI command Remove a reminder by ID (or <code>--all</code>) <code>/ctx-remind</code> Skill Natural language interface to reminders","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#step-1-leave-a-reminder","level":3,"title":"Step 1: Leave a Reminder","text":"<p>Tell your agent what to remember, or run it directly:</p> <pre><code>You: \"remind me to refactor the swagger definitions\"\n\nAgent: [runs ctx remind \"refactor the swagger definitions\"]\n       \"Reminder set:\n         + [1] refactor the swagger definitions\"\n</code></pre> <p>Or from the terminal:</p> <pre><code>ctx remind \"refactor the swagger definitions\"\n</code></pre>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#step-2-set-a-date-gate-optional","level":3,"title":"Step 2: Set a Date Gate (Optional)","text":"<p>If the reminder shouldn't fire until a specific date:</p> <pre><code>You: \"remind me to check the deploy logs after Tuesday\"\n\nAgent: [runs ctx remind \"check the deploy logs\" --after 2026-02-25]\n       \"Reminder set:\n         + [2] check the deploy logs  (after 2026-02-25)\"\n</code></pre> <p>The reminder stays silent until that date, then fires every session.</p> <p>The agent converts natural language dates (\"tomorrow\", \"next week\", \"after the release on Friday\") to <code>YYYY-MM-DD</code>. If it's ambiguous, it asks.</p>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#step-3-start-a-new-session","level":3,"title":"Step 3: Start a New Session","text":"<p>Next session, the reminder appears automatically before anything else:</p> <pre><code>┌─ Reminders ──────────────────────────────────────\n│  [1] refactor the swagger definitions\n│\n│ Dismiss: ctx remind dismiss &lt;id&gt;\n│ Dismiss all: ctx remind dismiss --all\n└──────────────────────────────────────────────────\n</code></pre> <p>No action needed: The <code>check-reminders</code> hook fires on <code>UserPromptSubmit</code> and the agent relays the box verbatim.</p>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#step-4-dismiss-when-done","level":3,"title":"Step 4: Dismiss When Done","text":"<p>After you've acted on a reminder (or decided to skip it):</p> <pre><code>You: \"dismiss reminder 1\"\n\nAgent: [runs ctx remind dismiss 1]\n       \"Dismissed:\n         - [1] refactor the swagger definitions\"\n</code></pre> <p>Or clear everything:</p> <pre><code>ctx remind dismiss --all\n</code></pre>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#step-5-check-whats-pending","level":3,"title":"Step 5: Check What's Pending","text":"<pre><code>ctx remind list\n</code></pre> <pre><code>  [1] refactor the swagger definitions\n  [3] review auth token expiry logic\n  [4] check deploy logs  (after 2026-02-25, not yet due)\n</code></pre> <p>Date-gated reminders that haven't reached their date show <code>(not yet due)</code>.</p>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#using-ctx-remind-in-a-session","level":2,"title":"Using <code>/ctx-remind</code> in a Session","text":"<p>Invoke the <code>/ctx-remind</code> skill, then describe what you want:</p> <pre><code>You: /ctx-remind remind me to update the API docs\nYou: /ctx-remind what reminders do I have?\nYou: /ctx-remind dismiss reminder 3\n</code></pre> You say (after <code>/ctx-remind</code>) What the agent does \"remind me to update the API docs\" <code>ctx remind \"update the API docs\"</code> \"remind me next week to check staging\" <code>ctx remind \"check staging\" --after 2026-03-02</code> \"what reminders do I have?\" <code>ctx remind list</code> \"dismiss reminder 3\" <code>ctx remind dismiss 3</code> \"clear all reminders\" <code>ctx remind dismiss --all</code>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#reminders-vs-scratchpad-vs-tasks","level":2,"title":"Reminders vs Scratchpad vs Tasks","text":"You want to... Use Leave a note that announces itself next session <code>ctx remind</code> Jot down a quick value or sensitive token <code>ctx pad</code> Track work with status and completion <code>TASKS.md</code> Record a decision or lesson for all sessions Context files <p>Decision guide:</p> <ul> <li>If it should announce itself at session start → <code>ctx remind</code></li> <li>If it's a quiet note you'll check manually → <code>ctx pad</code></li> <li>If it's a work item you'll mark done → <code>TASKS.md</code></li> </ul> <p>Reminders Are Sticky Notes, Not Tasks</p> <p>A reminder has no status, no priority, no lifecycle. It's a message to \"future you\" that fires until dismissed. </p> <p>If you need tracking, use a task in <code>TASKS.md</code>.</p>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#tips","level":2,"title":"Tips","text":"<ul> <li>Reminders fire every session: Unlike nudges (which throttle to   once per day), reminders repeat until you dismiss them. This is   intentional: You asked to be reminded.</li> <li>Date gating is session-scoped, not clock-scoped: <code>--after   2026-02-25</code> means \"don't show until sessions on or after Feb 25.\"   It does not mean \"alarm at midnight on Feb 25.\"</li> <li>The agent handles date parsing: Say \"next week\" or \"after   Friday\": The agent converts it to <code>YYYY-MM-DD</code>. The CLI only   accepts the explicit date format.</li> <li>Reminders are committed to git: They travel with the repo.   If you switch machines, your reminders follow.</li> <li>IDs never reuse: After dismissing reminder 3, the next reminder   gets ID 4 (or higher). No confusion from recycled numbers.</li> </ul>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#next-up","level":2,"title":"Next Up","text":"<p>Using the Scratchpad →: For quiet notes and sensitive values that don't need session-start announcements.</p>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/session-reminders/#see-also","level":2,"title":"See Also","text":"<ul> <li>CLI Reference: ctx remind: full   command syntax and flags</li> <li>The Complete Session: how reminders fit into   the session lifecycle</li> <li>Managing Tasks: for work items that need status   tracking</li> </ul>","path":["Recipes","Sessions","Session Reminders"],"tags":[]},{"location":"recipes/system-hooks-audit/","level":1,"title":"Auditing System Hooks","text":"","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#the-problem","level":2,"title":"The Problem","text":"<p><code>ctx</code> runs 14 system hooks behind the scenes: nudging your agent to persist context, warning about resource pressure, gating commits on QA. But these hooks are invisible by design. You never see them fire. You never know if they stopped working.</p> <p>How do you verify your hooks are actually running, audit what they do, and get alerted when they go silent?</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#tldr","level":2,"title":"TL;DR","text":"<pre><code>ctx system check-resources # run a hook manually\nls -la .context/logs/      # check hook execution logs\nctx notify setup           # get notified when hooks fire\n</code></pre> <p>Or ask your agent: \"Are our hooks running?\"</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx system &lt;hook&gt;</code> CLI command Run a system hook manually <code>ctx system resources</code> CLI command Show system resource status <code>ctx notify setup</code> CLI command Configure webhook for audit trail <code>ctx notify test</code> CLI command Verify webhook delivery <code>.ctxrc</code> <code>notify.events</code> Configuration Subscribe to <code>relay</code> for full hook audit <code>.context/logs/</code> Log files Local hook execution ledger","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#what-are-system-hooks","level":2,"title":"What Are System Hooks?","text":"<p>System hooks are plumbing commands that <code>ctx</code> registers with your AI tool (Claude Code, Cursor, etc.) via the plugin's <code>hooks.json</code>. They fire automatically at specific events during your AI session:</p> Event When Hooks <code>UserPromptSubmit</code> Before the agent sees your prompt 9 check hooks <code>PreToolUse</code> Before the agent uses a tool <code>block-non-path-ctx</code>, <code>qa-reminder</code> <code>PostToolUse</code> After a tool call succeeds <code>post-commit</code> <code>SessionEnd</code> Session terminates <code>cleanup-tmp</code> <p>You never run these manually. Your AI tool runs them for you: That's the point.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#the-complete-hook-catalog","level":2,"title":"The Complete Hook Catalog","text":"","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#prompt-time-checks-userpromptsubmit","level":3,"title":"Prompt-Time Checks (UserPromptSubmit)","text":"<p>These fire before every prompt, but most are throttled to avoid noise.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#check-context-size-context-capacity-warning","level":4,"title":"<code>check-context-size</code>: Context Capacity Warning","text":"<p>What: Adaptive prompt counter. Silent for the first 15 prompts, then nudges with increasing frequency (every 5<sup>th</sup>, then every 3<sup>rd</sup>).</p> <p>Why: Long sessions lose coherence. The nudge reminds both you and the agent to persist context before the window fills up.</p> <p>Output: VERBATIM relay box with prompt count.</p> <pre><code>┌─ Context Checkpoint (prompt #20) ────────────────\n│ This session is getting deep. Consider wrapping up\n│ soon. If there are unsaved learnings, decisions, or\n│ conventions, now is a good time to persist them.\n└──────────────────────────────────────────────────\n</code></pre>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#check-persistence-context-staleness-nudge","level":4,"title":"<code>check-persistence</code>: Context Staleness Nudge","text":"<p>What: Tracks when <code>.context/*.md</code> files were last modified. If too many prompts pass without a write, nudges the agent to persist.</p> <p>Why: Sessions produce insights that evaporate if not recorded. This catches the \"we talked about it but never wrote it down\" failure mode.</p> <p>Output: VERBATIM relay after 20+ prompts without a context file change.</p> <pre><code>┌─ Persistence Checkpoint (prompt #20) ───────────\n│ No context files updated in 20+ prompts.\n│ Have you discovered learnings, made decisions,\n│ established conventions, or completed tasks\n│ worth persisting?\n│\n│ Run /ctx-wrap-up to capture session context.\n└──────────────────────────────────────────────────\n</code></pre>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#check-ceremonies-session-ritual-adoption","level":4,"title":"<code>check-ceremonies</code>: Session Ritual Adoption","text":"<p>What: Scans your last 3 journal entries for <code>/ctx-remember</code> and <code>/ctx-wrap-up</code> usage. Nudges once per day if missing.</p> <p>Why: Session ceremonies are the highest-leverage habit in <code>ctx</code>. This hook bootstraps the habit until it becomes automatic.</p> <p>Output: Tailored nudge depending on which ceremony is missing.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#check-journal-unexported-session-reminder","level":4,"title":"<code>check-journal</code>: Unexported Session Reminder","text":"<p>What: Detects unexported Claude Code sessions and unenriched journal entries. Fires once per day.</p> <p>Why: Exported sessions become searchable history. Unenriched entries lack metadata for filtering. Both decay in value over time.</p> <p>Output: VERBATIM relay with counts and exact commands.</p> <pre><code>┌─ Journal Reminder ─────────────────────────────\n│ You have 3 new session(s) not yet exported.\n│ 5 existing entries need enrichment.\n│\n│ Export and enrich:\n│   ctx recall export --all\n│   /ctx-journal-enrich-all\n└────────────────────────────────────────────────\n</code></pre>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#check-resources-system-resource-pressure","level":4,"title":"<code>check-resources</code>: System Resource Pressure","text":"<p>What: Monitors memory, swap, disk, and CPU load. Only fires at DANGER severity (memory &gt;= 90%, swap &gt;= 75%, disk &gt;= 95%, load &gt;= 1.5x CPU count).</p> <p>Why: Resource exhaustion mid-session can corrupt work. This provides early warning to persist and exit.</p> <p>Output: VERBATIM relay listing critical resources.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#check-knowledge-knowledge-file-growth","level":4,"title":"<code>check-knowledge</code>: Knowledge File Growth","text":"<p>What: Counts entries in <code>LEARNINGS.md</code>, <code>DECISIONS.md</code>, and lines in <code>CONVENTIONS.md</code>. Fires once per day when thresholds are exceeded.</p> <p>Why: Large knowledge files dilute agent context. 35 learnings compete for attention; 15 focused ones get applied. Thresholds are configurable in <code>.ctxrc</code>.</p> <p>Default thresholds:</p> <pre><code># .ctxrc\nentry_count_learnings: 30\nentry_count_decisions: 20\nconvention_line_count: 200\n</code></pre>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#check-version-binaryplugin-version-drift","level":4,"title":"<code>check-version</code>: Binary/Plugin Version Drift","text":"<p>What: Compares the <code>ctx</code> binary version against the plugin version. Fires once per day. Also checks encryption key age for rotation nudge.</p> <p>Why: Version drift means hooks reference features the binary doesn't have. The key rotation nudge prevents indefinite key reuse.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#check-reminders-pending-reminder-relay","level":4,"title":"<code>check-reminders</code>: Pending Reminder Relay","text":"<p>What: Reads <code>.context/reminders.json</code> and surfaces any due reminders via VERBATIM relay. No throttle: fires every session until dismissed.</p> <p>Why: Reminders are sticky notes to future-you. Unlike nudges (which throttle to once per day), reminders repeat deliberately until the user dismisses them.</p> <p>Output: VERBATIM relay box listing due reminders.</p> <pre><code>┌─ Reminders ──────────────────────────────────────\n│  [1] refactor the swagger definitions\n│\n│ Dismiss: ctx remind dismiss &lt;id&gt;\n│ Dismiss all: ctx remind dismiss --all\n└──────────────────────────────────────────────────\n</code></pre>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#check-map-staleness-architecture-map-drift","level":4,"title":"<code>check-map-staleness</code>: Architecture Map Drift","text":"<p>What: Checks whether <code>map-tracking.json</code> is older than 30 days and there are commits touching <code>internal/</code> since the last map refresh. Daily throttle prevents repeated nudges.</p> <p>Why: Architecture documentation drifts silently as code evolves. This hook detects structural changes that the map hasn't caught up with and suggests running <code>/ctx-map</code> to refresh.</p> <p>Output: VERBATIM relay when stale and modules changed, silent otherwise.</p> <pre><code>┌─ Architecture Map Stale ────────────────────────────\n│ ARCHITECTURE.md hasn't been refreshed since 2026-01-15\n│ and there are commits touching 12 modules.\n│ /ctx-map keeps architecture docs drift-free.\n│\n│ Want me to run /ctx-map to refresh?\n└─────────────────────────────────────────────────────\n</code></pre>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#tool-time-hooks-pretooluse-posttooluse","level":3,"title":"Tool-Time Hooks (PreToolUse / PostToolUse)","text":"","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#block-non-path-ctx-path-enforcement-hard-gate","level":4,"title":"<code>block-non-path-ctx</code>: PATH Enforcement (Hard Gate)","text":"<p>What: Blocks any Bash command that invokes <code>./ctx</code>, <code>./dist/ctx</code>, <code>go run ./cmd/ctx</code>, or an absolute path to <code>ctx</code>. Only PATH invocations are allowed.</p> <p>Why: Enforces <code>CONSTITUTION.md</code>'s invocation invariant. Running a dev-built binary in production context causes version confusion and silent behavior drift.</p> <p>Output: Block response (prevents the tool call):</p> <pre><code>{\"decision\": \"block\", \"reason\": \"Use 'ctx' from PATH, not './ctx'...\"}\n</code></pre>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#qa-reminder-pre-commit-qa-gate","level":4,"title":"<code>qa-reminder</code>: Pre-Commit QA Gate","text":"<p>What: Fires on every <code>Edit</code> tool use. Reminds the agent to lint and test the entire project before committing.</p> <p>Why: Agents tend to \"I'll test later\" and then commit untested code. Repetition is intentional: the hook reinforces the habit on every edit, not just before commits.</p> <p>Output: Agent directive with hard QA gate instructions.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#post-commit-context-capture-after-commit","level":4,"title":"<code>post-commit</code>: Context Capture After Commit","text":"<p>What: Fires after any <code>git commit</code> (excludes <code>--amend</code>). Prompts the agent to offer context capture (decision? learning?) and suggest running lints/tests before pushing.</p> <p>Why: Commits are natural reflection points. The nudge converts mechanical git operations into context-capturing opportunities.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#session-lifecycle-sessionend","level":3,"title":"Session Lifecycle (SessionEnd)","text":"","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#cleanup-tmp-temp-file-cleanup","level":4,"title":"<code>cleanup-tmp</code>: Temp File Cleanup","text":"<p>What: Removes files older than 15 days from the <code>ctx</code> temp directory (<code>$XDG_RUNTIME_DIR/ctx/</code> or <code>/tmp/ctx-&lt;uid&gt;/</code>).</p> <p>Why: State files from throttling (daily markers, prompt counters) accumulate. Silent cleanup prevents temp directory bloat.</p> <p>Output: None (silent side-effect).</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#auditing-hooks-via-webhooks","level":2,"title":"Auditing Hooks via Webhooks","text":"<p>The most powerful audit setup pipes all hook output to a webhook, giving you a real-time external record of what your agent is being told.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#step-1-set-up-the-webhook","level":3,"title":"Step 1: Set Up the Webhook","text":"<pre><code>ctx notify setup\n# Enter your webhook URL (Slack, Discord, ntfy.sh, IFTTT, etc.)\n</code></pre> <p>See Webhook Notifications for service-specific setup.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#step-2-subscribe-to-relay-events","level":3,"title":"Step 2: Subscribe to <code>relay</code> Events","text":"<pre><code># .ctxrc\nnotify:\n  events:\n    - relay   # all hook output — VERBATIM relays, directives, blocks\n    - nudge   # just the user-facing VERBATIM relays\n</code></pre> <p>The <code>relay</code> event fires for every hook that produces output. This includes:</p> Hook Event sent <code>check-context-size</code> <code>relay</code> + <code>nudge</code> <code>check-persistence</code> <code>relay</code> + <code>nudge</code> <code>check-ceremonies</code> <code>relay</code> + <code>nudge</code> <code>check-journal</code> <code>relay</code> + <code>nudge</code> <code>check-resources</code> <code>relay</code> + <code>nudge</code> <code>check-knowledge</code> <code>relay</code> + <code>nudge</code> <code>check-version</code> <code>relay</code> + <code>nudge</code> <code>check-reminders</code> <code>relay</code> + <code>nudge</code> <code>check-map-staleness</code> <code>relay</code> + <code>nudge</code> <code>block-non-path-ctx</code> <code>relay</code> only <code>post-commit</code> <code>relay</code> only <code>qa-reminder</code> <code>relay</code> only <code>cleanup-tmp</code> (silent: no notification)","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#step-3-cross-reference","level":3,"title":"Step 3: Cross-Reference","text":"<p>With <code>relay</code> enabled, your webhook receives a JSON payload every time a hook fires:</p> <pre><code>{\n  \"event\": \"relay\",\n  \"message\": \"check-persistence: No context updated in 20+ prompts\",\n  \"session_id\": \"b854bd9c\",\n  \"timestamp\": \"2026-02-22T14:30:00Z\",\n  \"project\": \"my-project\"\n}\n</code></pre> <p>This creates an external audit trail independent of the agent. You can now cross-verify: did the agent actually relay the checkpoint the hook told it to relay?</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#verifying-hooks-actually-fire","level":2,"title":"Verifying Hooks Actually Fire","text":"<p>Hooks are invisible. An invisible thing that breaks is indistinguishable from an invisible thing that never existed. Three verification methods, from simplest to most robust:</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#method-1-ask-the-agent","level":3,"title":"Method 1: Ask the Agent","text":"<p>The simplest check. After a few prompts into a session:</p> <pre><code>\"Did you receive any hook output this session? Print the last\ncontext checkpoint or persistence nudge you saw.\"\n</code></pre> <p>The agent should be able to recall recent hook output from its context window. If it says \"I haven't received any hook output\", either:</p> <ul> <li>The hooks aren't firing (check installation);</li> <li>The session is too short (hooks throttle early);</li> <li>The hooks fired but the agent absorbed them silently.</li> </ul> <p>Limitation: You are trusting the agent to report accurately. Agents sometimes confabulate or miss context. Use this as a quick smoke test, not definitive proof.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#method-2-check-the-webhook-trail","level":3,"title":"Method 2: Check the Webhook Trail","text":"<p>If you have <code>relay</code> events enabled, check your webhook receiver. Every hook that fires sends a timestamped notification. No notification = no fire.</p> <p>This is the ground truth. The webhook is called directly by the <code>ctx</code> binary, not by the agent. The agent cannot fake, suppress, or modify webhook deliveries.</p> <p>Compare what the webhook received against what the agent claims to have relayed. Discrepancies mean the agent is absorbing nudges instead of surfacing them.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#method-3-read-the-local-logs","level":3,"title":"Method 3: Read the Local Logs","text":"<p>Hooks that support logging write to <code>.context/logs/</code>:</p> <pre><code># Check context-size hook activity\ncat .context/logs/check-context-size.log\n\n# Sample output:\n# [2026-02-22 09:15:00] [session:b854bd9c] prompt#1 silent\n# [2026-02-22 09:17:33] [session:b854bd9c] prompt#16 CHECKPOINT\n# [2026-02-22 09:20:01] [session:b854bd9c] prompt#20 CHECKPOINT\n</code></pre> <pre><code># Check persistence nudge activity\ncat .context/logs/check-persistence.log\n\n# Sample output:\n# [2026-02-22 09:15:00] [session:b854bd9c] init count=1 mtime=1770646611\n# [2026-02-22 09:20:01] [session:b854bd9c] prompt#20 NUDGE since_nudge=20\n</code></pre> <p>Logs are append-only and written by the <code>ctx</code> binary, not the agent.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#detecting-silent-hook-failures","level":2,"title":"Detecting Silent Hook Failures","text":"<p>The hardest failure mode: hooks that stop firing without error. The plugin config changes, a binary update drops a hook, or a PATH issue silently breaks execution. Nothing errors: The hook just never runs.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#the-staleness-signal","level":3,"title":"The Staleness Signal","text":"<p>If <code>.context/logs/check-context-size.log</code> has no entries newer than 5 days but you've been running sessions daily, something is wrong. The absence of evidence is evidence of absence — but only if you control for inactivity.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#false-positive-protection","level":3,"title":"False Positive Protection","text":"<p>A naive \"hooks haven't fired in N days\" alert fires incorrectly when you simply haven't used <code>ctx</code>. The correct check needs two inputs:</p> <ol> <li>Last hook fire time: from <code>.context/logs/</code> or webhook history</li> <li>Last session activity: from journal entries or <code>ctx recall list</code></li> </ol> <p>If sessions are happening but hooks aren't firing, that's a real problem. If neither sessions nor hooks are happening, that's a vacation.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#what-to-check","level":3,"title":"What to Check","text":"<p>When you suspect hooks aren't firing:</p> <pre><code># 1. Verify the plugin is installed\nls ~/.claude/plugins/\n\n# 2. Check hook registration\ncat ~/.claude/plugins/ctx/hooks.json | head -20\n\n# 3. Run a hook manually to see if it errors\necho '{\"session_id\":\"test\"}' | ctx system check-context-size\n\n# 4. Check for PATH issues\nwhich ctx\nctx --version\n</code></pre>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#tips","level":2,"title":"Tips","text":"<ul> <li>Start with <code>nudge</code>, graduate to <code>relay</code>: The <code>nudge</code> event covers   user-facing VERBATIM relays. Add <code>relay</code> when you want full visibility   into agent directives and hard gates.</li> <li>Webhooks are your trust anchor:    The agent can ignore a nudge, but it can't suppress the webhook.    If the webhook fired and the agent didn't relay, you have proof of a    compliance gap.</li> <li>Hooks are throttled by design: Most check hooks fire once per day   or use adaptive frequency. Don't expect a notification every prompt:   Silence usually means the throttle is working, not that the hook is   broken.</li> <li>Daily markers live in temp: Throttle files are stored in   <code>$XDG_RUNTIME_DIR/ctx/</code> and cleaned up by <code>cleanup-tmp</code> after 15   days. If you need to force a hook to re-fire during testing, delete   the corresponding marker file.</li> <li>The QA reminder is intentionally noisy: Unlike other hooks,   <code>qa-reminder</code> fires on every <code>Edit</code> call with no throttle. This is   deliberate: The commit quality degrades when the reminder fades from   salience.</li> <li>Log files are safe to commit: <code>.context/logs/</code> contains only   timestamps, session IDs, and status keywords. No secrets, no code.</li> </ul>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#next-up","level":2,"title":"Next Up","text":"<p>Detecting and Fixing Drift →: Keep context files accurate as your codebase evolves.</p>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/system-hooks-audit/#see-also","level":2,"title":"See Also","text":"<ul> <li>Webhook Notifications: setting up and   configuring the webhook system</li> <li>Hook Output Patterns: understanding   VERBATIM relays, agent directives, and hard gates</li> <li>Detecting and Fixing Drift: structural checks   that complement runtime hook auditing</li> <li>CLI Reference: full <code>ctx system</code>   command reference</li> </ul>","path":["Recipes","Hooks and Notifications","Auditing System Hooks"],"tags":[]},{"location":"recipes/task-management/","level":1,"title":"Tracking Work Across Sessions","text":"","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#the-problem","level":2,"title":"The Problem","text":"<p>You have work that spans multiple sessions. Tasks get added during one session, partially finished in another, and completed days later.</p> <p>Without a system, follow-up items fall through the cracks, priorities drift, and you lose track of what was done versus what still needs doing. <code>TASKS.md</code> grows cluttered with completed checkboxes that obscure the remaining work.</p> <p>How do you manage work items that span multiple sessions without losing context?</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#tldr","level":2,"title":"TL;DR","text":"<p>Manage Tasks:</p> <pre><code>ctx add task \"Fix race condition\" --priority high  # add\nctx add task \"Write tests\" --section \"Phase 2\"     # add to phase\nctx complete \"race condition\"                      # mark done\nctx tasks snapshot \"before-refactor\"               # backup\nctx tasks archive                                  # clean up\n</code></pre> <p>Pick Up the Next Task:</p> <pre><code>/ctx-next # pick what's next\n</code></pre> <p>Read on for the full workflow and conversational patterns.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx add task</code> Command Add a new task to <code>TASKS.md</code> <code>ctx complete</code> Command Mark a task as done by number or text <code>ctx tasks snapshot</code> Command Create a point-in-time backup of <code>TASKS.md</code> <code>ctx tasks archive</code> Command Move completed tasks to archive file <code>/ctx-add-task</code> Skill AI-assisted task creation with validation <code>/ctx-archive</code> Skill AI-guided archival with safety checks <code>/ctx-next</code> Skill Pick what to work on based on priorities","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-1-add-tasks-with-priorities","level":3,"title":"Step 1: Add Tasks with Priorities","text":"<p>Every piece of follow-up work gets a task. Use <code>ctx add task</code> from the terminal or <code>/ctx-add-task</code> from your AI assistant. Tasks should start with a verb and be specific enough that someone unfamiliar with the session could act on them.</p> <pre><code># High-priority bug found during code review\nctx add task \"Fix race condition in session cooldown\" --priority high\n\n# Medium-priority feature work\nctx add task \"Add --format json flag to ctx status for CI integration\" --priority medium\n\n# Low-priority cleanup\nctx add task \"Remove deprecated --raw flag from ctx load\" --priority low\n</code></pre> <p>The <code>/ctx-add-task</code> skill validates your task before recording it. It checks that the description is actionable, not a duplicate, and specific enough for someone else to pick up.</p> <p>If you say \"fix the bug,\" it will ask you to clarify which bug and where.</p> <p>Tasks Are Often Created Proactively</p> <p>In practice, many tasks are created proactively by the agent rather than by explicit CLI commands.</p> <p>After completing a feature, the agent will often identify follow-up work: tests, docs, edge cases, error handling, and offer to add them as tasks.</p> <p>You do not need to dictate <code>ctx add task</code> commands; the agent picks up on work context and suggests tasks naturally.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-2-organize-with-phase-sections","level":3,"title":"Step 2: Organize with Phase Sections","text":"<p>Tasks live in phase sections inside <code>TASKS.md</code>.</p> <p>Phases provide logical groupings that preserve order and enable replay.</p> <p>A task does not move between sections. It stays in its phase permanently, and status is tracked via checkboxes and inline tags.</p> <pre><code>## Phase 1: Core CLI\n\n- [x] Implement ctx add command `#done:2026-02-01-143022`\n- [x] Implement ctx complete command `#done:2026-02-03-091544`\n- [ ] Add --section flag to ctx add task `#priority:medium`\n\n## Phase 2: AI Integration\n\n- [ ] Implement ctx agent cooldown `#priority:high` `#in-progress`\n- [ ] Add ctx watch XML parsing `#priority:medium`\n  - Blocked by: Need to finalize agent output format\n\n## Backlog\n\n- [ ] Performance optimization for large TASKS.md files `#priority:low`\n- [ ] Add metrics dashboard to ctx status `#priority:deferred`\n</code></pre> <p>Use <code>--section</code> when adding a task to a specific phase:</p> <pre><code>ctx add task \"Add ctx watch XML parsing\" --priority medium --section \\\n    \"Phase 2: AI Integration\"\n</code></pre> <p>Without <code>--section</code>, the task is inserted before the first unchecked task in <code>TASKS.md</code>.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-3-pick-what-to-work-on","level":3,"title":"Step 3: Pick What to Work On","text":"<p>At the start of a session, or after finishing a task, use <code>/ctx-next</code> to get prioritized recommendations. </p> <p>The skill reads <code>TASKS.md</code>, checks recent sessions, and ranks candidates using  explicit priority, blocking status, in-progress state, momentum from  recent work, and phase order.</p> <p>You can also ask naturally: \"what should we work on?\" or \"what's the highest priority right now?\"</p> <pre><code>/ctx-next\n</code></pre> <p>The output looks like this:</p> <pre><code>**1. Implement ctx agent cooldown** `#priority:high`\n\n    Still in-progress from yesterday's session. The tombstone file approach is\n    half-built. Finishing is cheaper than context-switching.\n\n**2. Add --section flag to ctx add task** `#priority:medium`\n\n    Last Phase 1 item. Quick win that unblocks organized task entry.\n\n---\n\n*Based on 8 pending tasks across 3 phases.\n\nLast session: agent-cooldown (2026-02-06).*\n</code></pre> <p>In-progress tasks almost always come first: </p> <p>Finishing existing work takes priority over starting new work.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-4-complete-tasks","level":3,"title":"Step 4: Complete Tasks","text":"<p>When a task is done, mark it complete by number or partial text match:</p> <pre><code># By task number (as shown in TASKS.md)\nctx complete 3\n\n# By partial text match\nctx complete \"agent cooldown\"\n</code></pre> <p>The task's checkbox changes from <code>[ ]</code> to <code>[x]</code> and a <code>#done</code> timestamp is added. Tasks are never deleted: they stay in their phase section so history is preserved.</p> <p>Be Conversational</p> <p>You rarely need to run <code>ctx complete</code> yourself during an interactive session.</p> <p>When you say something like \"the rate limiter is done\" or \"we finished that,\" the agent marks the task complete and moves on to suggesting what is next.</p> <p>The CLI commands are most useful for manual housekeeping, scripted workflows, or when you want precision.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-5-snapshot-before-risky-changes","level":3,"title":"Step 5: Snapshot Before Risky Changes","text":"<p>Before a major refactor or any change that might break things, snapshot your current task state. This creates a copy of <code>TASKS.md</code> in <code>.context/archive/</code> without modifying the original.</p> <pre><code># Default snapshot\nctx tasks snapshot\n\n# Named snapshot (recommended before big changes)\nctx tasks snapshot \"before-refactor\"\n</code></pre> <p>This creates a file like <code>.context/archive/tasks-before-refactor-2026-02-08-1430.md</code>. If the refactor goes sideways, and you need to confirm what the task state looked like before you started, the snapshot is there.</p> <p>Snapshots are cheap: Take them before any change you might want to undo or review later.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-6-archive-when-tasksmd-gets-cluttered","level":3,"title":"Step 6: Archive When <code>TASKS.md</code> Gets Cluttered","text":"<p>After several sessions, <code>TASKS.md</code> accumulates completed tasks that make it hard to see what is still pending.</p> <p>Use <code>ctx tasks archive</code> to move all <code>[x]</code> items to a timestamped archive file.</p> <p>Start with a dry run to preview what will be moved:</p> <pre><code>ctx tasks archive --dry-run\n</code></pre> <p>Then archive:</p> <pre><code>ctx tasks archive\n</code></pre> <p>Completed tasks move to <code>.context/archive/tasks-2026-02-08.md</code>. Phase headers are preserved in the archive for traceability. Pending tasks (<code>[ ]</code>) remain in <code>TASKS.md</code>.</p> <p>The <code>/ctx-archive</code> skill adds two safety checks before archiving: it verifies that completed tasks are genuinely cluttering the view and that nothing was marked <code>[x]</code> prematurely.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#letting-the-agent-drive","level":2,"title":"Letting the Agent Drive","text":"<p>The steps above show the CLI commands for task management.</p> <p>In practice, most task management happens conversationally:</p> <p>An agent that has loaded the context files does not need you to type <code>ctx add task</code>. It tracks work naturally and offers the right operations.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#use-natural-language-instead-of-commands","level":3,"title":"Use Natural Language Instead of Commands","text":"<p>These conversational prompts replace explicit commands during interactive sessions:</p> Instead of typing... Just say... <code>ctx add task \"Write tests for X\"</code> \"We should add tests for this—track that?\" <code>/ctx-next</code> \"What should we work on?\" <code>ctx complete \"rate limiting\"</code> \"The rate limiter is done, what's next?\" <code>ctx tasks archive</code> \"<code>TASKS.md</code> is getting long, can you clean it up?\" <code>ctx add task ... &amp;&amp; ctx add task ...</code> \"Add follow-ups for what we just built.\" <p>The agent translates these into the right <code>ctx</code> operations behind the scenes.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#the-agent-creates-tasks-proactively","level":3,"title":"The Agent Creates Tasks Proactively","text":"<p>After completing a piece of work, the agent does not wait for you to dictate follow-up items. It identifies them from the work context and offers:</p> <pre><code>**Agent**: \"I've finished implementing the rate limiter middleware. I noticed\nthree follow-up items:\n\n1. Write integration tests for the rate limiter (the unit tests pass but\n   there's no end-to-end coverage)\n2. Add rate limit headers to API responses (X-RateLimit-Remaining, etc.)\n3. Document the rate limit configuration in the ops runbook\n\nWant me to add these as tasks?\"\n</code></pre> <p>This is how an agent behaves once it has read the Agent Playbook.</p> <p>The playbook's \"Work, Reflect, Persist\" cycle means the agent asks itself after every milestone: Did I just complete a task? Did new work emerge?</p> <p>When the answer is yes, it acts.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#asking-the-agent-what-to-capture","level":3,"title":"Asking the Agent What to Capture","text":"<p>You don't always know what's worth persisting.</p> <p>Instead of reviewing the session yourself and typing specific commands, ask the agent to do the thinking:</p> You say What happens \"What tasks came out of this session?\" Agent reviews the work, identifies follow-ups, and offers to add them \"Are there any tasks, learnings, or decisions worth adding?\" Agent scans the full session for all three types and proposes a batch \"What should we remember from today?\" Agent surfaces everything persist-worthy—not just tasks \"Anything we should track before we move on?\" Agent checks for loose ends specific to the work just completed <p>This is especially powerful after long or exploratory sessions where multiple threads were touched. </p> <p>The agent has the full conversation in context and can spot follow-ups you  might miss:</p> <pre><code>You:   \"Are there any tasks, learnings, or decisions worth adding\n        from this session?\"\n\nAgent: \"Yes—here's what I'd suggest:\n\n  Tasks:\n  - Add retry logic to the webhook delivery (we discussed it when\n    the timeout test failed but never tracked it)\n  - Update the API docs to reflect the new rate limit headers\n\n  Learnings:\n  - net/http's default client has no timeout—we burned 15 minutes\n    on that before adding an explicit 30s timeout\n\n  Decisions:\n  - We chose token-bucket over sliding-window for rate limiting\n    because it handles bursts better and the library is simpler\n\n  Want me to add all of these?\"\n\nYou:   \"All of them.\"\n</code></pre> <p>The agent fills in structured fields from what it observed during the session. You get the same quality entries as if you typed verbose commands, without needing to remember what happened or how to format it.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#the-agent-completes-tasks-and-moves-on","level":3,"title":"The Agent Completes Tasks and Moves On","text":"<p>When you confirm that work is finished, or when the agent can see that it is, it marks the task done and suggests the next step:</p> <pre><code>You: \n\"The cooldown logic is working now.\"\n\nAgent: \n\"Marked 'Implement ctx agent cooldown' as done. Your highest-\npriority remaining task is 'Add --section flag to ctx add task'.\n\nIt's the last item in Phase 1 and a quick win. Want to start on that?\"\n</code></pre> <p>The agent chains completion into next-task selection.</p> <p>One sentence from you triggers two operations.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#end-of-session-capture","level":3,"title":"End-of-Session Capture","text":"<p>At the end of a session, the agent reviews what happened and catches loose ends:</p> <pre><code>You: \n\"I think we're good for today.\"\n\nAgent: \n\"Before we wrap up: during the middleware work you mentioned\nwanting to add metrics for rate limit hits. That never made it into TASKS.md.\n\nWant me to add it as a task so it's there next session?\"\n</code></pre> <p>This is the proactive persistence model at work.</p> <p>The agent monitors the conversation for mentioned-but-not-tracked work and surfaces it before context is lost.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#a-conversational-session-example","level":3,"title":"A Conversational Session Example","text":"<p>Here is what task management looks like in a real session when the agent is driving:</p> <pre><code>You:   What's left to do?\nAgent: You have 5 pending tasks across 2 phases. The highest priority is\n       \"Implement ctx agent cooldown\"—it's marked in-progress from\n       yesterday and half-built. Want to pick that up?\n\nYou:   Yeah, let's finish it.\n       [... 20 minutes of implementation work ...]\n\nYou:   That's working. Tests pass.\nAgent: Nice. I'll mark \"Implement ctx agent cooldown\" as done.\n       I noticed two things from the implementation:\n       1. The tombstone file cleanup should happen on a timer, not just\n          at startup—want me to add that as a task?\n       2. We learned that file locks don't work reliably on NFS. I'll\n          add that to LEARNINGS.md.\n\nYou:   Yes to both. What's next?\nAgent: Added the cleanup task as high priority. Next up is \"Add --section\n       flag to ctx add task\"—last item in Phase 1. It should be\n       straightforward since the flag parsing pattern already exists\n       in the codebase. Ready?\n</code></pre> <p>It's All Conversational</p> <p>Notice what did not happen: The user never typed a <code>ctx</code> command.</p> <p>The agent handled task completion, follow-up creation, learning capture, and next-task selection—all from natural conversation.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"<pre><code># Add a task\nctx add task \"Implement rate limiting for API endpoints\" --priority high\n\n# Add to a specific phase\nctx add task \"Write integration tests for rate limiter\" --section \"Phase 2\"\n\n# See what to work on\n# (from AI assistant) /ctx-next\n\n# Mark done by text\nctx complete \"rate limiting\"\n\n# Mark done by number\nctx complete 5\n\n# Snapshot before a risky refactor\nctx tasks snapshot \"before-middleware-rewrite\"\n\n# Archive completed tasks when the list gets long\nctx tasks archive --dry-run     # preview first\nctx tasks archive               # then archive\n</code></pre>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#tips","level":2,"title":"Tips","text":"<ul> <li>Start tasks with a verb: \"Add,\" \"Fix,\" \"Implement,\" \"Investigate\":    not just a topic like \"Authentication.\"</li> <li>Include the why in the task description. Future sessions lack the context of   why you added the task. \"Add rate limiting\" is worse than \"Add rate limiting   to prevent abuse on the public API after the load test showed 10x traffic spikes.\"</li> <li>Use <code>#in-progress</code> sparingly. Only one or two tasks should carry this tag at   a time. If everything is in-progress, nothing is.</li> <li>Snapshot before, not after. The point of a snapshot is to capture the    state before a change, not to celebrate what you just finished.</li> <li>Archive regularly. Once completed tasks outnumber pending ones, it is time   to archive. A clean <code>TASKS.md</code> helps both you and your AI assistant focus.</li> <li>Never delete tasks. Mark them <code>[x]</code> (completed) or <code>[-]</code> (skipped with a   reason). Deletion breaks the audit trail.</li> <li>Trust the agent's task instincts. When the agent suggests follow-up items   after completing work, it is drawing on the full context of what just happened.</li> <li>Conversational prompts beat commands in interactive sessions. Saying   \"what should we work on?\" is faster and more natural than running <code>/ctx-next</code>.   Save explicit commands for scripts, CI, and unattended runs.</li> <li>Let the agent chain operations. A single statement like \"that's done, what's   next?\" can trigger completion, follow-up identification, and next-task   selection in one flow.</li> <li>Review proactive task suggestions before moving on. The best follow-ups come   from items spotted in-context right after the work completes.</li> </ul>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#next-up","level":2,"title":"Next Up","text":"<p>Using the Scratchpad →: Store short-lived sensitive notes in an encrypted scratchpad.</p>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#see-also","level":2,"title":"See Also","text":"<ul> <li>The Complete Session: full session lifecycle including   task management in context</li> <li>Persisting Decisions, Learnings, and Conventions:   capturing the \"why\" behind your work</li> <li>Detecting and Fixing Drift:   keeping <code>TASKS.md</code> accurate over time</li> <li>CLI Reference:   full documentation for <code>ctx add</code>, <code>ctx complete</code>, <code>ctx tasks</code></li> <li>Context Files: <code>TASKS.md</code>:    format and conventions for <code>TASKS.md</code></li> </ul>","path":["Recipes","Knowledge and Tasks","Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/webhook-notifications/","level":1,"title":"Webhook Notifications","text":"","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#the-problem","level":2,"title":"The Problem","text":"<p>Your agent runs autonomously (loops, implements, releases) while you are away from the terminal. You have no way to know when it finishes, hits a limit, or when a hook fires a nudge.</p> <p>How do you get notified about agent activity without watching the terminal?</p>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#tldr","level":2,"title":"TL;DR","text":"<pre><code>ctx notify setup  # configure webhook URL (encrypted)\nctx notify test   # verify delivery\n# Hooks auto-notify on: session-end, loop-iteration, resource-danger\n</code></pre>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx notify setup</code> CLI command Configure and encrypt webhook URL <code>ctx notify test</code> CLI command Send a test notification <code>ctx notify --event &lt;name&gt; \"msg\"</code> CLI command Send a notification from scripts/skills <code>.ctxrc</code> <code>notify.events</code> Configuration Filter which events reach your webhook","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#step-1-get-a-webhook-url","level":3,"title":"Step 1: Get a Webhook URL","text":"<p>Any service that accepts HTTP POST with JSON works. Common options:</p> Service How to get a URL IFTTT Create an applet with the \"Webhooks\" trigger Slack Create an Incoming Webhook Discord Channel Settings &gt; Integrations &gt; Webhooks ntfy.sh Use <code>https://ntfy.sh/your-topic</code> (no signup) Pushover Use API endpoint with your user key <p>The URL contains auth tokens. <code>ctx</code> encrypts it; it never appears in plaintext in your repo.</p>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#step-2-configure-the-webhook","level":3,"title":"Step 2: Configure the Webhook","text":"<pre><code>ctx notify setup\n# Enter webhook URL: https://maker.ifttt.com/trigger/ctx/json/with/key/YOUR_KEY\n# Webhook configured: https://maker.ifttt.com/***\n# Encrypted at: .context/.notify.enc\n</code></pre> <p>This encrypts the URL with AES-256-GCM using the same key as the scratchpad (<code>.context/.context.key</code>). The encrypted file (<code>.context/.notify.enc</code>) is safe to commit. The key is <code>.gitignore</code>d.</p>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#step-3-test-it","level":3,"title":"Step 3: Test It","text":"<pre><code>ctx notify test\n# Webhook responded: HTTP 200 OK\n</code></pre> <p>If you see <code>No webhook configured</code>, run <code>ctx notify setup</code> first.</p>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#step-4-configure-events","level":3,"title":"Step 4: Configure Events","text":"<p>Notifications are opt-in: no events are sent unless you configure an event list in <code>.ctxrc</code>:</p> <pre><code># .ctxrc\nnotify:\n  events:\n    - loop       # loop completion or max-iteration hit\n    - nudge      # VERBATIM relay hooks (context checkpoint, persistence, etc.)\n    - relay      # all hook output (verbose, for debugging)\n</code></pre> <p>Only listed events fire. Omitting an event silently drops it.</p>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#step-5-use-in-your-own-skills","level":3,"title":"Step 5: Use in Your Own Skills","text":"<p>Add <code>ctx notify</code> calls to any skill or script:</p> <pre><code># In a release skill\nctx notify --event release \"v1.2.0 released successfully\" 2&gt;/dev/null || true\n\n# In a backup script\nctx notify --event backup \"Nightly backup completed\" 2&gt;/dev/null || true\n</code></pre> <p>The <code>2&gt;/dev/null || true</code> suffix ensures the notification never breaks your script: If there's no webhook or the HTTP call fails, it's a silent noop.</p>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#event-types","level":2,"title":"Event Types","text":"<p><code>ctx</code> fires these events automatically:</p> Event Source When <code>loop</code> Loop script Loop completes or hits max iterations <code>nudge</code> System hooks VERBATIM relay nudge is emitted (context checkpoint, persistence, ceremonies, journal, resources, knowledge, version) <code>relay</code> System hooks Any hook output (VERBATIM relays, agent directives, block responses) <code>test</code> <code>ctx notify test</code> Manual test notification (custom) Your skills You wire <code>ctx notify --event &lt;name&gt;</code> in your own scripts <p><code>nudge</code> vs <code>relay</code>: The <code>nudge</code> event fires only for VERBATIM relay hooks (the ones the agent is instructed to show verbatim). The <code>relay</code> event fires for all hook output — VERBATIM relays, agent directives, and hard gates. Subscribe to <code>relay</code> for debugging (\"did the agent get the post-commit nudge?\"), <code>nudge</code> for user-facing assurance (\"was the checkpoint emitted?\").</p> <p>Webhooks as a Hook Audit Trail</p> <p>Subscribe to <code>relay</code> events and you get an external record of every hook that fires, independent of the agent. </p> <p>This lets you verify hooks are running and catch cases where the agent  absorbs a nudge instead of surfacing it. </p> <p>See Auditing System Hooks for the full workflow.</p>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#payload-format","level":2,"title":"Payload Format","text":"<p>Every notification sends a JSON POST:</p> <pre><code>{\n  \"event\": \"loop\",\n  \"message\": \"Loop completed after 5 iterations\",\n  \"session_id\": \"abc123-...\",\n  \"timestamp\": \"2026-02-22T14:30:00Z\",\n  \"project\": \"ctx\"\n}\n</code></pre>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#security-model","level":2,"title":"Security Model","text":"Component Location Committed? Permissions Encryption key <code>.context/.context.key</code> No (gitignored) <code>0600</code> Encrypted URL <code>.context/.notify.enc</code> Yes (safe) <code>0600</code> Webhook URL Never on disk in plaintext N/A N/A <p>The key is shared with the scratchpad. If you rotate the encryption key, re-run <code>ctx notify setup</code> to re-encrypt the webhook URL with the new key.</p>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#key-rotation","level":2,"title":"Key Rotation","text":"<p><code>ctx</code> checks the age of <code>.context/.context.key</code> once per day. If it's older than 90 days (configurable via <code>notify.key_rotation_days</code>), a VERBATIM nudge is emitted suggesting rotation.</p> <pre><code># .ctxrc\nnotify:\n  key_rotation_days: 30   # nudge sooner (default: 90)\n</code></pre>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#worktrees","level":2,"title":"Worktrees","text":"<p>The webhook URL is encrypted with the same encryption key (<code>.context/.context.key</code>), which is <code>.gitignore</code>d. In a git worktree, the key is absent: Notifications silently do nothing.</p> <p>This means agents running in worktrees cannot send webhook alerts. For autonomous runs where worktree agents are opaque, monitor them from the terminal rather than relying on webhooks. Enrich journals and review results on the main branch after merging.</p>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#tips","level":2,"title":"Tips","text":"<ul> <li>Fire-and-forget: Notifications never block. HTTP errors are silently   ignored. No retry, no response parsing.</li> <li>No webhook = no cost: When no webhook is configured, <code>ctx notify</code> exits   immediately. System hooks that call <code>notify.Send()</code> add zero overhead.</li> <li>Multiple projects: Each project has its own <code>.notify.enc</code>. You can point   different projects at different webhooks.</li> <li>Event filter is per-project: Configure <code>notify.events</code> in each project's   <code>.ctxrc</code> independently.</li> </ul>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#next-up","level":2,"title":"Next Up","text":"<p>Auditing System Hooks →: Verify your hooks are running, audit what they do, and get alerted when they go silent.</p>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/webhook-notifications/#see-also","level":2,"title":"See Also","text":"<ul> <li>CLI Reference: ctx notify:   full command reference</li> <li>Configuration: <code>.ctxrc</code> settings including   <code>notify</code> options</li> <li>Running an Unattended AI Agent: how loops work   and how notifications fit in</li> <li>Hook Output Patterns: understanding VERBATIM   relays, agent directives, and hard gates</li> <li>Auditing System Hooks: using webhooks as an   external audit trail for hook execution</li> </ul>","path":["Recipes","Hooks and Notifications","Webhook Notifications"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/","level":1,"title":"When to Use a Team of Agents","text":"","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#the-problem","level":2,"title":"The Problem","text":"<p>You have a task, and you are wondering: \"should I throw more agents at it?\"</p> <p>More agents can mean faster results, but they also mean coordination overhead, merge conflicts, divergent mental models, and wasted tokens re-reading context. </p> <p>The wrong setup costs more than it saves.</p> <p>This recipe is a decision framework: It helps you choose between a single agent, parallel worktrees, and a full agent team, and explains what <code>ctx</code> provides at each level.</p>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#tldr","level":2,"title":"TL;DR","text":"<ul> <li>Single agent for most work;</li> <li>Parallel worktrees when tasks touch disjoint file sets;</li> <li>Agent teams only when tasks need real-time   coordination. When in doubt, start with one agent.</li> </ul>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#the-spectrum","level":2,"title":"The Spectrum","text":"<p>There are three modes, ordered by complexity:</p>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#1-single-agent-default","level":3,"title":"1. Single Agent (Default)","text":"<p>One agent, one session, one branch. This is correct for most work.</p> <p>Use this when:</p> <ul> <li>The task has linear dependencies (step 2 needs step 1's output);</li> <li>Changes touch overlapping files;</li> <li>You need tight feedback loops (review each change before the next);</li> <li>The task requires deep understanding of a single area;</li> <li>Total effort is less than a few hours of agent time.</li> </ul> <p><code>ctx</code> provides: Full <code>.context/</code>: tasks, decisions, learnings, conventions, all in one session. </p> <p>The agent builds a coherent mental model and persists it as it goes.</p> <p>Example tasks: Bug fixes, feature implementation, refactoring a module, writing documentation for one area, debugging.</p>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#2-parallel-worktrees-independent-tracks","level":3,"title":"2. Parallel Worktrees (Independent Tracks)","text":"<p>2-4 agents, each in a separate git worktree on its own branch, working on non-overlapping parts of the codebase.</p> <p>Use this when:</p> <ul> <li>You have 5+ independent tasks in the backlog;</li> <li>Tasks group cleanly by directory or package;</li> <li>File overlap between groups is zero or near-zero;</li> <li>Each track can be completed and merged independently;</li> <li>You want parallelism without coordination complexity.</li> </ul> <p><code>ctx</code> provides: Shared <code>.context/</code> via <code>git</code> (each worktree sees the same tasks, decisions, conventions). <code>/ctx-worktree</code> skill for setup and teardown. <code>TASKS.md</code> as a lightweight work queue.</p> <p>Example tasks: Docs + new package + test coverage (three tracks that don't touch the same files). Parallel recipe writing. Independent module development.</p> <p>See: Parallel Agent Development with Git Worktrees</p>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#3-agent-team-coordinated-swarm","level":3,"title":"3. Agent Team (Coordinated Swarm)","text":"<p>Multiple agents communicating via messages, sharing a task list, with a lead agent coordinating. Claude Code's team/swarm feature.</p> <p>Use this when:</p> <ul> <li>Tasks have dependencies but can still partially overlap;</li> <li>You need research and implementation happening simultaneously;</li> <li>The work requires different roles (researcher, implementer, tester);</li> <li>A lead agent needs to review and integrate others' work;</li> <li>The task is large enough that coordination cost is justified.</li> </ul> <p><code>ctx</code> provides: <code>.context/</code> as shared state that all agents can read. Task tracking for work assignment. Decisions and learnings as team memory that survives individual agent turnover.</p> <p>Example tasks: Large refactor across modules where a lead reviews merges. Research and implementation where one agent explores options while another builds. Multi-file feature that needs integration testing after parallel implementation.</p>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#the-decision-framework","level":2,"title":"The Decision Framework","text":"<p>Ask these questions in order:</p> <pre><code>Can one agent do this in a reasonable time?\n  YES → Single agent. Stop here.\n  NO  ↓\n\nCan the work be split into non-overlapping file sets?\n  YES → Parallel worktrees (2-4 tracks)\n  NO  ↓\n\nDo the subtasks need to communicate during execution?\n  YES → Agent team with lead coordination\n  NO  → Parallel worktrees with a merge step\n</code></pre>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#the-file-overlap-test","level":3,"title":"The File Overlap Test","text":"<p>This is the critical decision point. Before choosing multi-agent, list the files each subtask would touch. If two subtasks modify the same file, they belong in the same track (or the same single-agent session).</p> <pre><code>You: \"I want to parallelize these tasks. Which files would each one touch?\"\n\nAgent: [reads `TASKS.md`, analyzes codebase]\n       \"Task A touches internal/config/ and internal/cli/initialize/\n        Task B touches docs/ and site/\n        Task C touches internal/config/ and internal/cli/status/\n\n        Tasks A and C overlap on internal/config/ — they should be\n        in the same track. Task B is independent.\"\n</code></pre> <p>When in doubt, keep things in one track. A merge conflict in a critical file costs more time than the parallelism saves.</p>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#when-teams-make-things-worse","level":2,"title":"When Teams Make Things Worse","text":"<p>\"More agents\" is not always better. Watch for these patterns:</p> <p>Merge hell: If you are spending more time resolving conflicts than the parallel work saved, you split wrong: Re-group by file overlap.</p> <p>Context divergence: Each agent builds its own mental model. After 30 minutes of independent work, agent A might make assumptions that contradict agent B's approach. Shorter tracks with frequent merges reduce this.</p> <p>Coordination theater: A lead agent spending most of its time assigning tasks, checking status, and sending messages instead of doing work. If the task list is clear enough, worktrees with no communication are cheaper.</p> <p>Re-reading overhead: Every agent reads <code>.context/</code> on startup. A team of 4 agents each reading 4000 tokens of context = 16000 tokens before anyone does any work. For small tasks, that overhead dominates.</p>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#what-ctx-gives-you-at-each-level","level":2,"title":"What ctx Gives You at Each Level","text":"ctx Feature Single Agent Worktrees Team <code>.context/</code> files Full access Shared via git Shared via filesystem <code>TASKS.md</code> Work queue Split by track Assigned by lead Decisions/Learnings Persisted in session Persisted per branch Persisted by any agent <code>/ctx-next</code> Picks next task Picks within track Lead assigns <code>/ctx-worktree</code> N/A Setup + teardown Optional <code>/ctx-commit</code> Normal commits Per-branch commits Per-agent commits","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#tips","level":2,"title":"Tips","text":"<ul> <li>Start with one agent: Only add parallelism when you have identified   the bottleneck. \"This would go faster with more agents\" is usually   wrong for tasks under 2 hours.</li> <li>The 3-4 agent ceiling is real: Coordination overhead grows   quadratically. 2 agents = 1 communication pair. 4 agents = 6 pairs.   Beyond 4, you are managing agents more than doing work.</li> <li>Worktrees &gt; teams for most parallelism needs: If agents don't   need to talk to each other during execution, worktrees give you   parallelism with zero coordination overhead.</li> <li>Use <code>ctx</code> as the shared brain: Whether it's one agent or four, the   <code>.context/</code> directory is the single source of truth. Decisions go in   <code>DECISIONS.md</code>, not in chat messages between agents.</li> <li>Merge early, merge often: Long-lived parallel branches diverge.   Merge a track as soon as it's done rather than waiting for all tracks   to finish.</li> <li><code>TASKS.md</code> conflicts are normal: Multiple agents completing different   tasks will conflict on merge. The resolution is always additive: accept   all <code>[x]</code> completions from both sides.</li> </ul>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#next-up","level":2,"title":"Next Up","text":"<p>Parallel Agent Development with Git Worktrees →: Run multiple agents on independent task tracks using git worktrees.</p>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#go-deeper","level":2,"title":"Go Deeper","text":"<ul> <li>CLI Reference — all commands and flags</li> <li>Integrations — setup for Claude Code, Cursor, Aider</li> <li>Session Journal — browse and search session history</li> </ul>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"recipes/when-to-use-agent-teams/#see-also","level":2,"title":"See Also","text":"<ul> <li>Parallel Agent Development with Git Worktrees:   the mechanical \"how\" for worktree-based parallelism</li> <li>Running an Unattended AI Agent: serial autonomous   loops — a different scaling strategy</li> <li>Tracking Work Across Sessions: managing the task   backlog that feeds into any multi-agent setup</li> </ul>","path":["Recipes","Agents and Automation","When to Use a Team of Agents"],"tags":[]},{"location":"reference/","level":1,"title":"Reference","text":"<p>Technical reference for <code>ctx</code> commands, skills, and internals.</p>","path":["Reference"],"tags":[]},{"location":"reference/#cli","level":3,"title":"CLI","text":"<p>Every command, subcommand, and flag. Now a top-level section — see CLI Reference.</p>","path":["Reference"],"tags":[]},{"location":"reference/#skills","level":3,"title":"Skills","text":"<p>The full skill catalog: what each skill does, when it triggers, and how skills interact with commands.</p>","path":["Reference"],"tags":[]},{"location":"reference/#tool-ecosystem","level":3,"title":"Tool Ecosystem","text":"<p>How <code>ctx</code> compares to Cursor Rules, Aider conventions, CLAUDE.md, and other context approaches.</p>","path":["Reference"],"tags":[]},{"location":"reference/#session-journal","level":3,"title":"Session Journal","text":"<p>Export, browse, and enrich your session history. Covers the journal site, Obsidian export, and the enrichment pipeline.</p>","path":["Reference"],"tags":[]},{"location":"reference/#scratchpad","level":3,"title":"Scratchpad","text":"<p>Encrypted, git-tracked scratch space for short notes and sensitive values that travel with the project.</p>","path":["Reference"],"tags":[]},{"location":"reference/#version-history","level":3,"title":"Version History","text":"<p>Changelog for every <code>ctx</code> release.</p>","path":["Reference"],"tags":[]},{"location":"reference/comparison/","level":1,"title":"Tool Ecosystem","text":"","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/comparison/#high-level-mental-model","level":2,"title":"High-Level Mental Model","text":"<p>Many tools help AI think.</p> <p><code>ctx</code> helps AI remember.</p> <ul> <li>Not by storing thoughts,</li> <li>but by preserving intent.</li> </ul>","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/comparison/#how-ctx-differs-from-similar-tools","level":2,"title":"How <code>ctx</code> Differs from Similar Tools","text":"<p>There are many tools in the AI ecosystem that touch parts of the context problem:</p> <ul> <li>Some manage prompts.  </li> <li>Some retrieve data.  </li> <li>Some provide runtime context objects.  </li> <li>Some offer enterprise platforms.</li> </ul> <p><code>ctx</code> focuses on a different layer entirely.</p> <p>This page explains where <code>ctx</code> fits, and where it intentionally does not.</p>","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/comparison/#the-core-distinction","level":2,"title":"The Core Distinction","text":"<p>Most tools treat context as input.</p> <p><code>ctx</code> treats context as infrastructure.</p> <p>That single difference explains nearly all of <code>ctx</code>'s design choices.</p> Question Most tools ctx Where does context live? In prompts or APIs In files How long does it last? One request / one session Across time Who can read it? The model Humans and tools How is it updated? Implicitly Explicitly Is it inspectable? Rarely Always","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/comparison/#prompt-management-tools","level":2,"title":"Prompt Management Tools","text":"<p>Examples include:</p> <ul> <li>prompt templates;</li> <li>reusable system prompts;</li> <li>prompt libraries;</li> <li>prompt versioning tools.</li> </ul> <p>These tools help you start a session.</p> <p>They do not help you continue one.</p> <p>Prompt tools:</p> <ul> <li>inject text at session start;</li> <li>are ephemeral by design;</li> <li>do not evolve with the project.</li> </ul> <p><code>ctx</code>:</p> <ul> <li>persists knowledge over time;</li> <li>accumulates decisions and learnings;</li> <li>makes the context part of the repository itself.</li> </ul> <p>Prompt tooling and <code>ctx</code> are complementary; not competing.  Yet, they operate in different layers.</p>","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/comparison/#retrieval-augmented-generation-rag","level":2,"title":"Retrieval-Augmented Generation (RAG)","text":"<p>RAG systems typically:</p> <ul> <li>index documents</li> <li>embed text</li> <li>retrieve chunks dynamically at runtime</li> </ul> <p>They are excellent for:</p> <ul> <li>large knowledge bases</li> <li>static documentation</li> <li>reference material</li> </ul> <p>RAG answers questions like:</p> <p>\"What information might be relevant right now?\"</p> <p><code>ctx</code> answers a different question:</p> <p>\"What have we already decided, learned, or committed to?\"</p> <p>Here are some key differences:</p> RAG ctx Statistical relevance Intentional relevance Embedding-based File-based Opaque retrieval Explicit structure Runtime query Persistent memory <p><code>ctx</code> does not replace RAG. Instead, it defines a persistent context layer that RAG can optionally augment.</p> <p>RAG belongs to the data plane; ctx defines the context control plane.</p> <p>It focuses on project memory, not knowledge search.</p>","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/comparison/#agent-frameworks","level":2,"title":"Agent Frameworks","text":"<p>Agent frameworks often provide:</p> <ul> <li>task loops</li> <li>tool orchestration</li> <li>planner/executor patterns</li> <li>autonomous iteration</li> </ul> <p>These systems are powerful, but they typically assume that:</p> <ul> <li>memory is external</li> <li>context is injected</li> <li>state is transient</li> </ul> <p>Agent frameworks answer:</p> <p>\"How should the agent act?\"</p> <p><code>ctx</code> answers:</p> <p>\"What should the agent remember?\"</p> <p>Without persistent context, agents tend to:</p> <ul> <li>rediscover decisions</li> <li>repeat mistakes</li> <li>lose architectural intent</li> </ul> <p>This is why <code>ctx</code> pairs well with autonomous loop workflows:</p> <ul> <li>The loop provides iteration</li> <li><code>ctx</code> provides continuity</li> </ul> <p>Together, loops become cumulative instead of forgetful.</p>","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/comparison/#sdk-level-context-objects","level":2,"title":"SDK-Level Context Objects","text":"<p>Some SDKs expose \"context\" objects that exist:</p> <ul> <li>inside a process</li> <li>during a request</li> <li>for the lifetime of a call chain</li> </ul> <p>These are extremely useful and completely different.</p> <p>SDK context objects:</p> <ul> <li>are in-memory</li> <li>disappear when the process ends</li> <li>are not shared across sessions</li> </ul> <p><code>ctx</code>:</p> <ul> <li>survives process restarts</li> <li>survives new chats</li> <li>survives new days</li> </ul> <p>They share a name, not a purpose.</p>","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/comparison/#enterprise-context-platforms","level":2,"title":"Enterprise Context Platforms","text":"<p>Enterprise platforms often provide:</p> <ul> <li>centralized context services</li> <li>dashboards</li> <li>access control</li> <li>organizational knowledge layers</li> </ul> <p>These tools are designed for:</p> <ul> <li>teams</li> <li>governance</li> <li>compliance</li> <li>managed environments</li> </ul> <p><code>ctx</code> is intentionally:</p> <ul> <li>local-first</li> <li>file-based</li> <li>dependency-free</li> <li>CLI-driven</li> <li>developer-controlled</li> </ul> <p>It does not require:</p> <ul> <li>a server</li> <li>a database</li> <li>an account</li> <li>a SaaS backend</li> </ul> <p><code>ctx</code> optimizes for individual and small-team workflows where context should live next to code; not behind a service boundary.</p>","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/comparison/#when-ctx-is-a-good-fit","level":2,"title":"When <code>ctx</code> Is a Good Fit","text":"<p><code>ctx</code> works best when:</p> <ul> <li>you want AI work to compound over time;</li> <li>architectural decisions matter;</li> <li>context must be inspectable;</li> <li>humans and AI must share the same source of truth;</li> <li>Git history should include why, not just what.</li> </ul>","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/comparison/#when-ctx-is-not-the-right-tool","level":2,"title":"When <code>ctx</code> Is Not the Right Tool","text":"<p><code>ctx</code> is probably not what you want if:</p> <ul> <li>you only need one-off prompts;</li> <li>you rely exclusively on RAG;</li> <li>you want autonomous agents without a human-readable state;</li> <li>you require centralized enterprise control;</li> <li>you want black-box memory systems,</li> </ul> <p>These are valid goals; just different ones.</p>","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/comparison/#further-reading","level":2,"title":"Further Reading","text":"<ul> <li>You Can't Import Expertise — Why project-specific context matters more than generic best practices</li> </ul>","path":["Reference","Tool Ecosystem"],"tags":[]},{"location":"reference/scratchpad/","level":1,"title":"Scratchpad","text":"","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#what-is-ctx-scratchpad","level":2,"title":"What Is <code>ctx</code> Scratchpad?","text":"<p>A one-liner scratchpad, encrypted at rest, synced via <code>git</code>.</p> <p>Quick notes that don't fit decisions, learnings, or tasks: reminders, intermediate values, sensitive tokens, working memory during debugging. Entries are numbered, reorderable, and persist across sessions.</p>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#encrypted-by-default","level":2,"title":"Encrypted by Default","text":"<p>Scratchpad entries are encrypted with <code>AES-256-GCM</code> before touching the disk.</p> Component Path Git status Encryption key <code>.context/.context.key</code> Gitignored, <code>0600</code> permissions Encrypted data <code>.context/scratchpad.enc</code> Committed <p>The key is generated automatically during <code>ctx init</code> (256-bit via <code>crypto/rand</code>). The ciphertext format is <code>[12-byte nonce][ciphertext+tag]</code>. No external dependencies: Go stdlib only.</p> <p>Because the key is <code>.gitignore</code>d and the data is committed, you get:</p> <ul> <li>At-rest encryption: the <code>.enc</code> file is opaque without the key</li> <li>Git sync: push/pull the encrypted file like any other tracked file</li> <li>Key separation: the key never leaves the machine unless you copy it</li> </ul>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#commands","level":2,"title":"Commands","text":"Command Purpose <code>ctx pad</code> List all entries (numbered 1-based) <code>ctx pad show N</code> Output raw text of entry N (no prefix, pipe-friendly) <code>ctx pad add \"text\"</code> Append a new entry <code>ctx pad rm N</code> Remove entry at position N <code>ctx pad edit N \"text\"</code> Replace entry N with new text <code>ctx pad edit N --append \"text\"</code> Append text to the end of entry N <code>ctx pad edit N --prepend \"text\"</code> Prepend text to the beginning of entry N <code>ctx pad add TEXT --file PATH</code> Ingest a file as a blob entry (TEXT is the label) <code>ctx pad show N --out PATH</code> Write decoded blob content to a file <code>ctx pad mv N M</code> Move entry from position N to position M <code>ctx pad resolve</code> Show both sides of a merge conflict for resolution <code>ctx pad import FILE</code> Bulk-import lines from a file (or stdin with <code>-</code>) <code>ctx pad export [DIR]</code> Export all blob entries to a directory as files <code>ctx pad merge FILE...</code> Merge entries from other scratchpad files into current <p>All commands decrypt on read, operate on plaintext in memory, and re-encrypt on write. The key file is never printed to stdout.</p>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#examples","level":3,"title":"Examples","text":"<pre><code># Add a note\nctx pad add \"check DNS propagation after deploy\"\n\n# List everything\nctx pad\n#   1. check DNS propagation after deploy\n#   2. staging API key: sk-test-abc123\n\n# Show raw text (for piping)\nctx pad show 2\n# sk-test-abc123\n\n# Compose entries\nctx pad edit 1 --append \"$(ctx pad show 2)\"\n\n# Reorder\nctx pad mv 2 1\n\n# Clean up\nctx pad rm 2\n</code></pre>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#bulk-import-and-export","level":2,"title":"Bulk Import and Export","text":"<p>Import lines from a file in bulk — each non-empty line becomes an entry:</p> <pre><code># Import from a file\nctx pad import notes.txt\n\n# Import from stdin\ngrep TODO *.go | ctx pad import -\n</code></pre> <p>Export all blob entries to a directory as files:</p> <pre><code># Export to a directory\nctx pad export ./ideas\n\n# Preview without writing\nctx pad export --dry-run\n\n# Overwrite existing files\nctx pad export --force ./backup\n</code></pre>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#merging-scratchpads","level":2,"title":"Merging Scratchpads","text":"<p>Combine entries from other scratchpad files into your current pad. Useful when merging work from parallel worktrees, other machines, or teammates:</p> <pre><code># Merge from a worktree's encrypted scratchpad\nctx pad merge worktree/.context/scratchpad.enc\n\n# Merge from multiple sources (encrypted and plaintext)\nctx pad merge pad-a.enc notes.md\n\n# Merge a foreign encrypted pad using its key\nctx pad merge --key /other/.context.key foreign.enc\n\n# Preview without writing\nctx pad merge --dry-run pad-a.enc pad-b.md\n</code></pre> <p>Each input file is auto-detected as encrypted or plaintext — decryption is attempted first, and on failure the file is parsed as plain text. Entries are deduplicated by exact content, so running merge twice with the same file is safe.</p>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#file-blobs","level":2,"title":"File Blobs","text":"<p>The scratchpad can store small files (up to 64 KB) as blob entries. Files are base64-encoded and stored with a human-readable label.</p> <pre><code># Ingest a file — first argument is the label\nctx pad add \"deploy config\" --file ./deploy.yaml\n\n# Listing shows label with a [BLOB] marker\nctx pad\n#   1. check DNS propagation after deploy\n#   2. deploy config [BLOB]\n\n# Extract to a file\nctx pad show 2 --out ./recovered.yaml\n\n# Or print decoded content to stdout\nctx pad show 2\n</code></pre> <p>Blob entries are encrypted identically to text entries. The internal format is <code>label:::base64data</code>: You never need to construct this manually.</p> Constraint Value Max file size (pre-encoding) 64 KB Storage format <code>label:::base64(content)</code> Display <code>label [BLOB]</code> in listings <p>When Should You Use Blobs</p> <p>Blobs are for small files you want encrypted and portable: config snippets, key fragments, deployment manifests, test fixtures. For anything larger than 64 KB, use the filesystem directly.</p>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#using-with-ai","level":2,"title":"Using with AI","text":"<p>Use Natural Language</p> <p>As in many <code>ctx</code> features, the <code>ctx</code> scratchpad can also be used with natural langauge. You don't have to memorize the CLI commands.</p> <p>CLI gives you \"precision\", whereas natural language gives you flow.</p> <p>The <code>/ctx-pad</code> skill maps natural language to <code>ctx pad</code> commands. You don't need to remember the syntax:</p> You say What happens \"jot down: check DNS after deploy\" <code>ctx pad add \"check DNS after deploy\"</code> \"show my scratchpad\" <code>ctx pad</code> \"delete the third entry\" <code>ctx pad rm 3</code> \"update entry 2 to include the new endpoint\" <code>ctx pad edit 2 \"...\"</code> \"move entry 4 to the top\" <code>ctx pad mv 4 1</code> \"import my notes from notes.txt\" <code>ctx pad import notes.txt</code> \"export all blobs to ./backup\" <code>ctx pad export ./backup</code> \"merge the scratchpad from the worktree\" <code>ctx pad merge worktree/.context/scratchpad.enc</code> <p>The skill handles the translation. You describe what you want in plain English; the agent picks the right command.</p>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#worktrees","level":2,"title":"Worktrees","text":"<p>The encryption key (<code>.context/.context.key</code>) is gitignored. It only exists in the main checkout. In a git worktree, <code>ctx pad</code> commands fail gracefully — no key is found, no crash, but the pad is inaccessible.</p> <p>Use the scratchpad from the main checkout only. This is by design: the key never leaves the machine where it was generated, and worktrees are ephemeral working copies.</p>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#key-distribution","level":2,"title":"Key Distribution","text":"<p>The encryption key (<code>.context/.context.key</code>) stays on the machine where it was generated. <code>ctx</code> never transmits it.</p> <p>To share the scratchpad across machines:</p> <ol> <li>Copy the key manually: <code>scp</code>, USB drive, password manager.</li> <li>Push/pull the <code>.enc</code> file via git as usual.</li> <li>Both machines can now read and write the same scratchpad.</li> </ol> <p>Never Commit the Key</p> <p>The key is <code>.gitignore</code>d by default. If you override this, anyone with repo access can decrypt your scratchpad. </p> <p>Treat the key like an SSH private key.</p> <p>See the Syncing Scratchpad Notes Across Machines recipe for a step-by-step walkthrough.</p>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#plaintext-override","level":2,"title":"Plaintext Override","text":"<p>For projects where encryption is unnecessary, disable it in <code>.ctxrc</code>:</p> <pre><code>scratchpad_encrypt: false\n</code></pre> <p>In plaintext mode:</p> <ul> <li>Entries are stored in <code>.context/scratchpad.md</code> instead of <code>.enc</code>.</li> <li>No key is generated or required.</li> <li>All <code>ctx pad</code> commands work identically.</li> <li>The file is human-readable and diffable.</li> </ul> <p>When Should You Use Plaintext</p> <p>Plaintext mode is useful for non-sensitive projects, solo work where encryption adds friction, or when you want scratchpad entries visible in <code>git diff</code>.</p>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#when-should-you-use-scratchpad-versus-context-files","level":2,"title":"When Should You Use Scratchpad versus Context Files","text":"Use case Where it goes Temporary reminders (\"check X after deploy\") Scratchpad Working values during debugging Scratchpad Sensitive tokens or API keys (short-term) Scratchpad Quick notes that don't fit anywhere else Scratchpad Items that are not directly relevant to the project Scratchpad Things that you want to keep near, but also hidden Scratchpad Work items with completion tracking <code>TASKS.md</code> Trade-offs with rationale <code>DECISIONS.md</code> Reusable lessons with context/lesson/application <code>LEARNINGS.md</code> Codified patterns and standards <code>CONVENTIONS.md</code> <p>Rule of thumb: </p> <ul> <li>If it needs structure or will be referenced months later, use   a context file (i.e. <code>DECISIONS.md</code>, <code>LEARNINGS.md</code>, <code>TASKS.md</code>). </li> <li>If it is working memory for the current session or week, use    the scratchpad.</li> </ul>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/scratchpad/#see-also","level":2,"title":"See Also","text":"<ul> <li>Syncing Scratchpad Notes Across Machines:   Key distribution, push/pull workflow, merge conflict resolution</li> <li>Using the Scratchpad:   Natural language examples, blob workflow, when to use scratchpad vs context files</li> <li>Context Files: Format and conventions for all   <code>.context/</code> files</li> <li>Security: Trust model and permission hygiene</li> </ul>","path":["Reference","Scratchpad"],"tags":[]},{"location":"reference/session-journal/","level":1,"title":"Session Journal","text":"<p>Important Security Note</p> <p>Session journals contain sensitive data such as file contents, commands, API keys, internal discussions,  error messages with stack traces, and more. </p> <p>The <code>.context/journal-site/</code> and <code>.context/journal-obsidian/</code> directories MUST be <code>.gitignore</code>d.</p> <ul> <li>DO NOT host your journal publicly.</li> <li>DO NOT commit your journal files to version control.</li> </ul>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#browse-your-session-history","level":2,"title":"Browse Your Session History","text":"<p><code>ctx</code>'s Session Journal turns your AI coding sessions into a browsable,  searchable, and editable archive.</p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#quick-start","level":2,"title":"Quick Start","text":"<p>After using <code>ctx</code> for a couple of sessions, you can generate a  journal site with:</p> <pre><code># Export all sessions to markdown\nctx recall export --all\n\n# Generate and serve the journal site\nctx journal site --serve\n</code></pre> <p>Then open http://localhost:8000 to browse your sessions.</p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#what-you-get","level":2,"title":"What You Get","text":"<p>The Session Journal gives you:</p> <ul> <li>Browsable history: Navigate through all your AI sessions by date</li> <li>Full conversations: See every message, tool use, and result</li> <li>Token usage: Track how many tokens each session consumed</li> <li>Search: Find sessions by content, project, or date</li> <li>Dark mode: Easy on the eyes for late-night archaeology</li> </ul> <p>Each session page includes the following sections:</p> Section Content Metadata Date, time, duration, model, project, git branch Summary Space for your notes (editable) Tool Usage Which tools were used and how often Conversation Full transcript with timestamps","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#1-export-sessions","level":3,"title":"1. Export Sessions","text":"<pre><code># Export all sessions from current project (only new files)\nctx recall export --all\n\n# Export sessions from all projects\nctx recall export --all --all-projects\n\n# Export a specific session by ID (always writes)\nctx recall export abc123\n\n# Preview what would be exported\nctx recall export --all --dry-run\n\n# Re-export existing (regenerates conversation, preserves YAML frontmatter)\nctx recall export --all --regenerate\n\n# Discard frontmatter during regeneration\nctx recall export --all --regenerate --keep-frontmatter=false -y\n</code></pre> <p>Exported sessions go to <code>.context/journal/</code> as editable Markdown files.</p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#2-generate-the-site","level":3,"title":"2. Generate the Site","text":"<pre><code># Generate site structure\nctx journal site\n\n# Generate and build static HTML\nctx journal site --build\n\n# Generate and serve locally\nctx journal site --serve\n\n# Custom output directory\nctx journal site --output ~/my-journal\n</code></pre> <p>The site is generated in <code>.context/journal-site/</code> by default.</p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#3-browse-and-search","level":3,"title":"3. Browse and Search","text":"<p>Open http://localhost:8000 after running <code>--serve</code>.</p> <ul> <li>Use the sidebar to navigate by date</li> <li>Use search (<code>/</code> key) to find specific content</li> <li>Click any session to see the full conversation</li> </ul>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#editing-sessions","level":2,"title":"Editing Sessions","text":"<p>Exported sessions are plain Markdown in <code>.context/journal/</code>. You can:</p> <ul> <li>Add summaries: Fill in the <code>## Summary</code> section</li> <li>Add notes: Insert your own commentary anywhere</li> <li>Highlight key moments: Use Markdown formatting</li> <li>Delete noise: Remove irrelevant tool outputs</li> </ul> <p>After editing, regenerate the site:</p> <pre><code>ctx journal site --serve\n</code></pre> Safe by Default <p>Running <code>ctx recall export --all</code> only exports new sessions. Existing files are skipped entirely — your edits and enrichments are never touched.</p> <p>Use <code>--regenerate</code> to re-export existing files. Conversation content is regenerated, but YAML frontmatter (topics, type, outcome, etc.) is preserved. You'll be prompted before any existing files are overwritten; add <code>-y</code> to skip the prompt.</p> <p>Use <code>--keep-frontmatter=false</code> to discard enriched frontmatter during regeneration.</p> <p>Locked entries (via <code>ctx recall lock</code>) are always skipped, regardless of flags. If you prefer to add <code>locked: true</code> to frontmatter during enrichment, run <code>ctx recall sync</code> to propagate the lock state to <code>.state.json</code>.</p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#large-sessions","level":2,"title":"Large Sessions","text":"<p>Sessions with many messages (200+) are automatically split into multiple parts  for better browser performance. Navigation links connect the parts:</p> <pre><code>session-abc123.md      (Part 1 of 3)\nsession-abc123-p2.md   (Part 2 of 3)\nsession-abc123-p3.md   (Part 3 of 3)\n</code></pre>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#suggestion-sessions","level":2,"title":"Suggestion Sessions","text":"<p>Claude Code generates \"suggestion\" sessions for auto-complete prompts. These are separated in the index under a \"Suggestions\" section to keep your main  session list focused.</p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#enriching-journal-entries","level":2,"title":"Enriching Journal Entries","text":"<p>Raw exported sessions contain basic metadata (date, time, project) but lack the structured information needed for effective search, filtering, and analysis. Journal enrichment adds semantic metadata that transforms a flat archive into a searchable knowledge base.</p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#why-enrich","level":3,"title":"Why Enrich?","text":"<p>Without enrichment, you have timestamps and raw conversations. With enrichment:</p> <ul> <li>Find sessions by topic: \"Show me all auth-related sessions\"</li> <li>Filter by outcome: \"What did I abandon vs complete?\"</li> <li>Track technology usage: \"When did I last work with PostgreSQL?\"</li> <li>Identify key files: Jump directly to the files discussed</li> <li>Get summaries: Understand what happened without reading transcripts</li> </ul>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#the-frontmatter-schema","level":3,"title":"The Frontmatter Schema","text":"<p>Enriched entries begin with YAML frontmatter:</p> <pre><code>---\ntitle: \"Implement caching layer\"\ndate: 2026-01-27\ntype: feature\noutcome: completed\ntopics:\n  - caching\n  - performance\ntechnologies:\n  - go\n  - redis\nlibraries:\n  - go-redis/redis\nkey_files:\n  - internal/cache/redis.go\n  - internal/cache/memory.go\n---\n</code></pre> Field Required Description <code>title</code> Yes Descriptive title (not the session slug) <code>date</code> Yes Session date (YYYY-MM-DD) <code>type</code> Yes Session type (see below) <code>outcome</code> Yes How the session ended (see below) <code>topics</code> No Subject areas discussed <code>technologies</code> No Languages, databases, frameworks <code>libraries</code> No Specific packages or libraries used <code>key_files</code> No Important files created or modified <p>Type values:</p> Type When to use <code>feature</code> Building new functionality <code>bugfix</code> Fixing broken behavior <code>refactor</code> Restructuring without behavior change <code>exploration</code> Research, learning, experimentation <code>debugging</code> Investigating issues <code>documentation</code> Writing docs, comments, README <p>Outcome values:</p> Outcome Meaning <code>completed</code> Goal achieved <code>partial</code> Some progress, work continues <code>abandoned</code> Stopped pursuing this approach <code>blocked</code> Waiting on external dependency","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#using-ctx-journal-enrich","level":3,"title":"Using <code>/ctx-journal-enrich</code>","text":"<p>The <code>/ctx-journal-enrich</code> skill automates enrichment by analyzing conversation content and proposing metadata.</p> <p>Invoke by session identifier:</p> <pre><code>/ctx-journal-enrich twinkly-stirring-kettle\n/ctx-journal-enrich twinkly\n/ctx-journal-enrich 2026-01-24\n/ctx-journal-enrich 76fe2ab9\n</code></pre> <p>The skill will:</p> <ol> <li>Find the matching journal file;</li> <li>Read and analyze the conversation;</li> <li>Propose frontmatter (type, topics, outcome, technologies);</li> <li>Generate a 2-3 sentence summary;</li> <li>Extract decisions, learnings, and tasks mentioned;</li> <li>Show a diff and ask for confirmation before writing.</li> </ol>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#before-and-after","level":3,"title":"Before and After","text":"<p>Before enrichment:</p> <pre><code># twinkly-stirring-kettle\n\n**ID**: abc123-def456\n**Date**: 2026-01-24\n**Time**: 14:30:00\n...\n\n## Summary\n\n[Add your summary of this session]\n\n## Conversation\n...\n</code></pre> <p>After enrichment:</p> <pre><code>---\ntitle: \"Add Redis caching to API endpoints\"\ndate: 2026-01-24\ntype: feature\noutcome: completed\ntopics:\n  - caching\n  - api-performance\ntechnologies:\n  - go\n  - redis\nkey_files:\n  - internal/api/middleware/cache.go\n  - internal/cache/redis.go\n---\n\n# twinkly-stirring-kettle\n\n**ID**: abc123-def456\n**Date**: 2026-01-24\n**Time**: 14:30:00\n...\n\n## Summary\n\nImplemented Redis-based caching middleware for frequently accessed API endpoints.\nAdded cache invalidation on writes and configurable TTL per route. Reduced\n the average response time from 200ms to 15ms for cached routes.\n\n## Decisions\n\n* Used Redis over in-memory cache for horizontal scaling\n* Chose per-route TTL configuration over global setting\n\n## Learnings\n\n* Redis WATCH command prevents race conditions during cache invalidation\n\n## Conversation\n...\n</code></pre>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#enrichment-and-site-generation","level":3,"title":"Enrichment and Site Generation","text":"<p>The journal site generator uses enriched metadata for better organization:</p> <ul> <li>Titles appear in navigation instead of slugs</li> <li>Summaries provide context in the index</li> <li>Topics enable filtering (when using search)</li> <li>Types allow grouping by work category</li> </ul> <p>Future improvements will add topic-based navigation and outcome filtering to the generated site.</p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#batch-enrichment","level":3,"title":"Batch Enrichment","text":"<p>To enrich multiple sessions, process them one at a time:</p> <pre><code># List unenriched sessions (those without frontmatter)\ngrep -L \"^---$\" .context/journal/*.md | head -10\n</code></pre> <p>Then run <code>/ctx-journal-enrich</code> on each. Enrichment is intentionally interactive to ensure accuracy.</p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#obsidian-vault-export","level":2,"title":"Obsidian Vault Export","text":"<p>If you use Obsidian for knowledge management, you can export your journal as an Obsidian vault instead of (or alongside) the static site:</p> <pre><code>ctx journal obsidian\n</code></pre> <p>This generates a vault in <code>.context/journal-obsidian/</code> with:</p> <ul> <li>Wikilinks (<code>[[target|display]]</code>) instead of Markdown links</li> <li>MOC pages (Map of Content) for topics, key files, and session types</li> <li>Related sessions footer per entry — links to entries sharing the same topics</li> <li>Transformed frontmatter — <code>topics</code> renamed to <code>tags</code> (Obsidian-recognized),   <code>aliases</code> added from title for search</li> <li>Graph-optimized structure — MOC hubs + cross-linked entries create dense   graph connectivity</li> </ul> <p>To use: open the output directory in Obsidian (\"Open folder as vault\").</p> <pre><code># Custom output directory\nctx journal obsidian --output ~/vaults/ctx-journal\n</code></pre> <p>Static site vs Obsidian Vault</p> <p>Use <code>ctx journal site</code> when you want a web-browsable archive with search and dark mode. Use <code>ctx journal obsidian</code> when you want graph view, backlinks, and tag-based navigation inside Obsidian. Both use the same enriched source entries: you can generate both.</p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#full-pipeline","level":2,"title":"Full Pipeline","text":"<p>The complete journal workflow has four stages. Each is idempotent — safe to re-run, and stages skip already-processed entries.</p> <pre><code>export → enrich → rebuild\n</code></pre> Stage Command / Skill What it does Skips if Export <code>ctx recall export --all</code> Converts session JSONL to Markdown File already exists (safe default) Enrich <code>/ctx-journal-enrich</code> Adds frontmatter, summaries, topics Frontmatter already present Rebuild <code>ctx journal site --build</code> Generates static HTML site — Obsidian <code>ctx journal obsidian</code> Generates Obsidian vault with wikilinks —","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#using-make-journal","level":3,"title":"Using <code>make journal</code>","text":"<p>If your project includes <code>Makefile.ctx</code> (deployed by <code>ctx init</code>), the first and last stages are combined:</p> <pre><code>make journal           # export + rebuild\n</code></pre> <p>After it runs, it reminds you to enrich in Claude Code:</p> <pre><code>Next steps (in Claude Code):\n  /ctx-journal-enrich-all  — add metadata per entry (skips if frontmatter exists)\n\nThen re-run: make journal\n</code></pre> <p>Rendering Issues?</p> <p>If individual entries have rendering problems (broken fences, malformed lists), use <code>/ctx-journal-normalize</code> on the affected file. This is rarely needed as programmatic normalization during export handles most cases.</p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#tips","level":2,"title":"Tips","text":"<p>Daily workflow: <pre><code># Export, browse, then enrich in Claude Code\nmake journal &amp;&amp; make journal-serve\n# Then in Claude Code: /ctx-journal-enrich &lt;session&gt;\n</code></pre></p> <p>After a productive session: <pre><code># Export just that session and add notes\nctx recall export &lt;session-id&gt;\n# Edit .context/journal/&lt;session&gt;.md\n# Regenerate: ctx journal site\n</code></pre></p> <p>Searching across all sessions: <pre><code># Use grep on the journal directory\ngrep -r \"authentication\" .context/journal/\n</code></pre></p>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#requirements","level":2,"title":"Requirements","text":"Use <code>pipx</code> for <code>zensical</code> <p><code>pip install zensical</code> may install a non-functional stub on system Python. Using <code>venv</code> has other issues too.</p> <p>These issues especially happen on Mac OSX.</p> <p>Use <code>pipx install zensical</code>, which creates an isolated environment and handles Python version management automatically.</p> <p>The journal site uses zensical for static site generation:</p> <pre><code>pipx install zensical\n</code></pre>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/session-journal/#see-also","level":2,"title":"See Also","text":"<ul> <li><code>ctx recall</code>: Session discovery and listing</li> <li><code>ctx journal site</code>: Static site generation</li> <li><code>ctx journal obsidian</code>: Obsidian vault export</li> <li>Context Files: The <code>.context/</code> directory structure</li> </ul>","path":["Reference","Session Journal"],"tags":[]},{"location":"reference/skills/","level":1,"title":"Skills","text":"","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#skills","level":2,"title":"Skills","text":"<p>Skills are slash commands that run inside your AI assistant (e.g., <code>/ctx-next</code>), as opposed to CLI commands that run in your terminal (e.g., <code>ctx status</code>). </p> <p>Skills give your agent structured workflows: It knows what to read, what to  run, and when to ask. Most wrap one or more <code>ctx</code> CLI commands with  opinionated behavior on top. </p> <p>Skills Are Best Used Conversationally</p> <p>The beauty of <code>ctx</code> is that it's designed to be intuitive and  conversational, allowing you to interact with your AI assistant  naturally. That's why you don't have to memorize many of these skills.</p> <p>See the Prompting Guide for natural-language  triggers that invoke these skills conversationally.</p> <p>However, when you need a more precise control, you have the option to invoke the relevant skills directly.</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#all-skills","level":2,"title":"All Skills","text":"Skill Description Type <code>/ctx-remember</code> Recall project context and present structured readback user-invocable <code>/ctx-wrap-up</code> End-of-session context persistence ceremony user-invocable <code>/ctx-status</code> Show context summary with interpretation user-invocable <code>/ctx-agent</code> Load full context packet for AI consumption user-invocable <code>/ctx-next</code> Suggest 1-3 concrete next actions with rationale user-invocable <code>/ctx-commit</code> Commit with integrated context persistence user-invocable <code>/ctx-reflect</code> Pause and reflect on session progress user-invocable <code>/ctx-add-task</code> Add actionable task to TASKS.md user-invocable <code>/ctx-add-decision</code> Record architectural decision with rationale user-invocable <code>/ctx-add-learning</code> Record gotchas and lessons learned user-invocable <code>/ctx-add-convention</code> Record coding convention for consistency user-invocable <code>/ctx-archive</code> Archive completed tasks from TASKS.md user-invocable <code>/ctx-pad</code> Manage encrypted scratchpad entries user-invocable <code>/ctx-recall</code> Browse and export AI session history user-invocable <code>/ctx-journal-enrich</code> Enrich single journal entry with metadata user-invocable <code>/ctx-journal-enrich-all</code> Batch-enrich all unenriched journal entries user-invocable <code>/ctx-journal-normalize</code> Normalize journal markdown for clean rendering user-invocable <code>/ctx-blog</code> Generate blog post draft from project activity user-invocable <code>/ctx-blog-changelog</code> Generate themed blog post from a commit range user-invocable <code>/ctx-consolidate</code> Consolidate redundant learnings or decisions user-invocable <code>/ctx-drift</code> Detect and fix context drift user-invocable <code>/ctx-alignment-audit</code> Audit docs claims against agent instructions user-invocable <code>/ctx-prompt-audit</code> Analyze prompting patterns for improvement user-invocable <code>/check-links</code> Audit docs for dead internal and external links user-invocable <code>/ctx-context-monitor</code> Respond to context checkpoint signals automatic <code>/ctx-implement</code> Execute a plan step-by-step with verification user-invocable <code>/ctx-loop</code> Generate autonomous loop script user-invocable <code>/ctx-worktree</code> Manage git worktrees for parallel agents user-invocable <code>/ctx-map</code> Build and maintain architecture maps user-invocable <code>/ctx-remind</code> Manage session-scoped reminders user-invocable","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#session-lifecycle","level":2,"title":"Session Lifecycle","text":"<p>Skills for starting, running, and ending a productive session.</p> <p>Session Ceremonies</p> <p>Two skills in this group are ceremony skills: <code>/ctx-remember</code> (session start) and <code>/ctx-wrap-up</code> (session end). Unlike other skills that work conversationally, these should be invoked as explicit slash commands for completeness. See Session Ceremonies.</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-remember","level":3,"title":"<code>/ctx-remember</code>","text":"<p>Recall project context and present a structured readback. Ceremony skill — invoke explicitly at session start.</p> <p>Wraps: <code>ctx agent --budget 4000</code>, <code>ctx recall list --limit 3</code>, reads TASKS.md, DECISIONS.md, LEARNINGS.md</p> <p>See also: Session Ceremonies, The Complete Session</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-status","level":3,"title":"<code>/ctx-status</code>","text":"<p>Show context summary — files, token budget, tasks, recent activity — with interpreted suggestions.</p> <p>Wraps: <code>ctx status [--verbose] [--json]</code></p> <p>See also: The Complete Session, <code>ctx status</code> CLI</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-agent","level":3,"title":"<code>/ctx-agent</code>","text":"<p>Load the full context packet optimized for AI consumption. Also runs automatically via the PreToolUse hook with cooldown.</p> <p>Wraps: <code>ctx agent [--budget] [--format] [--cooldown] [--session]</code></p> <p>See also: The Complete Session, <code>ctx agent</code> CLI</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-next","level":3,"title":"<code>/ctx-next</code>","text":"<p>Suggest 1-3 concrete next actions ranked by priority, momentum, and unblocked status.</p> <p>Wraps: reads TASKS.md, <code>ctx recall list --limit 3</code></p> <p>See also: The Complete Session, Tracking Work Across Sessions</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-commit","level":3,"title":"<code>/ctx-commit</code>","text":"<p>Commit code with integrated context persistence — pre-commit checks, staged files, Co-Authored-By trailer, and a post-commit prompt to capture decisions and learnings.</p> <p>Wraps: <code>git add</code>, <code>git commit</code>, optionally chains to <code>/ctx-add-decision</code> and <code>/ctx-add-learning</code></p> <p>See also: The Complete Session</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-reflect","level":3,"title":"<code>/ctx-reflect</code>","text":"<p>Pause and reflect on session progress. Walks through a checklist of learnings, decisions, task completions, and session notes to persist.</p> <p>Wraps: chains to <code>ctx add learning</code>, <code>ctx add decision</code>, manual TASKS.md updates</p> <p>See also: The Complete Session, Persisting Decisions, Learnings, and Conventions</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-wrap-up","level":3,"title":"<code>/ctx-wrap-up</code>","text":"<p>End-of-session context persistence ceremony. Gathers signal from git diff, recent commits, and conversation themes. Proposes candidates (learnings, decisions, conventions, tasks) with complete structured fields for user approval, then persists via <code>ctx add</code>. Offers <code>/ctx-commit</code> if uncommitted changes remain. Ceremony skill — invoke explicitly at session end.</p> <p>Wraps: <code>git diff --stat</code>, <code>git log</code>, <code>ctx add learning</code>, <code>ctx add decision</code>, <code>ctx add convention</code>, <code>ctx add task</code>, chains to <code>/ctx-commit</code></p> <p>See also: Session Ceremonies, The Complete Session</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#context-persistence","level":2,"title":"Context Persistence","text":"<p>Skills for recording work artifacts — tasks, decisions, learnings, conventions — into <code>.context/</code> files.</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-add-task","level":3,"title":"<code>/ctx-add-task</code>","text":"<p>Add an actionable task with optional priority and phase section.</p> <p>Wraps: <code>ctx add task \"description\" [--priority high|medium|low]</code></p> <p>See also: Tracking Work Across Sessions</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-add-decision","level":3,"title":"<code>/ctx-add-decision</code>","text":"<p>Record an architectural decision with context, rationale, and consequences. Supports Y-statement (lightweight) and full ADR formats.</p> <p>Wraps: <code>ctx add decision \"title\" --context \"...\" --rationale \"...\" --consequences \"...\"</code></p> <p>See also: Persisting Decisions, Learnings, and Conventions</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-add-learning","level":3,"title":"<code>/ctx-add-learning</code>","text":"<p>Record a project-specific gotcha, bug, or unexpected behavior. Filters for insights that are searchable, project-specific, and required real effort to discover.</p> <p>Wraps: <code>ctx add learning \"title\" --context \"...\" --lesson \"...\" --application \"...\"</code></p> <p>See also: Persisting Decisions, Learnings, and Conventions</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-add-convention","level":3,"title":"<code>/ctx-add-convention</code>","text":"<p>Record a coding convention that should be standardized across sessions. Targets patterns seen 2-3+ times.</p> <p>Wraps: <code>ctx add convention \"rule\" --section \"Name\"</code></p> <p>See also: Persisting Decisions, Learnings, and Conventions</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-archive","level":3,"title":"<code>/ctx-archive</code>","text":"<p>Archive completed tasks from TASKS.md to a timestamped file in <code>.context/archive/</code>. Preserves phase headers for traceability.</p> <p>Wraps: <code>ctx tasks archive [--dry-run]</code></p> <p>See also: Tracking Work Across Sessions</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#scratchpad","level":2,"title":"Scratchpad","text":"","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-pad","level":3,"title":"<code>/ctx-pad</code>","text":"<p>Manage the encrypted scratchpad — add, remove, edit, and reorder one-liner notes. Encrypted at rest with AES-256-GCM.</p> <p>Wraps: <code>ctx pad</code>, <code>ctx pad add</code>, <code>ctx pad rm</code>, <code>ctx pad edit</code>, <code>ctx pad mv</code>, <code>ctx pad import</code>, <code>ctx pad export</code></p> <p>See also: Scratchpad, Using the Scratchpad</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#journal-history","level":2,"title":"Journal &amp; History","text":"<p>Skills for browsing, exporting, and enriching your AI session history into a structured journal.</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-recall","level":3,"title":"<code>/ctx-recall</code>","text":"<p>Browse, inspect, and export AI session history. List recent sessions, show details by slug or ID, and export to <code>.context/journal/</code>.</p> <p>Wraps: <code>ctx recall list</code>, <code>ctx recall show</code>, <code>ctx recall export</code></p> <p>See also: Browsing and Enriching Past Sessions</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-journal-enrich","level":3,"title":"<code>/ctx-journal-enrich</code>","text":"<p>Enrich a single journal entry with YAML frontmatter — title, type, outcome, topics, technologies, and summary. Shows diff before writing.</p> <p>Wraps: reads and edits <code>.context/journal/*.md</code> files</p> <p>See also: Browsing and Enriching Past Sessions, Turning Activity into Content</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-journal-enrich-all","level":3,"title":"<code>/ctx-journal-enrich-all</code>","text":"<p>Batch-enrich all unenriched journal entries. Filters out short sessions and continuations. Can spawn subagents for large backlogs.</p> <p>Wraps: iterates <code>/ctx-journal-enrich</code> across all entries</p> <p>See also: Browsing and Enriching Past Sessions</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-journal-normalize","level":3,"title":"<code>/ctx-journal-normalize</code>","text":"<p>Normalize journal markdown for clean rendering — fix fence nesting, metadata formatting, list indentation, and collapse large tool outputs.</p> <p>Wraps: reads and edits <code>.context/journal/*.md</code> files</p> <p>See also: Browsing and Enriching Past Sessions, Turning Activity into Content</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#content-creation","level":2,"title":"Content Creation","text":"<p>Skills for turning project activity into publishable content.</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-blog","level":3,"title":"<code>/ctx-blog</code>","text":"<p>Generate a blog post draft from recent project activity — git history, decisions, learnings, tasks, and journal entries. Requires a narrative arc (problem, approach, outcome).</p> <p>Wraps: reads <code>git log</code>, DECISIONS.md, LEARNINGS.md, TASKS.md, journal entries; writes to <code>docs/blog/</code></p> <p>See also: Turning Activity into Content</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-blog-changelog","level":3,"title":"<code>/ctx-blog-changelog</code>","text":"<p>Generate a themed blog post from a commit range. Takes a starting commit and unifying theme, analyzes diffs and journal entries from that period.</p> <p>Wraps: <code>git log</code>, <code>git diff --stat</code>; writes to <code>docs/blog/</code></p> <p>See also: Turning Activity into Content</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#auditing-health","level":2,"title":"Auditing &amp; Health","text":"<p>Skills for detecting drift, auditing alignment, and improving prompt quality.</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-consolidate","level":3,"title":"<code>/ctx-consolidate</code>","text":"<p>Consolidate redundant entries in LEARNINGS.md or DECISIONS.md. Groups overlapping entries by keyword similarity, presents candidates, and — with user approval — merges groups into denser combined entries. Originals are archived, not deleted.</p> <p>Wraps: reads LEARNINGS.md and DECISIONS.md, writes consolidated entries, archives originals, runs <code>ctx reindex</code></p> <p>See also: Detecting and Fixing Drift</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-drift","level":3,"title":"<code>/ctx-drift</code>","text":"<p>Detect and fix context drift: stale paths, missing files, file age staleness, task accumulation, entry count warnings, and constitution violations via <code>ctx drift</code>. Also detects skill drift against canonical templates.</p> <p>Wraps: <code>ctx drift [--fix]</code></p> <p>See also: Detecting and Fixing Drift</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-alignment-audit","level":3,"title":"<code>/ctx-alignment-audit</code>","text":"<p>Audit behavioral claims in docs and recipes against actual agent instructions. Traces each claim to its backing instruction and reports coverage as Covered, Partial, or Gap.</p> <p>Wraps: reads AGENT_PLAYBOOK.md, plugin skill definitions, CLAUDE.md, and docs/recipes</p> <p>See also: Detecting and Fixing Drift</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-prompt-audit","level":3,"title":"<code>/ctx-prompt-audit</code>","text":"<p>Analyze recent prompting patterns to identify vague or ineffective prompts. Reviews 3-5 journal entries and suggests rewrites with positive observations.</p> <p>Wraps: reads <code>.context/journal/</code> entries</p> <p>See also: Detecting and Fixing Drift</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#check-links","level":3,"title":"<code>/check-links</code>","text":"<p>Scan all markdown files under <code>docs/</code> for broken links. Two passes: internal links (verify file targets exist on disk) and external links (HTTP HEAD with timeout, report failures as warnings). Also checks image references.</p> <p>Invoked automatically as check #12 during <code>/audit</code>.</p> <p>Wraps: Glob + Grep to scan, <code>curl</code> for external checks</p> <p>See also: <code>/audit</code></p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-context-monitor","level":3,"title":"<code>/ctx-context-monitor</code>","text":"<p>Respond to context checkpoint signals when usage hits high thresholds. Fires at adaptive intervals and offers context persistence before the session ends.</p> <p>Type: Automatic: Triggered by the <code>check-context-size</code> hook, not user-invocable</p> <p>Wraps: hook-driven; suggests <code>/ctx-reflect</code></p> <p>See also: Running an Unattended AI Agent</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#planning-execution","level":2,"title":"Planning &amp; Execution","text":"<p>Skills for structured implementation and parallel agent workflows.</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-implement","level":3,"title":"<code>/ctx-implement</code>","text":"<p>Execute a multi-step plan with build and test verification at each step. Loads a plan from a file or conversation context, breaks it into atomic steps, and checkpoints after every 3-5 steps.</p> <p>Wraps: reads plan file, runs verification commands (<code>go build</code>, <code>go test</code>, etc.)</p> <p>See also: Running an Unattended AI Agent</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-loop","level":3,"title":"<code>/ctx-loop</code>","text":"<p>Generate a ready-to-run shell script for autonomous AI iteration. Supports Claude Code, Aider, and generic tool templates with configurable completion signals.</p> <p>Wraps: <code>ctx loop [--tool] [--prompt] [--max-iterations] [--completion] [--output]</code></p> <p>See also: Autonomous Loops, Running an Unattended AI Agent</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-worktree","level":3,"title":"<code>/ctx-worktree</code>","text":"<p>Manage git worktrees for parallel agent development. Create sibling worktrees on dedicated branches, analyze task blast radius for grouping, and tear down with merge.</p> <p>Wraps: <code>git worktree add</code>, <code>git worktree list</code>, <code>git worktree remove</code>, <code>git merge</code></p> <p>See also: Parallel Agent Development with Git Worktrees</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-map","level":3,"title":"<code>/ctx-map</code>","text":"<p>Build and maintain architecture maps incrementally. Creates or refreshes <code>ARCHITECTURE.md</code> (succinct project map, loaded at session start) and <code>DETAILED_DESIGN.md</code> (deep per-module reference, consulted on-demand). Coverage is tracked in <code>map-tracking.json</code> so each run extends the map rather than re-analyzing everything.</p> <p>Wraps: <code>ctx status</code>, <code>git log</code>, reads source files; writes <code>ARCHITECTURE.md</code>, <code>DETAILED_DESIGN.md</code>, <code>map-tracking.json</code></p> <p>See also: Detecting and Fixing Drift</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#ctx-remind","level":3,"title":"<code>/ctx-remind</code>","text":"<p>Manage session-scoped reminders via natural language. Translates user intent (\"remind me to refactor swagger\") into the corresponding <code>ctx remind</code> command. Handles date conversion for <code>--after</code> flags.</p> <p>Wraps: <code>ctx remind</code>, <code>ctx remind list</code>, <code>ctx remind dismiss</code></p> <p>See also: Session Reminders</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/skills/#project-specific-skills","level":2,"title":"Project-Specific Skills","text":"<p>The ctx plugin ships the skills listed above. Teams can add their own project-specific skills to <code>.claude/skills/</code> in the project root — these are separate from plugin-shipped skills and are scoped to the project.</p> <p>Project-specific skills follow the same format and are invoked the same way.</p> <p>Custom skills are not covered in this reference.</p>","path":["Reference","Skills"],"tags":[]},{"location":"reference/versions/","level":1,"title":"Version History","text":"","path":["Reference","Version History"],"tags":[]},{"location":"reference/versions/#version-history","level":2,"title":"Version History","text":"<p>Documentation snapshots for each release. </p> <p>Tap the corresponding view docs to view the docs as they were at that release.</p>","path":["Reference","Version History"],"tags":[]},{"location":"reference/versions/#releases","level":2,"title":"Releases","text":"Version Release Date Documentation Notes v0.6.0 2026-02-16 view docs Plugin conversion: hooks are Go subcommands, skills ship as plugin v0.3.0 2026-02-07 view docs Journal site, skill sweep, consolidation pass, golangci-lint v2 v0.2.0 2026-02-01 view docs Journal system, recall export, constants refactor, CRLF handling v0.1.2 2026-01-27 view docs Default permissions in <code>ctx init</code>, prompting guide v0.1.1 2026-01-26 view docs Fix hook schema keys, fix JSON unicode escaping v0.1.0 2026-01-25 view docs Initial release: CLI, context files, build system","path":["Reference","Version History"],"tags":[]},{"location":"reference/versions/#latest","level":2,"title":"Latest","text":"<p>The main documentation always reflects the latest development version.</p> <p>For the most recent stable release, see v0.6.0.</p>","path":["Reference","Version History"],"tags":[]},{"location":"reference/versions/#changelog","level":2,"title":"Changelog","text":"<p>For detailed changes between versions, see the  GitHub Releases page.</p>","path":["Reference","Version History"],"tags":[]},{"location":"security/","level":1,"title":"Security","text":"<p>Security model, agent hardening, and vulnerability reporting.</p>","path":["Security"],"tags":[]},{"location":"security/#securing-ai-agents","level":3,"title":"Securing AI Agents","text":"<p>Defense in depth for unattended AI agents: five layers of protection, each with a known bypass, strength in combination.</p>","path":["Security"],"tags":[]},{"location":"security/#security-policy","level":3,"title":"Security Policy","text":"<p>Trust model, vulnerability reporting, permission hygiene, and security design principles.</p>","path":["Security"],"tags":[]},{"location":"security/agent-security/","level":1,"title":"Securing AI Agents","text":"","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#defense-in-depth-securing-ai-agents","level":1,"title":"Defense in Depth: Securing AI Agents","text":"","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#the-problem","level":2,"title":"The Problem","text":"<p>An unattended AI agent with unrestricted access to your machine is an unattended shell with unrestricted access to your machine.</p> <p>This is not a theoretical concern. AI coding agents execute shell commands, write files, make network requests, and modify project configuration. When running autonomously (overnight, in a loop, without a human watching) the attack surface is the full capability set of the operating system user account.</p> <p>The risk is not that the AI is malicious. The risk is that the AI is controllable: it follows instructions from context, and context can be poisoned.</p>","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#threat-model","level":2,"title":"Threat Model","text":"","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#how-agents-get-compromised","level":3,"title":"How Agents Get Compromised","text":"<p>AI agents follow instructions from multiple sources: system prompts, project files, conversation history, and tool outputs. An attacker who can inject content into any of these sources can redirect the agent's behavior.</p> Vector How it works Prompt injection via dependencies A malicious package includes instructions in its README, changelog, or error output. The agent reads these during installation or debugging and follows them. Prompt injection via fetched content The agent fetches a URL (documentation, API response, Stack Overflow answer) containing embedded instructions. Poisoned project files A contributor adds adversarial instructions to <code>CLAUDE.md</code>, <code>.cursorrules</code>, or <code>.context/</code> files. The agent loads these at session start. Self-modification between iterations In an autonomous loop, the agent modifies its own configuration files. The next iteration loads the modified config with no human review. Tool output injection A command's output (error messages, log lines, file contents) contains instructions the agent interprets and follows.","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#what-a-compromised-agent-can-do","level":3,"title":"What a Compromised Agent Can Do","text":"<p>Depends entirely on what permissions and access the agent has:</p> Access level Potential impact Unrestricted shell Execute any command, install software, modify system files Network access Exfiltrate source code, credentials, or context files to external servers Docker socket Escape container isolation by spawning privileged sibling containers SSH keys Pivot to other machines, push to remote repositories, access production systems Write access to own config Disable its own guardrails for the next iteration","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#the-defense-layers","level":2,"title":"The Defense Layers","text":"<p>No single layer is sufficient. Each layer catches what the others miss.</p> <pre><code>Layer 1: Soft instructions     (CONSTITUTION.md, playbook)\nLayer 2: Application controls  (permission allowlist, tool restrictions)\nLayer 3: OS-level isolation    (user accounts, filesystem, containers)\nLayer 4: Network controls      (firewall rules, airgap)\nLayer 5: Infrastructure        (VM isolation, resource limits)\n</code></pre>","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#layer-1-soft-instructions-probabilistic","level":3,"title":"Layer 1: Soft Instructions (Probabilistic)","text":"<p>Markdown files like <code>CONSTITUTION.md</code> and the Agent Playbook tell the agent what to do and what not to do. These are probabilistic: the agent usually follows them, but there is no enforcement mechanism.</p> <p>What it catches: Most common mistakes. An agent that has been told \"never delete production data\" will usually not delete production data.</p> <p>What it misses: Prompt injection. A sufficiently crafted injection can override soft instructions. Long context windows dilute attention on rules stated early. Edge cases where instructions are ambiguous.</p> <p>Verdict: Necessary but not sufficient. Good for the common case. Do not rely on it for security boundaries.</p>","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#layer-2-application-controls-deterministic-at-runtime-mutable-across-iterations","level":3,"title":"Layer 2: Application Controls (Deterministic at Runtime, Mutable Across Iterations)","text":"<p>AI tool runtimes (Claude Code, Cursor, etc.) provide permission systems: tool allowlists, command restrictions, confirmation prompts.</p> <p>For Claude Code, an explicit allowlist in <code>.claude/settings.local.json</code>:</p> <pre><code>{\n  \"permissions\": {\n    \"allow\": [\n      \"Bash(make:*)\",\n      \"Bash(go:*)\",\n      \"Bash(git:*)\",\n      \"Bash(ctx:*)\",\n      \"Read\",\n      \"Write\",\n      \"Edit\"\n    ]\n  }\n}\n</code></pre> <p>What it catches: The agent cannot run commands outside the allowlist. If <code>rm</code>, <code>curl</code>, <code>sudo</code>, or <code>docker</code> are not listed, the agent cannot invoke them regardless of what any prompt says.</p> <p>What it misses: The agent can modify the allowlist itself. In an autonomous loop, the agent writes to <code>.claude/settings.local.json</code>, and the next iteration loads the modified config. The application enforces the rules, but the application reads the rules from files the agent can write.</p> <p>Verdict: Strong first layer. Must be combined with self-modification prevention (Layer 3).</p>","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#layer-3-os-level-isolation-deterministic-and-unbypassable","level":3,"title":"Layer 3: OS-Level Isolation (Deterministic and Unbypassable)","text":"<p>The operating system enforces access controls that no application-level trick can override. An unprivileged user cannot read files owned by root. A process without <code>CAP_NET_RAW</code> cannot open raw sockets. These are kernel boundaries.</p> Control Purpose Dedicated user account No <code>sudo</code>, no privileged group membership (<code>docker</code>, <code>wheel</code>, <code>adm</code>). The agent cannot escalate privileges. Filesystem permissions Project directory writable; everything else read-only or inaccessible. Agent cannot reach other projects, home directories, or system config. Immutable config files <code>CLAUDE.md</code>, <code>.claude/settings.local.json</code>, and <code>.context/CONSTITUTION.md</code> owned by a different user or marked immutable (<code>chattr +i</code> on Linux). The agent cannot modify its own guardrails. <p>What it catches: Privilege escalation, self-modification, lateral movement to other projects or users.</p> <p>What it misses: Actions within the agent's legitimate scope. If the agent has write access to source code (which it needs to do its job), it can introduce vulnerabilities in the code itself.</p> <p>Verdict: Essential. This is the layer that makes the other layers trustworthy.</p> <p>OS-level isolation does not make the agent safe; it makes the other layers meaningful.</p>","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#layer-4-network-controls","level":3,"title":"Layer 4: Network Controls","text":"<p>An agent that cannot reach the internet cannot exfiltrate data. It also cannot ingest new instructions mid-loop from external documents, API responses, or hostile content.</p> Scenario Recommended control Agent does not need the internet <code>--network=none</code> (container) or outbound firewall drop-all Agent needs to fetch dependencies Allow specific registries (npmjs.com, proxy.golang.org, pypi.org) via firewall rules. Block everything else. Agent needs API access Allow specific API endpoints only. Use an HTTP proxy with allowlisting. <p>What it catches: Data exfiltration, phone-home payloads, downloading additional tools, and instruction injection via fetched content.</p> <p>What it misses: Nothing, if the agent genuinely does not need the network. The tradeoff is that many real workloads need dependency resolution, so a full airgap requires pre-populated caches.</p>","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#layer-5-infrastructure-isolation","level":3,"title":"Layer 5: Infrastructure Isolation","text":"<p>The strongest boundary is a separate machine — or something that behaves like one.</p> <p>The moment you stop arguing about prompts and start arguing about kernels, you are finally doing security.</p> <p>Containers (Docker, Podman):</p> <pre><code>docker run --rm \\\n  --network=none \\\n  --cap-drop=ALL \\\n  --memory=4g \\\n  --cpus=2 \\\n  -v /path/to/project:/workspace \\\n  -w /workspace \\\n  your-dev-image \\\n  ./loop.sh\n</code></pre> <p>Docker Socket is sudo Access</p> <p>Critical: never mount the Docker socket (<code>/var/run/docker.sock</code>).</p> <p>An agent with socket access can spawn sibling containers with full host access, effectively escaping the sandbox. </p> <p>Use rootless Docker or Podman to eliminate this escalation path.</p> <p>Virtual machines: The strongest isolation. The guest kernel has no visibility into the host OS. No shared folders, no filesystem passthrough, no SSH keys to other machines.</p> <p>Resource limits: CPU, memory, and disk quotas prevent a runaway agent from consuming all resources. Use <code>ulimit</code>, cgroup limits, or container resource constraints.</p>","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"<p>A defense-in-depth setup for overnight autonomous runs:</p> Layer Implementation Stops Soft instructions <code>CONSTITUTION.md</code> with \"never delete tests\", \"always run tests before committing\" Common mistakes (probabilistic) Application allowlist <code>.claude/settings.local.json</code> with explicit tool permissions Unauthorized commands (deterministic within runtime) Immutable config <code>chattr +i</code> on <code>CLAUDE.md</code>, <code>.claude/</code>, <code>CONSTITUTION.md</code> Self-modification between iterations Unprivileged user Dedicated user, no sudo, no docker group Privilege escalation Container <code>--cap-drop=ALL --network=none</code>, rootless, no socket mount Host escape, network exfiltration Resource limits <code>--memory=4g --cpus=2</code>, disk quotas Resource exhaustion <p>Each layer is simple. The strength is in the combination.</p>","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#common-mistakes","level":2,"title":"Common Mistakes","text":"<p>\"I'll just use <code>--dangerously-skip-permissions</code>\": This disables Layer 2 entirely. Without Layers 3-5, you have no protection at all. Only use this flag inside a properly isolated container or VM.</p> <p>\"The agent is sandboxed in Docker\": A Docker container with the Docker socket mounted, running as root, with <code>--privileged</code>, and full network access is not sandboxed. It is a root shell with extra steps.</p> <p>\"<code>CONSTITUTION.md</code> says not to do that\": Markdown is a suggestion. It works most of the time. It is not a security boundary. Do not use it as one.</p> <p>\"I reviewed the <code>CLAUDE.md</code>, it's fine\": The agent can modify <code>CLAUDE.md</code> during iteration N. Iteration N+1 loads the modified version. Unless the file is immutable, your review is stale.</p> <p>\"The agent only has access to this one project\": Does the project directory contain <code>.env</code> files, SSH keys, API tokens, or credentials? Does it have a <code>.git/config</code> with push access to a remote? Filesystem isolation means isolating what is in the directory too.</p>","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#checklist","level":2,"title":"Checklist","text":"<p>Before running an unattended AI agent:</p> <ul> <li> Agent runs as a dedicated unprivileged user (no sudo, no docker group)</li> <li> Agent's config files are immutable or owned by a different user</li> <li> Permission allowlist restricts tools to the project's toolchain</li> <li> Container drops all capabilities (<code>--cap-drop=ALL</code>)</li> <li> Docker socket is NOT mounted</li> <li> Network is disabled or restricted to specific domains</li> <li> Resource limits are set (memory, CPU, disk)</li> <li> No SSH keys, API tokens, or credentials are accessible to the agent</li> <li> Project directory does not contain <code>.env</code> or secrets files</li> <li> Iteration cap is set (<code>--max-iterations</code>)</li> </ul>","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/agent-security/#further-reading","level":2,"title":"Further Reading","text":"<ul> <li>Running an Unattended AI Agent: the   ctx recipe for autonomous loops, including step-by-step permissions   and isolation setup</li> <li>Security: <code>ctx</code>'s own trust model and vulnerability   reporting</li> <li>Autonomous Loops: full documentation of the   loop pattern, <code>PROMPT.md</code> templates, and troubleshooting</li> </ul>","path":["Security","Securing AI Agents"],"tags":[]},{"location":"security/reporting/","level":1,"title":"Security Policy","text":"","path":["Security","Security Policy"],"tags":[]},{"location":"security/reporting/#reporting-vulnerabilities","level":2,"title":"Reporting Vulnerabilities","text":"<p>At <code>ctx</code> we take security very seriously.</p> <p>If you discover a security vulnerability in <code>ctx</code>, please report it responsibly.</p> <p>Do NOT open a public issue for security vulnerabilities.</p>","path":["Security","Security Policy"],"tags":[]},{"location":"security/reporting/#email","level":3,"title":"Email","text":"<p>Send details to security@ctx.ist.</p>","path":["Security","Security Policy"],"tags":[]},{"location":"security/reporting/#github-private-reporting","level":3,"title":"GitHub Private Reporting","text":"<ol> <li>Go to the Security tab;</li> <li>Click \"Report a Vulnerability\";</li> <li>Provide a detailed description.</li> </ol>","path":["Security","Security Policy"],"tags":[]},{"location":"security/reporting/#what-to-include","level":3,"title":"What to Include","text":"<ul> <li>Description of the vulnerability,</li> <li>Steps to reproduce,</li> <li>Potential impact,</li> <li>Suggested fix (if any).</li> </ul>","path":["Security","Security Policy"],"tags":[]},{"location":"security/reporting/#attribution","level":2,"title":"Attribution","text":"<p>We appreciate responsible disclosure and will acknowledge security researchers who report valid vulnerabilities (unless they prefer to remain anonymous).</p>","path":["Security","Security Policy"],"tags":[]},{"location":"security/reporting/#response-timeline","level":3,"title":"Response Timeline","text":"<p>Open source, Best-Effort Timelines</p> <p><code>ctx</code> is a volunteer-maintained open source project. </p> <p>The timelines below are guidelines, not guarantees, and depend on  contributor availability.</p> <p>We will address security reports on a best-effort basis and prioritize them by severity.</p> Stage Timeframe Acknowledgment Within 48 hours Initial assessment Within 7 days Resolution target Within 30 days (depending on severity)","path":["Security","Security Policy"],"tags":[]},{"location":"security/reporting/#trust-model","level":2,"title":"Trust Model","text":"<p><code>ctx</code> operates within a single trust boundary: the local filesystem.</p> <p>The person who authors <code>.context/</code> files is the same person who runs the agent that reads them. There is no remote input, no shared state, and no server component.</p> <p>This means:</p> <ul> <li><code>ctx</code> does not sanitize context files for prompt injection. This is a   deliberate design choice, not an oversight. The files are authored by the   developer who owns the machine: Sanitizing their own instructions back   to them would be counterproductive.</li> <li>If you place adversarial instructions in your own <code>.context/</code> files,   your agent will follow them. This is expected behavior. You control the   context; the agent trusts it.</li> </ul> <p>Shared Repositories</p> <p>In shared repositories, <code>.context/</code> files should be reviewed in code review (the same way you would review CI/CD config or Makefiles). A malicious contributor could add harmful instructions to <code>CONSTITUTION.md</code> or <code>TASKS.md</code>.</p>","path":["Security","Security Policy"],"tags":[]},{"location":"security/reporting/#security-design","level":2,"title":"Security Design","text":"<p><code>ctx</code> is designed with security in mind:</p> <ul> <li>No secrets in context: The constitution explicitly forbids storing   secrets, tokens, API keys, or credentials in <code>.context/</code> files</li> <li>Local only: <code>ctx</code> runs entirely locally with no external network calls</li> <li>No code execution: ctx reads and writes Markdown files only; it does   not execute arbitrary code</li> <li>Git-tracked: Core context files are meant to be committed, so they should   never contain sensitive data. Exception: <code>sessions/</code> and <code>journal/</code> contain   raw conversation data and should be gitignored</li> </ul>","path":["Security","Security Policy"],"tags":[]},{"location":"security/reporting/#permission-hygiene","level":2,"title":"Permission Hygiene","text":"<p>Claude Code evaluates permissions in deny → ask → allow order. <code>ctx init</code> automatically populates <code>permissions.deny</code> with rules that block dangerous operations before the allow list is ever consulted.</p> <p>Default deny rules block:</p> <ul> <li><code>sudo</code>, <code>git push</code>, <code>rm -rf /</code>, <code>rm -rf ~</code>, <code>curl</code>, <code>wget</code>, <code>chmod 777</code></li> <li><code>Read</code>/<code>Edit</code> of <code>.env</code>, credentials, secrets, <code>.pem</code>, <code>.key</code> files</li> </ul> <p>Even with deny rules in place, the allow list accumulates one-off permissions over time. Periodically review for:</p> <ul> <li>Destructive commands: <code>git reset --hard</code>, <code>git clean -f</code>, etc.</li> <li>Config injection vectors: permissions that allow modifying files   controlling agent behavior (<code>CLAUDE.md</code>, <code>settings.local.json</code>)</li> <li>Broad wildcards: overly permissive patterns that pre-approve   more than intended</li> </ul>","path":["Security","Security Policy"],"tags":[]},{"location":"security/reporting/#temp-file-cleanup","level":2,"title":"Temp File Cleanup","text":"<p>Hook state files accumulate in the user-specific temp directory (<code>$XDG_RUNTIME_DIR/ctx-&lt;uid&gt;/</code> or <code>/tmp/ctx-&lt;uid&gt;/</code>). A <code>SessionEnd</code> hook automatically removes files older than 15 days. For manual cleanup or cron scheduling, use:</p> <pre><code>.context/tools/cleanup-ctx-tmp.sh        # default: 15-day threshold\n.context/tools/cleanup-ctx-tmp.sh 7      # custom: 7-day threshold\n</code></pre>","path":["Security","Security Policy"],"tags":[]},{"location":"security/reporting/#best-practices","level":2,"title":"Best Practices","text":"<ol> <li>Review before committing: Always review <code>.context/</code> files before committing</li> <li>Use <code>.gitignore</code>: If you must store sensitive notes locally,    add them to <code>.gitignore</code></li> <li>Drift detection: Run <code>ctx drift</code> to check for potential issues</li> <li>Permission audit: Review <code>.claude/settings.local.json</code> after busy sessions</li> </ol>","path":["Security","Security Policy"],"tags":[]}]}